{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd() \n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from model import *\n",
    "import torch\n",
    "from datasets import load_dataset,load_metric\n",
    "from transformers import  AutoTokenizer\n",
    "import torch_optimizer as optim\n",
    "from transformers.optimization import Adafactor, AdafactorSchedule\n",
    "from MT_hyperparams import seed_,max_length\n",
    "import torch.backends.cudnn as cudnn\n",
    "from utils import *\n",
    "from attention_params import *\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, SubsetRandomSampler\n",
    "from torch.autograd import Variable\n",
    "from losses import *\n",
    "from architect import *\n",
    "import logging\n",
    "import sys\n",
    "import transformers\n",
    "import time\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from os.path import exists\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from transformers import get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(\"main\")\n",
    "\n",
    "\n",
    "parser.add_argument('--valid_num_points', type=int,             default = -1, help='validation data number')\n",
    "parser.add_argument('--train_w_num_points', type=int,           default = 4000, help='train data number')#80*x\n",
    "parser.add_argument('--train_A_num_points', type=int,           default = 2000, help='train data number')\n",
    "parser.add_argument('--unlabel_num_points', type=int,           default = 4000, help='train data number')\n",
    "parser.add_argument('--test_num_points', type=int,              default = -1, help='train data number')\n",
    "\n",
    "parser.add_argument('--batch_size', type=int,                   default=32,     help='Batch size for test and validation')\n",
    "\n",
    "parser.add_argument('--w_bs', type=int,                         default=16,      help='train_w_num_points for each batch')\n",
    "parser.add_argument('--syn_bs', type=int,                       default=8,      help='train_v_synthetic_num_points for each batch')\n",
    "# parser.add_argument('--train_v_num_points', type=int,           default=0,      help='train_v_num_points for each batch')\n",
    "parser.add_argument('--A_bs', type=int,                         default=8,      help='train_A_num_points decay for each batch')\n",
    "\n",
    "parser.add_argument('--gpu', type=int,                          default=0,      help='gpu device id')\n",
    "parser.add_argument('--num_workers', type=int,                  default=0,      help='num_workers')\n",
    "parser.add_argument('--model_name_teacher', type=str,           default='roberta-base',      help='model_name')\n",
    "parser.add_argument('--model_name_student', type=str,           default='roberta-base',      help='model_name')\n",
    "parser.add_argument('--model_name_de2en', type=str,             default='roberta-base',      help='model_name')\n",
    "parser.add_argument('--exp_name', type=str,                     default='yelp',      help='experiment name')\n",
    "parser.add_argument('--rep_num', type=int,                      default=-1,      help='report times for 1 epoch')\n",
    "parser.add_argument('--test_num', type=int,                     default=-1,      help='test times for 1 epoch')\n",
    "\n",
    "parser.add_argument('--epochs', type=int,                       default=10,     help='num of training epochs')\n",
    "parser.add_argument('--pre_epochs', type=int,                   default=0,      help='train model W for x epoch first')\n",
    "parser.add_argument('--grad_clip', type=float,                  default=1,      help='gradient clipping')\n",
    "# parser.add_argument('--grad_acc_count', type=float,             default=-1,      help='gradient accumulate steps')\n",
    "\n",
    "parser.add_argument('--w_lr', type=float,                       default=2e-6,   help='learning rate for w')\n",
    "parser.add_argument('--unrolled_w_lr', type=float,              default=2e-6,   help='learning rate for w')\n",
    "parser.add_argument('--v_lr', type=float,                       default=2e-6,   help='learning rate for v')\n",
    "parser.add_argument('--unrolled_v_lr', type=float,              default=2e-6,   help='learning rate for v')\n",
    "parser.add_argument('--A_lr', type=float,                       default=100 ,   help='learning rate for A')\n",
    "# parser.add_argument('--learning_rate_min', type=float,          default=1e-8,   help='learning_rate_min')\n",
    "# parser.add_argument('--decay', type=float,                      default=1e-3,   help='weight decay')\n",
    "parser.add_argument('--beta1', type=float,                      default=0.9,    help='momentum')\n",
    "parser.add_argument('--beta2', type=float,                      default=0.999,    help='momentum')\n",
    "# parser.add_argument('--warm', type=float,                       default=10,    help='warmup step')\n",
    "parser.add_argument('--num_step_lr', type=float,                default=10,    help='warmup step')\n",
    "parser.add_argument('--decay_lr', type=float,                   default=1,    help='warmup step')\n",
    "# parser.add_argument('--smoothing', type=float,                  default=0.1,    help='labelsmoothing')\n",
    "\n",
    "parser.add_argument('--freeze', type=int,                       default=0,    help='whether freeze the pretrained encoder')\n",
    "\n",
    "parser.add_argument('--traindata_loss_ratio', type=float,       default=0,    help='human translated data ratio')\n",
    "parser.add_argument('--syndata_loss_ratio', type=float,         default=1,    help='augmented dataset ratio')\n",
    "\n",
    "parser.add_argument('--valid_begin', type=int,                  default=1,      help='whether valid before train')\n",
    "parser.add_argument('--train_A', type=int,                      default=1 ,     help='whether train A')\n",
    "parser.add_argument('--attack', type=int,                       default=0 ,     help='whether att')\n",
    "parser.add_argument('--clean_A_data', type=int,                 default=1 ,     help='whether att')\n",
    "\n",
    "\n",
    "parser.add_argument('--load_A', type=int,                       default=0 ,     help='whether att')\n",
    "parser.add_argument('--A_path', type=str,                       default='/tianyi-vol/Self-teaching-for-machine-translation/BERT/trainedA/A.pt' ,     help='whether att')\n",
    "\n",
    "# parser.add_argument('--embedding_dim', type=int,                default=300 ,     help='whether train A')\n",
    "parser.add_argument('--out_dim', type=int,                      default=2 ,     help='whether train A')\n",
    "# parser.add_argument('--hidden_size', type=int,                  default=64 ,     help='whether train A')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "args = parser.parse_args(args=[])#(args=['--batch_size', '8',  '--no_cuda'])#used in ipynb\n",
    "\n",
    "args.test_num = args.train_w_num_points #TODO: test each epoch\n",
    "args.rep_num = (args.train_w_num_points//5)//args.w_bs * args.w_bs#TODO: test each epoch\n",
    "\n",
    "args.train_w_num_points= args.train_w_num_points//args.w_bs * args.w_bs\n",
    "args.train_A_num_points= args.train_A_num_points//args.A_bs * args.A_bs\n",
    "args.unlabel_num_points= args.unlabel_num_points//args.syn_bs * args.syn_bs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33monlydrinkwater\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tianyi-vol/Self-teaching-for-machine-translation/BERT/wandb/run-20220707_040859-jngu59lr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/onlydrinkwater/Selftraining/runs/jngu59lr\" target=\"_blank\">yelp</a></strong> to <a href=\"https://wandb.ai/onlydrinkwater/Selftraining\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/onlydrinkwater/Selftraining/runs/jngu59lr?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fc2faf215e0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://wandb.ai/ check the running status online\n",
    "import wandb\n",
    "os.environ['WANDB_API_KEY'] = 'a166474b1b7ad33a0549adaaec19a2f6d3f91d87'\n",
    "os.environ['WANDB_NAME'] = args.exp_name\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":16:8\"\n",
    "\n",
    "wandb.init(project=\"Selftraining\", config=args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging file\n",
    "now = time.strftime(\"%Y-%m-%d-%H_%M_%S\", time.localtime(time.time()))\n",
    "\n",
    "log_format = '%(asctime)s |\\t  %(message)s'\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO,\n",
    "                    format=log_format, datefmt='%m/%d %I:%M:%S %p')\n",
    "fh = logging.FileHandler(os.path.join(\n",
    "    \"./log/\", now+'.txt'), 'w', encoding=\"UTF-8\")\n",
    "fh.setFormatter(logging.Formatter(log_format))\n",
    "logging.getLogger().addHandler(fh)\n",
    "\n",
    "\n",
    "# Setting the seeds\n",
    "np.random.seed(seed_)\n",
    "torch.cuda.set_device(args.gpu)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cudnn.benchmark = True\n",
    "torch.manual_seed(seed_)\n",
    "cudnn.enabled = True\n",
    "torch.cuda.manual_seed(seed_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/07 04:09:07 AM |\t  Using custom data configuration default-89b305f2de5c2a24\n",
      "07/07 04:09:07 AM |\t  Reusing dataset json (/root/.cache/huggingface/datasets/json/default-89b305f2de5c2a24/0.0.0/da492aad5680612e4028e7f6ddc04b1dfcec4b64db470ed7cc5f2bb265b9b6b5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 850.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/07 04:09:07 AM |\t  Using custom data configuration default-9e3205a4e9940313\n",
      "07/07 04:09:07 AM |\t  Reusing dataset json (/root/.cache/huggingface/datasets/json/default-9e3205a4e9940313/0.0.0/da492aad5680612e4028e7f6ddc04b1dfcec4b64db470ed7cc5f2bb265b9b6b5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1219.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/07 04:09:07 AM |\t  Using custom data configuration default-9c4aa945ceecc93d\n",
      "07/07 04:09:07 AM |\t  Reusing dataset json (/root/.cache/huggingface/datasets/json/default-9c4aa945ceecc93d/0.0.0/da492aad5680612e4028e7f6ddc04b1dfcec4b64db470ed7cc5f2bb265b9b6b5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1162.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/07 04:09:08 AM |\t  Using custom data configuration default-99489eb87fbc339f\n",
      "07/07 04:09:08 AM |\t  Reusing dataset json (/root/.cache/huggingface/datasets/json/default-99489eb87fbc339f/0.0.0/da492aad5680612e4028e7f6ddc04b1dfcec4b64db470ed7cc5f2bb265b9b6b5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1008.49it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from datasets import load_dataset\n",
    "l = ['dev','test','train','unlabeled']\n",
    "dev = load_dataset('json', data_files='/tianyi-vol/yelp/dev_data.json', field='data')\n",
    "test = load_dataset('json', data_files='/tianyi-vol/yelp/test_data.json', field='data')\n",
    "train = load_dataset('json', data_files='/tianyi-vol/yelp/train_data.json', field='data')\n",
    "unlabeled = load_dataset('json', data_files='/tianyi-vol/yelp/unlabeled_data.json', field='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label', 'major', 'len'],\n",
      "        num_rows: 25165\n",
      "    })\n",
      "}) DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label', 'major', 'len'],\n",
      "        num_rows: 3800\n",
      "    })\n",
      "}) DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label', 'major', 'len'],\n",
      "        num_rows: 5235\n",
      "    })\n",
      "}) DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label', 'major', 'len'],\n",
      "        num_rows: 3800\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(train,dev,unlabeled,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/07 04:09:21 AM |\t  modelsize:124.697433MB\n",
      "07/07 04:09:30 AM |\t  modelsize:124.697433MB\n",
      "07/07 04:09:39 AM |\t  modelsize:124.697433MB\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "modelname = args.model_name_teacher\n",
    "pretrained = AutoModelForMaskedLM.from_pretrained(modelname)\n",
    "pathname = modelname.replace('/', '')\n",
    "logging.info(f'modelsize:{count_parameters_in_MB(pretrained)}MB')\n",
    "\n",
    "if(exists(pathname+'.pt') == False):\n",
    "    logging.info(f'saving to {pathname}')\n",
    "    torch.save(pretrained, pathname+'.pt')\n",
    "\n",
    "modelname = args.model_name_student\n",
    "pretrained = AutoModelForMaskedLM.from_pretrained(modelname)\n",
    "pathname = modelname.replace('/', '')\n",
    "logging.info(f'modelsize:{count_parameters_in_MB(pretrained)}MB')\n",
    "if(exists(pathname+'.pt') == False):\n",
    "    logging.info(f'saving to {pathname}')\n",
    "    torch.save(pretrained, pathname+'.pt')\n",
    "\n",
    "modelname = args.model_name_de2en\n",
    "pretrained = AutoModelForMaskedLM.from_pretrained(modelname)\n",
    "pathname = modelname.replace('/', '')\n",
    "logging.info(f'modelsize:{count_parameters_in_MB(pretrained)}MB')\n",
    "if(exists(pathname+'.pt') == False):\n",
    "    logging.info(f'saving to {pathname}')\n",
    "    torch.save(pretrained, pathname+'.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/07 04:09:40 AM |\t  Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/json/default-9c4aa945ceecc93d/0.0.0/da492aad5680612e4028e7f6ddc04b1dfcec4b64db470ed7cc5f2bb265b9b6b5/cache-a565eec58ed7e408.arrow\n",
      "07/07 04:09:40 AM |\t  Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/json/default-89b305f2de5c2a24/0.0.0/da492aad5680612e4028e7f6ddc04b1dfcec4b64db470ed7cc5f2bb265b9b6b5/cache-5967255ee27fdb41.arrow\n",
      "07/07 04:09:40 AM |\t  Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/json/default-99489eb87fbc339f/0.0.0/da492aad5680612e4028e7f6ddc04b1dfcec4b64db470ed7cc5f2bb265b9b6b5/cache-5706d4fed9149c74.arrow\n",
      "07/07 04:09:40 AM |\t  Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/json/default-9e3205a4e9940313/0.0.0/da492aad5680612e4028e7f6ddc04b1dfcec4b64db470ed7cc5f2bb265b9b6b5/cache-7e682076f91c470f.arrow\n",
      "07/07 04:09:40 AM |\t  train len: 6000\n",
      "07/07 04:09:40 AM |\t  train_w_num_points_len and train_v_num_points_len: 4000\n",
      "07/07 04:09:40 AM |\t  train_v_synthetic_num_points_len: 2000\n",
      "07/07 04:09:40 AM |\t  train_A_num_points_len: 2000\n",
      "07/07 04:09:40 AM |\t  valid len: 3800\n",
      "07/07 04:09:40 AM |\t  test len: 3800\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train =train[\"train\"].shuffle(seed=seed_).select(range(args.train_w_num_points+args.train_A_num_points)) # A and W)\n",
    "valid = dev[\"train\"].shuffle(seed=seed_)#.select(range( r(args.valid_num_points, args.batch_size))) # dev\n",
    "unlabeled = unlabeled[\"train\"].shuffle(seed=seed_).select(range( args.unlabel_num_points) )# dev\n",
    "test = test[\"train\"].shuffle(seed=seed_)#.select(range( r(args.valid_num_points, args.batch_size))) # dev # test\n",
    "\n",
    "logging.info(\"train len: %d\", len(train))\n",
    "\n",
    "train_w_num_points_len = args.train_w_num_points\n",
    "\n",
    "\n",
    "\n",
    "train_v_synthetic_num_points_len = args.unlabel_num_points\n",
    "train_A_num_points_len =  args.train_A_num_points\n",
    "\n",
    "logging.info(\"train_w_num_points_len and train_v_num_points_len: %d\", train_w_num_points_len)\n",
    "logging.info(\"train_v_synthetic_num_points_len: %d\",\n",
    "             train_v_synthetic_num_points_len)\n",
    "# logging.info(\"train_v_num_points_len: %d\", train_v_num_points_len)\n",
    "logging.info(\"train_A_num_points_len: %d\", train_A_num_points_len)\n",
    "\n",
    "attn_idx_list = torch.arange(train_w_num_points_len).cuda()\n",
    "logging.info(\"valid len: %d\", len(valid))\n",
    "logging.info(\"test len: %d\", len(test))\n",
    "# logging.info(test[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/07 04:09:43 AM |\t  train w data size:batchsize:16\t numofbatch:250\t totoal:4000\n",
      "07/07 04:09:43 AM |\t  train syn data size:batchsize:8\t numofbatch:250\t totoal:2000\n",
      "07/07 04:09:43 AM |\t  train A data size:batchsize:8\t numofbatch:250\t totoal:2000\n",
      "07/07 04:09:44 AM |\t  validation data size:batchsize:32\t numofbatch:119\t totoal:3808\n",
      "07/07 04:09:45 AM |\t  test data size:batchsize:32\t numofbatch:119\t totoal:3808\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create the DataLoader for our training set.\n",
    "train_w_data = get_data_idx(train[:train_w_num_points_len], tokenizer,train_w_num_points_len)\n",
    "train_A_data = get_data_A(train[train_w_num_points_len:], tokenizer,args.clean_A_data)#TODO:use label now\n",
    "train_syn_data = get_syn_data(unlabeled, tokenizer)\n",
    "\n",
    "# indices = list(range(len(train)-train_w_num_points_len))\n",
    "\n",
    "train_w_dataloader = DataLoader(train_w_data, sampler=SequentialSampler(train_w_data),\n",
    "                              batch_size=args.w_bs, pin_memory=args.num_workers > 0, num_workers=args.num_workers)\n",
    "logging.info(f'train w data size:{get_dataloader_size(train_w_dataloader)}')\n",
    "\n",
    "\n",
    "train_syn_dataloader = DataLoader(train_syn_data, sampler=RandomSampler(train_syn_data),\n",
    "                              batch_size=args.syn_bs, pin_memory=args.num_workers > 0, num_workers=args.num_workers)\n",
    "logging.info(f'train syn data size:{get_dataloader_size(train_syn_dataloader)}')\n",
    "\n",
    "\n",
    "train_A_dataloader = DataLoader(train_A_data,  sampler=RandomSampler(train_A_data),\n",
    "                              batch_size=args.A_bs, pin_memory=args.num_workers > 0, num_workers=args.num_workers)\n",
    "logging.info(f'train A data size:{get_dataloader_size(train_A_dataloader)}')\n",
    "\n",
    "\n",
    "\n",
    "# Create the DataLoader for our training set.\n",
    "valid_data = get_data(valid, tokenizer)\n",
    "valid_dataloader = DataLoader(valid_data, sampler=SequentialSampler(valid_data),\n",
    "                              batch_size=args.batch_size, pin_memory=args.num_workers > 0, num_workers=args.num_workers)\n",
    "logging.info(f'validation data size:{get_dataloader_size(valid_dataloader)}')\n",
    "\n",
    "\n",
    "# Create the DataLoader for our training set.\n",
    "test_data = get_data(test, tokenizer)\n",
    "test_dataloader = DataLoader(test_data, sampler=SequentialSampler(test_data),\n",
    "                             batch_size=args.batch_size, pin_memory=args.num_workers > 0, num_workers=args.num_workers)  # , sampler=RandomSampler(test_data)\n",
    "logging.info(f'test data size:{get_dataloader_size(test_dataloader)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "A = attention_params(tokenizer, args, train_w_num_points_len)  # half of train regarded as u\n",
    "A = A.cuda()\n",
    "if(args.load_A==1):\n",
    "    state_dict = A.state_dict()\n",
    "    state_dict['alpha'] = torch.load(args.A_path)['alpha']\n",
    "    A.load_state_dict(state_dict)\n",
    "# TODO: model loaded from saved model\n",
    "model_w = Model(tokenizer, args, 'teacher')\n",
    "model_w = model_w.cuda()\n",
    "w_optimizer = torch.optim.AdamW(model_w.parameters(\n",
    "),  lr=args.w_lr,  betas=(args.beta1, args.beta2), eps=1e-8,weight_decay=1e-4)\n",
    "# w_optimizer = Adafactor(model_w.parameters(), lr = args.w_lr ,scale_parameter=False, relative_step=False , warmup_init=False,clip_threshold=1,beta1=0,eps=( 1e-30,0.001))\n",
    "\n",
    "scheduler_w = get_linear_schedule_with_warmup(w_optimizer, num_warmup_steps=args.epochs, num_training_steps=len(train_w_dataloader) * args.epochs)\n",
    "# scheduler_w  = Scheduler(w_optimizer,dim_embed=512, warmup_steps=args.warm, initlr = args.w_lr)\n",
    "\n",
    "\n",
    "model_v = Model(tokenizer, args, 'student')\n",
    "model_v = model_v.cuda()\n",
    "v_optimizer = torch.optim.AdamW(model_v.parameters(\n",
    "),  lr=args.v_lr,  betas=(args.beta1, args.beta2), eps=1e-8,weight_decay=1e-4)\n",
    "# v_optimizer =Adafactor(model_v.parameters(), lr = args.v_lr ,scale_parameter=False, relative_step=False , warmup_init=False,clip_threshold=1,beta1=0,eps=( 1e-30,0.001))\n",
    "\n",
    "scheduler_v = get_linear_schedule_with_warmup(v_optimizer, num_warmup_steps=args.epochs, num_training_steps=len(train_w_dataloader) * args.epochs)\n",
    "#  scheduler_v = StepLR(\n",
    "    # v_optimizer, step_size=args.num_step_lr, gamma=args.decay_lr)\n",
    "# scheduler_v  = Scheduler(v_optimizer,dim_embed=512, warmup_steps=args.warm, initlr = args.v_lr)\n",
    "\n",
    "\n",
    "architect = Architect(model_w, model_v,  A, args)\n",
    "architect.scheduler_A = get_linear_schedule_with_warmup(architect.optimizer_A, num_warmup_steps=args.epochs, num_training_steps=len(train_w_dataloader) * args.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def my_test(_dataloader,model,epoch):\n",
    "    # logging.info(f\"GPU mem before test:{getGPUMem(device)}%\")\n",
    "    acc = 0\n",
    "    counter = 0\n",
    "    model.eval()\n",
    "    objs_top1 = AvgrageMeter()\n",
    "    objs_top5 = AvgrageMeter()\n",
    "    \n",
    "    for step, batch in enumerate(_dataloader):\n",
    "        test_dataloaderx = Variable(batch[0], requires_grad=False).to(device, non_blocking=False)\n",
    "        test_dataloaderx_attn = Variable(batch[1], requires_grad=False).to(device, non_blocking=False)\n",
    "        test_dataloadery = Variable(batch[2], requires_grad=False).to(device, non_blocking=False)\n",
    "        logits,ls = my_loss(test_dataloaderx,test_dataloaderx_attn,test_dataloadery,model)\n",
    "        n = test_dataloaderx.shape[0]\n",
    "        acc+= ls.item()\n",
    "        counter+= 1\n",
    "        prec1, prec5 = accuracy(logits, test_dataloadery, topk=(1, 1))\n",
    "                \n",
    "        objs_top1.update(prec1.item(), n)\n",
    "        \n",
    "        objs_top5.update(prec5.item(), n)\n",
    "    acc = objs_top1.avg\n",
    "    logging.info('%s test loss : %f',model.name,acc/(counter))\n",
    "    logging.info('%s top1 : %f',model.name,objs_top1.avg)\n",
    "    objs_top1.reset()\n",
    "    logging.info('%s top5 : %f',model.name,objs_top5.avg)\n",
    "    objs_top5.reset()\n",
    "    logging.info('%s test loss : %f',model.name,acc/(counter))\n",
    "    wandb.log({'test_loss'+model.name: acc/counter})\n",
    "    model.train()\n",
    "    return acc\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_v = None\n",
    "best_w = None\n",
    "def my_train(epoch, wdataloader,syndataloader,Adataloader, validdataloader, w_model, v_model, architect, A, w_optimizer, v_optimizer,  scheduler_w, scheduler_v, tot_iter, past_v_accu):\n",
    "    objs_w = AvgrageMeter()\n",
    "    objs_v_syn = AvgrageMeter()\n",
    "    objs_v_train = AvgrageMeter()\n",
    "    objs_v_star_val = AvgrageMeter()\n",
    "    objs_v_val = AvgrageMeter()\n",
    "    objs_w_top1 = AvgrageMeter()\n",
    "    objs_w_top5 = AvgrageMeter()\n",
    "    objs_v_top1 = AvgrageMeter()\n",
    "    objs_v_top5 = AvgrageMeter()\n",
    "    objs_weight = AvgrageMeter_tensor()\n",
    "    objs_cor_weight = AvgrageMeter()\n",
    "    objs_incor_weight = AvgrageMeter()\n",
    "    improvementacc = 0\n",
    "    w_trainloss_acc = 0\n",
    "    # now  train_x is [num of batch, datasize], so its seperate batch for the code below\n",
    "    wsize = args.w_bs\n",
    "    synsize = args.syn_bs\n",
    "    vsize = -1\n",
    "    Asize = args.A_bs\n",
    "    loader_len = len(wdataloader)\n",
    "    w_model.train()\n",
    "    v_model.train()\n",
    "\n",
    "    for step, w_batch in enumerate(wdataloader):\n",
    "        scheduler_w.step()\n",
    "        scheduler_v.step()\n",
    "        architect.scheduler_A.step()\n",
    "\n",
    "\n",
    "        input_w = Variable(w_batch[0], requires_grad=False).to(\n",
    "            device, non_blocking=False)\n",
    "        input_w_attn = Variable(w_batch[1], requires_grad=False).to(\n",
    "            device, non_blocking=False)\n",
    "        output_w = Variable(w_batch[2], requires_grad=False).to(\n",
    "            device, non_blocking=False)\n",
    "        attn_idx = Variable(w_batch[3], requires_grad=False).to(\n",
    "            device, non_blocking=False)\n",
    "        real = Variable(w_batch[4], requires_grad=False).to(\n",
    "            device, non_blocking=False)\n",
    "        \n",
    "        syn_batch = next(iter(syndataloader))\n",
    "        input_syn = Variable(syn_batch[0], requires_grad=False).to(\n",
    "            device, non_blocking=False)\n",
    "        input_syn_attn = Variable(syn_batch[1], requires_grad=False).to(\n",
    "            device, non_blocking=False)\n",
    "\n",
    "\n",
    "\n",
    "        A_batch = next(iter(Adataloader))\n",
    "        input_A_v = Variable(A_batch[0], requires_grad=False).to(\n",
    "            device, non_blocking=False)\n",
    "        input_A_v_attn = Variable(A_batch[1], requires_grad=False).to(\n",
    "            device, non_blocking=False)\n",
    "        output_A_v = Variable(A_batch[2], requires_grad=False).to(\n",
    "            device, non_blocking=False)\n",
    "\n",
    "\n",
    "\n",
    "        tot_iter[0] += input_w.shape[0]\n",
    "        \n",
    "        \n",
    "        if(True):  # let v train on syn data and w data\n",
    "            input_v = input_w\n",
    "            input_v_attn = input_w_attn\n",
    "            output_v = output_w\n",
    "            vsize = wsize\n",
    "\n",
    "\n",
    "        v_star_val_loss=0\n",
    "        if (args.train_A == 1 and epoch>=args.pre_epochs):\n",
    "            epsilon_w = scheduler_w.get_lr()[0]\n",
    "            epsilon_v  = scheduler_v.get_lr()[0]\n",
    "            v_star_val_loss = architect.step(input_w,  output_w, input_w_attn, w_optimizer,\n",
    "                                             input_v, input_v_attn, output_v, input_syn, input_syn_attn,\n",
    "                                             input_A_v, input_A_v_attn, output_A_v, attn_idx,v_optimizer,\n",
    "                                             epsilon_w, epsilon_v, args.grad_clip)\n",
    "            objs_v_star_val.update(v_star_val_loss, Asize)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        with torch.no_grad():    \n",
    "            sampleweight = A(input_w, input_w_attn, attn_idx).data\n",
    "            iscor = real==output_w\n",
    "            cor_mean = torch.mean(sampleweight[iscor])#correct label mean weight\n",
    "            incor_mean = torch.mean(sampleweight[~iscor])#incorrect label mean weight\n",
    "            objs_weight.update(sampleweight)\n",
    "            objs_cor_weight.update(cor_mean,torch.sum(iscor))\n",
    "            objs_incor_weight.update(incor_mean,torch.sum(~iscor))\n",
    "\n",
    "        w_optimizer.zero_grad()\n",
    "        logits, loss_w = CTG_loss(input_w, input_w_attn, output_w,\n",
    "                                  A,attn_idx, w_model)\n",
    "        w_trainloss_acc += loss_w.item()\n",
    "        loss_w.backward()\n",
    "        objs_w.update(loss_w.item(), wsize)\n",
    "        w_optimizer.step()\n",
    "        torch.nn.utils.clip_grad_norm(w_model.parameters(), args.grad_clip)\n",
    "        prec1, prec5 = accuracy(logits, output_w, topk=(1, 1))\n",
    "        objs_w_top1.update(prec1.item(), wsize)\n",
    "        objs_w_top5.update(prec5.item(), wsize)\n",
    "\n",
    "        if(epoch >= args.pre_epochs):\n",
    "            v_optimizer.zero_grad()\n",
    "            loss_aug = calc_loss_aug(\n",
    "                input_syn, input_syn_attn, w_model, v_model)\n",
    "            logits, loss = my_loss2(input_v, input_v_attn, output_v,\n",
    "                                    v_model)\n",
    "            v_loss = (args.traindata_loss_ratio*loss +\n",
    "                      loss_aug*args.syndata_loss_ratio)\n",
    "            v_loss.backward()\n",
    "            objs_v_syn.update(loss_aug.item(), synsize)\n",
    "            objs_v_train.update(loss.item(), vsize)\n",
    "            v_optimizer.step()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm(v_model.parameters(), args.grad_clip)\n",
    "            prec1, prec5 = accuracy(logits, output_v, topk=(1, 1))\n",
    "            objs_v_top1.update(prec1.item(), vsize)\n",
    "            objs_v_top5.update(prec5.item(), vsize)\n",
    "\n",
    "\n",
    "        with torch.no_grad():#new V validation \n",
    "            _,new_v_loss = my_loss2(\n",
    "            input_A_v, input_A_v_attn,  output_A_v,model_v)\n",
    "            improvementacc+=v_star_val_loss-new_v_loss.item()\n",
    "            objs_v_val.update(new_v_loss.item(), Asize)\n",
    "\n",
    "\n",
    "        progress = 100*(step)/(loader_len-1)\n",
    "\n",
    "        \n",
    "        if(tot_iter[0] % args.rep_num == 0 and tot_iter[0] != 0):\n",
    "            logging.info('\\n')\n",
    "            \n",
    "            logging.info(f\"{progress:5.3}%:||W_train_loss:{objs_w.avg:^.7f}|V_train_syn_loss:{objs_v_syn.avg:^.7f}|V_train_loss:{objs_v_train.avg:^.7f}|V_val_loss:{objs_v_val.avg:^.7f}|V_star_val_loss:{objs_v_star_val.avg:^.7f}|improvement:{objs_v_star_val.avg-objs_v_val.avg:^.7f}|w_top1:{objs_w_top1.avg:^.7f}|w_top5:{objs_w_top5.avg:^.7f}|v_top1:{objs_v_top1.avg:^.7f}|v_top5:{objs_v_top5.avg:^.7f}|\")\n",
    "            temp = objs_weight.avg\n",
    "            logging.info(f\"avg weight:{temp}\")\n",
    "            logging.info(f\"current alpha:{A.alpha[attn_idx].data}\")\n",
    "            logging.info(f\"current weight:{A(input_w, input_w_attn, attn_idx)}\")\n",
    "            logging.info(f'noise:{torch.mean(temp[5:8]) if args.attack else None} mean:{torch.mean(temp)} max: {torch.max(temp)} min: {torch.min(temp)}')\n",
    "            wandb.log({'W_train_loss': objs_w.avg})\n",
    "            wandb.log({'V_train_syn_loss': objs_v_syn.avg})\n",
    "            wandb.log({'V_train_loss': objs_v_train.avg})\n",
    "            wandb.log({'V_star_val_loss': objs_v_star_val.avg})\n",
    "            wandb.log({'V_val_loss': objs_v_star_val.avg})\n",
    "            wandb.log({'W_accuracy': objs_w_top1.avg})\n",
    "            wandb.log({'v_accuracy': objs_v_top1.avg})\n",
    "            objs_v_syn.reset()\n",
    "            objs_v_train.reset()\n",
    "            objs_weight.reset()\n",
    "            objs_w.reset()\n",
    "            objs_v_star_val.reset()\n",
    "            objs_v_val.reset()\n",
    "            objs_w_top1.reset()\n",
    "            objs_w_top5.reset()\n",
    "\n",
    "        if(tot_iter[0] % args.test_num == 0 and tot_iter[0] != 0):\n",
    "            w_accu = my_test(validdataloader, model_w, epoch)\n",
    "            v_accu = my_test(validdataloader, model_v, epoch)\n",
    "            wandb.log({'W_test_accuracy': w_accu})\n",
    "            wandb.log({'v_test_accuracy':v_accu})\n",
    "            wandb.log({'correct_label_mean_weight': objs_cor_weight.avg})\n",
    "            wandb.log({'wrong_label_mean_weight':objs_incor_weight.avg})\n",
    "            logging.info(f'correct label mean weight: {objs_cor_weight.avg}, wrong label mean weight: {objs_incor_weight.avg}')\n",
    "            objs_cor_weight.reset()\n",
    "            objs_incor_weight.reset()\n",
    "            torch.save(A.state_dict(), os.path.join(wandb.run.dir, \"A.pt\"))\n",
    "            if(v_accu>past_v_accu):\n",
    "                past_v_accu = v_accu\n",
    "                logging.info('find a better model')\n",
    "                global best_w\n",
    "                global best_v\n",
    "                best_v = copy.deepcopy(model_v)\n",
    "                best_w = copy.deepcopy(model_w)\n",
    "                torch.save(model_w.state_dict(), os.path.join(\n",
    "                    wandb.run.dir, \"model_w.pt\"))\n",
    "                torch.save(model_v.state_dict(), os.path.join(\n",
    "                    wandb.run.dir, \"model_v.pt\"))\n",
    "            wandb.save(\"./files/*.pt\", base_path=\"./files\", policy=\"live\")\n",
    "            \n",
    "            logging.info(f'current best accuracy:{past_v_accu}')\n",
    "    logging.info(f'improvment:{improvementacc}')\n",
    "    return w_trainloss_acc,past_v_accu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/07 04:09:46 AM |\t  \n",
      "\n",
      "  ----------------epoch:0,\t\tlr_w:0.0,\t\tlr_v:0.0,\t\tlr_A:0.0----------------\n",
      "07/07 04:11:20 AM |\t  \n",
      "\n",
      "07/07 04:11:20 AM |\t   19.7%:||W_train_loss:0.6488984|V_train_syn_loss:0.6587221|V_train_loss:0.6166819|V_val_loss:0.7081232|V_star_val_loss:0.7083703|improvement:0.0002471|w_top1:73.2500000|w_top5:73.2500000|v_top1:73.2500000|v_top5:73.2500000|\n",
      "07/07 04:11:20 AM |\t  avg weight:tensor([1.0378, 0.9633, 1.0558, 1.1097, 1.1374, 0.9205, 0.9960, 0.9258, 0.9778,\n",
      "        1.1213, 0.9914, 0.9857, 0.9109, 0.8670, 0.9980, 1.0018],\n",
      "       device='cuda:0')\n",
      "07/07 04:11:20 AM |\t  current alpha:tensor([ 1.7776, -0.7633, -1.1160,  0.9304,  0.5560, -3.7938, -3.0867, -5.9173,\n",
      "         1.0559,  2.1526, 10.6311, -1.2390,  1.4142, -1.2428,  0.4993, -0.8342],\n",
      "       device='cuda:0')\n",
      "07/07 04:11:20 AM |\t  current weight:tensor([1.7874, 0.6644, 0.5156, 1.4986, 1.3280, 0.0460, 0.0912, 0.0056, 1.5503,\n",
      "        1.8721, 2.0896, 0.4693, 1.6809, 0.4680, 1.3004, 0.6327],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "07/07 04:11:20 AM |\t  noise:None mean:0.9999999403953552 max: 1.137363076210022 min: 0.86695796251297\n",
      "07/07 04:12:53 AM |\t  \n",
      "\n",
      "07/07 04:12:53 AM |\t   39.8%:||W_train_loss:0.6418941|V_train_syn_loss:0.6654183|V_train_loss:0.6187296|V_val_loss:0.7054041|V_star_val_loss:0.7040079|improvement:-0.0013962|w_top1:72.7500000|w_top5:72.7500000|v_top1:72.9375000|v_top5:72.9375000|\n",
      "07/07 04:12:53 AM |\t  avg weight:tensor([1.0167, 1.0954, 1.0034, 0.9211, 0.9651, 1.1453, 1.0735, 0.8940, 1.0203,\n",
      "        1.0428, 0.9450, 1.0706, 0.9409, 1.1204, 0.8253, 0.9200],\n",
      "       device='cuda:0')\n",
      "07/07 04:12:53 AM |\t  current alpha:tensor([ 0.4430, -0.9528, -1.3794,  0.0987,  3.6056,  1.3727,  0.9825, -1.7681,\n",
      "         0.6292,  1.6488, -1.9426,  2.7521, -2.4451,  2.1607, -1.9127, -2.8802],\n",
      "       device='cuda:0')\n",
      "07/07 04:12:53 AM |\t  current weight:tensor([1.2221, 0.5586, 0.4036, 1.0529, 1.9538, 1.6011, 1.4602, 0.2926, 1.3091,\n",
      "        1.6832, 0.2516, 1.8865, 0.1601, 1.7995, 0.2582, 0.1066],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "07/07 04:12:53 AM |\t  noise:None mean:1.0 max: 1.1453471183776855 min: 0.8253028392791748\n",
      "07/07 04:14:27 AM |\t  \n",
      "\n",
      "07/07 04:14:27 AM |\t   59.8%:||W_train_loss:0.6481589|V_train_syn_loss:0.6574518|V_train_loss:0.6101148|V_val_loss:0.7083433|V_star_val_loss:0.7033347|improvement:-0.0050086|w_top1:73.5000000|w_top5:73.5000000|v_top1:73.0833333|v_top5:73.0833333|\n",
      "07/07 04:14:27 AM |\t  avg weight:tensor([0.9683, 0.9087, 1.0393, 1.0098, 1.1244, 0.9946, 0.9335, 0.9748, 1.0227,\n",
      "        0.9467, 1.0558, 1.0057, 1.1683, 1.0298, 1.0157, 0.8018],\n",
      "       device='cuda:0')\n",
      "07/07 04:14:27 AM |\t  current alpha:tensor([  3.6492,   3.1059,   2.5361,   0.1381,   3.7331,   2.5436, -27.1562,\n",
      "          3.5479,  -1.5888,  -1.4375,   1.7196,   9.8235,   3.2235,   0.0435,\n",
      "          0.4404,   1.3070], device='cuda:0')\n",
      "07/07 04:14:27 AM |\t  current weight:tensor([1.3744e+00, 1.3497e+00, 1.3067e+00, 7.5370e-01, 1.3772e+00, 1.3074e+00,\n",
      "        2.2672e-12, 1.3707e+00, 2.3909e-01, 2.7066e-01, 1.1959e+00, 1.4101e+00,\n",
      "        1.3562e+00, 7.2041e-01, 8.5789e-01, 1.1098e+00], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "07/07 04:14:27 AM |\t  noise:None mean:1.0 max: 1.168287992477417 min: 0.8018288016319275\n",
      "07/07 04:16:02 AM |\t  \n",
      "\n",
      "07/07 04:16:02 AM |\t   79.9%:||W_train_loss:0.6556772|V_train_syn_loss:0.6623603|V_train_loss:0.6136099|V_val_loss:0.7042356|V_star_val_loss:0.7123793|improvement:0.0081438|w_top1:73.0000000|w_top5:73.0000000|v_top1:73.0312500|v_top5:73.0312500|\n",
      "07/07 04:16:02 AM |\t  avg weight:tensor([1.1641, 0.9801, 1.2119, 0.8897, 0.9343, 0.9588, 1.0560, 0.7730, 1.1611,\n",
      "        1.1566, 0.9851, 0.9296, 0.8458, 0.9764, 0.9651, 1.0123],\n",
      "       device='cuda:0')\n",
      "07/07 04:16:02 AM |\t  current alpha:tensor([ 8.7069, -1.0605, -5.8884, -1.2957,  4.0394, -3.5705,  2.2020, -3.9309,\n",
      "         1.4089, -3.2798, -4.8517, -1.0988, -4.8590, -2.0203,  0.5919, 14.3714],\n",
      "       device='cuda:0')\n",
      "07/07 04:16:02 AM |\t  current weight:tensor([2.5512, 0.6563, 0.0071, 0.5483, 2.5074, 0.0698, 2.2975, 0.0491, 2.0504,\n",
      "        0.0925, 0.0198, 0.6378, 0.0196, 0.2988, 1.6427, 2.5516],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "07/07 04:16:02 AM |\t  noise:None mean:1.0 max: 1.2118895053863525 min: 0.7730227708816528\n",
      "07/07 04:17:37 AM |\t  \n",
      "\n",
      "07/07 04:17:37 AM |\t  1e+02%:||W_train_loss:0.6549062|V_train_syn_loss:0.6711047|V_train_loss:0.6209988|V_val_loss:0.6916023|V_star_val_loss:0.6870278|improvement:-0.0045744|w_top1:71.2500000|w_top5:71.2500000|v_top1:72.6250000|v_top5:72.6250000|\n",
      "07/07 04:17:37 AM |\t  avg weight:tensor([1.0182, 1.0690, 0.9444, 0.9079, 1.0582, 1.2388, 0.9887, 0.9933, 1.1198,\n",
      "        1.0343, 1.0539, 0.9323, 0.9600, 0.9368, 0.8508, 0.8934],\n",
      "       device='cuda:0')\n",
      "07/07 04:17:37 AM |\t  current alpha:tensor([ 2.4844,  5.0254, -6.6134, -1.8562, -3.2759,  7.3456, -1.8237, -3.1796,\n",
      "         1.4006,  3.3820,  5.4026,  1.0203, -3.4618, -3.8804,  0.2226, -1.8807],\n",
      "       device='cuda:0')\n",
      "07/07 04:17:37 AM |\t  current weight:tensor([1.9676, 2.1177, 0.0029, 0.2881, 0.0776, 2.1302, 0.2963, 0.0851, 1.7102,\n",
      "        2.0616, 2.1221, 1.5668, 0.0648, 0.0431, 1.1840, 0.2820],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "07/07 04:17:37 AM |\t  noise:None mean:1.0 max: 1.23881196975708 min: 0.8508455753326416\n",
      "07/07 04:17:45 AM |\t  teacher test loss : 0.428793\n",
      "07/07 04:17:45 AM |\t  teacher top1 : 51.026316\n",
      "07/07 04:17:45 AM |\t  teacher top5 : 51.026316\n",
      "07/07 04:17:45 AM |\t  teacher test loss : 0.428793\n",
      "07/07 04:17:53 AM |\t  student test loss : 0.426139\n",
      "07/07 04:17:53 AM |\t  student top1 : 50.710526\n",
      "07/07 04:17:54 AM |\t  student top5 : 50.710526\n",
      "07/07 04:17:54 AM |\t  student test loss : 0.426139\n",
      "07/07 04:17:54 AM |\t  correct label mean weight: 1.0409480333328247, wrong label mean weight: 0.89764803647995\n",
      "07/07 04:17:54 AM |\t  find a better model\n",
      "07/07 04:17:55 AM |\t  current best accuracy:50.71052631578947\n",
      "07/07 04:17:55 AM |\t  improvment:-0.12941858172416687\n",
      "07/07 04:17:55 AM |\t  \n",
      "\n",
      "  ----------------epoch:1,\t\tlr_w:1.8072289156626506e-06,\t\tlr_v:1.8072289156626506e-06,\t\tlr_A:90.36144578313254----------------\n",
      "07/07 04:19:30 AM |\t  \n",
      "\n",
      "07/07 04:19:30 AM |\t   19.7%:||W_train_loss:0.6047054|V_train_syn_loss:0.6671635|V_train_loss:0.6122634|V_val_loss:0.6657113|V_star_val_loss:0.6647158|improvement:-0.0009955|w_top1:74.3750000|w_top5:74.3750000|v_top1:73.2500000|v_top5:73.2500000|\n",
      "07/07 04:19:30 AM |\t  avg weight:tensor([1.1387, 0.9326, 1.0546, 1.1889, 1.0770, 0.8946, 0.8195, 1.0264, 1.1748,\n",
      "        1.1090, 1.0006, 0.8426, 0.7591, 0.7777, 1.0091, 1.1950],\n",
      "       device='cuda:0')\n",
      "07/07 04:19:30 AM |\t  current alpha:tensor([  3.4251,  -2.1699, -11.9150,   3.8430,  -7.2707,  -6.5210,  -6.5131,\n",
      "        -10.0349,  -0.2691,   3.9313,  18.2332,  -4.0942,  -6.4034,  -3.2078,\n",
      "          9.9644,  12.4968], device='cuda:0')\n",
      "07/07 04:19:30 AM |\t  current weight:tensor([2.3750e+00, 2.5133e-01, 1.6404e-05, 2.4009e+00, 1.7047e-03, 3.6050e-03,\n",
      "        3.6335e-03, 1.0751e-04, 1.0621e+00, 2.4051e+00, 2.4523e+00, 4.0207e-02,\n",
      "        4.0541e-03, 9.5330e-02, 2.4522e+00, 2.4523e+00], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "07/07 04:19:30 AM |\t  noise:None mean:0.9999999403953552 max: 1.194950819015503 min: 0.7590968012809753\n",
      "07/07 04:21:05 AM |\t  \n",
      "\n",
      "07/07 04:21:05 AM |\t   39.8%:||W_train_loss:0.5320999|V_train_syn_loss:0.6598984|V_train_loss:0.6189991|V_val_loss:0.6227927|V_star_val_loss:0.6237424|improvement:0.0009497|w_top1:75.6250000|w_top5:75.6250000|v_top1:71.8750000|v_top5:71.8750000|\n",
      "07/07 04:21:05 AM |\t  avg weight:tensor([0.9781, 1.3197, 1.0550, 0.9544, 1.0437, 1.0002, 1.0734, 0.8588, 1.1715,\n",
      "        1.0576, 0.7956, 0.8988, 0.8038, 1.2075, 0.8093, 0.9728],\n",
      "       device='cuda:0')\n",
      "07/07 04:21:05 AM |\t  current alpha:tensor([21.6150, -5.4875,  0.4995,  0.8380,  5.8898, -0.9513,  6.0021, -6.6302,\n",
      "         1.4418, -3.3240, -1.8319,  3.1056, -3.6337,  2.2207, -3.7914, -3.4416],\n",
      "       device='cuda:0')\n",
      "07/07 04:21:05 AM |\t  current weight:tensor([2.1280, 0.0088, 1.3243, 1.4854, 2.1221, 0.5929, 2.1228, 0.0028, 1.7210,\n",
      "        0.0740, 0.2937, 2.0368, 0.0548, 1.9197, 0.0470, 0.0660],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "07/07 04:21:05 AM |\t  noise:None mean:0.9999999403953552 max: 1.3197381496429443 min: 0.79558265209198\n",
      "07/07 04:22:40 AM |\t  \n",
      "\n",
      "07/07 04:22:40 AM |\t   59.8%:||W_train_loss:0.5284520|V_train_syn_loss:0.6079780|V_train_loss:0.5374578|V_val_loss:0.4457515|V_star_val_loss:0.4513160|improvement:0.0055646|w_top1:73.1250000|w_top5:73.1250000|v_top1:72.0833333|v_top5:72.0833333|\n",
      "07/07 04:22:40 AM |\t  avg weight:tensor([0.8542, 0.9400, 1.0554, 0.9994, 1.2621, 0.9302, 0.9691, 1.0454, 1.1695,\n",
      "        1.0915, 0.9314, 1.2214, 1.0515, 0.9611, 0.7789, 0.7390],\n",
      "       device='cuda:0')\n",
      "07/07 04:22:40 AM |\t  current alpha:tensor([  5.5966,   4.4343,   6.9774,   2.5561,   5.3612,   3.1595, -40.8925,\n",
      "          5.7080,  -0.3328,   0.1168,   3.6659,  14.7358,   4.4894, -13.6309,\n",
      "        -13.8665,   3.8458], device='cuda:0')\n",
      "07/07 04:22:40 AM |\t  current weight:tensor([1.3564e+00, 1.3454e+00, 1.3601e+00, 1.2633e+00, 1.3550e+00, 1.3060e+00,\n",
      "        2.3691e-18, 1.3569e+00, 5.6846e-01, 7.2042e-01, 1.3274e+00, 1.3614e+00,\n",
      "        1.3463e+00, 1.6375e-06, 1.2937e-06, 1.3329e+00], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "07/07 04:22:40 AM |\t  noise:None mean:0.9999999403953552 max: 1.2620643377304077 min: 0.7390198111534119\n",
      "07/07 04:24:15 AM |\t  \n",
      "\n",
      "07/07 04:24:15 AM |\t   79.9%:||W_train_loss:0.5200262|V_train_syn_loss:0.6045492|V_train_loss:0.4869848|V_val_loss:0.4230930|V_star_val_loss:0.4308111|improvement:0.0077181|w_top1:74.8750000|w_top5:74.8750000|v_top1:73.2812500|v_top5:73.2812500|\n",
      "07/07 04:24:15 AM |\t  avg weight:tensor([1.1243, 0.7462, 1.3079, 1.0342, 0.8063, 1.1230, 0.9631, 0.8299, 0.9673,\n",
      "        0.8450, 1.0788, 0.9179, 0.8846, 1.0483, 1.0091, 1.3141],\n",
      "       device='cuda:0')\n",
      "07/07 04:24:15 AM |\t  current alpha:tensor([12.8796,  2.0983, -8.7447,  2.5071,  6.1410, -4.4713, -3.9296, -5.0715,\n",
      "         5.8440, -4.5029, -7.0389,  5.4360, -6.7446, -0.0616,  0.6553, 21.2120],\n",
      "       device='cuda:0')\n",
      "07/07 04:24:15 AM |\t  current weight:tensor([2.0003e+00, 1.7817e+00, 3.1860e-04, 1.8496e+00, 1.9960e+00, 2.2610e-02,\n",
      "        3.8550e-02, 1.2470e-02, 1.9945e+00, 2.1914e-02, 1.7529e-03, 1.9916e+00,\n",
      "        2.3521e-03, 9.6935e-01, 1.3166e+00, 2.0003e+00], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "07/07 04:24:15 AM |\t  noise:None mean:1.0 max: 1.3140699863433838 min: 0.7462060451507568\n",
      "07/07 04:25:49 AM |\t  \n",
      "\n",
      "07/07 04:25:49 AM |\t  1e+02%:||W_train_loss:0.5339392|V_train_syn_loss:0.5811357|V_train_loss:0.5304553|V_val_loss:0.3886435|V_star_val_loss:0.3922713|improvement:0.0036278|w_top1:70.7500000|w_top5:70.7500000|v_top1:72.7250000|v_top5:72.7250000|\n",
      "07/07 04:25:49 AM |\t  avg weight:tensor([1.0155, 0.9932, 1.0265, 0.7675, 0.9847, 1.4901, 1.0804, 1.1273, 0.8750,\n",
      "        1.0140, 1.0378, 0.7905, 0.8733, 0.9797, 0.8959, 1.0487],\n",
      "       device='cuda:0')\n",
      "07/07 04:25:49 AM |\t  current alpha:tensor([10.4375,  7.1230, -9.6206, -6.4384, -1.5722, 10.7161, -0.6873,  4.3886,\n",
      "         9.4357,  1.2728,  7.7254, 28.6055, -4.8312, -6.1183,  6.7070, -7.7907],\n",
      "       device='cuda:0')\n",
      "07/07 04:25:49 AM |\t  current weight:tensor([1.7231e+00, 1.7218e+00, 1.1432e-04, 2.7510e-03, 2.9623e-01, 1.7232e+00,\n",
      "        5.7665e-01, 1.7021e+00, 1.7231e+00, 1.3462e+00, 1.7224e+00, 1.7232e+00,\n",
      "        1.3637e-02, 3.7864e-03, 1.7211e+00, 7.1239e-04], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "07/07 04:25:49 AM |\t  noise:None mean:1.0 max: 1.4900835752487183 min: 0.7675089836120605\n",
      "07/07 04:25:57 AM |\t  teacher test loss : 0.764264\n",
      "07/07 04:25:57 AM |\t  teacher top1 : 90.947368\n",
      "07/07 04:25:57 AM |\t  teacher top5 : 90.947368\n",
      "07/07 04:25:57 AM |\t  teacher test loss : 0.764264\n",
      "07/07 04:26:05 AM |\t  student test loss : 0.767802\n",
      "07/07 04:26:05 AM |\t  student top1 : 91.368421\n",
      "07/07 04:26:05 AM |\t  student top5 : 91.368421\n",
      "07/07 04:26:05 AM |\t  student test loss : 0.767802\n",
      "07/07 04:26:05 AM |\t  correct label mean weight: 1.061707615852356, wrong label mean weight: 0.845758318901062\n",
      "07/07 04:26:06 AM |\t  find a better model\n",
      "07/07 04:26:07 AM |\t  current best accuracy:91.36842105263158\n",
      "07/07 04:26:07 AM |\t  improvment:0.8432359546422958\n",
      "07/07 04:26:07 AM |\t  \n",
      "\n",
      "  ----------------epoch:2,\t\tlr_w:1.606425702811245e-06,\t\tlr_v:1.606425702811245e-06,\t\tlr_A:80.32128514056225----------------\n",
      "07/07 04:27:41 AM |\t  \n",
      "\n",
      "07/07 04:27:41 AM |\t   19.7%:||W_train_loss:0.5349171|V_train_syn_loss:0.5906924|V_train_loss:0.5085817|V_val_loss:0.4257391|V_star_val_loss:0.4160043|improvement:-0.0097348|w_top1:73.2500000|w_top5:73.2500000|v_top1:71.8750000|v_top5:71.8750000|\n",
      "07/07 04:27:41 AM |\t  avg weight:tensor([1.2890, 0.9535, 1.1078, 1.1739, 1.0429, 0.9387, 0.8123, 0.8529, 1.2232,\n",
      "        1.1302, 1.0200, 0.9950, 0.7679, 0.6831, 1.0172, 0.9923],\n",
      "       device='cuda:0')\n",
      "07/07 04:27:41 AM |\t  current alpha:tensor([  7.7749, -18.4534, -16.8142,   6.4624, -10.8874,  -8.2085,  -8.1523,\n",
      "        -11.9047, -64.1953,   4.3483,  18.2332,  -5.8540, -10.2083,  -8.1018,\n",
      "         14.2551,  18.5442], device='cuda:0')\n",
      "07/07 04:27:41 AM |\t  current weight:tensor([2.6704e+00, 2.5856e-08, 1.3318e-07, 2.6674e+00, 4.9936e-05, 7.2731e-04,\n",
      "        7.6940e-04, 1.8055e-05, 3.5244e-28, 2.6374e+00, 2.6715e+00, 7.6409e-03,\n",
      "        9.8474e-05, 8.0922e-04, 2.6715e+00, 2.6715e+00], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "07/07 04:27:41 AM |\t  noise:None mean:1.0 max: 1.2890022993087769 min: 0.6830654144287109\n",
      "07/07 04:29:16 AM |\t  \n",
      "\n",
      "07/07 04:29:16 AM |\t   39.8%:||W_train_loss:0.5020647|V_train_syn_loss:0.5656067|V_train_loss:0.4747643|V_val_loss:0.3834561|V_star_val_loss:0.3881346|improvement:0.0046785|w_top1:77.0000000|w_top5:77.0000000|v_top1:73.7500000|v_top5:73.7500000|\n",
      "07/07 04:29:16 AM |\t  avg weight:tensor([0.9146, 1.3907, 1.1044, 0.8476, 0.8607, 1.1438, 1.1917, 0.9311, 1.0274,\n",
      "        1.1704, 0.7922, 0.9941, 0.7402, 1.2213, 0.7381, 0.9317],\n",
      "       device='cuda:0')\n",
      "07/07 04:29:16 AM |\t  current alpha:tensor([ 2.1615e+01, -7.0166e+00, -7.0099e-02, -7.8492e+01,  7.0850e+00,\n",
      "         1.3765e+01,  8.6061e+00, -8.8992e+00,  1.5730e+01,  7.9244e+00,\n",
      "         7.0684e+00,  9.8899e+00, -1.6024e+01,  6.9722e+00, -2.9187e+00,\n",
      "        -3.4823e+00], device='cuda:0')\n",
      "07/07 04:29:16 AM |\t  current weight:tensor([1.6734e+00, 1.4995e-03, 8.0739e-01, 1.3647e-34, 1.6720e+00, 1.6734e+00,\n",
      "        1.6731e+00, 2.2839e-04, 1.6734e+00, 1.6728e+00, 1.6720e+00, 1.6733e+00,\n",
      "        1.8385e-07, 1.6718e+00, 8.5738e-02, 4.9902e-02], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "07/07 04:29:16 AM |\t  noise:None mean:1.0 max: 1.3906656503677368 min: 0.7381246089935303\n",
      "07/07 04:30:51 AM |\t  \n",
      "\n",
      "07/07 04:30:51 AM |\t   59.8%:||W_train_loss:0.4725651|V_train_syn_loss:0.5428982|V_train_loss:0.5040070|V_val_loss:0.3815825|V_star_val_loss:0.3743941|improvement:-0.0071884|w_top1:73.8750000|w_top5:73.8750000|v_top1:73.4166667|v_top5:73.4166667|\n",
      "07/07 04:30:51 AM |\t  avg weight:tensor([0.8854, 0.9308, 1.1202, 0.9942, 1.1302, 0.8901, 0.9223, 1.0525, 1.1598,\n",
      "        1.1247, 0.9711, 1.2545, 1.0711, 1.0090, 0.7418, 0.7423],\n",
      "       device='cuda:0')\n",
      "07/07 04:30:51 AM |\t  current alpha:tensor([  6.2844,   1.5184,   8.7388,  23.1948,   6.9319,   0.8023, -46.9956,\n",
      "          7.1922,  13.5234,  27.0873,   8.2672,  16.9178,   3.2687, -19.7046,\n",
      "        -20.2221,   7.6409], device='cuda:0')\n",
      "07/07 04:30:51 AM |\t  current weight:tensor([1.2807e+00, 1.0525e+00, 1.2829e+00, 1.2831e+00, 1.2819e+00, 8.8595e-01,\n",
      "        4.9926e-21, 1.2822e+00, 1.2831e+00, 1.2831e+00, 1.2828e+00, 1.2831e+00,\n",
      "        1.2361e+00, 3.5535e-09, 2.1180e-09, 1.2825e+00], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "07/07 04:30:51 AM |\t  noise:None mean:0.9999998807907104 max: 1.254455327987671 min: 0.7418079376220703\n",
      "07/07 04:32:25 AM |\t  \n",
      "\n",
      "07/07 04:32:25 AM |\t   79.9%:||W_train_loss:0.4428060|V_train_syn_loss:0.5443036|V_train_loss:0.4487651|V_val_loss:0.3819043|V_star_val_loss:0.3733850|improvement:-0.0085193|w_top1:77.7500000|w_top5:77.7500000|v_top1:74.5000000|v_top5:74.5000000|\n",
      "07/07 04:32:25 AM |\t  avg weight:tensor([1.0388, 0.7978, 1.3163, 0.9438, 0.8467, 1.1740, 0.9743, 0.8262, 1.0109,\n",
      "        1.0094, 0.9993, 0.9250, 0.9423, 0.9584, 1.0344, 1.2022],\n",
      "       device='cuda:0')\n",
      "07/07 04:32:25 AM |\t  current alpha:tensor([ 14.7209,   4.7607, -10.0028,   2.9133,   7.0356,  -5.2623,  -7.5014,\n",
      "         -5.9383,   7.7451,  -5.3889,  -8.0231,   8.2689,  -7.7855, -17.8982,\n",
      "         -6.9065,  21.2120], device='cuda:0')\n",
      "07/07 04:32:25 AM |\t  current weight:tensor([2.3011e+00, 2.2816e+00, 1.0417e-04, 2.1826e+00, 2.2991e+00, 1.1866e-02,\n",
      "        1.2702e-03, 6.0507e-03, 2.3001e+00, 1.0461e-02, 7.5406e-04, 2.3005e+00,\n",
      "        9.5619e-04, 3.8800e-08, 2.3017e-03, 2.3011e+00], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "07/07 04:32:25 AM |\t  noise:None mean:0.9999999403953552 max: 1.316330075263977 min: 0.7978395819664001\n",
      "07/07 04:33:59 AM |\t  \n",
      "\n",
      "07/07 04:33:59 AM |\t  1e+02%:||W_train_loss:0.4702685|V_train_syn_loss:0.5181805|V_train_loss:0.4989043|V_val_loss:0.3141783|V_star_val_loss:0.3177518|improvement:0.0035734|w_top1:73.3750000|w_top5:73.3750000|v_top1:74.2250000|v_top5:74.2250000|\n",
      "07/07 04:33:59 AM |\t  avg weight:tensor([1.0449, 1.0182, 0.9889, 0.7572, 0.9148, 1.4476, 1.1185, 1.0939, 0.8769,\n",
      "        1.0138, 1.0190, 0.7587, 0.9716, 0.9651, 0.9259, 1.0851],\n",
      "       device='cuda:0')\n",
      "07/07 04:33:59 AM |\t  current alpha:tensor([ 13.9268,   8.0631, -10.9534,  -8.4597, -12.6850,  12.1958,  -2.3954,\n",
      "          7.6218,  12.9591,  11.4900,   8.7648,  28.6055,  -7.1489,  -7.1221,\n",
      "          9.5521, -10.3820], device='cuda:0')\n",
      "07/07 04:33:59 AM |\t  current weight:tensor([1.7613e+00, 1.7607e+00, 3.0820e-05, 3.7301e-04, 5.4552e-06, 1.7613e+00,\n",
      "        1.4711e-01, 1.7604e+00, 1.7613e+00, 1.7613e+00, 1.7610e+00, 1.7613e+00,\n",
      "        1.3828e-03, 1.4204e-03, 1.7611e+00, 5.4571e-05], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "07/07 04:33:59 AM |\t  noise:None mean:1.0 max: 1.4475584030151367 min: 0.7571855783462524\n",
      "07/07 04:34:08 AM |\t  teacher test loss : 0.758735\n",
      "07/07 04:34:08 AM |\t  teacher top1 : 90.289474\n",
      "07/07 04:34:08 AM |\t  teacher top5 : 90.289474\n",
      "07/07 04:34:08 AM |\t  teacher test loss : 0.758735\n",
      "07/07 04:34:16 AM |\t  student test loss : 0.772225\n",
      "07/07 04:34:16 AM |\t  student top1 : 91.894737\n",
      "07/07 04:34:16 AM |\t  student top5 : 91.894737\n",
      "07/07 04:34:16 AM |\t  student test loss : 0.772225\n",
      "07/07 04:34:16 AM |\t  correct label mean weight: 1.0812886953353882, wrong label mean weight: 0.7968152165412903\n",
      "07/07 04:34:16 AM |\t  find a better model\n",
      "07/07 04:34:17 AM |\t  current best accuracy:91.89473684210526\n",
      "07/07 04:34:17 AM |\t  improvment:-0.8595288619399071\n",
      "07/07 04:34:17 AM |\t  \n",
      "\n",
      "  ----------------epoch:3,\t\tlr_w:1.4056224899598392e-06,\t\tlr_v:1.4056224899598392e-06,\t\tlr_A:70.28112449799197----------------\n",
      "07/07 04:35:52 AM |\t  \n",
      "\n",
      "07/07 04:35:53 AM |\t   19.7%:||W_train_loss:0.4995707|V_train_syn_loss:0.5226124|V_train_loss:0.5148333|V_val_loss:0.3631296|V_star_val_loss:0.3590944|improvement:-0.0040352|w_top1:73.8750000|w_top5:73.8750000|v_top1:72.3750000|v_top5:72.3750000|\n",
      "07/07 04:35:53 AM |\t  avg weight:tensor([1.3712, 0.8905, 1.1250, 1.1666, 1.0443, 0.9474, 0.8003, 0.8420, 1.1698,\n",
      "        1.1233, 1.0523, 1.0717, 0.7534, 0.5652, 1.1237, 0.9532],\n",
      "       device='cuda:0')\n",
      "07/07 04:35:53 AM |\t  current alpha:tensor([  9.6771, -25.5658, -18.9539,   7.7500, -12.4668,  -8.9685,  -8.8822,\n",
      "        -12.7209, -92.1344,   3.2723,  18.2332,  -7.1237, -11.8703, -10.2219,\n",
      "         16.1290,  18.5442], device='cuda:0')\n",
      "07/07 04:35:53 AM |\t  current weight:tensor([2.6826e+00, 2.1159e-11, 1.5739e-08, 2.6816e+00, 1.0335e-05, 3.4162e-04,\n",
      "        3.7242e-04, 8.0159e-06, 0.0000e+00, 2.5847e+00, 2.6827e+00, 2.1598e-03,\n",
      "        1.8766e-05, 9.7554e-05, 2.6827e+00, 2.6827e+00], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "07/07 04:35:53 AM |\t  noise:None mean:1.0 max: 1.3712307214736938 min: 0.5652050375938416\n",
      "07/07 04:37:27 AM |\t  \n",
      "\n",
      "07/07 04:37:27 AM |\t   39.8%:||W_train_loss:0.4794354|V_train_syn_loss:0.5233981|V_train_loss:0.4620194|V_val_loss:0.3854572|V_star_val_loss:0.3865637|improvement:0.0011065|w_top1:77.8750000|w_top5:77.8750000|v_top1:74.3750000|v_top5:74.3750000|\n",
      "07/07 04:37:27 AM |\t  avg weight:tensor([0.9476, 1.3667, 1.0902, 0.8009, 0.8619, 1.0349, 1.1630, 0.9470, 1.0101,\n",
      "        1.1274, 0.8190, 1.0372, 0.7906, 1.2323, 0.7625, 1.0088],\n",
      "       device='cuda:0')\n",
      "07/07 04:37:27 AM |\t  current alpha:tensor([  21.6150,   -7.6810,  -22.3433, -113.0119,    7.6073,   20.1637,\n",
      "           9.7469,   -9.8859,   21.9418,   12.8373,   10.9259,   12.8422,\n",
      "         -21.4108,    9.0854,   -2.2717,   -3.7305], device='cuda:0')\n",
      "07/07 04:37:27 AM |\t  current weight:tensor([1.7550e+00, 8.0958e-04, 3.4730e-10, 0.0000e+00, 1.7541e+00, 1.7550e+00,\n",
      "        1.7549e+00, 8.9300e-05, 1.7550e+00, 1.7550e+00, 1.7550e+00, 1.7550e+00,\n",
      "        8.8244e-10, 1.7548e+00, 1.6409e-01, 4.1100e-02], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "07/07 04:37:27 AM |\t  noise:None mean:0.9999999403953552 max: 1.3666884899139404 min: 0.7625154852867126\n",
      "07/07 04:39:01 AM |\t  \n",
      "\n",
      "07/07 04:39:01 AM |\t   59.8%:||W_train_loss:0.4396944|V_train_syn_loss:0.5157334|V_train_loss:0.4953693|V_val_loss:0.3183197|V_star_val_loss:0.3182412|improvement:-0.0000785|w_top1:75.6250000|w_top5:75.6250000|v_top1:74.0833333|v_top5:74.0833333|\n",
      "07/07 04:39:01 AM |\t  avg weight:tensor([0.8618, 0.9335, 1.1394, 0.9820, 1.0741, 0.9080, 0.9553, 1.0868, 1.1594,\n",
      "        1.1239, 0.9721, 1.2116, 1.1031, 1.0441, 0.7326, 0.7124],\n",
      "       device='cuda:0')\n",
      "07/07 04:39:01 AM |\t  current alpha:tensor([  6.5812,  -0.5557,   9.5024,  23.1948,   7.6130,  -0.6615, -49.6374,\n",
      "          7.8364,  19.5204,  27.0873,  10.2586,  16.9178,   2.8376, -22.3333,\n",
      "        -22.9727,   9.2842], device='cuda:0')\n",
      "07/07 04:39:01 AM |\t  current weight:tensor([1.3718e+00, 5.0079e-01, 1.3736e+00, 1.3737e+00, 1.3730e+00, 4.6761e-01,\n",
      "        3.8074e-22, 1.3732e+00, 1.3737e+00, 1.3737e+00, 1.3737e+00, 1.3737e+00,\n",
      "        1.2977e+00, 2.7458e-10, 1.4487e-10, 1.3736e+00], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "07/07 04:39:01 AM |\t  noise:None mean:0.9999999403953552 max: 1.211587905883789 min: 0.7123692631721497\n",
      "07/07 04:40:36 AM |\t  \n",
      "\n",
      "07/07 04:40:36 AM |\t   79.9%:||W_train_loss:0.4092624|V_train_syn_loss:0.4919974|V_train_loss:0.4330273|V_val_loss:0.3305485|V_star_val_loss:0.3330153|improvement:0.0024667|w_top1:79.6250000|w_top5:79.6250000|v_top1:75.4687500|v_top5:75.4687500|\n",
      "07/07 04:40:36 AM |\t  avg weight:tensor([1.0496, 0.7864, 1.2981, 0.9500, 0.8629, 1.1688, 0.9829, 0.8010, 1.0114,\n",
      "        1.0413, 0.9910, 0.9179, 0.8910, 0.9868, 1.0402, 1.2207],\n",
      "       device='cuda:0')\n",
      "07/07 04:40:36 AM |\t  current alpha:tensor([ 15.5141,   6.3473, -10.5332,   9.6086,   7.4547,  -5.2138,  -8.9080,\n",
      "         -5.5664,   8.5855,  -5.4706,  -8.4267,   9.5022,  -8.0734, -25.5830,\n",
      "        -10.1207,  21.2120], device='cuda:0')\n",
      "07/07 04:40:36 AM |\t  current weight:tensor([2.2820e+00, 2.2780e+00, 6.0784e-05, 2.2818e+00, 2.2806e+00, 1.2349e-02,\n",
      "        3.0871e-04, 8.6938e-03, 2.2815e+00, 9.5637e-03, 4.9953e-04, 2.2818e+00,\n",
      "        7.1113e-04, 1.7691e-11, 9.1817e-05, 2.2820e+00], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "07/07 04:40:36 AM |\t  noise:None mean:1.0 max: 1.2981274127960205 min: 0.7864474058151245\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-8dd013a43866>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         f\"\\n\\n  ----------------epoch:{epoch},\\t\\tlr_w:{lr_w},\\t\\tlr_v:{lr_v},\\t\\tlr_A:{lr_A}----------------\")\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     w_train_loss,v_accu = my_train(epoch, train_w_dataloader,train_syn_dataloader,train_A_dataloader, valid_dataloader, model_w,\n\u001b[0m\u001b[1;32m     16\u001b[0m                             model_v,  architect, A, w_optimizer, v_optimizer, scheduler_w, scheduler_v, tot_iter,v_accu)\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-c320bc50021a>\u001b[0m in \u001b[0;36mmy_train\u001b[0;34m(epoch, wdataloader, syndataloader, Adataloader, validdataloader, w_model, v_model, architect, A, w_optimizer, v_optimizer, scheduler_w, scheduler_v, tot_iter, past_v_accu)\u001b[0m\n\u001b[1;32m    112\u001b[0m             v_loss = (args.traindata_loss_ratio*loss +\n\u001b[1;32m    113\u001b[0m                       loss_aug*args.syndata_loss_ratio)\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0mv_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m             \u001b[0mobjs_v_syn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_aug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msynsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mobjs_v_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# if(args.valid_begin == 1):\n",
    "#     my_test(valid_dataloader, model_w, -1)  # before train\n",
    "#     my_test(valid_dataloader, model_v, -1)\n",
    "\n",
    "tot_iter = [0]\n",
    "v_accu = 0\n",
    "for epoch in range(args.epochs):\n",
    "    lr_w = scheduler_w.get_lr()[0]\n",
    "    lr_v = scheduler_v.get_lr()[0]\n",
    "    lr_A = architect.scheduler_A.get_lr()[0]\n",
    "\n",
    "    logging.info(\n",
    "        f\"\\n\\n  ----------------epoch:{epoch},\\t\\tlr_w:{lr_w},\\t\\tlr_v:{lr_v},\\t\\tlr_A:{lr_A}----------------\")\n",
    "\n",
    "    w_train_loss,v_accu = my_train(epoch, train_w_dataloader,train_syn_dataloader,train_A_dataloader, valid_dataloader, model_w,\n",
    "                            model_v,  architect, A, w_optimizer, v_optimizer, scheduler_w, scheduler_v, tot_iter,v_accu)\n",
    "\n",
    "    # scheduler_w.step()\n",
    "    # scheduler_v.step()\n",
    "    # architect.scheduler_A.step()\n",
    "\n",
    "\n",
    "\n",
    "w_accu = my_test(test_dataloader,best_w, -2)\n",
    "v_accu = my_test(test_dataloader,best_v, -2)\n",
    "logging.info(f'best w on test:{w_accu} accuracy; best v on test:{v_accu} accuracy')\n",
    "\n",
    "wandb.log({'v_testdata_accuracy': v_accu})\n",
    "wandb.log({'w_testdata_accuracy': w_accu})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
