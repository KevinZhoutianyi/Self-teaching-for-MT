{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd() \n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from model import *\n",
    "import torch\n",
    "from datasets import load_dataset,load_metric\n",
    "from transformers import  AutoTokenizer\n",
    "import torch_optimizer as optim\n",
    "from transformers.optimization import Adafactor, AdafactorSchedule\n",
    "from MT_hyperparams import seed_,max_length\n",
    "import torch.backends.cudnn as cudnn\n",
    "from utils import *\n",
    "from attention_params import *\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, SubsetRandomSampler\n",
    "from torch.autograd import Variable\n",
    "from losses import *\n",
    "from architect import *\n",
    "import logging\n",
    "import sys\n",
    "import transformers\n",
    "import time\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from os.path import exists\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(\"main\")\n",
    "\n",
    "\n",
    "parser.add_argument('--valid_num_points', type=int,             default = 10000, help='validation data number')\n",
    "parser.add_argument('--train_num_points', type=int,             default = 20000, help='train data number')\n",
    "parser.add_argument('--test_num_points', type=int,              default = -1, help='train data number')\n",
    "\n",
    "parser.add_argument('--batch_size', type=int,                   default=4,     help='Batch size')\n",
    "parser.add_argument('--train_w_num_points', type=int,           default=2,      help='train_w_num_points for each batch')\n",
    "parser.add_argument('--train_v_synthetic_num_points', type=int, default=1,      help='train_v_synthetic_num_points for each batch')\n",
    "parser.add_argument('--train_v_num_points', type=int,           default=0,      help='train_v_num_points for each batch')\n",
    "parser.add_argument('--train_A_num_points', type=int,           default=1,      help='train_A_num_points decay for each batch')\n",
    "\n",
    "parser.add_argument('--gpu', type=int,                          default=0,      help='gpu device id')\n",
    "parser.add_argument('--num_workers', type=int,                  default=0,      help='num_workers')\n",
    "parser.add_argument('--model_name_teacher', type=str,           default='roberta-base',      help='model_name')\n",
    "parser.add_argument('--model_name_student', type=str,           default='roberta-base',      help='model_name')\n",
    "parser.add_argument('--model_name_de2en', type=str,             default='roberta-base',      help='model_name')\n",
    "parser.add_argument('--exp_name', type=str,                     default='SST2,withnoise',      help='experiment name')\n",
    "parser.add_argument('--rep_num', type=int,                      default=100,      help='report times for 1 epoch')\n",
    "parser.add_argument('--test_num', type=int,                     default=20000,      help='test times for 1 epoch')\n",
    "\n",
    "parser.add_argument('--epochs', type=int,                       default=50,     help='num of training epochs')\n",
    "parser.add_argument('--pre_epochs', type=int,                   default=0,      help='train model W for x epoch first')\n",
    "parser.add_argument('--grad_clip', type=float,                  default=5,      help='gradient clipping')\n",
    "parser.add_argument('--grad_acc_count', type=float,             default=-1,      help='gradient accumulate steps')\n",
    "\n",
    "parser.add_argument('--w_lr', type=float,                       default=2e-6,   help='learning rate for w')\n",
    "parser.add_argument('--unrolled_w_lr', type=float,              default=2e-6,   help='learning rate for w')\n",
    "parser.add_argument('--v_lr', type=float,                       default=2e-6,   help='learning rate for v')\n",
    "parser.add_argument('--unrolled_v_lr', type=float,              default=2e-6,   help='learning rate for v')\n",
    "parser.add_argument('--A_lr', type=float,                       default=2,   help='learning rate for A')\n",
    "parser.add_argument('--learning_rate_min', type=float,          default=1e-8,   help='learning_rate_min')\n",
    "parser.add_argument('--decay', type=float,                      default=1e-3,   help='weight decay')\n",
    "parser.add_argument('--beta1', type=float,                      default=0.9,    help='momentum')\n",
    "parser.add_argument('--beta2', type=float,                      default=0.999,    help='momentum')\n",
    "parser.add_argument('--warm', type=float,                       default=10,    help='warmup step')\n",
    "parser.add_argument('--num_step_lr', type=float,                default=10,    help='warmup step')\n",
    "parser.add_argument('--decay_lr', type=float,                   default=1,    help='warmup step')\n",
    "# parser.add_argument('--smoothing', type=float,                  default=0.1,    help='labelsmoothing')\n",
    "\n",
    "parser.add_argument('--freeze', type=int,                       default=1,    help='whether freeze the pretrained encoder')\n",
    "\n",
    "parser.add_argument('--traindata_loss_ratio', type=float,       default=0.7,    help='human translated data ratio')\n",
    "parser.add_argument('--syndata_loss_ratio', type=float,         default=0.3,    help='augmented dataset ratio')\n",
    "\n",
    "parser.add_argument('--valid_begin', type=int,                  default=1,      help='whether valid before train')\n",
    "parser.add_argument('--train_A', type=int,                      default=1 ,     help='whether train A')\n",
    "\n",
    "parser.add_argument('--embedding_dim', type=int,                default=300 ,     help='whether train A')\n",
    "parser.add_argument('--out_dim', type=int,                      default=2 ,     help='whether train A')\n",
    "parser.add_argument('--hidden_size', type=int,                  default=64 ,     help='whether train A')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "args = parser.parse_args(args=[])#(args=['--batch_size', '8',  '--no_cuda'])#used in ipynb\n",
    "args.test_num = args.test_num//args.batch_size * args.batch_size\n",
    "args.rep_num = args.rep_num//args.batch_size * args.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33monlydrinkwater\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.20 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.17"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>g:\\GitCode\\Self-teaching-for-machine-translation\\BERT\\wandb\\run-20220630_172325-2hyfhouc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/onlydrinkwater/Selftraining/runs/2hyfhouc\" target=\"_blank\">SST2,withnoise</a></strong> to <a href=\"https://wandb.ai/onlydrinkwater/Selftraining\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/onlydrinkwater/Selftraining/runs/2hyfhouc?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x2ce7dbf1be0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://wandb.ai/ check the running status online\n",
    "import wandb\n",
    "os.environ['WANDB_API_KEY'] = 'a166474b1b7ad33a0549adaaec19a2f6d3f91d87'\n",
    "os.environ['WANDB_NAME'] = args.exp_name\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":16:8\"\n",
    "\n",
    "wandb.init(project=\"Selftraining\", config=args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/30 05:23:33 PM |\t  Reusing dataset glue (C:\\Users\\kevin\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 604.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/30 05:23:33 PM |\t  Namespace(A_lr=2, batch_size=4, beta1=0.9, beta2=0.999, decay=0.001, decay_lr=1, embedding_dim=300, epochs=50, exp_name='SST2,withnoise', freeze=1, gpu=0, grad_acc_count=-1, grad_clip=5, hidden_size=64, learning_rate_min=1e-08, model_name_de2en='roberta-base', model_name_student='roberta-base', model_name_teacher='roberta-base', num_step_lr=10, num_workers=0, out_dim=2, pre_epochs=0, rep_num=1000, syndata_loss_ratio=0.3, test_num=20000, test_num_points=-1, train_A=1, train_A_num_points=1, train_num_points=20000, train_v_num_points=0, train_v_synthetic_num_points=1, train_w_num_points=2, traindata_loss_ratio=0.7, unrolled_v_lr=2e-06, unrolled_w_lr=2e-06, v_lr=2e-06, valid_begin=1, valid_num_points=10000, w_lr=2e-06, warm=10)\n",
      "06/30 05:23:33 PM |\t  DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence', 'label', 'idx'],\n",
      "        num_rows: 67349\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sentence', 'label', 'idx'],\n",
      "        num_rows: 872\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sentence', 'label', 'idx'],\n",
      "        num_rows: 1821\n",
      "    })\n",
      "})\n",
      "06/30 05:23:33 PM |\t  {'sentence': \"that 's far too tragic to merit such superficial treatment \", 'idx': 5, 'label': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# logging file\n",
    "now = time.strftime(\"%Y-%m-%d-%H_%M_%S\", time.localtime(time.time()))\n",
    "\n",
    "log_format = '%(asctime)s |\\t  %(message)s'\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO,\n",
    "                    format=log_format, datefmt='%m/%d %I:%M:%S %p')\n",
    "fh = logging.FileHandler(os.path.join(\n",
    "    \"./log/\", now+'.txt'), 'w', encoding=\"UTF-8\")\n",
    "fh.setFormatter(logging.Formatter(log_format))\n",
    "logging.getLogger().addHandler(fh)\n",
    "dataset = load_dataset('glue', 'sst2')\n",
    "\n",
    "logging.info(args)\n",
    "logging.info(dataset)\n",
    "logging.info(dataset['train'][5])\n",
    "\n",
    "\n",
    "# Setting the seeds\n",
    "np.random.seed(seed_)\n",
    "torch.cuda.set_device(args.gpu)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cudnn.benchmark = True\n",
    "torch.manual_seed(seed_)\n",
    "cudnn.enabled = True\n",
    "torch.cuda.manual_seed(seed_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/30 05:23:38 PM |\t  modelsize:124.697433MB\n",
      "06/30 05:23:39 PM |\t  modelsize:124.697433MB\n",
      "06/30 05:23:41 PM |\t  modelsize:124.697433MB\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "modelname = args.model_name_teacher\n",
    "pretrained = AutoModelForMaskedLM.from_pretrained(modelname)\n",
    "pathname = modelname.replace('/', '')\n",
    "logging.info(f'modelsize:{count_parameters_in_MB(pretrained)}MB')\n",
    "\n",
    "if(exists(pathname+'.pt') == False):\n",
    "    logging.info(f'saving to {pathname}')\n",
    "    torch.save(pretrained, pathname+'.pt')\n",
    "\n",
    "modelname = args.model_name_student\n",
    "pretrained = AutoModelForMaskedLM.from_pretrained(modelname)\n",
    "pathname = modelname.replace('/', '')\n",
    "logging.info(f'modelsize:{count_parameters_in_MB(pretrained)}MB')\n",
    "if(exists(pathname+'.pt') == False):\n",
    "    logging.info(f'saving to {pathname}')\n",
    "    torch.save(pretrained, pathname+'.pt')\n",
    "\n",
    "modelname = args.model_name_de2en\n",
    "pretrained = AutoModelForMaskedLM.from_pretrained(modelname)\n",
    "pathname = modelname.replace('/', '')\n",
    "logging.info(f'modelsize:{count_parameters_in_MB(pretrained)}MB')\n",
    "if(exists(pathname+'.pt') == False):\n",
    "    logging.info(f'saving to {pathname}')\n",
    "    torch.save(pretrained, pathname+'.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/30 05:23:41 PM |\t  Loading cached shuffled indices for dataset at C:\\Users\\kevin\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-36b1289ef425e728.arrow\n",
      "06/30 05:23:41 PM |\t  Loading cached split indices for dataset at C:\\Users\\kevin\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-e940625853b8d0ac.arrow and C:\\Users\\kevin\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-f88915528015136b.arrow\n",
      "06/30 05:23:41 PM |\t  Loading cached shuffled indices for dataset at C:\\Users\\kevin\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-6b2827c92319cc33.arrow\n",
      "06/30 05:23:41 PM |\t  train len: 20000\n",
      "06/30 05:23:41 PM |\t  train_w_num_points_len and train_v_num_points_len: 10000\n",
      "06/30 05:23:41 PM |\t  train_v_synthetic_num_points_len: 5000\n",
      "06/30 05:23:41 PM |\t  train_A_num_points_len: 5000\n",
      "06/30 05:23:41 PM |\t  valid len: 10000\n",
      "06/30 05:23:41 PM |\t  test len: 872\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "num_batch = args.train_num_points//args.batch_size\n",
    "\n",
    "\n",
    "def r(a, b):\n",
    "    return b*(a//b)\n",
    "\n",
    "\n",
    "temp = dataset['train'].shuffle(seed=seed_).select(range(r(args.train_num_points, args.batch_size) + r(args.valid_num_points, args.batch_size))).\\\n",
    "    train_test_split(test_size=r(args.valid_num_points, args.batch_size)/(\n",
    "        r(args.train_num_points, args.batch_size) + r(args.valid_num_points, args.batch_size)))\n",
    "train = temp['train']\n",
    "valid = temp['test']\n",
    "# # valid = dataset['validation'].shuffle(seed=seed_).select(range(args.valid_num_points))\n",
    "# .select(range(args.test_num_points))#[L_t+L_v:L_t+L_v+L_test]\n",
    "test = dataset['validation'].shuffle(seed=seed_)\n",
    "\n",
    "# #TODO: Syn_input should be monolingual data, should try en-fo's en. cuz wmt may align\n",
    "logging.info(\"train len: %d\", len(train))\n",
    "\n",
    "'''\n",
    "each mini batch consist of : \n",
    "1. data to train W\n",
    "2. monolingual data to generate parallel data\n",
    "3. data to train V\n",
    "4. data to train A\n",
    "'''\n",
    "train_w_num_points_len = num_batch * args.train_w_num_points\n",
    "train_v_synthetic_num_points_len = num_batch * args.train_v_synthetic_num_points\n",
    "train_v_num_points_len = num_batch * args.train_v_num_points\n",
    "train_A_num_points_len = num_batch * args.train_A_num_points\n",
    "logging.info(\"train_w_num_points_len and train_v_num_points_len: %d\", train_w_num_points_len)\n",
    "logging.info(\"train_v_synthetic_num_points_len: %d\",\n",
    "             train_v_synthetic_num_points_len)\n",
    "# logging.info(\"train_v_num_points_len: %d\", train_v_num_points_len)\n",
    "logging.info(\"train_A_num_points_len: %d\", train_A_num_points_len)\n",
    "\n",
    "attn_idx_list = torch.arange(train_w_num_points_len).cuda()\n",
    "logging.info(\"valid len: %d\", len(valid))\n",
    "logging.info(\"test len: %d\", len(test))\n",
    "# logging.info(test[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get train data start\n",
      "Input shape: \n",
      "torch.Size([20000, 64]) torch.Size([20000, 64]) torch.Size([20000])\n",
      "06/30 05:23:42 PM |\t  train data get\n",
      "06/30 05:23:42 PM |\t  train data loader get\n",
      "get train data start\n",
      "Input shape: \n",
      "torch.Size([10000, 67]) torch.Size([10000, 67]) torch.Size([10000])\n",
      "06/30 05:23:43 PM |\t  valid data loader get\n",
      "get train data start\n",
      "Input shape: \n",
      "torch.Size([872, 63]) torch.Size([872, 63]) torch.Size([872])\n",
      "06/30 05:23:43 PM |\t  test data loader get\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create the DataLoader for our training set.\n",
    "train_data = get_data(train, tokenizer)\n",
    "logging.info('train data get')\n",
    "train_dataloader = DataLoader(train_data, sampler=SequentialSampler(train_data),\n",
    "                              batch_size=args.batch_size, pin_memory=args.num_workers > 0, num_workers=args.num_workers)\n",
    "logging.info('train data loader get')\n",
    "# Create the DataLoader for our training set.\n",
    "valid_data = get_data(valid, tokenizer)\n",
    "valid_dataloader = DataLoader(valid_data, sampler=SequentialSampler(valid_data),\n",
    "                              batch_size=args.batch_size, pin_memory=args.num_workers > 0, num_workers=args.num_workers)\n",
    "logging.info('valid data loader get')\n",
    "# Create the DataLoader for our training set.\n",
    "test_data = get_data(test, tokenizer)\n",
    "test_dataloader = DataLoader(test_data, sampler=SequentialSampler(test_data),\n",
    "                             batch_size=args.batch_size, pin_memory=args.num_workers > 0, num_workers=args.num_workers)  # , sampler=RandomSampler(test_data)\n",
    "logging.info('test data loader get')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "A = attention_params(train_w_num_points_len)  # half of train regarded as u\n",
    "A = A.cuda()\n",
    "\n",
    "# TODO: model loaded from saved model\n",
    "model_w = Model(tokenizer, args, 'teacher')\n",
    "model_w = model_w.cuda()\n",
    "w_optimizer = torch.optim.Adam(model_w.parameters(\n",
    "),  lr=args.w_lr,  betas=(args.beta1, args.beta2), eps=1e-8)\n",
    "# w_optimizer = Adafactor(model_w.parameters(), lr = args.w_lr ,scale_parameter=False, relative_step=False , warmup_init=False,clip_threshold=1,beta1=0,eps=( 1e-30,0.001))\n",
    "scheduler_w = StepLR(\n",
    "    w_optimizer, step_size=args.num_step_lr, gamma=args.decay_lr)\n",
    "# scheduler_w  = Scheduler(w_optimizer,dim_embed=512, warmup_steps=args.warm, initlr = args.w_lr)\n",
    "\n",
    "\n",
    "model_v = Model(tokenizer, args, 'student')\n",
    "model_v = model_v.cuda()\n",
    "v_optimizer = torch.optim.Adam(model_v.parameters(\n",
    "),  lr=args.v_lr,  betas=(args.beta1, args.beta2), eps=1e-8)\n",
    "# v_optimizer =Adafactor(model_v.parameters(), lr = args.v_lr ,scale_parameter=False, relative_step=False , warmup_init=False,clip_threshold=1,beta1=0,eps=( 1e-30,0.001))\n",
    "scheduler_v = StepLR(\n",
    "    v_optimizer, step_size=args.num_step_lr, gamma=args.decay_lr)\n",
    "# scheduler_v  = Scheduler(v_optimizer,dim_embed=512, warmup_steps=args.warm, initlr = args.v_lr)\n",
    "\n",
    "\n",
    "architect = Architect(model_w, model_v,  A, args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def my_test(_dataloader,model,epoch):\n",
    "    # logging.info(f\"GPU mem before test:{getGPUMem(device)}%\")\n",
    "    acc = 0\n",
    "    counter = 0\n",
    "    model.eval()\n",
    "    objs_top1 = AvgrageMeter()\n",
    "    objs_top5 = AvgrageMeter()\n",
    "    \n",
    "    for step, batch in enumerate(_dataloader):\n",
    "        test_dataloaderx = Variable(batch[0], requires_grad=False).to(device, non_blocking=False)\n",
    "        test_dataloaderx_attn = Variable(batch[1], requires_grad=False).to(device, non_blocking=False)\n",
    "        test_dataloadery = Variable(batch[2], requires_grad=False).to(device, non_blocking=False)\n",
    "        logits,ls = my_loss(test_dataloaderx,test_dataloaderx_attn,test_dataloadery,model)\n",
    "        n = test_dataloaderx.shape[0]\n",
    "        acc+= ls.item()\n",
    "        counter+= 1\n",
    "        prec1, prec5 = accuracy(logits, test_dataloadery, topk=(1, 1))\n",
    "                \n",
    "        objs_top1.update(prec1.item(), n)\n",
    "        \n",
    "        objs_top5.update(prec5.item(), n)\n",
    "    acc = objs_top1.avg\n",
    "    logging.info('%s test loss : %f',model.name,acc/(counter))\n",
    "    logging.info('%s top1 : %f',model.name,objs_top1.avg)\n",
    "    objs_top1.reset()\n",
    "    logging.info('%s top5 : %f',model.name,objs_top5.avg)\n",
    "    objs_top5.reset()\n",
    "    logging.info('%s test loss : %f',model.name,acc/(counter))\n",
    "    wandb.log({'test_loss'+model.name: acc/counter})\n",
    "    model.train()\n",
    "    return acc\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "attn_idx_list = torch.arange(train_w_num_points_len).cuda()\n",
    "\n",
    "def my_train(epoch, _dataloader, validdataloader, w_model, v_model, architect, A, w_optimizer, v_optimizer, lr_w, lr_v, tot_iter, past_v_accu):\n",
    "    objs_w = AvgrageMeter()\n",
    "    objs_v_syn = AvgrageMeter()\n",
    "    objs_v_train = AvgrageMeter()\n",
    "    objs_v_star_val = AvgrageMeter()\n",
    "    objs_w_top1 = AvgrageMeter()\n",
    "    objs_w_top5 = AvgrageMeter()\n",
    "    objs_v_top1 = AvgrageMeter()\n",
    "    objs_v_top5 = AvgrageMeter()\n",
    "    w_trainloss_acc = 0\n",
    "    # now  train_x is [num of batch, datasize], so its seperate batch for the code below\n",
    "    wsize = args.train_w_num_points\n",
    "    synsize = args.train_v_synthetic_num_points\n",
    "    vsize = args.train_v_num_points\n",
    "    Asize = args.train_A_num_points\n",
    "    loader_len = len(_dataloader)\n",
    "    split_size = [wsize, synsize, vsize, Asize]\n",
    "    bs = args.batch_size\n",
    "    w_model.train()\n",
    "    v_model.train()\n",
    "\n",
    "    logging.info(f\"split size:{split_size}\")\n",
    "    for step, batch in enumerate(_dataloader):\n",
    "        tot_iter[0] += bs\n",
    "\n",
    "        # logging.info(f\"GPU mem :{getGPUMem(device)}%\")\n",
    "        train_x = Variable(batch[0], requires_grad=False).to(\n",
    "            device, non_blocking=False)\n",
    "        train_x_attn = Variable(batch[1], requires_grad=False).to(\n",
    "            device, non_blocking=False)\n",
    "        train_y = Variable(batch[2], requires_grad=False).to(\n",
    "            device, non_blocking=False)\n",
    "        (input_w, input_syn, input_v, input_A_v) = torch.split(train_x, split_size)\n",
    "        (input_w_attn, input_syn_attn, input_v_attn,\n",
    "         input_A_v_attn) = torch.split(train_x_attn, split_size)\n",
    "        (output_w, _, output_v, output_A_v) = torch.split(train_y, split_size)\n",
    "\n",
    "        attn_idx = attn_idx_list[wsize*step:(wsize*step+wsize)]\n",
    "\n",
    "        \n",
    "        input_w[step%wsize]+=1 # noise input\n",
    "        if(True):  # let v train on syn data and w data\n",
    "            input_v = input_w\n",
    "            input_v_attn = input_w_attn\n",
    "            output_v = output_w\n",
    "            vsize = wsize\n",
    "\n",
    "\n",
    "        if (args.train_A == 1 and epoch>=args.pre_epochs):\n",
    "            epsilon_w = args.unrolled_w_lr\n",
    "            epsilon_v  = args.unrolled_v_lr\n",
    "            v_star_val_loss = architect.step(input_w,  output_w, input_w_attn, w_optimizer,\n",
    "                                             input_v, input_v_attn, output_v, input_syn, input_syn_attn,\n",
    "                                             input_A_v, input_A_v_attn, output_A_v, attn_idx,v_optimizer,\n",
    "                                             epsilon_w, epsilon_v,args.grad_clip)\n",
    "            objs_v_star_val.update(v_star_val_loss, Asize)\n",
    "\n",
    "        w_optimizer.zero_grad()\n",
    "        logits, loss_w = CTG_loss(input_w, input_w_attn, output_w,\n",
    "                                  A,attn_idx, w_model)\n",
    "        w_trainloss_acc += loss_w.item()\n",
    "        loss_w.backward()\n",
    "        objs_w.update(loss_w.item(), wsize)\n",
    "        w_optimizer.step()\n",
    "\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm(w_model.parameters(), args.grad_clip)\n",
    "        prec1, prec5 = accuracy(logits, output_w, topk=(1, 1))\n",
    "        objs_w_top1.update(prec1.item(), wsize)\n",
    "        objs_w_top5.update(prec5.item(), wsize)\n",
    "\n",
    "        if(epoch >= args.pre_epochs):\n",
    "            v_optimizer.zero_grad()\n",
    "            loss_aug = calc_loss_aug(\n",
    "                input_syn, input_syn_attn, w_model, v_model)\n",
    "            logits, loss = my_loss2(input_v, input_v_attn, output_v,\n",
    "                                    v_model)\n",
    "            v_loss = (args.traindata_loss_ratio*loss +\n",
    "                      loss_aug*args.syndata_loss_ratio)\n",
    "            v_loss.backward()\n",
    "            objs_v_syn.update(loss_aug.item(), synsize)\n",
    "            objs_v_train.update(loss.item(), vsize)\n",
    "            v_optimizer.step()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm(v_model.parameters(), args.grad_clip)\n",
    "            prec1, prec5 = accuracy(logits, output_v, topk=(1, 1))\n",
    "            objs_v_top1.update(prec1.item(), vsize)\n",
    "            objs_v_top5.update(prec5.item(), vsize)\n",
    "\n",
    "        input_w[step%wsize]-=1\n",
    "\n",
    "\n",
    "\n",
    "        progress = 100*(step)/(loader_len-1)\n",
    "        if(tot_iter[0] % args.test_num == 0 and tot_iter[0] != 0):\n",
    "            w_accu = my_test(validdataloader, model_w, epoch)\n",
    "            v_accu = my_test(validdataloader, model_v, epoch)\n",
    "            if(v_accu>past_v_accu):\n",
    "                past_v_accu = v_accu\n",
    "                logging.info('find a better model')\n",
    "                torch.save(model_w, './model/'+'model_w.pt')  # +now+\n",
    "                torch.save(model_v, './model/'+'model_v.pt')\n",
    "                torch.save(A, './model/'+'A.pt')\n",
    "                torch.save(model_w.state_dict(), os.path.join(\n",
    "                    wandb.run.dir, \"model_w.pt\"))\n",
    "                torch.save(model_v.state_dict(), os.path.join(\n",
    "                    wandb.run.dir, \"model_v.pt\"))\n",
    "                torch.save(A.state_dict(), os.path.join(wandb.run.dir, \"A.pt\"))\n",
    "                wandb.save(\"./files/*.pt\", base_path=\"./files\", policy=\"live\")\n",
    "\n",
    "        if(tot_iter[0] % args.rep_num == 0 and tot_iter[0] != 0):\n",
    "            logging.info(f\"{progress:5.3}%:\\t  W_train_loss:{objs_w.avg:^.7f}\\tV_train_syn_loss:{objs_v_syn.avg:^.7f}\\tV_train_loss:{objs_v_train.avg:^.7f}\\t  V_star_val_loss:{objs_v_star_val.avg:^.7f}\\t w_top1:{objs_w_top1.avg:^.7f}\\t  w_top5:{objs_w_top5.avg:^.7f}\\t v_top1:{objs_v_top1.avg:^.7f}\\t v_top5:{objs_v_top5.avg:^.7f}\\t \")\n",
    "            with torch.no_grad():\n",
    "                temp = A(input_w, input_w_attn)\n",
    "            logging.info(f\"weight:{temp}\")\n",
    "            logging.info(f'noise input weight:{temp[step%wsize]}')\n",
    "            wandb.log({'W_train_loss': objs_w.avg})\n",
    "            wandb.log({'V_train_syn_loss': objs_v_syn.avg})\n",
    "            wandb.log({'V_train_loss': objs_v_train.avg})\n",
    "            wandb.log({'V_star_val_loss': objs_v_star_val.avg})\n",
    "            wandb.log({'W_accuracy': objs_w_top1.avg})\n",
    "            wandb.log({'v_accuracy': objs_v_top1.avg})\n",
    "            objs_v_syn.reset()\n",
    "            objs_v_train.reset()\n",
    "            objs_w.reset()\n",
    "            objs_v_star_val.reset()\n",
    "            objs_w_top1.reset()\n",
    "            objs_w_top5.reset()\n",
    "    return w_trainloss_acc,past_v_accu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/30 05:23:44 PM |\t  \n",
      "\n",
      "  ----------------epoch:0,\t\tlr_w:2e-06,\t\tlr_v:2e-06,\t\tlr_A:2----------------\n",
      "06/30 05:23:44 PM |\t  split size:[2, 1, 0, 1]\n",
      "tensor([1.0000e-04, 1.0000e-04], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([1.0000e-04, 1.0000e-04], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([1.0000e-04, 1.0000e-04], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([1.0000e-04, 1.0000e-04], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([1.0000e-04, 1.0000e-04], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([0.0001, 0.0001], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([0.0001, 0.0001], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([0.0001, 0.0001], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([0.0001, 0.0001], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([0.0001, 0.0001], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([0.0001, 0.0001], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([0.0001, 0.0001], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([1.0000e-04, 1.0000e-04], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([1.0000e-04, 1.0000e-04], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([1.0000e-04, 1.0000e-04], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([1.0000e-04, 1.0000e-04], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([1.0000e-04, 1.0000e-04], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([9.9988e-05, 9.9990e-05], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([1.0000e-04, 1.0000e-04], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([1.0000e-04, 1.0000e-04], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([1.0000e-04, 1.0000e-04], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([1.0000e-04, 1.0000e-04], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([1.0000e-04, 1.0000e-04], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([0.0001, 0.0001], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([1.0000e-04, 1.0000e-04], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([1.0000e-04, 1.0000e-04], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([1.0000e-04, 1.0000e-04], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([1.0000e-04, 1.0000e-04], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([1.0000e-04, 1.0000e-04], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([9.9980e-05, 9.9990e-05], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([1.0000e-04, 1.0000e-04], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([1.0000e-04, 1.0000e-04], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([1.0000e-04, 1.0000e-04], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([1.0000e-04, 1.0000e-04], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([1.0000e-04, 1.0000e-04], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([1.0001e-04, 9.9973e-05], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([1.0000e-04, 1.0000e-04], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([1.0000e-04, 1.0000e-04], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([1.0000e-04, 1.0000e-04], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([1.0000e-04, 1.0000e-04], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([1.0000e-04, 1.0000e-04], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([1.0000e-04, 9.9997e-05], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([1.0000e-04, 1.0000e-04], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([1.0000e-04, 1.0000e-04], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([1.0000e-04, 1.0000e-04], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([1.0000e-04, 1.0000e-04], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([1.0000e-04, 1.0000e-04], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([1.0000e-04, 9.9996e-05], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([0.0001, 0.0001], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([0.0001, 0.0001], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([0.0001, 0.0001], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([0.0001, 0.0001], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([0.0001, 0.0001], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([9.9996e-05, 9.9996e-05], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([1.0000e-04, 1.0000e-04], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([1.0000e-04, 1.0000e-04], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([1.0000e-04, 1.0000e-04], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([1.0000e-04, 1.0000e-04], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([1.0000e-04, 1.0000e-04], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([9.9996e-05, 1.0000e-04], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([1.0000e-04, 1.0000e-04], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([1.0000e-04, 1.0000e-04], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([1.0000e-04, 1.0000e-04], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([1.0000e-04, 1.0000e-04], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([1.0000e-04, 1.0000e-04], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([9.9998e-05, 1.0001e-04], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([1.0000e-04, 1.0000e-04], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([1.0000e-04, 1.0000e-04], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([1.0000e-04, 1.0000e-04], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([1.0000e-04, 1.0000e-04], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([1.0000e-04, 1.0000e-04], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([1.0000e-04, 9.9997e-05], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([1.0000e-04, 1.0000e-04], device='cuda:0', grad_fn=<IndexBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11924/3179711576.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m         f\"\\n\\n  ----------------epoch:{epoch},\\t\\tlr_w:{lr_w},\\t\\tlr_v:{lr_v},\\t\\tlr_A:{lr_A}----------------\")\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     w_train_loss,v_accu = my_train(epoch, train_dataloader, valid_dataloader, model_w,\n\u001b[0m\u001b[0;32m     16\u001b[0m                             model_v,  architect, A, w_optimizer, v_optimizer, lr_w, lr_v, tot_iter,v_accu)\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11924/1833416813.py\u001b[0m in \u001b[0;36mmy_train\u001b[1;34m(epoch, _dataloader, validdataloader, w_model, v_model, architect, A, w_optimizer, v_optimizer, lr_w, lr_v, tot_iter, past_v_accu)\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[0mepsilon_w\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munrolled_w_lr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mepsilon_v\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munrolled_v_lr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m             v_star_val_loss = architect.step(input_w,  output_w, input_w_attn, w_optimizer,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                              \u001b[0minput_v\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_v_attn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_v\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_syn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_syn_attn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m                                              \u001b[0minput_A_v\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_A_v_attn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_A_v\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattn_idx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv_optimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mg:\\GitCode\\Self-teaching-for-machine-translation\\BERT\\architect.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, input_w, output_w, input_w_attn, w_optimizer, input_v, input_v_attn, output_v, input_syn, input_syn_attn, input_A_v, input_A_v_attn, output_A_v, attn_idx, v_optimizer, lr_w, lr_v, clip)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_grad_norm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munrolled_w_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m         unrolled_v_model = self._compute_unrolled_v_model(\n\u001b[0m\u001b[0;32m    174\u001b[0m             input_v, input_v_attn, output_v, input_syn, input_syn_attn, unrolled_w_model,  lr_v, v_optimizer)\n\u001b[0;32m    175\u001b[0m         \u001b[0munrolled_v_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mg:\\GitCode\\Self-teaching-for-machine-translation\\BERT\\architect.py\u001b[0m in \u001b[0;36m_compute_unrolled_v_model\u001b[1;34m(self, input_v, input_v_attn, output_v, input_syn, input_syn_attn, unrolled_w_model, eta_v, v_optimizer)\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1e-08\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meta_v\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m         unrolled_v_model = self._construct_v_model_from_theta(\n\u001b[0m\u001b[0;32m    133\u001b[0m             \u001b[0mtheta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdenom\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m         )\n",
      "\u001b[1;32mg:\\GitCode\\Self-teaching-for-machine-translation\\BERT\\architect.py\u001b[0m in \u001b[0;36m_construct_v_model_from_theta\u001b[1;34m(self, theta)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m         \u001b[1;31m# create the new bart model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m         \u001b[0mv_model_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[1;31m# encoder update\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mg:\\GitCode\\Self-teaching-for-machine-translation\\BERT\\model.py\u001b[0m in \u001b[0;36mnew\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mnew\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'unknown'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m         model_new = Model( self.tokenizer,\n\u001b[0m\u001b[0;32m     76\u001b[0m                        args=self.args, name=name).cuda()\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mg:\\GitCode\\Self-teaching-for-machine-translation\\BERT\\model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, tokenizer, args, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'none'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m         self.model = torch.load(\n\u001b[0m\u001b[0;32m     54\u001b[0m             args.model_name_teacher.replace('/', '')+'.pt').roberta.cuda()\n\u001b[0;32m     55\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'student'\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'student*'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mcuda\u001b[1;34m(self, device)\u001b[0m\n\u001b[0;32m    678\u001b[0m             \u001b[0mModule\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m         \"\"\"\n\u001b[1;32m--> 680\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mxpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    568\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 570\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    568\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 570\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    568\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 570\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    568\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 570\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    568\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 570\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    568\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 570\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    591\u001b[0m             \u001b[1;31m# `with torch.no_grad():`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m                 \u001b[0mparam_applied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    594\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    678\u001b[0m             \u001b[0mModule\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m         \"\"\"\n\u001b[1;32m--> 680\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mxpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# if(args.valid_begin == 1):\n",
    "#     my_test(valid_dataloader, model_w, -1)  # before train\n",
    "#     my_test(valid_dataloader, model_v, -1)\n",
    "\n",
    "tot_iter = [0]\n",
    "v_accu = 0\n",
    "for epoch in range(args.epochs):\n",
    "    lr_w = scheduler_w.get_lr()[0]\n",
    "    lr_v = scheduler_v.get_lr()[0]\n",
    "    lr_A = architect.scheduler_A.get_lr()[0]\n",
    "\n",
    "    logging.info(\n",
    "        f\"\\n\\n  ----------------epoch:{epoch},\\t\\tlr_w:{lr_w},\\t\\tlr_v:{lr_v},\\t\\tlr_A:{lr_A}----------------\")\n",
    "\n",
    "    w_train_loss,v_accu = my_train(epoch, train_dataloader, valid_dataloader, model_w,\n",
    "                            model_v,  architect, A, w_optimizer, v_optimizer, lr_w, lr_v, tot_iter,v_accu)\n",
    "\n",
    "    scheduler_w.step()\n",
    "    scheduler_v.step()\n",
    "    architect.scheduler_A.step()\n",
    "\n",
    "    logging.info(f\"w_train_loss:{w_train_loss}\")\n",
    "\n",
    "\n",
    "torch.save(model_v, './model/'+now+'model_w.pt')\n",
    "torch.save(model_v, './model/'+now+'model_v.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('python38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d33c3b0ef123e851f98887a8750ca7da758e4ff258891935cfe6ff9c0394387"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
