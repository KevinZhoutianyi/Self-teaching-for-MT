{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import math\n",
    "from utils import *\n",
    "from opt import *\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, SubsetRandomSampler\n",
    "\n",
    "from datasets import load_dataset,load_metric\n",
    "import torch\n",
    "import logging\n",
    "import numpy as np\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "import sys\n",
    "import time\n",
    "from transformers.optimization import Adafactor\n",
    "import os\n",
    "import gc\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartForConditionalGeneration, BartConfig\n",
    "configuration = BartConfig(vocab_size=32768 ,max_position_embeddings=512,d_model = 512,encoder_layers=6,encoder_ffn_dim=2048,encoder_attention_heads=8,\\\n",
    "    dropout=0.1,activation_function='relu')\n",
    "transformer = BartForConditionalGeneration(configuration).cuda()\n",
    "transformer.model.encoder.embed_positions = PositionalEncoding(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/25 08:02:17 PM |\t  test step: 992\n",
      "06/25 08:02:17 PM |\t  rep step: 96\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "local_test = 1\n",
    "if(local_test==0):\n",
    "    max_length= 128\n",
    "    test_step = 500000\n",
    "    report_step = 10000\n",
    "    seed = 2\n",
    "    bs = 128 \n",
    "    lr = 1e-4\n",
    "    train_num = 1000000\n",
    "    valid_num = 2000\n",
    "    test_num = 2000\n",
    "else:\n",
    "    max_length= 128\n",
    "    test_step = 1000\n",
    "    report_step = 100\n",
    "    seed = 2\n",
    "    bs = 32\n",
    "    lr = 1e-4\n",
    "    train_num = 200\n",
    "    valid_num = 100\n",
    "    test_num = 100\n",
    "\n",
    "\n",
    "test_step = test_step//bs * bs\n",
    "report_step = report_step//bs * bs\n",
    "\n",
    "now = time.strftime(\"%Y-%m-%d-%H_%M_%S\",time.localtime(time.time())) \n",
    "log_format = '%(asctime)s |\\t  %(message)s'\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO,\n",
    "    format=log_format, datefmt='%m/%d %I:%M:%S %p')\n",
    "fh = logging.FileHandler(os.path.join(\"./log/\", now+'.txt'),'w',encoding = \"UTF-8\")\n",
    "fh.setFormatter(logging.Formatter(log_format))\n",
    "logging.getLogger().addHandler(fh)\n",
    "\n",
    "logging.info(f\"test step: {test_step}\")\n",
    "logging.info(f\"rep step: {report_step}\")\n",
    "\n",
    "# Setting the seeds\n",
    "np.random.seed(seed)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cudnn.benchmark = True\n",
    "torch.manual_seed(seed)\n",
    "cudnn.enabled=True\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/25 08:02:18 PM |\t  Reusing dataset wmt14 (C:\\Users\\kevin\\.cache\\huggingface\\datasets\\wmt14\\de-en\\1.0.0\\d239eaf0ff090d28da19b6bc9758e24634d84de0a1ef092f0b5c54e6f132d7e2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 33.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/25 08:02:18 PM |\t  Loading cached shuffled indices for dataset at C:\\Users\\kevin\\.cache\\huggingface\\datasets\\wmt14\\de-en\\1.0.0\\d239eaf0ff090d28da19b6bc9758e24634d84de0a1ef092f0b5c54e6f132d7e2\\cache-43836e47740ac86b.arrow\n",
      "06/25 08:02:18 PM |\t  Loading cached shuffled indices for dataset at C:\\Users\\kevin\\.cache\\huggingface\\datasets\\wmt14\\de-en\\1.0.0\\d239eaf0ff090d28da19b6bc9758e24634d84de0a1ef092f0b5c54e6f132d7e2\\cache-ea51f87c507d6244.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = load_dataset('wmt14','de-en')\n",
    "train = dataset['train'].shuffle(seed=seed).select(range(train_num))\n",
    "valid = train[:100]#dataset['validation'].shuffle(seed=seed).select(range(valid_num))\n",
    "test = dataset['test'].shuffle(seed=seed).select(range(test_num))\n",
    "train = train['translation']\n",
    "valid = valid['translation']\n",
    "test = test['translation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast(tokenizer_file=\"tokenizer-en-de.json\")\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]','unk_token':'[UNK]','eos_token':'[SEP]'})\n",
    "optimizer = ScheduledOptim(\n",
    "        optim.Adam(transformer.parameters(), betas=(0.9, 0.98), eps=1e-09),\n",
    "        1, 512, 4000)\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index = tokenizer.pad_token_id,  label_smoothing=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "train_data = get_Dataset(train, tokenizer,max_length=max_length)\n",
    "train_dataloader = DataLoader(train_data, sampler= SequentialSampler(train_data), \n",
    "                        batch_size=bs, pin_memory=True, num_workers=4)\n",
    "valid_data = get_Dataset(valid, tokenizer,max_length=max_length)\n",
    "valid_dataloader = DataLoader(valid_data, sampler=SequentialSampler(valid_data), \n",
    "                        batch_size=bs, pin_memory=True, num_workers=4)\n",
    "test_data = get_Dataset(test, tokenizer,max_length=max_length)\n",
    "test_dataloader = DataLoader(test_data, sampler=SequentialSampler(test_data), \n",
    "                        batch_size=bs, pin_memory=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_train(_dataloader,model,optimizer,iter):#\n",
    "    objs = AvgrageMeter()\n",
    "    \n",
    "    for step,batch in enumerate(_dataloader):\n",
    "        iter[0] += batch[0].shape[0]\n",
    "        optimizer.zero_grad()\n",
    "        train_x = Variable(batch[0], requires_grad=False).to(device, non_blocking=False)\n",
    "        train_x_attn = Variable(batch[1], requires_grad=False).to(device, non_blocking=False)\n",
    "        train_y = Variable(batch[2], requires_grad=False).to(device, non_blocking=False)    \n",
    "        train_y_attn = Variable(batch[3], requires_grad=False).to(device, non_blocking=False)   \n",
    "        logits = model(input_ids=train_x, attention_mask=train_x_attn, labels=train_y,decoder_attention_mask= train_y_attn).logits\n",
    "        # print(logits.shape)\n",
    "        loss = criterion(logits.view(-1,logits.shape[-1]),train_y.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step_and_update_lr()\n",
    "        objs.update(loss.item(), bs)\n",
    "        if(iter[0]%report_step==0 and iter[0]!=0):\n",
    "            logging.info(f'iter:{iter[0]}\\t,avgloss:{objs.avg}')\n",
    "            objs.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "@torch.no_grad()\n",
    "def my_test(_dataloader,model,epoch):\n",
    "    # logging.info(f\"GPU mem before test:{getGPUMem(device)}%\")\n",
    "    acc = 0\n",
    "    counter = 0\n",
    "    model.eval()\n",
    "    metric_sacrebleu =  load_metric('sacrebleu')\n",
    "    \n",
    "    # for step, batch in enumerate(tqdm(_dataloader,desc =\"test for epoch\"+str(epoch))):\n",
    "    for step, batch in enumerate(_dataloader):\n",
    "        \n",
    "        test_dataloaderx = Variable(batch[0], requires_grad=False).to(device, non_blocking=False)\n",
    "        test_dataloaderx_attn = Variable(batch[1], requires_grad=False).to(device, non_blocking=False)\n",
    "        test_dataloadery = Variable(batch[2], requires_grad=False).to(device, non_blocking=False)\n",
    "        test_dataloadery_attn = Variable(batch[3], requires_grad=False).to(device, non_blocking=False)\n",
    "        ls = model(input_ids=test_dataloaderx, attention_mask=test_dataloaderx_attn, labels=test_dataloadery, decoder_attention_mask= test_dataloadery_attn).loss\n",
    "        acc+= ls.item()\n",
    "        counter+= 1\n",
    "        pre = model.generate(test_dataloaderx ,num_beams = 4, early_stopping = True, max_length = max_length, length_penalty =0.6, repetition_penalty = 0.8)\n",
    "        x_decoded = tokenizer.batch_decode(test_dataloaderx,skip_special_tokens=True)\n",
    "        pred_decoded = tokenizer.batch_decode(pre,skip_special_tokens=True)\n",
    "        label_decoded =  tokenizer.batch_decode(test_dataloadery,skip_special_tokens=True)\n",
    "        \n",
    "        pred_str = [x  for x in pred_decoded]\n",
    "        label_str = [[x] for x in label_decoded]\n",
    "        metric_sacrebleu.add_batch(predictions=pred_str, references=label_str)\n",
    "        if  step%100==0:\n",
    "            logging.info(f'x_decoded[:2]:{x_decoded[:2]}')\n",
    "            logging.info(f'pred_decoded[:2]:{pred_decoded[:2]}')\n",
    "            logging.info(f'label_decoded[:2]:{label_decoded[:2]}')\n",
    "            \n",
    "            \n",
    "    sacrebleu_score = metric_sacrebleu.compute()\n",
    "    logging.info('sacreBLEU : %f',sacrebleu_score['score'])#TODO:bleu may be wrong cuz max length\n",
    "    logging.info('test loss : %f',acc/(counter))\n",
    "    \n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    \n",
    "    # logging.info(f\"GPU mem after test:{getGPUMem(device)}%\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/25 08:02:18 PM |\t  \n",
      "\n",
      "  ----------------epoch:0-----lr:0.001-----------\n",
      "06/25 08:02:23 PM |\t  iter:96\t,avgloss:9.178187052408854\n",
      "06/25 08:02:25 PM |\t  iter:192\t,avgloss:8.151235421498617\n",
      "06/25 08:02:33 PM |\t  x_decoded[:2]:['Die Kommission schlägt jetzt prim är eine finanzielle Lasten teilung im Rahmen des Europäischen Flüchtlings fonds vor.', 'Die Rechts beziehungen zwischen Liefer ant und der Firma Ernst Kl immer GmbH ( im nachfolgenden Besteller genannt ) richten sich ausschließlich nach diesen Bedingungen und etwa igen sonstigen individuellen Vereinbarungen zwischen den Vertrag spartnern.']\n",
      "06/25 08:02:33 PM |\t  pred_decoded[:2]:['the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the']\n",
      "06/25 08:02:33 PM |\t  label_decoded[:2]:['The Commission now proposes, first of all, to share the financial burden on the basis of the Ref uge e Fund.', 'The legal relationship between the supplier and Ernst Kl immer GmbH ( in the following : Buyer ) shall be in accordance with these conditions, and any other individual agreement between the contract partners.']\n",
      "06/25 08:02:46 PM |\t  sacreBLEU : 0.009644\n",
      "06/25 08:02:46 PM |\t  test loss : 9.992888\n",
      "06/25 08:02:46 PM |\t  \n",
      "\n",
      "  ----------------epoch:1-----lr:0.001-----------\n",
      "06/25 08:02:50 PM |\t  iter:96\t,avgloss:6.5193891525268555\n",
      "06/25 08:02:51 PM |\t  iter:192\t,avgloss:6.670261700948079\n",
      "06/25 08:02:59 PM |\t  x_decoded[:2]:['Die Kommission schlägt jetzt prim är eine finanzielle Lasten teilung im Rahmen des Europäischen Flüchtlings fonds vor.', 'Die Rechts beziehungen zwischen Liefer ant und der Firma Ernst Kl immer GmbH ( im nachfolgenden Besteller genannt ) richten sich ausschließlich nach diesen Bedingungen und etwa igen sonstigen individuellen Vereinbarungen zwischen den Vertrag spartnern.']\n",
      "06/25 08:02:59 PM |\t  pred_decoded[:2]:[',,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,', ',,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,']\n",
      "06/25 08:02:59 PM |\t  label_decoded[:2]:['The Commission now proposes, first of all, to share the financial burden on the basis of the Ref uge e Fund.', 'The legal relationship between the supplier and Ernst Kl immer GmbH ( in the following : Buyer ) shall be in accordance with these conditions, and any other individual agreement between the contract partners.']\n",
      "06/25 08:03:12 PM |\t  sacreBLEU : 0.009259\n",
      "06/25 08:03:12 PM |\t  test loss : 11.441870\n",
      "06/25 08:03:13 PM |\t  \n",
      "\n",
      "  ----------------epoch:2-----lr:0.001-----------\n",
      "06/25 08:03:16 PM |\t  iter:96\t,avgloss:6.300349394480388\n",
      "06/25 08:03:17 PM |\t  iter:192\t,avgloss:6.491390228271484\n",
      "06/25 08:03:25 PM |\t  x_decoded[:2]:['Die Kommission schlägt jetzt prim är eine finanzielle Lasten teilung im Rahmen des Europäischen Flüchtlings fonds vor.', 'Die Rechts beziehungen zwischen Liefer ant und der Firma Ernst Kl immer GmbH ( im nachfolgenden Besteller genannt ) richten sich ausschließlich nach diesen Bedingungen und etwa igen sonstigen individuellen Vereinbarungen zwischen den Vertrag spartnern.']\n",
      "06/25 08:03:25 PM |\t  pred_decoded[:2]:[',,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,', ',,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,']\n",
      "06/25 08:03:25 PM |\t  label_decoded[:2]:['The Commission now proposes, first of all, to share the financial burden on the basis of the Ref uge e Fund.', 'The legal relationship between the supplier and Ernst Kl immer GmbH ( in the following : Buyer ) shall be in accordance with these conditions, and any other individual agreement between the contract partners.']\n",
      "06/25 08:03:38 PM |\t  sacreBLEU : 0.009259\n",
      "06/25 08:03:38 PM |\t  test loss : 11.868831\n",
      "06/25 08:03:39 PM |\t  \n",
      "\n",
      "  ----------------epoch:3-----lr:0.001-----------\n",
      "06/25 08:03:43 PM |\t  iter:96\t,avgloss:6.341540654500325\n",
      "06/25 08:03:44 PM |\t  iter:192\t,avgloss:6.4278890291849775\n",
      "06/25 08:03:52 PM |\t  x_decoded[:2]:['Die Kommission schlägt jetzt prim är eine finanzielle Lasten teilung im Rahmen des Europäischen Flüchtlings fonds vor.', 'Die Rechts beziehungen zwischen Liefer ant und der Firma Ernst Kl immer GmbH ( im nachfolgenden Besteller genannt ) richten sich ausschließlich nach diesen Bedingungen und etwa igen sonstigen individuellen Vereinbarungen zwischen den Vertrag spartnern.']\n",
      "06/25 08:03:52 PM |\t  pred_decoded[:2]:['the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the']\n",
      "06/25 08:03:52 PM |\t  label_decoded[:2]:['The Commission now proposes, first of all, to share the financial burden on the basis of the Ref uge e Fund.', 'The legal relationship between the supplier and Ernst Kl immer GmbH ( in the following : Buyer ) shall be in accordance with these conditions, and any other individual agreement between the contract partners.']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# my_test(valid_dataloader,transformer,-1)\n",
    "for epoch in range(10):\n",
    "    iter = [0]\n",
    "    logging.info(f\"\\n\\n  ----------------epoch:{epoch}-----lr:{optimizer._optimizer.param_groups[0]['lr']}-----------\")\n",
    "    my_train(train_dataloader,transformer,optimizer,iter)\n",
    "    lr = optimizer._optimizer.param_groups[0]['lr']\n",
    "\n",
    "    my_test(valid_dataloader,transformer,epoch) \n",
    "    torch.save(transformer,'./model/'+now+'model.pt')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('python38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d33c3b0ef123e851f98887a8750ca7da758e4ff258891935cfe6ff9c0394387"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
