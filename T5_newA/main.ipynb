{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd() \n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from T5 import *\n",
    "import torch\n",
    "from datasets import load_dataset,load_metric\n",
    "from transformers import T5Tokenizer,AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import torch_optimizer as optim\n",
    "from transformers.optimization import Adafactor, AdafactorSchedule\n",
    "from MT_hyperparams import seed_,max_length,target_language\n",
    "import torch.backends.cudnn as cudnn\n",
    "from utils import *\n",
    "from attention_params import *\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, SubsetRandomSampler\n",
    "from torch.autograd import Variable\n",
    "from losses import *\n",
    "from architect import *\n",
    "import logging\n",
    "import sys\n",
    "import transformers\n",
    "import time\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from os.path import exists\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(\"main\")\n",
    "\n",
    "\n",
    "parser.add_argument('--valid_num_points', type=int,             default = 10, help='validation data number')\n",
    "parser.add_argument('--train_num_points', type=int,             default = 2000, help='train data number')\n",
    "parser.add_argument('--test_num_points', type=int,              default = 50, help='train data number')\n",
    "\n",
    "parser.add_argument('--batch_size', type=int,                   default=16,     help='Batch size')\n",
    "parser.add_argument('--train_w_num_points', type=int,           default=4,      help='train_w_num_points for each batch')\n",
    "parser.add_argument('--train_v_synthetic_num_points', type=int, default=8,      help='train_v_synthetic_num_points for each batch')\n",
    "parser.add_argument('--train_v_num_points', type=int,           default=0,      help='train_v_num_points for each batch')\n",
    "parser.add_argument('--train_A_num_points', type=int,           default=4,      help='train_A_num_points decay for each batch')\n",
    "\n",
    "parser.add_argument('--gpu', type=int,                          default=0,      help='gpu device id')\n",
    "parser.add_argument('--num_workers', type=int,                  default=0,      help='num_workers')\n",
    "parser.add_argument('--model_name_teacher', type=str,           default='google/t5-small-lm-adapt',      help='model_name')\n",
    "parser.add_argument('--model_name_student', type=str,           default='google/t5-small-lm-adapt',      help='model_name')\n",
    "parser.add_argument('--model_name_de2en', type=str,             default='Onlydrinkwater/t5-small-de-en-mt',      help='model_name')\n",
    "parser.add_argument('--exp_name', type=str,                     default='T5spec',      help='experiment name')\n",
    "parser.add_argument('--rep_num', type=int,                      default=50,      help='report times for 1 epoch')\n",
    "parser.add_argument('--test_num', type=int,                     default=8000,      help='test times for 1 epoch')\n",
    "\n",
    "parser.add_argument('--epochs', type=int,                       default=500,     help='num of training epochs')\n",
    "parser.add_argument('--pre_epochs', type=int,                   default=0,      help='train model W for x epoch first')\n",
    "parser.add_argument('--grad_clip', type=float,                  default=1,      help='gradient clipping')\n",
    "parser.add_argument('--grad_acc_count', type=float,             default=-1,      help='gradient accumulate steps')\n",
    "\n",
    "parser.add_argument('--w_lr', type=float,                       default=1e-3,   help='learning rate for w')\n",
    "parser.add_argument('--unrolled_w_lr', type=float,              default=1e-3,   help='learning rate for w')\n",
    "parser.add_argument('--v_lr', type=float,                       default=1e-3,   help='learning rate for v')\n",
    "parser.add_argument('--unrolled_v_lr', type=float,              default=1e-3,   help='learning rate for v')\n",
    "parser.add_argument('--A_lr', type=float,                       default=1e-3,   help='learning rate for A')\n",
    "parser.add_argument('--learning_rate_min', type=float,          default=1e-8,   help='learning_rate_min')\n",
    "parser.add_argument('--decay', type=float,                      default=1e-3,   help='weight decay')\n",
    "parser.add_argument('--beta1', type=float,                      default=0,    help='momentum')\n",
    "parser.add_argument('--beta2', type=float,                      default=0,    help='momentum')\n",
    "parser.add_argument('--warm', type=float,                       default=10,    help='warmup step')\n",
    "parser.add_argument('--num_step_lr', type=float,                default=2,    help='warmup step')\n",
    "parser.add_argument('--decay_lr', type=float,                   default=0.7,    help='warmup step')\n",
    "# parser.add_argument('--smoothing', type=float,                  default=0.1,    help='labelsmoothing')\n",
    "\n",
    "parser.add_argument('--freeze', type=int,                       default=1,    help='whether freeze the pretrained encoder')\n",
    "\n",
    "parser.add_argument('--traindata_loss_ratio', type=float,       default=0,    help='human translated data ratio')\n",
    "parser.add_argument('--syndata_loss_ratio', type=float,         default=1,    help='augmented dataset ratio')\n",
    "\n",
    "parser.add_argument('--valid_begin', type=int,                  default=1,      help='whether valid before train')\n",
    "parser.add_argument('--train_A', type=int,                      default=1 ,     help='whether train A')\n",
    "\n",
    "\n",
    "\n",
    "args = parser.parse_args(args=[])#(args=['--batch_size', '8',  '--no_cuda'])#used in ipynb\n",
    "args.test_num = args.test_num//args.batch_size * args.batch_size\n",
    "args.rep_num = args.rep_num//args.batch_size * args.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33monlydrinkwater\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.19 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.17"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>g:\\GitCode\\Self-teaching-for-machine-translation\\T5_newA\\wandb\\run-20220622_222148-1ms6d99h</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/onlydrinkwater/Selftraining/runs/1ms6d99h\" target=\"_blank\">T5spec</a></strong> to <a href=\"https://wandb.ai/onlydrinkwater/Selftraining\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/onlydrinkwater/Selftraining/runs/1ms6d99h?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1ee95ad6a00>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://wandb.ai/ check the running status online\n",
    "import wandb\n",
    "os.environ['WANDB_API_KEY']='a166474b1b7ad33a0549adaaec19a2f6d3f91d87'\n",
    "os.environ['WANDB_NAME']=args.exp_name\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "wandb.init(project=\"Selftraining\",config=args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/22 10:21:52 PM |\t  Reusing dataset wmt14 (C:\\Users\\kevin\\.cache\\huggingface\\datasets\\wmt14\\de-en\\1.0.0\\d239eaf0ff090d28da19b6bc9758e24634d84de0a1ef092f0b5c54e6f132d7e2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 13.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/22 10:21:52 PM |\t  Namespace(A_lr=0.001, batch_size=16, beta1=0, beta2=0, decay=0.001, decay_lr=0.7, epochs=500, exp_name='T5spec', freeze=1, gpu=0, grad_acc_count=-1, grad_clip=1, learning_rate_min=1e-08, model_name_de2en='Onlydrinkwater/t5-small-de-en-mt', model_name_student='google/t5-small-lm-adapt', model_name_teacher='google/t5-small-lm-adapt', num_step_lr=2, num_workers=0, pre_epochs=0, rep_num=48, syndata_loss_ratio=1, test_num=8000, test_num_points=50, train_A=1, train_A_num_points=4, train_num_points=2000, train_v_num_points=0, train_v_synthetic_num_points=8, train_w_num_points=4, traindata_loss_ratio=0, unrolled_v_lr=0.001, unrolled_w_lr=0.001, v_lr=0.001, valid_begin=1, valid_num_points=10, w_lr=0.001, warm=10)\n",
      "06/22 10:21:52 PM |\t  DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 4508785\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 3000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 3003\n",
      "    })\n",
      "})\n",
      "06/22 10:21:52 PM |\t  {'translation': {'de': 'Ich bitte Sie, sich zu einer Schweigeminute zu erheben.', 'en': \"Please rise, then, for this minute' s silence.\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# logging file\n",
    "now = time.strftime(\"%Y-%m-%d-%H_%M_%S\", time.localtime(time.time()))\n",
    "\n",
    "log_format = '%(asctime)s |\\t  %(message)s'\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO,\n",
    "                    format=log_format, datefmt='%m/%d %I:%M:%S %p')\n",
    "fh = logging.FileHandler(os.path.join(\n",
    "    \"./log/\", now+'.txt'), 'w', encoding=\"UTF-8\")\n",
    "fh.setFormatter(logging.Formatter(log_format))\n",
    "logging.getLogger().addHandler(fh)\n",
    "dataset = load_dataset('wmt14', 'de-en')\n",
    "\n",
    "logging.info(args)\n",
    "logging.info(dataset)\n",
    "logging.info(dataset['train'][5])\n",
    "\n",
    "\n",
    "# Setting the seeds\n",
    "np.random.seed(seed_)\n",
    "torch.cuda.set_device(args.gpu)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cudnn.benchmark = True\n",
    "torch.manual_seed(seed_)\n",
    "cudnn.enabled = True\n",
    "torch.cuda.manual_seed(seed_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/22 10:21:54 PM |\t  modelsize:76.961152MB\n",
      "06/22 10:21:55 PM |\t  modelsize:76.961152MB\n",
      "06/22 10:21:56 PM |\t  modelsize:76.961152MB\n"
     ]
    }
   ],
   "source": [
    "modelname = args.model_name_teacher\n",
    "pretrained  =  AutoModelForSeq2SeqLM.from_pretrained(modelname)\n",
    "pathname = modelname.replace('/','')\n",
    "logging.info(f'modelsize:{count_parameters_in_MB(pretrained)}MB')\n",
    "\n",
    "if(exists(pathname+'.pt')==False):\n",
    "    logging.info(f'saving to {pathname}')\n",
    "    torch.save(pretrained,pathname+'.pt')\n",
    "\n",
    "modelname = args.model_name_student\n",
    "pretrained  =  AutoModelForSeq2SeqLM.from_pretrained(modelname)\n",
    "pathname = modelname.replace('/','')\n",
    "logging.info(f'modelsize:{count_parameters_in_MB(pretrained)}MB')\n",
    "if(exists(pathname+'.pt')==False):\n",
    "    logging.info(f'saving to {pathname}')\n",
    "    torch.save(pretrained,pathname+'.pt')\n",
    "\n",
    "modelname = args.model_name_de2en\n",
    "pretrained  =  AutoModelForSeq2SeqLM.from_pretrained(modelname)\n",
    "pathname = modelname.replace('/','')\n",
    "logging.info(f'modelsize:{count_parameters_in_MB(pretrained)}MB')\n",
    "if(exists(pathname+'.pt')==False):\n",
    "    logging.info(f'saving to {pathname}')\n",
    "    torch.save(pretrained,pathname+'.pt')\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/22 10:21:59 PM |\t  Loading cached shuffled indices for dataset at C:\\Users\\kevin\\.cache\\huggingface\\datasets\\wmt14\\de-en\\1.0.0\\d239eaf0ff090d28da19b6bc9758e24634d84de0a1ef092f0b5c54e6f132d7e2\\cache-8a0e8ff6dde4594c.arrow\n",
      "06/22 10:22:00 PM |\t  Loading cached shuffled indices for dataset at C:\\Users\\kevin\\.cache\\huggingface\\datasets\\wmt14\\de-en\\1.0.0\\d239eaf0ff090d28da19b6bc9758e24634d84de0a1ef092f0b5c54e6f132d7e2\\cache-5fa876205460c4a9.arrow\n",
      "06/22 10:22:00 PM |\t  Loading cached shuffled indices for dataset at C:\\Users\\kevin\\.cache\\huggingface\\datasets\\wmt14\\de-en\\1.0.0\\d239eaf0ff090d28da19b6bc9758e24634d84de0a1ef092f0b5c54e6f132d7e2\\cache-fd5b6295b346fe99.arrow\n",
      "06/22 10:22:00 PM |\t  train len: 2000\n",
      "06/22 10:22:00 PM |\t  train_w_num_points_len: 500\n",
      "06/22 10:22:00 PM |\t  train_v_synthetic_num_points_len: 1000\n",
      "06/22 10:22:00 PM |\t  train_v_num_points_len: 0\n",
      "06/22 10:22:00 PM |\t  train_A_num_points_len: 500\n",
      "06/22 10:22:00 PM |\t  valid len: 10\n",
      "06/22 10:22:00 PM |\t  test len: 50\n",
      "06/22 10:22:00 PM |\t  {'de': 'Der Konflikt vom Juni 1998 ist zurückgekehrt, und die Bevölkerung befindet sich erneut in Massen auf der Flucht.', 'en': 'translate English to German: The conflict of June 1998 has returned and people are once again fleeing in large numbers.'}\n",
      "06/22 10:22:00 PM |\t  {'de': 'Er wird von Co-Trainern wie Claude Makelele unterstützt, der auf derselben Position spielte wie ich.', 'en': \"translate English to German: He's supported by deputies like Claude Makelele, who played in the same position as me.\"}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# preprocess the data, make a dataloader\n",
    "import random\n",
    "modelname = args.model_name_teacher\n",
    "tokenizer = AutoTokenizer.from_pretrained('t5-small')\n",
    "criterion = torch.nn.CrossEntropyLoss( reduction='none')#teacher shouldn't have label smoothing, especially when student got same size.\n",
    "criterion_v = torch.nn.CrossEntropyLoss( reduction='none')#,label_smoothing=args.smoothing) #without LS, V may be too confident to that syn data, and LS do well for real data also.\n",
    "\n",
    "\n",
    "\n",
    "train = dataset['train'].shuffle(seed=seed_).select(range(args.train_num_points))\n",
    "valid = dataset['validation'].shuffle(seed=seed_).select(range(args.valid_num_points))\n",
    "test = dataset['test'].shuffle(seed=seed_).select(range(args.test_num_points))#[L_t+L_v:L_t+L_v+L_test]\n",
    "train = train['translation']\n",
    "valid = valid['translation']\n",
    "test = test['translation']\n",
    "def preprocess(dat):\n",
    "    for t in dat:\n",
    "        t['en'] = \"translate English to German: \" + t['en']  #needed for T5\n",
    "preprocess(train)\n",
    "preprocess(valid)\n",
    "preprocess(test)\n",
    "#TODO: Syn_input should be monolingual data, should try en-fo's en. cuz wmt may align\n",
    "num_batch = args.train_num_points//args.batch_size\n",
    "train = train[:args.batch_size*num_batch]\n",
    "logging.info(\"train len: %d\",len(train))\n",
    "\n",
    "'''\n",
    "each mini batch consist of : \n",
    "1. data to train W\n",
    "2. monolingual data to generate parallel data\n",
    "3. data to train V\n",
    "4. data to train A\n",
    "'''\n",
    "train_w_num_points_len = num_batch * args.train_w_num_points\n",
    "train_v_synthetic_num_points_len = num_batch * args.train_v_synthetic_num_points\n",
    "train_v_num_points_len = num_batch * args.train_v_num_points\n",
    "train_A_num_points_len = num_batch * args.train_A_num_points\n",
    "logging.info(\"train_w_num_points_len: %d\",train_w_num_points_len)\n",
    "logging.info(\"train_v_synthetic_num_points_len: %d\",train_v_synthetic_num_points_len)\n",
    "logging.info(\"train_v_num_points_len: %d\",train_v_num_points_len)\n",
    "logging.info(\"train_A_num_points_len: %d\",train_A_num_points_len)\n",
    "\n",
    "attn_idx_list = torch.arange(train_w_num_points_len).cuda()\n",
    "logging.info(\"valid len: %d\",len(valid))\n",
    "logging.info(\"test len: %d\" ,len(test))\n",
    "logging.info(train[2])\n",
    "logging.info(valid[2])\n",
    "# logging.info(test[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get train data start\n",
      "get train data end\n",
      "06/22 10:22:00 PM |\t  train data get\n",
      "06/22 10:22:00 PM |\t  train data loader get\n",
      "06/22 10:22:00 PM |\t  valid data loader get\n",
      "06/22 10:22:00 PM |\t  test data loader get\n"
     ]
    }
   ],
   "source": [
    "target_language  = 'de'\n",
    "train_data = get_train_Dataset(train, tokenizer)# Create the DataLoader for our training set.\n",
    "logging.info('train data get')\n",
    "train_dataloader = DataLoader(train_data, sampler= SequentialSampler(train_data), \n",
    "                        batch_size=args.batch_size, pin_memory=args.num_workers>0, num_workers=args.num_workers)\n",
    "logging.info('train data loader get')\n",
    "valid_data = get_aux_dataset(valid, tokenizer)# Create the DataLoader for our training set.\n",
    "valid_dataloader = DataLoader(valid_data, sampler=SequentialSampler(valid_data), \n",
    "                        batch_size=args.batch_size, pin_memory=args.num_workers>0, num_workers=args.num_workers)\n",
    "logging.info('valid data loader get')\n",
    "test_data = get_aux_dataset(test, tokenizer)# Create the DataLoader for our training set.\n",
    "test_dataloader = DataLoader(test_data, sampler=SequentialSampler(test_data),\n",
    "                        batch_size=args.batch_size, pin_memory=args.num_workers>0, num_workers=args.num_workers)#, sampler=RandomSampler(test_data)\n",
    "logging.info('test data loader get')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./model\\\\A.pt']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "A = attention_params(args)#half of train regarded as u\n",
    "# A = A.cuda()\n",
    "# B = load()[0]\n",
    "# A.load_state_dict(B)\n",
    "\n",
    "\n",
    "\n",
    "# TODO: model loaded from saved model\n",
    "model_w = T5(criterion=criterion, tokenizer= tokenizer, args = args, name = 'model_w_in_main')\n",
    "model_w = model_w.cuda()\n",
    "w_optimizer = torch.optim.Adam(model_w.parameters(),  lr= args.w_lr ,  betas=(args.beta1, args.beta2) ,eps=1e-9 )\n",
    "# w_optimizer = Adafactor(model_w.parameters(), lr = args.w_lr ,scale_parameter=False, relative_step=False , warmup_init=False,clip_threshold=1,beta1=0,eps=( 1e-30,0.001))\n",
    "scheduler_w  =   StepLR(w_optimizer, step_size=1e10, gamma=args.decay_lr)\n",
    "# scheduler_w  = Scheduler(w_optimizer,dim_embed=512, warmup_steps=args.warm, initlr = args.w_lr)\n",
    "\n",
    "\n",
    "\n",
    "model_v = T5(criterion=criterion_v, tokenizer= tokenizer, args = args, name = 'model_v_in_main')\n",
    "model_v = model_v.cuda()\n",
    "v_optimizer = torch.optim.Adam(model_v.parameters(),  lr= args.v_lr ,  betas=(args.beta1,args.beta2) ,eps=1e-9  )\n",
    "# v_optimizer =Adafactor(model_v.parameters(), lr = args.v_lr ,scale_parameter=False, relative_step=False , warmup_init=False,clip_threshold=1,beta1=0,eps=( 1e-30,0.001))\n",
    "scheduler_v  =   StepLR(v_optimizer, step_size=1e10, gamma=args.decay_lr)\n",
    "# scheduler_v  = Scheduler(v_optimizer,dim_embed=512, warmup_steps=args.warm, initlr = args.v_lr)\n",
    "\n",
    "\n",
    "architect = Architect(model_w, model_v,  A, args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def my_test(_dataloader,model,epoch):\n",
    "    # logging.info(f\"GPU mem before test:{getGPUMem(device)}%\")\n",
    "    acc = 0\n",
    "    counter = 0\n",
    "    model.eval()\n",
    "    metric_sacrebleu =  load_metric('sacrebleu')\n",
    "    # metric_bleu =  load_metric('bleu')\n",
    "    \n",
    "    for step, batch in enumerate(_dataloader):\n",
    "        \n",
    "        test_dataloaderx = Variable(batch[0], requires_grad=False).to(device, non_blocking=False)[:args.train_w_num_points]\n",
    "        test_dataloaderx_attn = Variable(batch[1], requires_grad=False).to(device, non_blocking=False)[:args.train_w_num_points]\n",
    "        test_dataloadery = Variable(batch[2], requires_grad=False).to(device, non_blocking=False)[:args.train_w_num_points]\n",
    "        test_dataloadery_attn = Variable(batch[3], requires_grad=False).to(device, non_blocking=False)[:args.train_w_num_points]\n",
    "        ls = my_loss(test_dataloaderx,test_dataloaderx_attn,test_dataloadery,test_dataloadery_attn,model)\n",
    "        acc+= ls.item()\n",
    "        counter+= 1\n",
    "        pre = model.generate(test_dataloaderx)\n",
    "        x_decoded = tokenizer.batch_decode(test_dataloaderx,skip_special_tokens=True)\n",
    "        pred_decoded = tokenizer.batch_decode(pre,skip_special_tokens=True)\n",
    "        label_decoded =  tokenizer.batch_decode(test_dataloadery,skip_special_tokens=True)\n",
    "        \n",
    "        pred_str = [x  for x in pred_decoded]\n",
    "        label_str = [[x] for x in label_decoded]\n",
    "        # pred_list = [x.split()  for x in pred_decoded]\n",
    "        # label_list = [[x.split()] for x in label_decoded]\n",
    "        metric_sacrebleu.add_batch(predictions=pred_str, references=label_str)\n",
    "        # metric_bleu.add_batch(predictions=pred_list, references=label_list)\n",
    "        if  step==0:\n",
    "            logging.info(f'x_decoded[:2]:{x_decoded[:2]}')\n",
    "            logging.info(f'pred_decoded[:2]:{pred_decoded[:2]}')\n",
    "            logging.info(f'label_decoded[:2]:{label_decoded[:2]}')\n",
    "            \n",
    "            \n",
    "    logging.info('computing score...') \n",
    "    sacrebleu_score = metric_sacrebleu.compute()\n",
    "    # bleu_score = metric_bleu.compute()\n",
    "    logging.info('%s sacreBLEU : %f',model.name,sacrebleu_score['score'])#TODO:bleu may be wrong cuz max length\n",
    "    # logging.info('%s BLEU : %f',model.name,bleu_score['bleu'])\n",
    "    logging.info('%s test loss : %f',model.name,acc/(counter))\n",
    "    wandb.log({'sacreBLEU'+model.name: sacrebleu_score['score']})\n",
    "    wandb.log({'test_loss'+model.name: acc/counter})\n",
    "    # del test_dataloaderx,acc,counter,test_dataloaderx_attn,sacrebleu_score,bleu_score,test_dataloadery,test_dataloadery_attn,ls,pre,x_decoded,pred_decoded,label_decoded,pred_str,label_str,pred_list,label_list\n",
    "    # gc.collect()\n",
    "    # torch.cuda.empty_cache()\n",
    "    model.eval()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_train(epoch, _dataloader, validdataloader, w_model, v_model, architect, A, w_optimizer, v_optimizer, lr_w, lr_v, tot_iter):\n",
    "\n",
    "    objs_w = AvgrageMeter()\n",
    "    objs_v_syn = AvgrageMeter()\n",
    "    objs_v_train = AvgrageMeter()\n",
    "    objs_v_star_val = AvgrageMeter()\n",
    "    objs_v_val = AvgrageMeter()\n",
    "    improvement = 0\n",
    "    w_trainloss_acc = 0\n",
    "    # now  train_x is [num of batch, datasize], so its seperate batch for the code below\n",
    "    wsize = args.train_w_num_points\n",
    "    synsize = args.train_v_synthetic_num_points\n",
    "    vsize = args.train_v_num_points\n",
    "    Asize = args.train_A_num_points\n",
    "    loader_len = len(_dataloader)\n",
    "    split_size = [wsize, synsize, vsize, Asize]\n",
    "    bs = args.batch_size\n",
    "    w_model.eval()\n",
    "    v_model.eval()\n",
    "\n",
    "    logging.info(f\"split size:{split_size}\")\n",
    "    for step, batch in enumerate(_dataloader):\n",
    "        tot_iter[0] += bs\n",
    "        \n",
    "\n",
    "        # logging.info(f\"GPU mem :{getGPUMem(device)}%\")\n",
    "        train_x = Variable(batch[0], requires_grad=False).to(\n",
    "            device, non_blocking=False)\n",
    "        train_x_attn = Variable(batch[1], requires_grad=False).to(\n",
    "            device, non_blocking=False)\n",
    "        train_y = Variable(batch[2], requires_grad=False).to(\n",
    "            device, non_blocking=False)\n",
    "        train_y_attn = Variable(batch[3], requires_grad=False).to(\n",
    "            device, non_blocking=False)\n",
    "        (input_w, input_syn, input_v, input_A_v) = torch.split(train_x, split_size)\n",
    "        (input_w_attn, input_syn_attn, input_v_attn,\n",
    "         input_A_v_attn) = torch.split(train_x_attn, split_size)\n",
    "        (output_w, _, output_v, output_A_v) = torch.split(train_y, split_size)\n",
    "        (output_w_attn, _, output_v_attn, output_A_v_attn) = torch.split(\n",
    "            train_y_attn, split_size)\n",
    "            \n",
    "        if(True):# let v train on syn data and w data\n",
    "            input_v = input_w\n",
    "            input_v_attn = input_w_attn\n",
    "            output_v = output_w\n",
    "            output_v_attn = output_w_attn\n",
    "            vsize = wsize\n",
    "\n",
    "\n",
    "        output_w[step%wsize]+=1 # noise input\n",
    "        if (args.train_A == 1 and epoch>=args.pre_epochs):\n",
    "            epsilon_w = args.unrolled_w_lr\n",
    "            epsilon_v  = args.unrolled_v_lr\n",
    "            v_star_val_loss = architect.step(input_w,  output_w, input_w_attn, output_w_attn, w_optimizer,\n",
    "                                             input_v, input_v_attn, output_v, output_v_attn, input_syn, input_syn_attn,\n",
    "                                             input_A_v, input_A_v_attn, output_A_v, output_A_v_attn, v_optimizer,\n",
    "                                             epsilon_w, epsilon_v)\n",
    "            objs_v_star_val.update(v_star_val_loss, Asize)\n",
    "                            \n",
    "\n",
    "\n",
    "\n",
    "        w_optimizer.zero_grad()\n",
    "        loss_w = CTG_loss(input_w, input_w_attn, output_w,\n",
    "                          output_w_attn, A, w_model)\n",
    "        w_trainloss_acc += loss_w.item()\n",
    "        loss_w.backward()\n",
    "        objs_w.update(loss_w.item(), wsize)\n",
    "        w_optimizer.step()\n",
    "\n",
    "\n",
    "        if(epoch>=args.pre_epochs):  \n",
    "            v_optimizer.zero_grad()\n",
    "            loss_aug = calc_loss_aug(input_syn, input_syn_attn, w_model, v_model)\n",
    "            loss = my_loss2(input_v, input_v_attn, output_v,\n",
    "                            output_v_attn, v_model)\n",
    "            v_loss = (args.traindata_loss_ratio*loss +\n",
    "                    loss_aug*args.syndata_loss_ratio)\n",
    "            v_loss.backward()\n",
    "            objs_v_syn.update(loss_aug.item(), synsize)\n",
    "            objs_v_train.update(loss.item(), vsize)\n",
    "            v_optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                valloss = my_loss2(input_A_v, input_A_v_attn,  output_A_v, output_A_v_attn,v_model)\n",
    "                objs_v_val.update(valloss.item(), Asize)\n",
    "                improvement += (v_star_val_loss-valloss.item())\n",
    "                \n",
    "        progress = 100*(step)/(loader_len-1)\n",
    "        if(tot_iter[0] % args.test_num == 0 and tot_iter[0] != 0):\n",
    "            my_test(validdataloader, model_w, epoch)\n",
    "            my_test(validdataloader, model_v, epoch)\n",
    "            # logging.info(str((\"Attention Weights A : \", A.ReLU(A.alpha))))\n",
    "            torch.save(model_w,'./model/'+'model_w.pt')#+now+\n",
    "            torch.save(model_v,'./model/'+'model_v.pt')\n",
    "            torch.save(A,'./model/'+'A.pt')\n",
    "            torch.save(model_w.state_dict(),os.path.join(wandb.run.dir, \"model_w.pt\"))\n",
    "            torch.save(model_v.state_dict(),os.path.join(wandb.run.dir, \"model_v.pt\"))\n",
    "            torch.save(A.state_dict(),os.path.join(wandb.run.dir, \"A.pt\"))\n",
    "            wandb.save(\"./files/*.pt\", base_path=\"./files\", policy=\"live\")\n",
    "\n",
    "        if(tot_iter[0] % args.rep_num == 0 and tot_iter[0] != 0):\n",
    "            logging.info(f\"{progress:5.3}%:\\t  W_train_loss:{objs_w.avg:^.7f}\\tV_train_syn_loss:{objs_v_syn.avg:^.7f}\\tV_train_loss:{objs_v_train.avg:^.7f}\\t  V_star_val_loss:{objs_v_star_val.avg:^.7f}\\t  improvement:{(objs_v_star_val.avg-objs_v_val.avg):^.7f}\")\n",
    "            with torch.no_grad():\n",
    "                temp = A(input_w, input_w_attn, output_w,output_w_attn)\n",
    "            logging.info(f\"weight:{temp}\")\n",
    "            logging.info(f'noise input weight:{temp[step%wsize]}')\n",
    "            wandb.log({'W_train_loss': objs_w.avg})\n",
    "            wandb.log({'V_train_syn_loss': objs_v_syn.avg})\n",
    "            wandb.log({'V_train_loss': objs_v_train.avg})\n",
    "            wandb.log({'V_star_val_loss': objs_v_star_val.avg})\n",
    "            wandb.log({'V_val_loss': objs_v_val.avg})\n",
    "            objs_v_syn.reset()\n",
    "            objs_v_train.reset()\n",
    "            objs_w.reset()\n",
    "            objs_v_star_val.reset()\n",
    "            objs_v_val.reset()\n",
    "    return w_trainloss_acc, improvement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/22 10:22:04 PM |\t  \n",
      "\n",
      "  ----------------epoch:0,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:0.001----------------\n",
      "06/22 10:22:04 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/22 10:22:22 PM |\t   1.61%:\t  W_train_loss:5.1937935\tV_train_syn_loss:2.5200849\tV_train_loss:6.1911012\t  V_star_val_loss:4.9016728\t  improvement:0.0078187\n",
      "06/22 10:22:22 PM |\t  weight:tensor([1.2656e+00, 1.3708e+00, 4.1575e-07, 1.3635e+00], device='cuda:0')\n",
      "06/22 10:22:22 PM |\t  noise input weight:4.1574821807444096e-07\n",
      "06/22 10:22:39 PM |\t   4.03%:\t  W_train_loss:4.7530929\tV_train_syn_loss:1.6877218\tV_train_loss:6.2612915\t  V_star_val_loss:5.5273484\t  improvement:-0.0001208\n",
      "06/22 10:22:39 PM |\t  weight:tensor([6.9858e-07, 4.2684e-07, 2.0166e+00, 1.9834e+00], device='cuda:0')\n",
      "06/22 10:22:39 PM |\t  noise input weight:4.2684177969931625e-07\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16876/4246411912.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"\\n\\n  ----------------epoch:{epoch},\\t\\tlr_w:{lr_w},\\t\\tlr_v:{lr_v},\\t\\tlr_A:{lr_A}----------------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mw_train_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimprovement\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mmy_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_v\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0marchitect\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_optimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv_optimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr_w\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr_v\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtot_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mscheduler_w\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16876/1722603461.py\u001b[0m in \u001b[0;36mmy_train\u001b[1;34m(epoch, _dataloader, validdataloader, w_model, v_model, architect, A, w_optimizer, v_optimizer, lr_w, lr_v, tot_iter)\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[0mepsilon_w\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munrolled_w_lr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mepsilon_v\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munrolled_v_lr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m             v_star_val_loss = architect.step(input_w,  output_w, input_w_attn, output_w_attn, w_optimizer,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                              \u001b[0minput_v\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_v_attn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_v\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_v_attn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_syn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_syn_attn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m                                              \u001b[0minput_A_v\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_A_v_attn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_A_v\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_A_v_attn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv_optimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mg:\\GitCode\\Self-teaching-for-machine-translation\\T5_newA\\architect.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, input_w, output_w, input_w_attn, output_w_attn, w_optimizer, input_v, input_v_attn, output_v, output_v_attn, input_syn, input_syn_attn, input_A_v, input_A_v_attn, output_A_v, output_A_v_attn, v_optimizer, lr_w, lr_v)\u001b[0m\n\u001b[0;32m    172\u001b[0m         \u001b[0munrolled_w_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         unrolled_v_model = self._compute_unrolled_v_model(\n\u001b[0m\u001b[0;32m    175\u001b[0m             input_v, input_v_attn, output_v, output_v_attn, input_syn, input_syn_attn, unrolled_w_model,  lr_v, v_optimizer)\n\u001b[0;32m    176\u001b[0m         \u001b[0munrolled_v_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mg:\\GitCode\\Self-teaching-for-machine-translation\\T5_newA\\architect.py\u001b[0m in \u001b[0;36m_compute_unrolled_v_model\u001b[1;34m(self, input_v, input_v_attn, output_v, output_v_attn, input_syn, input_syn_attn, unrolled_w_model, eta_v, v_optimizer)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;31m# DS loss on augmented dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         loss_aug = calc_loss_aug(\n\u001b[0m\u001b[0;32m    112\u001b[0m             input_syn, input_syn_attn, unrolled_w_model, self.v_model)\n\u001b[0;32m    113\u001b[0m         loss = my_loss2(input_v, input_v_attn, output_v,\n",
      "\u001b[1;32mg:\\GitCode\\Self-teaching-for-machine-translation\\T5_newA\\losses.py\u001b[0m in \u001b[0;36mcalc_loss_aug\u001b[1;34m(input_syn_ids, input_syn_attn, w_model, v_model)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcalc_loss_aug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_syn_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_syn_attn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[0mw_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mturnoff_dropout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m     \u001b[0moutput_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_syn_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_beams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[0matt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0moutput_ids\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[0mw_logits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_syn_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_syn_attn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_attn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0matt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogits\u001b[0m  \u001b[1;31m# TODO,forward_decoderinput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mg:\\GitCode\\Self-teaching-for-machine-translation\\T5_newA\\T5.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, input_ids, num_beams, max_length)\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_beams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m         \u001b[0moutput_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_beams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_beams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlength_penalty\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m0.6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrepetition_penalty\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cache\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m         \u001b[1;31m## sampling with top_p\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, typical_p, repetition_penalty, bad_words_ids, force_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, stopping_criteria, constraints, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, exponential_decay_length_penalty, **model_kwargs)\u001b[0m\n\u001b[0;32m   1252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1253\u001b[0m             \u001b[1;31m# 10. run greedy search\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1254\u001b[1;33m             return self.greedy_search(\n\u001b[0m\u001b[0;32m   1255\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogits_processor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\generation_utils.py\u001b[0m in \u001b[0;36mgreedy_search\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[0;32m   1636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1637\u001b[0m             \u001b[1;31m# forward pass to get next token\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1638\u001b[1;33m             outputs = self(\n\u001b[0m\u001b[0;32m   1639\u001b[0m                 \u001b[1;33m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1640\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1637\u001b[0m         \u001b[1;31m# Decode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1638\u001b[1;33m         decoder_outputs = self.decoder(\n\u001b[0m\u001b[0;32m   1639\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1640\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecoder_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1031\u001b[0m                 )\n\u001b[0;32m   1032\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1033\u001b[1;33m                 layer_outputs = layer_module(\n\u001b[0m\u001b[0;32m   1034\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1035\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[0;32m    718\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m         \u001b[1;31m# Apply Feed Forward layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 720\u001b[1;33m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    721\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    722\u001b[0m         \u001b[1;31m# clamp inf values to enable fp16 training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    326\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m         \u001b[0mforwarded_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m         \u001b[0mforwarded_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDenseReluDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforwarded_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    329\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhidden_states\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforwarded_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 303\u001b[1;33m         \u001b[0mhidden_gelu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgelu_act\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwi_0\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    304\u001b[0m         \u001b[0mhidden_linear\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwi_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhidden_gelu\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mhidden_linear\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1846\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1847\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# if(args.valid_begin==1):\n",
    "#     my_test(valid_dataloader,model_w,-1) #before train\n",
    "#     my_test(valid_dataloader,model_v,-1)  \n",
    "\n",
    "tot_iter = [0]\n",
    "for epoch in range(args.epochs):\n",
    "    lr_w = scheduler_w.get_lr()[0]\n",
    "    lr_v = scheduler_v.get_lr()[0]\n",
    "    lr_A = architect.scheduler_A.get_lr()[0]\n",
    "\n",
    "    logging.info(f\"\\n\\n  ----------------epoch:{epoch},\\t\\tlr_w:{lr_w},\\t\\tlr_v:{lr_v},\\t\\tlr_A:{lr_A}----------------\")\n",
    "\n",
    "    w_train_loss,improvement =  my_train(epoch, train_dataloader, valid_dataloader, model_w, model_v,  architect, A, w_optimizer, v_optimizer, lr_w,lr_v,tot_iter)\n",
    "    \n",
    "    scheduler_w.step()\n",
    "    scheduler_v.step()\n",
    "    architect.scheduler_A.step()\n",
    "\n",
    "\n",
    "    logging.info(f\"w_train_loss:{w_train_loss},improvement:{improvement}\")\n",
    "    # wandb.log({'w_train_loss': w_train_loss, 'v_train_loss':v_train_loss})\n",
    "\n",
    "\n",
    "\n",
    "torch.save(model_v,'./model/'+now+'model_w.pt')\n",
    "torch.save(model_v,'./model/'+now+'model_v.pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./model\\\\input_w.pt', './model\\\\input_w_attn.pt', './model\\\\output_w.pt', './model\\\\output_w_attn.pt']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['translate English to German: The occupational profiles drawn up by the LOB in collaboration with industry are taken as a basis.',\n",
       " 'translate English to German: We need to tackle the reasons why women are more likely to have precarious jobs: the stereotypes, the unequal sharing of family and household tasks, and the undervaluation of female-dominated jobs.',\n",
       " 'translate English to German: They are a source of inexhaustible renewable energy.',\n",
       " 'translate English to German: Yes, it is. O&O UnErase 4 runs with all versions of Windows Vista, XP, 2000, 2003 and NT.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_en2de.embed_tokens.weight\n",
      "tensor(67.2679, device='cuda:0')\n",
      "model_en2de.block.0.layer.0.SelfAttention.q.weight\n",
      "tensor(568.9545, device='cuda:0')\n",
      "model_en2de.block.0.layer.0.SelfAttention.k.weight\n",
      "tensor(242.2342, device='cuda:0')\n",
      "model_en2de.block.0.layer.0.SelfAttention.v.weight\n",
      "tensor(436.4152, device='cuda:0')\n",
      "model_en2de.block.0.layer.0.SelfAttention.o.weight\n",
      "tensor(361.4578, device='cuda:0')\n",
      "model_en2de.block.0.layer.0.SelfAttention.relative_attention_bias.weight\n",
      "tensor(0.6704, device='cuda:0')\n",
      "model_en2de.block.0.layer.0.layer_norm.weight\n",
      "tensor(2.0775, device='cuda:0')\n",
      "model_en2de.block.0.layer.1.DenseReluDense.wi_0.weight\n",
      "tensor(567.9850, device='cuda:0')\n",
      "model_en2de.block.0.layer.1.DenseReluDense.wi_1.weight\n",
      "tensor(516.1033, device='cuda:0')\n",
      "model_en2de.block.0.layer.1.DenseReluDense.wo.weight\n",
      "tensor(691.3812, device='cuda:0')\n",
      "model_en2de.block.0.layer.1.layer_norm.weight\n",
      "tensor(2.1770, device='cuda:0')\n",
      "model_en2de.block.1.layer.0.SelfAttention.q.weight\n",
      "tensor(576.1372, device='cuda:0')\n",
      "model_en2de.block.1.layer.0.SelfAttention.k.weight\n",
      "tensor(248.1481, device='cuda:0')\n",
      "model_en2de.block.1.layer.0.SelfAttention.v.weight\n",
      "tensor(365.8608, device='cuda:0')\n",
      "model_en2de.block.1.layer.0.SelfAttention.o.weight\n",
      "tensor(318.2111, device='cuda:0')\n",
      "model_en2de.block.1.layer.0.layer_norm.weight\n",
      "tensor(2.3148, device='cuda:0')\n",
      "model_en2de.block.1.layer.1.DenseReluDense.wi_0.weight\n",
      "tensor(534.0239, device='cuda:0')\n",
      "model_en2de.block.1.layer.1.DenseReluDense.wi_1.weight\n",
      "tensor(464.0726, device='cuda:0')\n",
      "model_en2de.block.1.layer.1.DenseReluDense.wo.weight\n",
      "tensor(630.1975, device='cuda:0')\n",
      "model_en2de.block.1.layer.1.layer_norm.weight\n",
      "tensor(2.2458, device='cuda:0')\n",
      "model_en2de.block.2.layer.0.SelfAttention.q.weight\n",
      "tensor(542.4028, device='cuda:0')\n",
      "model_en2de.block.2.layer.0.SelfAttention.k.weight\n",
      "tensor(219.9352, device='cuda:0')\n",
      "model_en2de.block.2.layer.0.SelfAttention.v.weight\n",
      "tensor(314.8081, device='cuda:0')\n",
      "model_en2de.block.2.layer.0.SelfAttention.o.weight\n",
      "tensor(284.2662, device='cuda:0')\n",
      "model_en2de.block.2.layer.0.layer_norm.weight\n",
      "tensor(2.2525, device='cuda:0')\n",
      "model_en2de.block.2.layer.1.DenseReluDense.wi_0.weight\n",
      "tensor(546.5812, device='cuda:0')\n",
      "model_en2de.block.2.layer.1.DenseReluDense.wi_1.weight\n",
      "tensor(377.4855, device='cuda:0')\n",
      "model_en2de.block.2.layer.1.DenseReluDense.wo.weight\n",
      "tensor(521.3868, device='cuda:0')\n",
      "model_en2de.block.2.layer.1.layer_norm.weight\n",
      "tensor(2.3766, device='cuda:0')\n",
      "model_en2de.block.3.layer.0.SelfAttention.q.weight\n",
      "tensor(562.6523, device='cuda:0')\n",
      "model_en2de.block.3.layer.0.SelfAttention.k.weight\n",
      "tensor(213.2258, device='cuda:0')\n",
      "model_en2de.block.3.layer.0.SelfAttention.v.weight\n",
      "tensor(311.8695, device='cuda:0')\n",
      "model_en2de.block.3.layer.0.SelfAttention.o.weight\n",
      "tensor(277.8563, device='cuda:0')\n",
      "model_en2de.block.3.layer.0.layer_norm.weight\n",
      "tensor(2.6306, device='cuda:0')\n",
      "model_en2de.block.3.layer.1.DenseReluDense.wi_0.weight\n",
      "tensor(550.1205, device='cuda:0')\n",
      "model_en2de.block.3.layer.1.DenseReluDense.wi_1.weight\n",
      "tensor(332.6325, device='cuda:0')\n",
      "model_en2de.block.3.layer.1.DenseReluDense.wo.weight\n",
      "tensor(464.1398, device='cuda:0')\n",
      "model_en2de.block.3.layer.1.layer_norm.weight\n",
      "tensor(2.7252, device='cuda:0')\n",
      "model_en2de.block.4.layer.0.SelfAttention.q.weight\n",
      "tensor(548.1038, device='cuda:0')\n",
      "model_en2de.block.4.layer.0.SelfAttention.k.weight\n",
      "tensor(189.7236, device='cuda:0')\n",
      "model_en2de.block.4.layer.0.SelfAttention.v.weight\n",
      "tensor(329.3830, device='cuda:0')\n",
      "model_en2de.block.4.layer.0.SelfAttention.o.weight\n",
      "tensor(297.2483, device='cuda:0')\n",
      "model_en2de.block.4.layer.0.layer_norm.weight\n",
      "tensor(3.2573, device='cuda:0')\n",
      "model_en2de.block.4.layer.1.DenseReluDense.wi_0.weight\n",
      "tensor(477.9637, device='cuda:0')\n",
      "model_en2de.block.4.layer.1.DenseReluDense.wi_1.weight\n",
      "tensor(233.2219, device='cuda:0')\n",
      "model_en2de.block.4.layer.1.DenseReluDense.wo.weight\n",
      "tensor(309.8362, device='cuda:0')\n",
      "model_en2de.block.4.layer.1.layer_norm.weight\n",
      "tensor(3.1666, device='cuda:0')\n",
      "model_en2de.block.5.layer.0.SelfAttention.q.weight\n",
      "tensor(523.6483, device='cuda:0')\n",
      "model_en2de.block.5.layer.0.SelfAttention.k.weight\n",
      "tensor(169.2817, device='cuda:0')\n",
      "model_en2de.block.5.layer.0.SelfAttention.v.weight\n",
      "tensor(207.2054, device='cuda:0')\n",
      "model_en2de.block.5.layer.0.SelfAttention.o.weight\n",
      "tensor(176.2467, device='cuda:0')\n",
      "model_en2de.block.5.layer.0.layer_norm.weight\n",
      "tensor(3.0603, device='cuda:0')\n",
      "model_en2de.block.5.layer.1.DenseReluDense.wi_0.weight\n",
      "tensor(455.4868, device='cuda:0')\n",
      "model_en2de.block.5.layer.1.DenseReluDense.wi_1.weight\n",
      "tensor(196.5108, device='cuda:0')\n",
      "model_en2de.block.5.layer.1.DenseReluDense.wo.weight\n",
      "tensor(263.6595, device='cuda:0')\n",
      "model_en2de.block.5.layer.1.layer_norm.weight\n",
      "tensor(3.2413, device='cuda:0')\n",
      "model_en2de.block.6.layer.0.SelfAttention.q.weight\n",
      "tensor(513.9932, device='cuda:0')\n",
      "model_en2de.block.6.layer.0.SelfAttention.k.weight\n",
      "tensor(169.2892, device='cuda:0')\n",
      "model_en2de.block.6.layer.0.SelfAttention.v.weight\n",
      "tensor(228.1034, device='cuda:0')\n",
      "model_en2de.block.6.layer.0.SelfAttention.o.weight\n",
      "tensor(238.0981, device='cuda:0')\n",
      "model_en2de.block.6.layer.0.layer_norm.weight\n",
      "tensor(3.8994, device='cuda:0')\n",
      "model_en2de.block.6.layer.1.DenseReluDense.wi_0.weight\n",
      "tensor(429.3879, device='cuda:0')\n",
      "model_en2de.block.6.layer.1.DenseReluDense.wi_1.weight\n",
      "tensor(163.3060, device='cuda:0')\n",
      "model_en2de.block.6.layer.1.DenseReluDense.wo.weight\n",
      "tensor(226.0288, device='cuda:0')\n",
      "model_en2de.block.6.layer.1.layer_norm.weight\n",
      "tensor(3.9279, device='cuda:0')\n",
      "model_en2de.block.7.layer.0.SelfAttention.q.weight\n",
      "tensor(346.2502, device='cuda:0')\n",
      "model_en2de.block.7.layer.0.SelfAttention.k.weight\n",
      "tensor(89.7197, device='cuda:0')\n",
      "model_en2de.block.7.layer.0.SelfAttention.v.weight\n",
      "tensor(181.4499, device='cuda:0')\n",
      "model_en2de.block.7.layer.0.SelfAttention.o.weight\n",
      "tensor(158.2651, device='cuda:0')\n",
      "model_en2de.block.7.layer.0.layer_norm.weight\n",
      "tensor(3.6082, device='cuda:0')\n",
      "model_en2de.block.7.layer.1.DenseReluDense.wi_0.weight\n",
      "tensor(414.0901, device='cuda:0')\n",
      "model_en2de.block.7.layer.1.DenseReluDense.wi_1.weight\n",
      "tensor(131.2566, device='cuda:0')\n",
      "model_en2de.block.7.layer.1.DenseReluDense.wo.weight\n",
      "tensor(199.6495, device='cuda:0')\n",
      "model_en2de.block.7.layer.1.layer_norm.weight\n",
      "tensor(3.9461, device='cuda:0')\n",
      "model_en2de.final_layer_norm.weight\n",
      "tensor(4.4334, device='cuda:0')\n",
      "model_de2en.embed_tokens.weight\n",
      "tensor(801.5894, device='cuda:0')\n",
      "model_de2en.block.0.layer.0.SelfAttention.q.weight\n",
      "tensor(898.0894, device='cuda:0')\n",
      "model_de2en.block.0.layer.0.SelfAttention.k.weight\n",
      "tensor(574.4008, device='cuda:0')\n",
      "model_de2en.block.0.layer.0.SelfAttention.v.weight\n",
      "tensor(748.6073, device='cuda:0')\n",
      "model_de2en.block.0.layer.0.SelfAttention.o.weight\n",
      "tensor(692.9612, device='cuda:0')\n",
      "model_de2en.block.0.layer.0.SelfAttention.relative_attention_bias.weight\n",
      "tensor(0.9750, device='cuda:0')\n",
      "model_de2en.block.0.layer.0.layer_norm.weight\n",
      "tensor(2.4661, device='cuda:0')\n",
      "model_de2en.block.0.layer.1.DenseReluDense.wi_0.weight\n",
      "tensor(1639.0005, device='cuda:0')\n",
      "model_de2en.block.0.layer.1.DenseReluDense.wi_1.weight\n",
      "tensor(1561.5640, device='cuda:0')\n",
      "model_de2en.block.0.layer.1.DenseReluDense.wo.weight\n",
      "tensor(1723.3479, device='cuda:0')\n",
      "model_de2en.block.0.layer.1.layer_norm.weight\n",
      "tensor(2.5800, device='cuda:0')\n",
      "model_de2en.block.1.layer.0.SelfAttention.q.weight\n",
      "tensor(891.4679, device='cuda:0')\n",
      "model_de2en.block.1.layer.0.SelfAttention.k.weight\n",
      "tensor(581.4658, device='cuda:0')\n",
      "model_de2en.block.1.layer.0.SelfAttention.v.weight\n",
      "tensor(719.8340, device='cuda:0')\n",
      "model_de2en.block.1.layer.0.SelfAttention.o.weight\n",
      "tensor(677.5421, device='cuda:0')\n",
      "model_de2en.block.1.layer.0.layer_norm.weight\n",
      "tensor(2.4175, device='cuda:0')\n",
      "model_de2en.block.1.layer.1.DenseReluDense.wi_0.weight\n",
      "tensor(1628.2676, device='cuda:0')\n",
      "model_de2en.block.1.layer.1.DenseReluDense.wi_1.weight\n",
      "tensor(1506.9668, device='cuda:0')\n",
      "model_de2en.block.1.layer.1.DenseReluDense.wo.weight\n",
      "tensor(1638.7325, device='cuda:0')\n",
      "model_de2en.block.1.layer.1.layer_norm.weight\n",
      "tensor(2.2794, device='cuda:0')\n",
      "model_de2en.block.2.layer.0.SelfAttention.q.weight\n",
      "tensor(923.7200, device='cuda:0')\n",
      "model_de2en.block.2.layer.0.SelfAttention.k.weight\n",
      "tensor(578.3286, device='cuda:0')\n",
      "model_de2en.block.2.layer.0.SelfAttention.v.weight\n",
      "tensor(708.0308, device='cuda:0')\n",
      "model_de2en.block.2.layer.0.SelfAttention.o.weight\n",
      "tensor(667.8108, device='cuda:0')\n",
      "model_de2en.block.2.layer.0.layer_norm.weight\n",
      "tensor(2.6736, device='cuda:0')\n",
      "model_de2en.block.2.layer.1.DenseReluDense.wi_0.weight\n",
      "tensor(1611.4705, device='cuda:0')\n",
      "model_de2en.block.2.layer.1.DenseReluDense.wi_1.weight\n",
      "tensor(1320.5791, device='cuda:0')\n",
      "model_de2en.block.2.layer.1.DenseReluDense.wo.weight\n",
      "tensor(1498.3956, device='cuda:0')\n",
      "model_de2en.block.2.layer.1.layer_norm.weight\n",
      "tensor(2.4739, device='cuda:0')\n",
      "model_de2en.block.3.layer.0.SelfAttention.q.weight\n",
      "tensor(923.8933, device='cuda:0')\n",
      "model_de2en.block.3.layer.0.SelfAttention.k.weight\n",
      "tensor(604.6178, device='cuda:0')\n",
      "model_de2en.block.3.layer.0.SelfAttention.v.weight\n",
      "tensor(714.7224, device='cuda:0')\n",
      "model_de2en.block.3.layer.0.SelfAttention.o.weight\n",
      "tensor(654.5333, device='cuda:0')\n",
      "model_de2en.block.3.layer.0.layer_norm.weight\n",
      "tensor(2.8788, device='cuda:0')\n",
      "model_de2en.block.3.layer.1.DenseReluDense.wi_0.weight\n",
      "tensor(1583.7214, device='cuda:0')\n",
      "model_de2en.block.3.layer.1.DenseReluDense.wi_1.weight\n",
      "tensor(1170.3311, device='cuda:0')\n",
      "model_de2en.block.3.layer.1.DenseReluDense.wo.weight\n",
      "tensor(1386.8579, device='cuda:0')\n",
      "model_de2en.block.3.layer.1.layer_norm.weight\n",
      "tensor(2.6230, device='cuda:0')\n",
      "model_de2en.block.4.layer.0.SelfAttention.q.weight\n",
      "tensor(941.5922, device='cuda:0')\n",
      "model_de2en.block.4.layer.0.SelfAttention.k.weight\n",
      "tensor(656.6433, device='cuda:0')\n",
      "model_de2en.block.4.layer.0.SelfAttention.v.weight\n",
      "tensor(736.8121, device='cuda:0')\n",
      "model_de2en.block.4.layer.0.SelfAttention.o.weight\n",
      "tensor(670.6483, device='cuda:0')\n",
      "model_de2en.block.4.layer.0.layer_norm.weight\n",
      "tensor(3.0495, device='cuda:0')\n",
      "model_de2en.block.4.layer.1.DenseReluDense.wi_0.weight\n",
      "tensor(1515.0409, device='cuda:0')\n",
      "model_de2en.block.4.layer.1.DenseReluDense.wi_1.weight\n",
      "tensor(1038.8635, device='cuda:0')\n",
      "model_de2en.block.4.layer.1.DenseReluDense.wo.weight\n",
      "tensor(1281.1443, device='cuda:0')\n",
      "model_de2en.block.4.layer.1.layer_norm.weight\n",
      "tensor(2.5843, device='cuda:0')\n",
      "model_de2en.block.5.layer.0.SelfAttention.q.weight\n",
      "tensor(968.3727, device='cuda:0')\n",
      "model_de2en.block.5.layer.0.SelfAttention.k.weight\n",
      "tensor(625.9304, device='cuda:0')\n",
      "model_de2en.block.5.layer.0.SelfAttention.v.weight\n",
      "tensor(685.1980, device='cuda:0')\n",
      "model_de2en.block.5.layer.0.SelfAttention.o.weight\n",
      "tensor(615.1463, device='cuda:0')\n",
      "model_de2en.block.5.layer.0.layer_norm.weight\n",
      "tensor(3.2990, device='cuda:0')\n",
      "model_de2en.block.5.layer.1.DenseReluDense.wi_0.weight\n",
      "tensor(1499.8867, device='cuda:0')\n",
      "model_de2en.block.5.layer.1.DenseReluDense.wi_1.weight\n",
      "tensor(956.2568, device='cuda:0')\n",
      "model_de2en.block.5.layer.1.DenseReluDense.wo.weight\n",
      "tensor(1203.4055, device='cuda:0')\n",
      "model_de2en.block.5.layer.1.layer_norm.weight\n",
      "tensor(3.0147, device='cuda:0')\n",
      "model_de2en.block.6.layer.0.SelfAttention.q.weight\n",
      "tensor(965.1334, device='cuda:0')\n",
      "model_de2en.block.6.layer.0.SelfAttention.k.weight\n",
      "tensor(642.0560, device='cuda:0')\n",
      "model_de2en.block.6.layer.0.SelfAttention.v.weight\n",
      "tensor(749.5436, device='cuda:0')\n",
      "model_de2en.block.6.layer.0.SelfAttention.o.weight\n",
      "tensor(628.1562, device='cuda:0')\n",
      "model_de2en.block.6.layer.0.layer_norm.weight\n",
      "tensor(3.7304, device='cuda:0')\n",
      "model_de2en.block.6.layer.1.DenseReluDense.wi_0.weight\n",
      "tensor(1462.1595, device='cuda:0')\n",
      "model_de2en.block.6.layer.1.DenseReluDense.wi_1.weight\n",
      "tensor(799.7180, device='cuda:0')\n",
      "model_de2en.block.6.layer.1.DenseReluDense.wo.weight\n",
      "tensor(1067.0294, device='cuda:0')\n",
      "model_de2en.block.6.layer.1.layer_norm.weight\n",
      "tensor(3.7447, device='cuda:0')\n",
      "model_de2en.block.7.layer.0.SelfAttention.q.weight\n",
      "tensor(1041.5747, device='cuda:0')\n",
      "model_de2en.block.7.layer.0.SelfAttention.k.weight\n",
      "tensor(628.5803, device='cuda:0')\n",
      "model_de2en.block.7.layer.0.SelfAttention.v.weight\n",
      "tensor(637.4072, device='cuda:0')\n",
      "model_de2en.block.7.layer.0.SelfAttention.o.weight\n",
      "tensor(632.4077, device='cuda:0')\n",
      "model_de2en.block.7.layer.0.layer_norm.weight\n",
      "tensor(4.9989, device='cuda:0')\n",
      "model_de2en.block.7.layer.1.DenseReluDense.wi_0.weight\n",
      "tensor(1061.6124, device='cuda:0')\n",
      "model_de2en.block.7.layer.1.DenseReluDense.wi_1.weight\n",
      "tensor(399.5722, device='cuda:0')\n",
      "model_de2en.block.7.layer.1.DenseReluDense.wo.weight\n",
      "tensor(594.2369, device='cuda:0')\n",
      "model_de2en.block.7.layer.1.layer_norm.weight\n",
      "tensor(4.6407, device='cuda:0')\n",
      "model_de2en.final_layer_norm.weight\n",
      "tensor(8.8642, device='cuda:0')\n",
      "linear1.weight\n",
      "tensor(3503.7356, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "linear2.weight\n",
      "tensor(11.3955, device='cuda:0', grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for (k,v),b in zip(A.named_parameters(),B.values()):\n",
    "    print(k)\n",
    "    print(torch.sum(abs(b-v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.2642e+00, -5.7511e-01, -1.9056e-01,  ...,  3.6191e-01,\n",
      "          3.7525e-01,  3.3562e+00],\n",
      "        [-1.3564e+01,  8.8761e+00, -9.6229e-02,  ...,  1.1249e+01,\n",
      "          5.5307e+00,  9.1999e+01],\n",
      "        [ 9.8127e+00,  5.1874e+00, -4.1874e+00,  ..., -7.5000e+00,\n",
      "          1.2813e+01,  1.8875e+01],\n",
      "        ...,\n",
      "        [-4.5117e-01, -3.3594e-01, -3.8867e-01,  ..., -2.0996e-01,\n",
      "         -2.0000e+00, -9.1406e-01],\n",
      "        [-1.0234e+00, -8.0859e-01,  4.3555e-01,  ..., -5.9326e-02,\n",
      "         -9.2188e-01, -9.2969e-01],\n",
      "        [ 1.0078e+00,  1.5234e-01, -2.4902e-01,  ..., -1.8555e-01,\n",
      "         -2.7148e-01,  1.7969e+00]], device='cuda:0')\n",
      "tensor([[-0.0124,  0.0573, -0.0913,  ..., -0.0868, -0.0742,  0.0421],\n",
      "        [ 0.0888,  0.0094,  0.0585,  ..., -0.0170,  0.0142, -0.1148],\n",
      "        [-0.0787, -0.0301, -0.0939,  ...,  0.1497,  0.0637,  0.0431],\n",
      "        ...,\n",
      "        [-0.0124, -0.0159, -0.1205,  ...,  0.0250,  0.0508, -0.0129],\n",
      "        [ 0.0623, -0.0515, -0.0224,  ...,  0.0552,  0.0287,  0.0309],\n",
      "        [ 0.0689, -0.0022, -0.0847,  ..., -0.0368, -0.0535, -0.0896]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.1712,  0.3849,  0.4524,  ..., -0.5068,  0.4885,  0.1026],\n",
      "        [-0.4605, -1.0706, -0.0990,  ..., -1.7094, -0.2352, -1.2204],\n",
      "        [-0.1349, -0.8418, -0.2394,  ...,  0.3947, -0.2817,  0.0924],\n",
      "        ...,\n",
      "        [-0.5078, -0.2381,  0.0158,  ..., -0.4598, -0.4844, -0.1148],\n",
      "        [-0.2444,  0.2012, -0.4375,  ..., -0.0437, -0.1681,  0.2785],\n",
      "        [ 0.3695, -0.1020, -0.1491,  ..., -0.1183, -0.1647, -0.0318]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.6669,  0.3034,  0.0009,  ...,  0.2812,  0.4082, -0.0454],\n",
      "        [ 0.0995, -0.0172,  0.5242,  ...,  0.9288,  0.3386, -0.3761],\n",
      "        [-0.1800, -0.4070,  0.1951,  ...,  0.0246,  0.1894,  0.0397],\n",
      "        ...,\n",
      "        [ 0.6412, -0.6701,  0.1359,  ...,  0.3089,  0.3341,  0.1217],\n",
      "        [ 0.5436,  0.3297, -0.1600,  ..., -0.2284,  0.0155,  0.2546],\n",
      "        [-0.0469, -0.4551, -0.2431,  ...,  0.1048, -0.0659, -0.2751]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.5180, -0.1903,  0.4236,  ..., -0.1809,  0.2945,  0.6270],\n",
      "        [-0.6182, -0.0118,  0.5089,  ..., -0.1461, -0.5197,  0.1877],\n",
      "        [ 0.2352, -0.1711, -1.0720,  ..., -0.2037, -0.7043, -0.1426],\n",
      "        ...,\n",
      "        [ 0.2354, -0.8221,  0.0405,  ...,  0.1028, -0.2128, -0.2987],\n",
      "        [-0.4952,  1.1109, -0.2984,  ..., -0.2534,  0.4232, -0.5034],\n",
      "        [ 0.3585,  0.1638,  0.1049,  ..., -0.0446, -0.2518,  0.8675]],\n",
      "       device='cuda:0')\n",
      "tensor([[  5.2572,  -8.1251,   2.7382,  -9.5005,   4.4704, -17.8750],\n",
      "        [  7.6781,   8.1794,   0.7913,   3.3048,   7.4026,   5.5356],\n",
      "        [  5.7797,   6.4353,   1.1160,   3.4992,   7.4492,   5.7636],\n",
      "        [  4.8156,   5.3768,   1.0973,   3.6395,   7.0845,   5.6900],\n",
      "        [  4.2801,   4.6582,   1.1562,   3.7519,   6.7759,   5.6217],\n",
      "        [  3.9443,   4.1341,   1.1196,   3.7781,   6.5324,   5.5247],\n",
      "        [  3.6389,   3.6588,   1.1150,   3.8376,   6.2519,   5.4672],\n",
      "        [  3.4088,   3.3223,   1.1705,   3.8710,   6.0647,   5.4052],\n",
      "        [  2.9033,   2.4892,   1.0803,   3.9675,   5.5971,   5.2400],\n",
      "        [  2.3765,   1.6442,   1.1105,   3.9766,   4.9721,   5.0726],\n",
      "        [  1.9141,   0.8644,   0.9378,   4.0005,   4.3795,   4.8366],\n",
      "        [  1.5104,   0.1607,   0.7775,   4.0585,   3.6129,   4.5653],\n",
      "        [  1.1383,  -0.2226,   0.5691,   4.0989,   2.8411,   4.2539],\n",
      "        [  0.6937,  -0.9720,   0.2546,   4.1292,   2.0983,   3.8901],\n",
      "        [  0.3965,  -1.8203,   0.0786,   4.1250,   1.5000,   3.5781],\n",
      "        [ -1.3984,  -0.9883,  -1.6797,   4.1562,  -0.7383,   2.2812],\n",
      "        [  0.0801,  -0.0801,   0.3340,  -0.3594,   0.3145,  -0.2793],\n",
      "        [  3.5476,   0.1279,   8.5675,   4.2158,   1.1866, -16.8750],\n",
      "        [  3.2445,   0.2553,   7.3979,   4.4181,   1.3608,   2.5285],\n",
      "        [  3.1289,   0.3387,   6.7144,   4.5329,   1.4892,   2.5988],\n",
      "        [  3.0492,   0.3840,   6.2844,   4.5674,   1.4515,   2.5887],\n",
      "        [  2.8980,   0.2443,   5.9372,   4.6236,   1.2184,   2.5772],\n",
      "        [  2.8307,   0.3879,   5.6561,   4.6276,   1.5052,   2.6234],\n",
      "        [  2.8651,   0.3268,   5.4305,   4.6587,   1.3806,   2.5481],\n",
      "        [  2.7507,   0.3992,   4.9981,   4.6893,   1.4307,   2.5110],\n",
      "        [  2.6336,   0.3571,   4.4363,   4.7178,   1.3727,   2.4509],\n",
      "        [  2.4379,   0.3941,   3.8971,   4.7152,   1.3016,   2.3149],\n",
      "        [  2.1591,   0.3612,   3.2876,   4.7238,   1.2075,   2.2256],\n",
      "        [  1.7215,   0.2876,   2.7407,   4.7079,   1.0504,   2.1289],\n",
      "        [  1.1073,   0.2173,   2.1061,   4.6887,   0.9396,   1.9639],\n",
      "        [  0.5039,   0.1260,   1.7109,   4.6562,   0.8438,   1.8906],\n",
      "        [ -4.6562,   0.2188,   0.3398,   4.7500,   0.1406,   1.5859]],\n",
      "       device='cuda:0')\n",
      "tensor([0.0635, 0.0817, 0.0651, 0.0910, 0.0755, 0.0786, 0.1110, 0.0734, 0.0618,\n",
      "        0.1064, 0.0780, 0.0751, 0.0784, 0.0680, 0.0703, 0.1033, 0.0726, 0.0638,\n",
      "        0.1093, 0.0567, 0.0916, 0.0562, 0.0995, 0.0944, 0.0721, 0.0622, 0.0650,\n",
      "        0.0936, 0.0714, 0.0890, 0.0799, 0.0880, 0.1194, 0.0776, 0.0718, 0.0735,\n",
      "        0.0799, 0.0796, 0.0808, 0.0506, 0.0882, 0.0625, 0.0821, 0.0542, 0.0688,\n",
      "        0.1370, 0.0935, 0.0617, 0.0638, 0.0583, 0.0612, 0.0745, 0.0731, 0.0696,\n",
      "        0.1044, 0.0677, 0.0587, 0.1052, 0.0683, 0.0656, 0.0720, 0.0741, 0.0832,\n",
      "        0.0721, 0.0950, 0.0785, 0.0607, 0.0668, 0.1145, 0.0843, 0.0955, 0.0594,\n",
      "        0.0632, 0.0724, 0.1014, 0.0922, 0.0690, 0.0731, 0.0685, 0.0550, 0.0851,\n",
      "        0.0732, 0.0846, 0.0923, 0.0653, 0.0787, 0.0804, 0.0794, 0.0814, 0.1063,\n",
      "        0.0644, 0.0544, 0.0878, 0.0780, 0.0728, 0.0686, 0.0684, 0.0775, 0.0721,\n",
      "        0.0802, 0.0905, 0.0715, 0.0773, 0.0652, 0.0730, 0.0726, 0.0607, 0.0770,\n",
      "        0.0628, 0.0851, 0.0688, 0.0848, 0.1132, 0.0659, 0.0841, 0.0712, 0.0449,\n",
      "        0.0758, 0.0697, 0.0816, 0.0858, 0.1083, 0.0864, 0.0816, 0.0717, 0.0758,\n",
      "        0.0865, 0.0887, 0.0508, 0.0626, 0.0819, 0.0842, 0.0679, 0.0624, 0.0713,\n",
      "        0.0803, 0.1440, 0.0528, 0.0709, 0.0876, 0.0662, 0.1049, 0.0747, 0.0796,\n",
      "        0.0907, 0.0946, 0.0694, 0.0873, 0.0850, 0.0626, 0.0869, 0.1058, 0.0648,\n",
      "        0.0752, 0.0583, 0.0873, 0.0769, 0.1066, 0.0958, 0.0968, 0.0676, 0.0857,\n",
      "        0.0908, 0.0515, 0.0689, 0.0805, 0.0745, 0.0879, 0.0858, 0.1052, 0.0678,\n",
      "        0.0690, 0.0702, 0.0771, 0.0709, 0.0735, 0.0767, 0.0451, 0.0736, 0.0854,\n",
      "        0.0682, 0.0654, 0.0975, 0.0673, 0.0854, 0.0803, 0.0922, 0.1112, 0.0860,\n",
      "        0.0857, 0.0614, 0.1140, 0.0761, 0.1098, 0.0726, 0.0525, 0.0780, 0.0841,\n",
      "        0.0841, 0.0673, 0.0637, 0.0784, 0.0581, 0.0813, 0.0610, 0.0801, 0.0722,\n",
      "        0.0692, 0.0669, 0.0882, 0.1085, 0.0766, 0.0941, 0.0678, 0.0664, 0.0856,\n",
      "        0.0887, 0.0717, 0.0817, 0.1147, 0.0741, 0.0608, 0.0869, 0.0973, 0.0741,\n",
      "        0.0555, 0.0795, 0.0726, 0.0812, 0.0855, 0.0641, 0.0547, 0.0603, 0.0721,\n",
      "        0.0790, 0.0664, 0.0652, 0.0914, 0.0766, 0.0816, 0.0855, 0.0744, 0.0814,\n",
      "        0.0767, 0.0855, 0.0848, 0.0863, 0.0833, 0.0752, 0.0760, 0.0785, 0.0795,\n",
      "        0.0671, 0.0802, 0.0627, 0.0698, 0.0758, 0.0839, 0.0763, 0.0848, 0.0856,\n",
      "        0.0748, 0.0660, 0.0661, 0.1114, 0.0793, 0.0801, 0.0884, 0.0654, 0.0726,\n",
      "        0.0664, 0.0622, 0.0829, 0.0717, 0.0886, 0.0719, 0.0705, 0.0938, 0.0697,\n",
      "        0.0938, 0.0595, 0.0744, 0.0752, 0.1104, 0.0684, 0.0674, 0.0864, 0.0609,\n",
      "        0.1107, 0.0598, 0.0777, 0.0555, 0.0839, 0.0630, 0.0745, 0.0816, 0.0570,\n",
      "        0.0469, 0.0925, 0.0544, 0.1106, 0.0849, 0.0644, 0.0996, 0.0607, 0.1036,\n",
      "        0.0833, 0.0590, 0.0567, 0.0656, 0.0728, 0.0876, 0.0806, 0.0826, 0.0872,\n",
      "        0.1100, 0.0752, 0.0730, 0.0949, 0.0755, 0.1067, 0.0679, 0.0744, 0.1118,\n",
      "        0.0538, 0.0612, 0.0885, 0.0871, 0.0747, 0.0962, 0.0810, 0.0838, 0.0899,\n",
      "        0.0447, 0.0630, 0.0538, 0.0742, 0.0902, 0.0874, 0.0604, 0.0603, 0.0706,\n",
      "        0.0725, 0.0747, 0.0751, 0.0723, 0.1021, 0.0809, 0.0741, 0.0622, 0.0799,\n",
      "        0.0720, 0.0662, 0.0848, 0.0827, 0.0859, 0.0776, 0.0835, 0.0964, 0.0803,\n",
      "        0.0737, 0.0756, 0.0862, 0.0841, 0.0524, 0.0842, 0.0754, 0.0271, 0.0958,\n",
      "        0.0878, 0.0848, 0.0744, 0.1075, 0.0786, 0.0645, 0.0622, 0.0939, 0.0731,\n",
      "        0.0657, 0.0711, 0.0857, 0.0791, 0.0644, 0.0704, 0.0733, 0.0882, 0.1338,\n",
      "        0.0860, 0.0826, 0.0470, 0.0679, 0.0786, 0.0848, 0.0779, 0.0952, 0.0722,\n",
      "        0.0916, 0.0792, 0.0618, 0.0699, 0.0585, 0.0659, 0.0830, 0.0719, 0.0804,\n",
      "        0.0848, 0.0813, 0.0746, 0.1073, 0.0663, 0.0796, 0.0693, 0.0520, 0.0678,\n",
      "        0.0284, 0.0885, 0.0745, 0.0663, 0.0531, 0.0930, 0.0708, 0.0918, 0.0735,\n",
      "        0.0639, 0.0464, 0.0735, 0.0864, 0.0812, 0.0636, 0.0700, 0.0586, 0.0956,\n",
      "        0.0741, 0.0787, 0.0893, 0.0846, 0.0785, 0.0751, 0.0733, 0.0883, 0.0679,\n",
      "        0.0589, 0.0626, 0.0638, 0.0798, 0.0763, 0.0643, 0.1028, 0.1038, 0.0692,\n",
      "        0.0579, 0.0793, 0.0570, 0.0767, 0.1008, 0.0635, 0.0595, 0.0667, 0.0787,\n",
      "        0.0640, 0.1036, 0.0775, 0.0743, 0.0520, 0.0649, 0.0935, 0.0766, 0.0664,\n",
      "        0.0873, 0.0915, 0.0654, 0.0880, 0.0895, 0.0652, 0.0663, 0.1142, 0.0850,\n",
      "        0.0755, 0.0425, 0.0688, 0.0785, 0.0797, 0.0843, 0.0970, 0.0751, 0.0812,\n",
      "        0.1097, 0.0843, 0.1081, 0.0733, 0.0684, 0.0654, 0.0677, 0.1039, 0.0918,\n",
      "        0.0676, 0.0863, 0.0969, 0.0744, 0.0912, 0.0923, 0.1109, 0.0965, 0.0964,\n",
      "        0.0798, 0.0557, 0.0768, 0.0632, 0.0646, 0.0712, 0.0681, 0.0976],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.1906,  0.3422,  0.4985,  ..., -0.6780, -0.3054,  0.9985],\n",
      "        [ 0.1341, -0.0683, -0.0565,  ..., -1.0300, -0.7003, -0.0645],\n",
      "        [-0.4711,  0.7760, -0.7894,  ..., -0.6614, -0.0883, -0.3125],\n",
      "        ...,\n",
      "        [-0.9094, -0.9191, -0.8176,  ...,  0.4264, -0.0117,  0.0718],\n",
      "        [-0.1245, -0.1778,  0.2559,  ..., -0.8997, -0.0328, -0.3729],\n",
      "        [-0.4281,  0.1073, -0.1125,  ..., -0.3171,  0.1731, -0.4898]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.2879, -0.5417,  0.0734,  ..., -0.1500, -0.4111, -0.1644],\n",
      "        [ 0.2645, -0.5479,  1.1873,  ..., -0.7842,  0.7628,  0.2490],\n",
      "        [-0.0334,  1.0777,  0.4365,  ...,  0.6185,  0.0784, -0.1593],\n",
      "        ...,\n",
      "        [-0.0281, -0.0302,  0.4659,  ...,  0.3209,  0.4333,  0.0419],\n",
      "        [-0.9149, -0.4502, -0.5358,  ...,  0.6910, -1.2039,  0.1144],\n",
      "        [ 0.3513,  0.5940, -0.0446,  ...,  0.9591,  0.2156, -0.2159]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.0189, -0.0026,  0.2556,  ...,  0.3056,  0.2191, -0.1681],\n",
      "        [-0.1804,  0.4382, -0.0214,  ..., -0.2826,  0.2924,  0.1732],\n",
      "        [ 0.3022, -0.1746, -0.3420,  ..., -0.1286, -0.0138, -0.1561],\n",
      "        ...,\n",
      "        [ 0.0485, -0.2103, -0.0777,  ..., -0.0139, -0.1748, -0.0461],\n",
      "        [ 0.2425,  0.0574,  0.4475,  ...,  0.1634,  0.3667,  0.3258],\n",
      "        [ 1.0977,  0.0838, -0.3488,  ..., -0.3055,  0.2577,  0.0615]],\n",
      "       device='cuda:0')\n",
      "tensor([0.1015, 0.0930, 0.0524, 0.0812, 0.0742, 0.0744, 0.1123, 0.0816, 0.0615,\n",
      "        0.0739, 0.0873, 0.0488, 0.0680, 0.0739, 0.0666, 0.0959, 0.0845, 0.0629,\n",
      "        0.1104, 0.0579, 0.0982, 0.0780, 0.1042, 0.0909, 0.0666, 0.0546, 0.0536,\n",
      "        0.0850, 0.0807, 0.0638, 0.0718, 0.1041, 0.1423, 0.0842, 0.0584, 0.0714,\n",
      "        0.1022, 0.0521, 0.0761, 0.0563, 0.0928, 0.0682, 0.0836, 0.0615, 0.0731,\n",
      "        0.1177, 0.0919, 0.0735, 0.0651, 0.0563, 0.0617, 0.0904, 0.0653, 0.0727,\n",
      "        0.0733, 0.0754, 0.0543, 0.1002, 0.0848, 0.0725, 0.0793, 0.0801, 0.0806,\n",
      "        0.0867, 0.1218, 0.0703, 0.0552, 0.0650, 0.1170, 0.0628, 0.1003, 0.0557,\n",
      "        0.0915, 0.0631, 0.0973, 0.0938, 0.0693, 0.0598, 0.0369, 0.0603, 0.0743,\n",
      "        0.0758, 0.0820, 0.0916, 0.0542, 0.0795, 0.0870, 0.0714, 0.0622, 0.0995,\n",
      "        0.0641, 0.0673, 0.0978, 0.0739, 0.0788, 0.0624, 0.0566, 0.0751, 0.0600,\n",
      "        0.0690, 0.0727, 0.0805, 0.0619, 0.0745, 0.0708, 0.0762, 0.0728, 0.0710,\n",
      "        0.0559, 0.0737, 0.0722, 0.0654, 0.1227, 0.0521, 0.0666, 0.0684, 0.0382,\n",
      "        0.0736, 0.0593, 0.0714, 0.0615, 0.0998, 0.0793, 0.0803, 0.0645, 0.0807,\n",
      "        0.0894, 0.0722, 0.0591, 0.0685, 0.0906, 0.0831, 0.0807, 0.0785, 0.0644,\n",
      "        0.0775, 0.1923, 0.0648, 0.0824, 0.0965, 0.0626, 0.1066, 0.0609, 0.0761,\n",
      "        0.0661, 0.0928, 0.0587, 0.0669, 0.0753, 0.0597, 0.0908, 0.0979, 0.0703,\n",
      "        0.0952, 0.0539, 0.0653, 0.0900, 0.1026, 0.0813, 0.0818, 0.0774, 0.1010,\n",
      "        0.0817, 0.0218, 0.0624, 0.0778, 0.0538, 0.0934, 0.0702, 0.0873, 0.0712,\n",
      "        0.0671, 0.0722, 0.0637, 0.0954, 0.0680, 0.0732, 0.0485, 0.0770, 0.0849,\n",
      "        0.0709, 0.0566, 0.0990, 0.0678, 0.0641, 0.0797, 0.0952, 0.0933, 0.0728,\n",
      "        0.0772, 0.0616, 0.1044, 0.0513, 0.1007, 0.0880, 0.0547, 0.0770, 0.0878,\n",
      "        0.0838, 0.0853, 0.0659, 0.0842, 0.0770, 0.0903, 0.0796, 0.0666, 0.0728,\n",
      "        0.0483, 0.0838, 0.0895, 0.1020, 0.0757, 0.0852, 0.0598, 0.0822, 0.0718,\n",
      "        0.0744, 0.0846, 0.0654, 0.0998, 0.0787, 0.0441, 0.0796, 0.0868, 0.0662,\n",
      "        0.0568, 0.0583, 0.0783, 0.0730, 0.0956, 0.0566, 0.0595, 0.0668, 0.0690,\n",
      "        0.0834, 0.0643, 0.0637, 0.1012, 0.0914, 0.0676, 0.0677, 0.0937, 0.0821,\n",
      "        0.0495, 0.0743, 0.0675, 0.0844, 0.0731, 0.0788, 0.0738, 0.0958, 0.0838,\n",
      "        0.0724, 0.0745, 0.0680, 0.0569, 0.0583, 0.0854, 0.0855, 0.0727, 0.0934,\n",
      "        0.0500, 0.0688, 0.0847, 0.0929, 0.0846, 0.0664, 0.0817, 0.0772, 0.0594,\n",
      "        0.0763, 0.0631, 0.0715, 0.0757, 0.0892, 0.0603, 0.0789, 0.0924, 0.0802,\n",
      "        0.0643, 0.0657, 0.0638, 0.0713, 0.1214, 0.0667, 0.0712, 0.0851, 0.0592,\n",
      "        0.0872, 0.0742, 0.0651, 0.0511, 0.0858, 0.0756, 0.0782, 0.0625, 0.0695,\n",
      "        0.0538, 0.0838, 0.0609, 0.1090, 0.0618, 0.0640, 0.0893, 0.0665, 0.1013,\n",
      "        0.0970, 0.0531, 0.0505, 0.0758, 0.0610, 0.0842, 0.0901, 0.0827, 0.0826,\n",
      "        0.0917, 0.0813, 0.0787, 0.1074, 0.0676, 0.0980, 0.0634, 0.0594, 0.1195,\n",
      "        0.0717, 0.0700, 0.0761, 0.0790, 0.0777, 0.0776, 0.0799, 0.0796, 0.0936,\n",
      "        0.0416, 0.0900, 0.0633, 0.0751, 0.0779, 0.0621, 0.1117, 0.0833, 0.0631,\n",
      "        0.0650, 0.0542, 0.0631, 0.0826, 0.0895, 0.0599, 0.0630, 0.0592, 0.0856,\n",
      "        0.0782, 0.1011, 0.0752, 0.0759, 0.0711, 0.0725, 0.0660, 0.0956, 0.0689,\n",
      "        0.0820, 0.0792, 0.0920, 0.0725, 0.0628, 0.0827, 0.0679, 0.0435, 0.0942,\n",
      "        0.0794, 0.1038, 0.0787, 0.1162, 0.0783, 0.0717, 0.0704, 0.0957, 0.0722,\n",
      "        0.0679, 0.0770, 0.0812, 0.0739, 0.0740, 0.0676, 0.0637, 0.0747, 0.1079,\n",
      "        0.0927, 0.0708, 0.0527, 0.0878, 0.0721, 0.0814, 0.0770, 0.0945, 0.0697,\n",
      "        0.0934, 0.0603, 0.0679, 0.0735, 0.0655, 0.0470, 0.0770, 0.0603, 0.0755,\n",
      "        0.0702, 0.0680, 0.0841, 0.1078, 0.0746, 0.0613, 0.0723, 0.0579, 0.0564,\n",
      "        0.0401, 0.0765, 0.0650, 0.0792, 0.0548, 0.1019, 0.0606, 0.0887, 0.0699,\n",
      "        0.0479, 0.0393, 0.0870, 0.0739, 0.0741, 0.0650, 0.0738, 0.0553, 0.0896,\n",
      "        0.0649, 0.0727, 0.0852, 0.0821, 0.0738, 0.0840, 0.0792, 0.0842, 0.0756,\n",
      "        0.0494, 0.0730, 0.0698, 0.0737, 0.0830, 0.0511, 0.1178, 0.0814, 0.0547,\n",
      "        0.0679, 0.0733, 0.0680, 0.0608, 0.1047, 0.0652, 0.0881, 0.0626, 0.0625,\n",
      "        0.0653, 0.1032, 0.0901, 0.0711, 0.0441, 0.0787, 0.0810, 0.0636, 0.0447,\n",
      "        0.0794, 0.0931, 0.0692, 0.0812, 0.0660, 0.0800, 0.0607, 0.0961, 0.0874,\n",
      "        0.0747, 0.0467, 0.0638, 0.0810, 0.0771, 0.0699, 0.0855, 0.0708, 0.0842,\n",
      "        0.1154, 0.0850, 0.0921, 0.0867, 0.0735, 0.0554, 0.0526, 0.0852, 0.0840,\n",
      "        0.0509, 0.0786, 0.1015, 0.0878, 0.0843, 0.0823, 0.0999, 0.0650, 0.0887,\n",
      "        0.0794, 0.0561, 0.0711, 0.0830, 0.0606, 0.0705, 0.0773, 0.1479],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.0185, -0.0019, -0.0603,  ...,  0.0735, -0.0842, -0.1444],\n",
      "        [ 0.0569, -0.0190, -0.0260,  ...,  0.0435,  0.0101, -0.0914],\n",
      "        [-0.0507,  0.0928, -0.0644,  ...,  0.0828, -0.0245, -0.0301],\n",
      "        ...,\n",
      "        [-0.0385, -0.1051, -0.0339,  ...,  0.0207, -0.0194,  0.0357],\n",
      "        [ 0.0500,  0.0585, -0.0338,  ..., -0.0275,  0.0463,  0.0550],\n",
      "        [ 0.0677,  0.0097,  0.0757,  ...,  0.0464,  0.0205,  0.0064]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.8158, -0.3741,  0.0384,  ..., -0.4324,  0.5407,  0.0025],\n",
      "        [ 1.0543, -0.4963,  0.0020,  ..., -0.8965,  0.0851, -0.6147],\n",
      "        [ 0.2125, -0.4043,  0.2801,  ...,  0.5636, -0.3783,  0.0220],\n",
      "        ...,\n",
      "        [ 0.2381,  0.0432, -0.3022,  ...,  0.2830,  0.1330,  0.0710],\n",
      "        [ 0.2063, -0.0171, -0.4188,  ...,  0.1980, -0.2930,  0.3884],\n",
      "        [-0.2052,  0.2751,  0.5343,  ...,  0.5310,  0.5842, -0.1268]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.6774, -0.2934,  0.1417,  ...,  0.0061,  0.0659, -0.0280],\n",
      "        [-0.2892, -0.1766,  0.9028,  ...,  0.8289, -0.2812,  0.0256],\n",
      "        [-0.4290, -0.0770,  0.2257,  ...,  0.5391,  0.5019,  0.1046],\n",
      "        ...,\n",
      "        [ 0.2341,  0.0081,  0.2381,  ...,  0.1172,  0.2985, -0.1576],\n",
      "        [-0.0842, -0.5522,  0.5095,  ...,  0.2415, -0.0178, -0.1634],\n",
      "        [-0.0541, -0.4661, -0.3964,  ..., -0.1918, -0.2277,  0.0513]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.3266, -0.0161,  0.3349,  ..., -0.2327,  0.7741,  0.1371],\n",
      "        [ 0.6066,  0.2188, -0.2300,  ..., -0.4167, -0.8987,  0.6013],\n",
      "        [ 0.3388, -0.3322, -0.0558,  ...,  0.0412,  0.1263,  0.0439],\n",
      "        ...,\n",
      "        [-0.2428,  0.1707,  0.5078,  ...,  1.1387, -0.7233, -0.2211],\n",
      "        [ 1.0081,  0.9103,  0.6234,  ..., -0.2764,  0.3012,  0.0049],\n",
      "        [ 0.4536, -0.1588, -0.0546,  ..., -0.0734, -0.1032,  0.3650]],\n",
      "       device='cuda:0')\n",
      "tensor([0.1073, 0.1193, 0.1109, 0.1202, 0.1052, 0.1089, 0.0700, 0.1387, 0.0926,\n",
      "        0.1509, 0.1128, 0.0460, 0.1197, 0.1185, 0.1131, 0.1519, 0.1026, 0.0996,\n",
      "        0.1212, 0.1026, 0.0968, 0.0894, 0.1279, 0.1045, 0.0965, 0.0881, 0.0768,\n",
      "        0.1084, 0.1151, 0.1085, 0.1226, 0.1440, 0.1134, 0.1154, 0.1111, 0.1157,\n",
      "        0.1363, 0.1039, 0.1188, 0.0901, 0.1124, 0.0937, 0.1363, 0.0760, 0.1110,\n",
      "        0.1753, 0.1314, 0.1028, 0.1162, 0.1014, 0.0992, 0.1217, 0.1113, 0.1043,\n",
      "        0.1415, 0.1111, 0.1092, 0.1404, 0.0953, 0.1004, 0.1322, 0.1363, 0.1258,\n",
      "        0.1116, 0.1455, 0.1283, 0.0691, 0.1192, 0.1490, 0.1002, 0.1256, 0.0813,\n",
      "        0.1094, 0.1160, 0.1194, 0.1139, 0.0978, 0.1265, 0.0293, 0.1154, 0.1361,\n",
      "        0.1050, 0.1241, 0.1296, 0.1152, 0.1297, 0.1210, 0.1199, 0.1051, 0.1590,\n",
      "        0.0998, 0.0921, 0.1098, 0.1254, 0.1121, 0.1124, 0.0976, 0.1247, 0.0944,\n",
      "        0.0991, 0.1199, 0.1125, 0.1105, 0.1035, 0.0996, 0.1192, 0.0929, 0.1116,\n",
      "        0.0779, 0.1190, 0.1024, 0.1126, 0.1251, 0.0907, 0.1032, 0.1035, 0.0767,\n",
      "        0.1126, 0.1089, 0.1249, 0.1112, 0.1345, 0.1252, 0.1314, 0.0994, 0.1186,\n",
      "        0.1224, 0.1152, 0.0833, 0.0816, 0.1197, 0.1290, 0.0905, 0.0878, 0.1026,\n",
      "        0.1167, 0.1243, 0.0904, 0.0886, 0.1457, 0.0892, 0.1476, 0.1059, 0.1228,\n",
      "        0.1321, 0.1323, 0.1101, 0.0942, 0.1232, 0.0932, 0.1233, 0.1421, 0.1137,\n",
      "        0.1348, 0.0913, 0.1221, 0.1258, 0.1425, 0.1188, 0.1333, 0.1061, 0.1389,\n",
      "        0.1292, 0.0332, 0.1079, 0.1275, 0.1124, 0.1458, 0.0969, 0.1368, 0.1036,\n",
      "        0.1279, 0.1135, 0.1220, 0.1289, 0.1123, 0.1092, 0.0864, 0.1118, 0.1183,\n",
      "        0.1038, 0.0880, 0.1382, 0.0954, 0.1143, 0.1130, 0.1567, 0.1483, 0.1045,\n",
      "        0.0976, 0.1111, 0.1394, 0.1116, 0.1515, 0.1309, 0.0909, 0.1189, 0.1298,\n",
      "        0.1063, 0.1085, 0.0940, 0.1043, 0.1143, 0.1071, 0.0779, 0.1081, 0.1122,\n",
      "        0.0840, 0.1209, 0.1307, 0.1642, 0.1141, 0.1137, 0.0988, 0.1090, 0.1147,\n",
      "        0.1249, 0.1200, 0.1073, 0.1436, 0.0830, 0.0956, 0.1051, 0.1149, 0.0987,\n",
      "        0.0888, 0.1137, 0.1053, 0.1146, 0.1333, 0.0904, 0.1071, 0.0962, 0.1147,\n",
      "        0.1401, 0.1107, 0.1322, 0.1221, 0.1233, 0.1082, 0.1173, 0.1089, 0.1202,\n",
      "        0.1026, 0.1186, 0.1114, 0.1236, 0.1121, 0.0809, 0.1334, 0.0865, 0.1259,\n",
      "        0.0996, 0.0907, 0.1051, 0.0891, 0.1170, 0.1076, 0.1202, 0.1279, 0.1324,\n",
      "        0.1049, 0.1006, 0.1166, 0.1310, 0.1385, 0.1207, 0.1375, 0.0826, 0.0924,\n",
      "        0.1009, 0.1133, 0.1153, 0.1210, 0.1288, 0.1053, 0.1109, 0.1140, 0.1156,\n",
      "        0.1230, 0.0948, 0.1342, 0.1065, 0.1320, 0.1158, 0.1022, 0.1241, 0.0875,\n",
      "        0.1510, 0.1025, 0.1220, 0.1031, 0.1300, 0.0795, 0.1071, 0.0676, 0.1068,\n",
      "        0.0766, 0.1329, 0.1053, 0.1442, 0.1207, 0.1161, 0.1351, 0.0943, 0.1567,\n",
      "        0.1247, 0.0944, 0.0770, 0.1018, 0.1223, 0.1182, 0.1034, 0.1051, 0.1327,\n",
      "        0.1335, 0.1379, 0.1375, 0.1235, 0.1024, 0.1447, 0.0996, 0.0990, 0.1247,\n",
      "        0.0973, 0.1027, 0.0998, 0.0931, 0.0998, 0.1431, 0.1282, 0.1067, 0.1277,\n",
      "        0.0498, 0.1174, 0.0966, 0.1020, 0.1230, 0.0890, 0.1088, 0.0922, 0.1231,\n",
      "        0.1151, 0.1183, 0.1024, 0.0858, 0.1289, 0.0975, 0.0991, 0.1085, 0.1114,\n",
      "        0.1207, 0.0906, 0.1150, 0.1210, 0.1145, 0.1285, 0.1072, 0.1465, 0.0846,\n",
      "        0.1095, 0.1253, 0.1271, 0.0948, 0.0932, 0.1220, 0.1066, 0.0191, 0.1344,\n",
      "        0.1102, 0.1394, 0.0868, 0.1381, 0.1309, 0.0932, 0.1098, 0.1144, 0.1002,\n",
      "        0.0996, 0.1283, 0.1384, 0.1046, 0.1155, 0.1069, 0.1104, 0.1271, 0.1870,\n",
      "        0.1349, 0.1118, 0.1038, 0.1226, 0.1045, 0.1073, 0.1113, 0.1447, 0.0988,\n",
      "        0.1142, 0.1153, 0.1061, 0.1195, 0.0910, 0.0940, 0.1228, 0.1108, 0.1047,\n",
      "        0.1059, 0.1455, 0.1125, 0.1240, 0.1265, 0.1180, 0.0977, 0.0628, 0.1032,\n",
      "        0.0225, 0.1214, 0.1163, 0.1124, 0.0964, 0.1206, 0.1127, 0.1451, 0.1365,\n",
      "        0.0890, 0.0842, 0.1041, 0.1164, 0.1171, 0.0809, 0.1045, 0.0978, 0.1394,\n",
      "        0.0890, 0.1205, 0.1359, 0.1099, 0.1061, 0.1204, 0.1259, 0.1056, 0.1168,\n",
      "        0.0948, 0.0962, 0.1217, 0.1249, 0.1234, 0.0865, 0.1674, 0.1139, 0.0901,\n",
      "        0.0873, 0.1260, 0.1091, 0.1051, 0.1362, 0.0986, 0.1014, 0.1069, 0.0825,\n",
      "        0.1069, 0.1352, 0.1094, 0.0990, 0.0744, 0.0878, 0.1218, 0.1102, 0.0972,\n",
      "        0.1341, 0.1305, 0.1202, 0.0985, 0.1002, 0.0979, 0.1068, 0.1347, 0.1157,\n",
      "        0.1046, 0.0622, 0.1057, 0.1262, 0.1044, 0.1341, 0.1140, 0.1084, 0.1127,\n",
      "        0.1397, 0.1020, 0.1412, 0.1192, 0.1189, 0.1002, 0.1191, 0.1415, 0.1370,\n",
      "        0.1037, 0.1250, 0.1438, 0.1300, 0.1184, 0.1327, 0.1312, 0.1028, 0.1602,\n",
      "        0.1274, 0.1042, 0.1403, 0.1079, 0.0851, 0.1150, 0.1330, 0.1472],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.1465,  0.0194,  0.6526,  ...,  0.1334, -0.1227, -1.1143],\n",
      "        [ 0.1453,  0.3640,  0.2423,  ..., -0.2358,  1.2491, -0.5799],\n",
      "        [-0.5926, -0.5788, -0.3904,  ...,  0.2163, -0.4588,  0.1567],\n",
      "        ...,\n",
      "        [-0.3478, -0.1901, -0.8084,  ..., -0.3654, -0.5863,  0.2240],\n",
      "        [ 0.6395,  0.4576,  0.7622,  ...,  0.8370, -0.2741,  0.7671],\n",
      "        [ 0.2265, -0.0704, -0.1944,  ...,  0.1443, -0.5315, -0.0785]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.1812,  0.7143,  0.1840,  ...,  0.1485, -0.0847,  0.8826],\n",
      "        [-0.2371, -0.2718, -0.8159,  ..., -0.3632, -0.9963, -0.3673],\n",
      "        [ 0.1440, -0.5886,  0.2458,  ...,  0.1370,  0.9649,  1.0029],\n",
      "        ...,\n",
      "        [-0.5874, -0.3532, -0.2714,  ...,  0.7266, -0.3399,  0.3467],\n",
      "        [-0.0329, -0.1373,  0.5842,  ..., -0.6913,  1.0693,  0.6302],\n",
      "        [-0.0863, -0.4191, -0.0503,  ..., -0.1353,  0.6993, -0.1992]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.0665, -0.5506,  0.3351,  ...,  0.4262, -0.7177,  0.3957],\n",
      "        [-0.2950, -0.1084,  0.3940,  ..., -0.1135, -0.2589,  0.0417],\n",
      "        [ 0.3476, -0.0274, -0.1788,  ...,  0.2187,  0.1438, -0.0388],\n",
      "        ...,\n",
      "        [ 0.2679, -0.2456,  0.4485,  ..., -0.0224,  0.0730, -0.4348],\n",
      "        [ 0.0510, -0.3863,  0.4012,  ..., -0.1469, -0.4940, -0.4401],\n",
      "        [ 0.1608,  0.1122, -0.1140,  ...,  0.0049, -0.2195, -0.0951]],\n",
      "       device='cuda:0')\n",
      "tensor([0.1250, 0.1244, 0.0748, 0.1139, 0.1163, 0.0992, 0.1248, 0.1043, 0.0789,\n",
      "        0.1334, 0.1058, 0.0421, 0.0957, 0.0836, 0.0792, 0.1230, 0.1112, 0.0883,\n",
      "        0.1092, 0.0864, 0.1017, 0.0635, 0.1142, 0.1044, 0.0800, 0.0708, 0.0581,\n",
      "        0.0808, 0.1027, 0.0915, 0.0903, 0.1293, 0.2039, 0.1009, 0.0850, 0.0914,\n",
      "        0.1093, 0.0884, 0.1022, 0.0818, 0.1128, 0.0871, 0.1010, 0.0791, 0.0986,\n",
      "        0.1481, 0.0977, 0.1053, 0.0888, 0.0834, 0.0816, 0.0966, 0.0849, 0.1081,\n",
      "        0.1251, 0.1019, 0.0799, 0.1267, 0.0972, 0.0841, 0.1080, 0.0919, 0.1132,\n",
      "        0.0984, 0.1434, 0.1117, 0.0564, 0.0840, 0.1323, 0.0929, 0.1171, 0.0843,\n",
      "        0.1019, 0.0980, 0.1168, 0.0966, 0.0858, 0.1168, 0.0410, 0.0849, 0.1079,\n",
      "        0.0920, 0.0927, 0.0849, 0.0958, 0.1219, 0.0986, 0.0913, 0.1119, 0.1319,\n",
      "        0.0991, 0.0858, 0.0956, 0.1069, 0.1048, 0.0873, 0.1000, 0.1013, 0.0915,\n",
      "        0.0913, 0.0919, 0.0936, 0.1024, 0.0908, 0.0860, 0.0864, 0.0929, 0.1145,\n",
      "        0.0657, 0.1030, 0.1071, 0.0898, 0.1593, 0.0702, 0.0773, 0.0975, 0.0517,\n",
      "        0.0922, 0.0823, 0.1091, 0.0983, 0.1022, 0.1303, 0.1138, 0.1063, 0.1105,\n",
      "        0.0925, 0.0822, 0.0934, 0.0729, 0.1103, 0.0985, 0.0976, 0.0838, 0.0836,\n",
      "        0.0994, 0.3291, 0.0773, 0.0884, 0.1134, 0.0941, 0.1360, 0.0873, 0.1102,\n",
      "        0.0810, 0.1211, 0.0883, 0.1038, 0.0914, 0.0771, 0.1031, 0.1111, 0.0947,\n",
      "        0.1276, 0.0902, 0.0909, 0.1108, 0.1295, 0.0983, 0.1131, 0.0821, 0.1268,\n",
      "        0.1050, 0.0214, 0.1032, 0.1099, 0.0790, 0.1186, 0.0934, 0.1108, 0.1016,\n",
      "        0.0909, 0.0883, 0.0962, 0.1175, 0.0869, 0.1085, 0.0633, 0.0974, 0.1007,\n",
      "        0.0974, 0.0720, 0.1203, 0.0716, 0.0906, 0.1074, 0.1304, 0.1287, 0.1060,\n",
      "        0.0777, 0.0868, 0.1529, 0.0901, 0.1152, 0.1149, 0.0662, 0.1067, 0.0903,\n",
      "        0.1028, 0.1050, 0.0798, 0.0871, 0.0917, 0.0993, 0.0873, 0.0971, 0.0974,\n",
      "        0.0868, 0.1005, 0.1110, 0.1262, 0.0816, 0.1009, 0.0797, 0.0953, 0.1163,\n",
      "        0.0976, 0.1217, 0.0879, 0.1237, 0.0728, 0.0875, 0.0890, 0.1180, 0.0821,\n",
      "        0.0696, 0.1087, 0.0939, 0.0908, 0.1166, 0.0734, 0.0891, 0.0856, 0.0958,\n",
      "        0.1164, 0.1052, 0.0974, 0.1333, 0.1100, 0.0929, 0.0941, 0.0967, 0.0824,\n",
      "        0.0896, 0.1138, 0.0975, 0.1155, 0.0944, 0.0805, 0.1045, 0.0779, 0.1122,\n",
      "        0.0835, 0.0932, 0.0666, 0.0831, 0.0916, 0.1026, 0.1026, 0.1056, 0.1163,\n",
      "        0.0793, 0.0787, 0.1195, 0.1115, 0.1220, 0.1028, 0.1314, 0.0849, 0.0666,\n",
      "        0.1094, 0.0850, 0.1019, 0.0899, 0.1243, 0.0908, 0.0891, 0.1091, 0.0973,\n",
      "        0.1057, 0.0891, 0.1045, 0.0839, 0.1451, 0.1135, 0.0971, 0.1001, 0.0813,\n",
      "        0.1124, 0.0920, 0.1027, 0.0614, 0.1099, 0.0736, 0.0891, 0.0563, 0.0944,\n",
      "        0.0647, 0.0937, 0.0906, 0.1247, 0.0980, 0.0926, 0.1288, 0.0978, 0.1157,\n",
      "        0.1154, 0.0807, 0.0588, 0.0960, 0.0918, 0.0957, 0.0994, 0.1048, 0.1130,\n",
      "        0.1479, 0.0942, 0.1079, 0.1177, 0.0821, 0.1416, 0.0839, 0.0908, 0.1471,\n",
      "        0.1060, 0.0771, 0.1133, 0.0908, 0.0823, 0.1098, 0.0897, 0.0964, 0.1232,\n",
      "        0.0421, 0.0961, 0.0805, 0.1055, 0.0916, 0.0863, 0.1246, 0.1003, 0.1047,\n",
      "        0.0905, 0.0899, 0.0863, 0.1032, 0.1045, 0.1003, 0.0946, 0.0812, 0.1022,\n",
      "        0.0992, 0.1166, 0.1105, 0.1078, 0.0860, 0.1236, 0.0949, 0.1196, 0.0899,\n",
      "        0.0928, 0.0973, 0.1010, 0.0765, 0.0618, 0.1082, 0.0864, 0.0389, 0.1145,\n",
      "        0.0917, 0.1401, 0.0991, 0.1441, 0.1192, 0.0932, 0.0961, 0.1135, 0.1180,\n",
      "        0.0882, 0.1014, 0.1085, 0.1080, 0.0961, 0.0845, 0.0806, 0.0986, 0.1592,\n",
      "        0.1025, 0.0915, 0.0912, 0.1287, 0.0825, 0.1055, 0.0901, 0.1336, 0.0936,\n",
      "        0.1116, 0.0999, 0.1047, 0.1039, 0.0803, 0.0866, 0.1321, 0.0842, 0.0900,\n",
      "        0.1001, 0.1104, 0.0962, 0.0978, 0.0975, 0.0983, 0.0895, 0.0274, 0.0887,\n",
      "        0.0283, 0.0928, 0.0864, 0.1014, 0.0888, 0.1128, 0.1023, 0.1245, 0.1136,\n",
      "        0.0728, 0.0667, 0.0895, 0.1207, 0.0940, 0.0752, 0.0761, 0.0871, 0.1238,\n",
      "        0.0887, 0.1150, 0.1124, 0.0886, 0.0940, 0.1025, 0.1067, 0.0897, 0.0765,\n",
      "        0.0748, 0.0782, 0.1070, 0.1006, 0.1104, 0.0838, 0.0988, 0.1036, 0.0791,\n",
      "        0.0647, 0.1194, 0.0827, 0.0821, 0.1334, 0.1038, 0.0892, 0.0859, 0.0703,\n",
      "        0.0975, 0.1407, 0.1023, 0.0847, 0.0672, 0.0807, 0.1036, 0.0833, 0.0587,\n",
      "        0.1012, 0.1178, 0.0899, 0.1083, 0.0861, 0.0797, 0.0963, 0.1295, 0.0950,\n",
      "        0.0984, 0.0617, 0.1018, 0.0999, 0.0914, 0.1223, 0.1008, 0.0842, 0.1116,\n",
      "        0.1416, 0.1189, 0.1390, 0.0996, 0.1089, 0.0904, 0.0875, 0.1124, 0.1088,\n",
      "        0.0783, 0.0982, 0.1164, 0.0994, 0.1161, 0.1034, 0.1478, 0.1040, 0.1157,\n",
      "        0.0835, 0.0934, 0.1152, 0.1170, 0.0741, 0.1101, 0.1011, 0.1713],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.0677,  0.0191,  0.0121,  ...,  0.0302, -0.0428, -0.0523],\n",
      "        [ 0.0682,  0.0401,  0.0638,  ...,  0.0723, -0.0084, -0.0130],\n",
      "        [-0.0976, -0.0092,  0.0826,  ...,  0.0043,  0.0541,  0.0600],\n",
      "        ...,\n",
      "        [ 0.0586,  0.0053, -0.0106,  ...,  0.0321, -0.0567, -0.0009],\n",
      "        [ 0.0176,  0.0965, -0.0185,  ..., -0.0040, -0.1074, -0.0463],\n",
      "        [ 0.1008, -0.0324,  0.0550,  ..., -0.0104,  0.0048,  0.0900]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.1189, -0.4315,  0.5119,  ...,  0.4654,  0.5386, -0.3407],\n",
      "        [-0.2428,  0.1450, -0.3265,  ...,  0.0922, -1.0395, -0.5331],\n",
      "        [-0.1859,  0.1524, -0.3301,  ...,  0.0681, -0.4995,  0.2534],\n",
      "        ...,\n",
      "        [ 0.2566, -0.4622,  0.0538,  ..., -0.1917, -0.4439, -0.3072],\n",
      "        [ 0.2872,  0.5648, -0.7902,  ...,  0.1601, -0.5530, -0.1221],\n",
      "        [ 0.5122, -0.5658,  0.4736,  ..., -0.0494, -0.0571,  0.1657]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.0572,  0.7381,  0.8701,  ...,  0.5944,  0.9067, -0.2467],\n",
      "        [-0.1865, -0.6963, -0.1526,  ..., -0.1982,  0.1060,  0.0337],\n",
      "        [-0.3324,  0.4419,  1.1407,  ...,  0.8326,  0.3521,  0.0053],\n",
      "        ...,\n",
      "        [-0.0630,  0.9199,  0.5395,  ..., -0.6243, -0.5587,  0.2390],\n",
      "        [-0.3987,  0.4089,  0.3794,  ...,  0.9825,  0.4213,  0.3137],\n",
      "        [-0.4501, -0.3521,  0.1055,  ...,  0.0522,  0.3278, -0.0377]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.0264, -0.3875,  0.2635,  ..., -0.4162, -0.5107,  0.8102],\n",
      "        [-0.1628,  0.2825, -0.0987,  ..., -0.0900,  0.1631,  0.2597],\n",
      "        [ 0.2327,  0.2529, -0.8244,  ..., -0.1278,  0.0717, -0.5947],\n",
      "        ...,\n",
      "        [-0.1799, -0.3873,  0.0976,  ...,  0.2384, -0.6291, -1.3017],\n",
      "        [ 0.5958, -0.4567, -1.1393,  ...,  0.0352, -0.0857, -0.3632],\n",
      "        [ 0.5967,  0.5393, -0.5283,  ...,  0.0358,  0.5182,  0.0247]],\n",
      "       device='cuda:0')\n",
      "tensor([0.1360, 0.1261, 0.0783, 0.1242, 0.1173, 0.1094, 0.0451, 0.1235, 0.0879,\n",
      "        0.1840, 0.1454, 0.0465, 0.1132, 0.1366, 0.1221, 0.1513, 0.1146, 0.1088,\n",
      "        0.1458, 0.0850, 0.1101, 0.0958, 0.1219, 0.1444, 0.0964, 0.0862, 0.0887,\n",
      "        0.1349, 0.1313, 0.1277, 0.1113, 0.1468, 0.0934, 0.1270, 0.1037, 0.1126,\n",
      "        0.1320, 0.1185, 0.1121, 0.0957, 0.1151, 0.1119, 0.1391, 0.1036, 0.1178,\n",
      "        0.1624, 0.1320, 0.1208, 0.1053, 0.1112, 0.1171, 0.1084, 0.1212, 0.1102,\n",
      "        0.1357, 0.1227, 0.1142, 0.1240, 0.1183, 0.0933, 0.1266, 0.1077, 0.1239,\n",
      "        0.1195, 0.1235, 0.1359, 0.1050, 0.1187, 0.1561, 0.0990, 0.1408, 0.0928,\n",
      "        0.1198, 0.1122, 0.1190, 0.1015, 0.1053, 0.1291, 0.0426, 0.1035, 0.1465,\n",
      "        0.1268, 0.1217, 0.1150, 0.1025, 0.1235, 0.1088, 0.1358, 0.1262, 0.1373,\n",
      "        0.0954, 0.0991, 0.1340, 0.1055, 0.1259, 0.1172, 0.1163, 0.1237, 0.0965,\n",
      "        0.0977, 0.1207, 0.1126, 0.1193, 0.1153, 0.1055, 0.1058, 0.1216, 0.1208,\n",
      "        0.0855, 0.1240, 0.1052, 0.1154, 0.1677, 0.0984, 0.1070, 0.1088, 0.0779,\n",
      "        0.1239, 0.1038, 0.1277, 0.1146, 0.1324, 0.1209, 0.1582, 0.1018, 0.1273,\n",
      "        0.1249, 0.0988, 0.0830, 0.0761, 0.1204, 0.1207, 0.1007, 0.1085, 0.0909,\n",
      "        0.1253, 0.0750, 0.1027, 0.0963, 0.1380, 0.1059, 0.1608, 0.1106, 0.1345,\n",
      "        0.1200, 0.1357, 0.1201, 0.1162, 0.0993, 0.0986, 0.1337, 0.1404, 0.1273,\n",
      "        0.1726, 0.1074, 0.1204, 0.1250, 0.1279, 0.1324, 0.1288, 0.1189, 0.1347,\n",
      "        0.1250, 0.0470, 0.1159, 0.1128, 0.1009, 0.1567, 0.1062, 0.1445, 0.1452,\n",
      "        0.1059, 0.1142, 0.1272, 0.1166, 0.1077, 0.1047, 0.0914, 0.1061, 0.1119,\n",
      "        0.1094, 0.0886, 0.1475, 0.1169, 0.1175, 0.1146, 0.1398, 0.1429, 0.1158,\n",
      "        0.1034, 0.1178, 0.1208, 0.1137, 0.1491, 0.1313, 0.0815, 0.1159, 0.1191,\n",
      "        0.1359, 0.1200, 0.1052, 0.0952, 0.1155, 0.1045, 0.0896, 0.1012, 0.1015,\n",
      "        0.0871, 0.1318, 0.1293, 0.1540, 0.1170, 0.1229, 0.0867, 0.1317, 0.1163,\n",
      "        0.1181, 0.1469, 0.1187, 0.1382, 0.1004, 0.1095, 0.1246, 0.1236, 0.1248,\n",
      "        0.0950, 0.1364, 0.0971, 0.1213, 0.1418, 0.0897, 0.1228, 0.1110, 0.1167,\n",
      "        0.1416, 0.1146, 0.1422, 0.1324, 0.1274, 0.1207, 0.1295, 0.1283, 0.1194,\n",
      "        0.1236, 0.1170, 0.1227, 0.1327, 0.1045, 0.0846, 0.1196, 0.0903, 0.1357,\n",
      "        0.1062, 0.1198, 0.1182, 0.1054, 0.1269, 0.1121, 0.1216, 0.1161, 0.1303,\n",
      "        0.0957, 0.1033, 0.1301, 0.1632, 0.1370, 0.1203, 0.1359, 0.0905, 0.1009,\n",
      "        0.1079, 0.1110, 0.1162, 0.1075, 0.1409, 0.1021, 0.0860, 0.1258, 0.1108,\n",
      "        0.1366, 0.1214, 0.1159, 0.0958, 0.1263, 0.1311, 0.1226, 0.1388, 0.1041,\n",
      "        0.1508, 0.1010, 0.1294, 0.0878, 0.1115, 0.1028, 0.1205, 0.0795, 0.1046,\n",
      "        0.0873, 0.1219, 0.0938, 0.1375, 0.1359, 0.1350, 0.1438, 0.0885, 0.1481,\n",
      "        0.1235, 0.0910, 0.0751, 0.1022, 0.1122, 0.1216, 0.1072, 0.1352, 0.1200,\n",
      "        0.1411, 0.1307, 0.1385, 0.1036, 0.1120, 0.1647, 0.1114, 0.1209, 0.1318,\n",
      "        0.1194, 0.1097, 0.1310, 0.1168, 0.1094, 0.1207, 0.1149, 0.1297, 0.1251,\n",
      "        0.0666, 0.1104, 0.1043, 0.1219, 0.1392, 0.0883, 0.1152, 0.1204, 0.1203,\n",
      "        0.1176, 0.1056, 0.1217, 0.1094, 0.1210, 0.1045, 0.1077, 0.1048, 0.1046,\n",
      "        0.1142, 0.0908, 0.1157, 0.1270, 0.1123, 0.1147, 0.1126, 0.1217, 0.0959,\n",
      "        0.1006, 0.1065, 0.1391, 0.0976, 0.0847, 0.1127, 0.1084, 0.0342, 0.1372,\n",
      "        0.1427, 0.1443, 0.1171, 0.1504, 0.1360, 0.0995, 0.1504, 0.1268, 0.1013,\n",
      "        0.1080, 0.1109, 0.1392, 0.1276, 0.1312, 0.1043, 0.1064, 0.1455, 0.1696,\n",
      "        0.1409, 0.1085, 0.1082, 0.1325, 0.1038, 0.1123, 0.1356, 0.1438, 0.1048,\n",
      "        0.1168, 0.1213, 0.1063, 0.1159, 0.1157, 0.0988, 0.1439, 0.1112, 0.1151,\n",
      "        0.1237, 0.1324, 0.1276, 0.1044, 0.1163, 0.1233, 0.1184, 0.0621, 0.1231,\n",
      "        0.0481, 0.1237, 0.1091, 0.1294, 0.0917, 0.1522, 0.1059, 0.1420, 0.1141,\n",
      "        0.0939, 0.0923, 0.0914, 0.1188, 0.1097, 0.1116, 0.1202, 0.1138, 0.1495,\n",
      "        0.0971, 0.1051, 0.1116, 0.0961, 0.1321, 0.1233, 0.1134, 0.1041, 0.1312,\n",
      "        0.0817, 0.1141, 0.1272, 0.1183, 0.1222, 0.0749, 0.1875, 0.1069, 0.1131,\n",
      "        0.0959, 0.1064, 0.1071, 0.1069, 0.1484, 0.1014, 0.1120, 0.1162, 0.1085,\n",
      "        0.1000, 0.1370, 0.1100, 0.0995, 0.0803, 0.0784, 0.1425, 0.1007, 0.0897,\n",
      "        0.1270, 0.1483, 0.1037, 0.1174, 0.1146, 0.1129, 0.1347, 0.1412, 0.1169,\n",
      "        0.1069, 0.0880, 0.1287, 0.1141, 0.1152, 0.1327, 0.1408, 0.1035, 0.1317,\n",
      "        0.1419, 0.0951, 0.1350, 0.1249, 0.1462, 0.0942, 0.1230, 0.1153, 0.1473,\n",
      "        0.1019, 0.1136, 0.1549, 0.1111, 0.1238, 0.1418, 0.1324, 0.1221, 0.1356,\n",
      "        0.1172, 0.1008, 0.1430, 0.1483, 0.0960, 0.1222, 0.1254, 0.1473],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.5658, -0.7900, -0.2263,  ...,  0.0489, -0.2465, -0.1522],\n",
      "        [ 0.0393, -0.1459,  0.6821,  ..., -0.0261, -0.2674,  0.3179],\n",
      "        [ 0.0394,  0.0122,  0.1086,  ..., -0.1210,  0.0735, -0.1195],\n",
      "        ...,\n",
      "        [-0.5527, -0.7909, -0.4530,  ..., -0.2195, -0.4081,  1.8777],\n",
      "        [-0.4350,  0.0078,  0.2835,  ..., -0.0284,  1.1160, -0.5134],\n",
      "        [ 0.2953, -0.2076, -0.4492,  ..., -0.3822, -0.7315, -0.2459]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.6214, -0.2547, -0.8441,  ...,  1.1404,  0.1970, -0.1067],\n",
      "        [ 0.2325, -0.7536, -0.1306,  ...,  0.2242, -0.0176,  0.5044],\n",
      "        [ 0.1649, -0.7850,  0.4151,  ...,  0.2255, -0.2542,  0.1823],\n",
      "        ...,\n",
      "        [ 0.6416,  0.1452, -0.3078,  ..., -0.9218,  0.9471,  2.4216],\n",
      "        [ 0.6141,  0.7233, -0.6174,  ...,  0.1138, -0.1159,  0.3250],\n",
      "        [-0.1769, -1.5308,  0.7537,  ...,  0.3165, -0.2281,  0.2495]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.0700,  0.0958,  0.4161,  ..., -0.2529, -0.7879,  0.4858],\n",
      "        [ 0.2670,  0.4854, -0.0533,  ...,  0.1414,  0.5590,  0.2464],\n",
      "        [-0.7113,  0.0248,  0.0250,  ...,  0.0058,  0.3013,  0.1927],\n",
      "        ...,\n",
      "        [ 0.2353, -0.3529, -0.0664,  ...,  0.4575,  0.7035,  0.4671],\n",
      "        [ 0.4025, -0.1063, -0.0611,  ..., -0.0402, -0.3043, -0.2374],\n",
      "        [ 0.3803, -0.3488, -0.0055,  ..., -0.2567, -0.7919,  0.3010]],\n",
      "       device='cuda:0')\n",
      "tensor([0.1330, 0.1369, 0.0723, 0.1270, 0.1104, 0.0836, 0.1356, 0.0985, 0.0787,\n",
      "        0.1234, 0.1143, 0.0445, 0.0966, 0.0877, 0.0788, 0.1227, 0.0967, 0.0860,\n",
      "        0.1035, 0.0836, 0.0810, 0.0596, 0.0989, 0.1042, 0.0832, 0.0715, 0.0585,\n",
      "        0.0978, 0.1038, 0.0968, 0.1095, 0.1190, 0.1932, 0.1028, 0.0907, 0.0991,\n",
      "        0.1190, 0.0849, 0.0867, 0.0759, 0.0972, 0.0951, 0.1171, 0.0706, 0.0918,\n",
      "        0.1312, 0.1145, 0.1114, 0.0885, 0.0936, 0.0855, 0.1160, 0.1145, 0.1062,\n",
      "        0.1145, 0.1027, 0.0849, 0.1145, 0.1068, 0.0907, 0.1137, 0.0798, 0.1052,\n",
      "        0.0985, 0.1460, 0.1167, 0.0726, 0.0970, 0.1075, 0.0906, 0.1200, 0.0964,\n",
      "        0.0852, 0.0912, 0.0955, 0.0847, 0.0959, 0.1161, 0.0288, 0.0866, 0.1182,\n",
      "        0.0985, 0.0926, 0.0991, 0.0998, 0.0982, 0.0948, 0.1068, 0.1090, 0.1412,\n",
      "        0.0914, 0.0766, 0.0844, 0.1010, 0.1149, 0.0955, 0.1085, 0.1109, 0.0807,\n",
      "        0.0921, 0.0851, 0.1059, 0.0920, 0.1013, 0.0772, 0.0823, 0.0958, 0.0991,\n",
      "        0.0697, 0.0905, 0.0849, 0.0920, 0.1466, 0.0785, 0.0852, 0.0911, 0.0610,\n",
      "        0.0844, 0.0710, 0.1124, 0.1114, 0.0923, 0.1049, 0.1190, 0.0883, 0.1031,\n",
      "        0.1008, 0.0926, 0.0713, 0.0818, 0.1132, 0.0919, 0.0940, 0.0707, 0.0837,\n",
      "        0.0931, 0.6779, 0.0860, 0.1030, 0.1016, 0.0816, 0.1369, 0.0928, 0.1216,\n",
      "        0.0906, 0.1330, 0.0871, 0.1020, 0.1088, 0.0963, 0.1180, 0.0985, 0.0987,\n",
      "        0.1161, 0.0827, 0.0888, 0.0941, 0.1175, 0.0947, 0.1035, 0.0915, 0.1164,\n",
      "        0.1137, 0.0192, 0.0917, 0.1000, 0.0765, 0.1077, 0.0856, 0.1127, 0.1131,\n",
      "        0.0928, 0.0963, 0.0989, 0.1148, 0.0970, 0.0939, 0.0668, 0.0973, 0.0982,\n",
      "        0.0872, 0.0771, 0.1203, 0.0767, 0.1015, 0.1033, 0.1368, 0.1085, 0.0881,\n",
      "        0.0856, 0.0884, 0.1391, 0.0730, 0.1065, 0.1240, 0.0784, 0.0908, 0.0980,\n",
      "        0.0916, 0.0978, 0.0820, 0.0916, 0.0968, 0.0993, 0.0911, 0.0961, 0.0910,\n",
      "        0.0844, 0.1014, 0.1160, 0.1243, 0.0924, 0.0961, 0.0731, 0.1031, 0.1021,\n",
      "        0.0914, 0.1040, 0.0986, 0.1364, 0.0851, 0.0783, 0.0921, 0.1081, 0.0821,\n",
      "        0.0827, 0.0975, 0.0831, 0.0748, 0.1195, 0.0703, 0.0926, 0.0885, 0.1047,\n",
      "        0.1239, 0.1015, 0.1086, 0.1199, 0.1070, 0.0971, 0.1045, 0.0863, 0.1065,\n",
      "        0.0833, 0.0950, 0.1041, 0.1027, 0.0716, 0.0788, 0.1076, 0.0820, 0.1144,\n",
      "        0.1107, 0.1005, 0.0908, 0.0821, 0.0961, 0.0951, 0.0911, 0.1125, 0.0970,\n",
      "        0.0723, 0.0791, 0.1104, 0.1119, 0.1068, 0.0953, 0.1227, 0.0793, 0.0866,\n",
      "        0.1042, 0.1009, 0.1018, 0.0866, 0.1077, 0.0936, 0.0904, 0.1114, 0.0905,\n",
      "        0.1042, 0.0975, 0.0885, 0.0882, 0.1214, 0.1015, 0.0790, 0.0953, 0.0915,\n",
      "        0.1253, 0.1102, 0.0937, 0.0769, 0.1046, 0.0955, 0.0936, 0.0650, 0.0930,\n",
      "        0.0683, 0.1013, 0.0986, 0.1383, 0.1082, 0.0930, 0.1399, 0.1139, 0.1188,\n",
      "        0.1155, 0.0787, 0.0673, 0.0854, 0.0874, 0.1007, 0.0793, 0.1056, 0.1058,\n",
      "        0.1304, 0.1190, 0.1015, 0.1015, 0.0897, 0.1288, 0.0857, 0.1015, 0.1183,\n",
      "        0.0970, 0.0847, 0.1130, 0.0964, 0.0945, 0.1136, 0.0899, 0.0914, 0.1036,\n",
      "        0.0496, 0.1043, 0.0868, 0.0891, 0.1117, 0.0817, 0.1161, 0.0953, 0.1014,\n",
      "        0.0953, 0.1071, 0.0912, 0.0890, 0.1135, 0.0949, 0.1018, 0.0952, 0.0930,\n",
      "        0.0924, 0.1106, 0.1016, 0.1122, 0.0904, 0.1144, 0.1090, 0.1038, 0.0871,\n",
      "        0.0935, 0.0958, 0.1036, 0.0797, 0.0751, 0.1051, 0.0804, 0.0333, 0.1121,\n",
      "        0.1022, 0.1280, 0.0881, 0.1105, 0.1208, 0.0768, 0.1149, 0.0956, 0.1032,\n",
      "        0.0903, 0.1067, 0.1252, 0.0906, 0.0891, 0.0813, 0.0814, 0.1194, 0.1520,\n",
      "        0.1158, 0.0972, 0.0889, 0.1007, 0.0834, 0.1001, 0.1043, 0.1366, 0.0901,\n",
      "        0.1023, 0.0991, 0.1171, 0.1130, 0.0965, 0.0809, 0.1297, 0.1073, 0.0989,\n",
      "        0.1013, 0.1093, 0.1029, 0.0986, 0.1126, 0.0870, 0.0969, 0.0382, 0.0890,\n",
      "        0.0259, 0.0939, 0.0950, 0.0996, 0.0837, 0.1152, 0.0978, 0.1256, 0.1104,\n",
      "        0.0749, 0.0837, 0.1012, 0.0917, 0.0901, 0.0772, 0.0748, 0.0961, 0.1269,\n",
      "        0.1096, 0.0988, 0.1160, 0.1000, 0.0824, 0.0965, 0.0936, 0.0760, 0.0938,\n",
      "        0.0820, 0.0876, 0.1109, 0.0938, 0.1092, 0.0880, 0.0774, 0.0943, 0.0884,\n",
      "        0.0651, 0.1060, 0.0917, 0.0848, 0.1157, 0.0937, 0.0834, 0.1016, 0.0722,\n",
      "        0.0957, 0.1059, 0.0990, 0.0776, 0.0704, 0.0729, 0.1100, 0.0929, 0.0658,\n",
      "        0.0970, 0.1227, 0.0866, 0.1097, 0.0726, 0.0875, 0.1107, 0.1199, 0.0897,\n",
      "        0.0806, 0.0781, 0.1053, 0.1024, 0.0959, 0.1205, 0.0997, 0.0874, 0.1154,\n",
      "        0.1254, 0.1112, 0.1104, 0.1076, 0.1180, 0.0791, 0.0865, 0.0917, 0.1162,\n",
      "        0.0756, 0.0984, 0.1145, 0.1031, 0.1092, 0.1071, 0.1198, 0.0956, 0.1127,\n",
      "        0.0989, 0.1013, 0.1179, 0.0991, 0.0658, 0.0978, 0.0967, 0.2220],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.0268, -0.0056,  0.0632,  ...,  0.0683, -0.0464,  0.0017],\n",
      "        [ 0.0214,  0.1276,  0.0187,  ..., -0.1343, -0.1587,  0.0608],\n",
      "        [-0.0306,  0.0135,  0.0310,  ..., -0.0281, -0.0855,  0.0487],\n",
      "        ...,\n",
      "        [-0.0541,  0.0332, -0.0101,  ..., -0.0653,  0.0367,  0.0110],\n",
      "        [ 0.0876,  0.0140,  0.0447,  ...,  0.0625, -0.0237,  0.0743],\n",
      "        [-0.0808,  0.0108, -0.0012,  ..., -0.0838,  0.0122, -0.0249]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.0713, -0.6638, -0.2287,  ..., -0.0720,  0.3978, -0.4275],\n",
      "        [ 0.2770, -0.2352, -0.2033,  ...,  0.4372,  0.2376, -0.3731],\n",
      "        [-0.2218,  0.4868, -0.1520,  ..., -0.4284, -0.3917,  0.5976],\n",
      "        ...,\n",
      "        [-0.0650,  0.5439,  0.2587,  ..., -0.1589, -0.1840, -0.0714],\n",
      "        [ 0.1784, -0.2101,  0.1564,  ...,  0.1806, -0.1115,  0.2044],\n",
      "        [-0.2710,  0.5737, -0.3462,  ..., -0.3202, -0.1089, -0.1076]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.1594, -0.0159,  0.2252,  ..., -0.7226,  0.2629,  0.7560],\n",
      "        [ 0.3325, -0.4748, -0.3510,  ...,  0.0064,  0.3055, -0.0519],\n",
      "        [-0.2762, -0.4282, -0.0205,  ...,  0.7143,  0.0674,  0.0156],\n",
      "        ...,\n",
      "        [-0.7150, -0.1658,  0.7001,  ...,  0.0231, -0.4704, -0.2220],\n",
      "        [ 0.9919, -0.1003,  1.3090,  ..., -1.0787,  1.0012,  0.5422],\n",
      "        [ 0.1147, -0.1589,  0.3981,  ...,  0.7481,  0.4295,  0.1620]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.6314, -0.3577, -0.1685,  ..., -1.0468, -0.2076, -0.5496],\n",
      "        [-0.1434,  0.1919,  0.0763,  ..., -0.9023, -0.6118,  0.5243],\n",
      "        [ 0.4652, -0.2541, -0.8861,  ...,  0.4159,  1.3552,  0.2248],\n",
      "        ...,\n",
      "        [-0.7222,  0.3419,  0.3745,  ...,  0.6796, -1.0998,  0.6703],\n",
      "        [ 0.8520,  0.5103,  0.0334,  ..., -0.2619, -0.0078,  0.0167],\n",
      "        [-0.2856,  0.2811,  0.2187,  ..., -0.0588,  0.8177, -0.1818]],\n",
      "       device='cuda:0')\n",
      "tensor([0.1924, 0.1722, 0.1146, 0.1480, 0.1581, 0.1522, 0.0574, 0.1698, 0.1369,\n",
      "        0.2095, 0.1688, 0.0645, 0.1527, 0.1442, 0.1587, 0.2055, 0.1373, 0.1460,\n",
      "        0.1876, 0.1061, 0.1290, 0.1202, 0.1357, 0.1773, 0.1472, 0.1224, 0.1119,\n",
      "        0.1728, 0.1535, 0.1655, 0.1330, 0.1722, 0.1847, 0.1584, 0.1322, 0.1571,\n",
      "        0.1561, 0.1634, 0.1620, 0.1365, 0.1598, 0.1364, 0.1716, 0.1310, 0.1353,\n",
      "        0.1748, 0.1545, 0.1747, 0.1434, 0.1408, 0.1304, 0.1535, 0.1398, 0.1694,\n",
      "        0.1487, 0.1605, 0.1398, 0.1595, 0.1593, 0.1427, 0.1369, 0.1541, 0.1664,\n",
      "        0.1418, 0.1580, 0.1757, 0.1326, 0.1578, 0.1937, 0.1334, 0.1782, 0.1207,\n",
      "        0.1608, 0.1438, 0.1244, 0.1463, 0.1695, 0.1752, 0.0540, 0.1580, 0.1565,\n",
      "        0.1386, 0.1563, 0.1369, 0.1650, 0.1529, 0.1523, 0.1721, 0.1621, 0.1387,\n",
      "        0.1318, 0.1345, 0.1354, 0.1611, 0.1669, 0.1406, 0.1519, 0.1680, 0.1329,\n",
      "        0.1387, 0.1244, 0.1442, 0.1433, 0.1533, 0.1390, 0.1489, 0.1596, 0.1539,\n",
      "        0.1147, 0.1491, 0.1232, 0.1391, 0.2004, 0.1328, 0.1468, 0.1512, 0.1146,\n",
      "        0.1224, 0.1366, 0.1802, 0.1376, 0.1571, 0.1544, 0.1615, 0.1354, 0.1557,\n",
      "        0.1466, 0.1493, 0.1335, 0.1378, 0.1741, 0.1454, 0.1347, 0.1215, 0.1303,\n",
      "        0.1584, 0.0611, 0.1468, 0.1528, 0.1437, 0.1404, 0.1631, 0.1564, 0.1695,\n",
      "        0.1497, 0.1650, 0.1521, 0.1594, 0.1471, 0.1313, 0.1737, 0.1597, 0.1560,\n",
      "        0.1570, 0.1475, 0.1598, 0.1382, 0.1355, 0.1481, 0.1590, 0.1446, 0.1950,\n",
      "        0.1705, 0.0775, 0.1425, 0.1408, 0.1367, 0.1832, 0.1453, 0.1607, 0.1506,\n",
      "        0.1289, 0.1482, 0.1492, 0.1517, 0.1517, 0.1423, 0.1443, 0.1546, 0.1731,\n",
      "        0.1630, 0.1351, 0.2039, 0.1388, 0.1518, 0.1540, 0.1564, 0.1751, 0.1509,\n",
      "        0.1350, 0.1392, 0.1516, 0.1596, 0.1508, 0.1512, 0.1365, 0.1562, 0.1614,\n",
      "        0.1361, 0.1567, 0.1496, 0.1324, 0.1440, 0.1422, 0.1156, 0.1142, 0.1334,\n",
      "        0.1413, 0.1550, 0.1479, 0.1822, 0.1614, 0.1716, 0.1399, 0.1492, 0.1469,\n",
      "        0.1379, 0.1944, 0.1476, 0.1508, 0.1536, 0.1475, 0.1453, 0.1468, 0.1741,\n",
      "        0.1295, 0.1478, 0.1258, 0.1487, 0.1469, 0.1397, 0.1455, 0.1324, 0.1508,\n",
      "        0.1869, 0.1431, 0.1733, 0.1730, 0.1779, 0.1725, 0.1523, 0.1396, 0.1520,\n",
      "        0.1355, 0.1302, 0.1584, 0.1591, 0.1626, 0.1122, 0.1550, 0.1024, 0.1435,\n",
      "        0.1509, 0.1523, 0.1316, 0.1313, 0.1594, 0.1485, 0.1445, 0.1601, 0.1574,\n",
      "        0.1364, 0.1553, 0.1682, 0.1878, 0.1475, 0.1705, 0.1839, 0.1439, 0.1096,\n",
      "        0.1504, 0.1548, 0.1435, 0.1364, 0.1909, 0.1258, 0.1324, 0.1540, 0.1329,\n",
      "        0.1660, 0.1413, 0.1663, 0.1356, 0.1559, 0.1524, 0.1158, 0.1777, 0.1396,\n",
      "        0.1738, 0.1454, 0.1328, 0.1278, 0.1606, 0.1469, 0.1592, 0.1055, 0.1393,\n",
      "        0.1120, 0.1607, 0.1304, 0.1588, 0.1543, 0.1471, 0.1553, 0.1590, 0.1796,\n",
      "        0.1436, 0.1194, 0.1096, 0.1437, 0.1512, 0.1708, 0.1339, 0.1475, 0.1517,\n",
      "        0.1721, 0.1364, 0.1649, 0.1644, 0.1459, 0.1921, 0.1326, 0.1400, 0.1758,\n",
      "        0.1518, 0.1500, 0.1463, 0.1550, 0.1451, 0.1550, 0.1451, 0.1445, 0.1525,\n",
      "        0.0839, 0.1497, 0.1394, 0.1583, 0.1491, 0.1502, 0.1652, 0.1471, 0.1495,\n",
      "        0.1586, 0.1397, 0.1591, 0.1430, 0.1790, 0.1337, 0.1572, 0.1258, 0.1372,\n",
      "        0.1760, 0.1504, 0.1564, 0.1625, 0.1551, 0.1533, 0.1461, 0.1395, 0.1128,\n",
      "        0.1599, 0.1608, 0.1644, 0.1428, 0.1140, 0.1323, 0.1412, 0.0354, 0.1659,\n",
      "        0.1764, 0.1613, 0.1535, 0.1690, 0.1683, 0.1295, 0.1617, 0.1402, 0.1815,\n",
      "        0.1339, 0.1665, 0.1743, 0.1503, 0.1580, 0.1430, 0.1362, 0.1769, 0.2045,\n",
      "        0.1562, 0.1596, 0.1186, 0.1641, 0.1473, 0.1689, 0.1718, 0.1857, 0.1430,\n",
      "        0.1619, 0.1681, 0.1498, 0.1452, 0.1521, 0.1210, 0.1623, 0.1502, 0.1354,\n",
      "        0.1633, 0.1514, 0.1590, 0.1395, 0.1502, 0.1513, 0.1536, 0.0997, 0.1586,\n",
      "        0.0399, 0.1547, 0.1436, 0.1485, 0.1493, 0.1614, 0.1631, 0.1811, 0.1420,\n",
      "        0.1287, 0.1331, 0.1318, 0.1633, 0.1338, 0.1242, 0.1480, 0.1451, 0.1731,\n",
      "        0.1310, 0.1456, 0.1534, 0.1190, 0.1415, 0.1404, 0.1569, 0.1433, 0.1425,\n",
      "        0.1287, 0.1478, 0.1738, 0.1329, 0.1568, 0.1305, 0.1712, 0.1365, 0.1416,\n",
      "        0.1273, 0.1534, 0.1572, 0.1483, 0.1694, 0.1272, 0.1484, 0.1654, 0.1241,\n",
      "        0.1267, 0.1670, 0.1454, 0.1286, 0.1211, 0.1049, 0.1736, 0.1154, 0.1242,\n",
      "        0.1794, 0.1678, 0.1296, 0.1531, 0.1348, 0.1509, 0.1716, 0.2136, 0.1544,\n",
      "        0.1543, 0.1305, 0.1438, 0.1523, 0.1632, 0.1693, 0.1720, 0.1232, 0.1830,\n",
      "        0.1739, 0.1458, 0.1565, 0.1680, 0.1714, 0.1253, 0.1548, 0.1411, 0.1667,\n",
      "        0.1478, 0.1303, 0.1938, 0.1411, 0.1531, 0.1594, 0.1899, 0.1533, 0.1575,\n",
      "        0.1599, 0.1300, 0.1618, 0.1755, 0.1259, 0.1605, 0.1617, 0.1595],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.4972, -0.2693, -0.2971,  ...,  0.0754,  0.0697, -0.1492],\n",
      "        [-0.1677, -0.2959,  0.3680,  ..., -0.4661,  0.3161,  0.0719],\n",
      "        [ 0.0046,  0.2493,  0.4225,  ...,  0.2074, -0.0284,  0.2747],\n",
      "        ...,\n",
      "        [ 0.3273,  0.3545,  0.4586,  ...,  0.5239, -0.3772, -0.0345],\n",
      "        [-0.3074, -0.4417,  0.4466,  ...,  0.4918, -0.0347, -0.3934],\n",
      "        [-0.7892, -0.2638, -0.3231,  ...,  0.5839,  0.4401, -0.3589]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.0703, -1.1402,  0.6524,  ...,  0.0836,  0.9649, -0.1404],\n",
      "        [ 0.1038, -0.3360,  0.6249,  ..., -0.2830,  1.3590,  0.4505],\n",
      "        [ 0.1567, -0.5120,  0.7619,  ...,  0.4203, -0.1342, -1.1692],\n",
      "        ...,\n",
      "        [-0.5813,  0.9907,  0.5008,  ...,  0.0579,  0.4268,  0.5699],\n",
      "        [-2.7505,  2.0627,  2.1247,  ...,  0.8324,  1.2024,  0.9959],\n",
      "        [ 0.2872, -1.2515,  0.1130,  ...,  0.4619,  0.7660,  0.2600]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.8747, -0.0947,  0.1019,  ...,  1.1057, -0.3988, -0.0412],\n",
      "        [ 0.1326,  0.0318,  0.6713,  ..., -0.7515,  0.0791, -0.3185],\n",
      "        [ 0.1763,  0.3992, -0.3425,  ...,  1.1250,  1.1725,  0.2385],\n",
      "        ...,\n",
      "        [-0.3619,  0.5482, -0.7135,  ...,  0.3463, -0.0779,  0.3108],\n",
      "        [-0.1586,  1.0092, -0.2954,  ...,  0.4576, -0.5996, -0.0681],\n",
      "        [ 0.0405, -0.0107, -0.2003,  ..., -0.4630, -0.3421,  0.4668]],\n",
      "       device='cuda:0')\n",
      "tensor([0.1303, 0.1166, 0.0810, 0.1139, 0.1128, 0.0966, 0.0483, 0.1157, 0.0754,\n",
      "        0.1265, 0.1002, 0.0397, 0.1041, 0.0973, 0.0852, 0.1186, 0.1004, 0.0866,\n",
      "        0.1029, 0.1015, 0.0910, 0.0673, 0.0930, 0.0927, 0.0931, 0.0786, 0.0734,\n",
      "        0.1017, 0.1103, 0.0874, 0.0971, 0.1185, 0.1259, 0.0990, 0.0936, 0.0993,\n",
      "        0.1008, 0.0928, 0.0910, 0.0738, 0.1079, 0.1006, 0.1004, 0.0852, 0.1002,\n",
      "        0.1109, 0.1071, 0.1110, 0.0857, 0.0971, 0.0757, 0.1220, 0.0995, 0.1083,\n",
      "        0.1071, 0.1173, 0.0866, 0.1198, 0.1029, 0.0892, 0.1106, 0.0893, 0.1101,\n",
      "        0.1114, 0.1422, 0.1102, 0.0764, 0.1074, 0.1242, 0.0911, 0.1159, 0.0814,\n",
      "        0.0898, 0.0892, 0.0994, 0.1046, 0.0949, 0.1145, 0.0377, 0.1026, 0.1082,\n",
      "        0.0946, 0.0834, 0.0999, 0.1090, 0.1107, 0.1058, 0.1022, 0.1086, 0.0980,\n",
      "        0.0897, 0.0794, 0.0941, 0.0996, 0.1283, 0.1016, 0.1021, 0.1143, 0.0771,\n",
      "        0.0693, 0.0796, 0.0924, 0.1083, 0.1135, 0.0936, 0.0877, 0.1065, 0.0901,\n",
      "        0.0895, 0.0956, 0.0897, 0.0941, 0.1263, 0.0701, 0.0912, 0.1004, 0.0806,\n",
      "        0.0800, 0.0809, 0.1246, 0.1021, 0.0928, 0.0961, 0.1227, 0.0993, 0.1153,\n",
      "        0.0918, 0.0979, 0.0964, 0.0810, 0.1117, 0.0917, 0.0956, 0.0772, 0.0842,\n",
      "        0.0982, 0.2431, 0.0828, 0.0997, 0.1114, 0.0789, 0.1135, 0.0953, 0.1165,\n",
      "        0.1037, 0.1139, 0.0996, 0.0914, 0.1015, 0.0830, 0.1190, 0.1039, 0.0955,\n",
      "        0.1191, 0.0727, 0.1003, 0.1039, 0.1030, 0.0960, 0.1094, 0.0937, 0.1297,\n",
      "        0.1018, 0.0230, 0.1121, 0.1026, 0.0967, 0.1044, 0.1088, 0.0948, 0.1182,\n",
      "        0.0955, 0.1155, 0.0879, 0.1121, 0.0895, 0.0941, 0.0809, 0.1127, 0.1071,\n",
      "        0.0774, 0.0704, 0.1049, 0.0842, 0.0944, 0.1102, 0.1128, 0.1053, 0.1058,\n",
      "        0.0842, 0.0922, 0.1193, 0.1068, 0.0952, 0.1015, 0.0862, 0.0832, 0.1107,\n",
      "        0.0920, 0.0961, 0.0865, 0.0804, 0.1023, 0.0847, 0.1033, 0.0987, 0.0800,\n",
      "        0.0961, 0.0996, 0.1170, 0.1105, 0.1000, 0.1102, 0.1000, 0.1212, 0.1081,\n",
      "        0.0934, 0.1065, 0.0880, 0.1389, 0.0758, 0.0898, 0.0987, 0.1056, 0.0862,\n",
      "        0.0793, 0.1058, 0.1044, 0.0948, 0.1207, 0.0751, 0.1046, 0.0880, 0.0946,\n",
      "        0.1262, 0.0971, 0.1102, 0.1322, 0.1134, 0.0892, 0.1112, 0.1016, 0.0846,\n",
      "        0.0889, 0.0921, 0.1025, 0.0993, 0.0936, 0.0816, 0.0839, 0.0875, 0.1082,\n",
      "        0.1042, 0.1058, 0.0943, 0.0859, 0.0877, 0.1016, 0.1101, 0.1163, 0.1082,\n",
      "        0.0711, 0.0935, 0.0960, 0.1243, 0.1085, 0.0873, 0.1146, 0.0810, 0.0911,\n",
      "        0.1039, 0.1058, 0.0956, 0.0914, 0.1146, 0.0889, 0.0844, 0.1050, 0.0986,\n",
      "        0.1100, 0.0882, 0.0950, 0.0940, 0.1079, 0.1112, 0.0769, 0.1037, 0.0898,\n",
      "        0.1151, 0.0947, 0.0910, 0.0869, 0.1020, 0.0878, 0.1056, 0.0673, 0.0970,\n",
      "        0.0775, 0.0997, 0.0886, 0.1286, 0.1131, 0.1093, 0.1207, 0.1018, 0.1234,\n",
      "        0.1120, 0.0814, 0.0882, 0.1073, 0.0936, 0.0945, 0.0727, 0.1101, 0.0968,\n",
      "        0.1243, 0.1156, 0.1186, 0.1121, 0.1047, 0.1136, 0.0808, 0.0877, 0.1011,\n",
      "        0.1165, 0.0787, 0.1196, 0.0836, 0.1045, 0.1141, 0.1007, 0.1015, 0.1162,\n",
      "        0.0597, 0.1164, 0.0796, 0.0962, 0.1052, 0.0875, 0.1247, 0.0943, 0.1072,\n",
      "        0.0853, 0.0999, 0.0899, 0.1100, 0.0981, 0.1013, 0.1011, 0.1004, 0.0899,\n",
      "        0.1124, 0.0989, 0.0907, 0.0960, 0.0919, 0.1070, 0.1037, 0.1248, 0.0816,\n",
      "        0.0946, 0.0961, 0.1075, 0.0799, 0.0624, 0.1073, 0.0764, 0.0335, 0.1030,\n",
      "        0.1114, 0.1201, 0.0950, 0.1177, 0.1053, 0.0781, 0.0973, 0.0938, 0.0771,\n",
      "        0.1081, 0.0995, 0.1063, 0.0981, 0.1021, 0.0963, 0.0856, 0.1217, 0.1290,\n",
      "        0.1080, 0.0910, 0.0918, 0.1125, 0.0855, 0.1027, 0.0983, 0.1091, 0.0986,\n",
      "        0.0940, 0.1036, 0.1137, 0.1014, 0.0960, 0.0772, 0.1106, 0.1034, 0.0982,\n",
      "        0.1049, 0.0911, 0.1095, 0.1169, 0.1040, 0.1038, 0.0964, 0.0373, 0.1012,\n",
      "        0.0298, 0.1073, 0.1007, 0.0859, 0.0870, 0.1092, 0.0977, 0.1197, 0.0948,\n",
      "        0.0836, 0.0873, 0.0929, 0.1064, 0.0950, 0.0914, 0.0872, 0.0979, 0.1355,\n",
      "        0.1005, 0.1244, 0.1002, 0.0698, 0.0889, 0.1054, 0.0867, 0.0762, 0.0889,\n",
      "        0.0944, 0.0957, 0.1098, 0.1049, 0.1103, 0.0807, 0.1107, 0.0862, 0.0943,\n",
      "        0.0828, 0.1077, 0.0956, 0.0793, 0.1015, 0.0694, 0.0785, 0.0997, 0.0786,\n",
      "        0.1062, 0.1022, 0.0928, 0.0889, 0.0802, 0.0861, 0.1035, 0.0998, 0.0744,\n",
      "        0.0903, 0.1212, 0.1018, 0.0991, 0.0919, 0.1033, 0.0934, 0.1041, 0.0924,\n",
      "        0.1046, 0.0723, 0.1015, 0.1064, 0.0984, 0.1239, 0.0968, 0.0946, 0.1125,\n",
      "        0.1245, 0.1073, 0.1084, 0.1033, 0.1167, 0.0862, 0.0918, 0.1042, 0.1162,\n",
      "        0.1014, 0.0973, 0.1108, 0.1031, 0.1151, 0.0980, 0.1146, 0.0914, 0.1083,\n",
      "        0.1065, 0.0903, 0.1039, 0.1066, 0.0786, 0.1071, 0.1103, 0.1473],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.0468, -0.0243, -0.0141,  ...,  0.0253,  0.0064, -0.0077],\n",
      "        [-0.0385, -0.0130,  0.0153,  ...,  0.0114,  0.0160, -0.0245],\n",
      "        [ 0.0202,  0.0724,  0.0502,  ...,  0.0899,  0.0042, -0.0042],\n",
      "        ...,\n",
      "        [-0.0102,  0.0052,  0.0159,  ..., -0.0002,  0.0183, -0.0918],\n",
      "        [ 0.0227, -0.0130,  0.0056,  ...,  0.0898,  0.0172,  0.0296],\n",
      "        [-0.0214, -0.0124, -0.0578,  ...,  0.0099,  0.0439, -0.0850]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.7721, -0.8980,  0.2991,  ...,  0.6671, -0.1523, -0.2984],\n",
      "        [-0.4582, -0.0393, -0.0014,  ...,  0.5894, -0.3890, -0.7618],\n",
      "        [ 0.5831,  0.1119,  0.4262,  ..., -0.0346,  0.1667,  0.1056],\n",
      "        ...,\n",
      "        [-0.0703, -0.4339,  0.1363,  ..., -0.2414,  0.1362, -0.3913],\n",
      "        [ 0.2050,  0.3487,  0.2206,  ...,  1.0067, -0.5540, -0.0470],\n",
      "        [-0.1025, -0.0093,  0.3020,  ..., -0.3154,  0.4185, -0.3658]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.3265,  1.2265, -0.2293,  ..., -0.1495,  0.3401, -0.5330],\n",
      "        [ 0.0996, -0.3506, -0.3362,  ..., -0.6209, -0.0024, -0.5093],\n",
      "        [ 0.6607,  1.4042,  0.6372,  ..., -0.0367,  0.7567,  0.3052],\n",
      "        ...,\n",
      "        [ 0.3122,  0.1559,  0.1170,  ..., -0.5651,  0.9291,  0.4125],\n",
      "        [ 1.4756,  0.7733, -0.1007,  ..., -0.8946,  0.2037, -0.1055],\n",
      "        [ 0.8434, -0.4301,  0.7377,  ...,  0.7164,  0.4991, -0.0110]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.2856,  0.3483, -0.2903,  ...,  0.3983,  0.0371, -0.9758],\n",
      "        [ 0.3094,  0.6343,  0.2180,  ..., -0.2104, -0.3054,  0.3234],\n",
      "        [ 0.4916,  0.3544,  0.5248,  ...,  0.0967, -0.7763,  0.0433],\n",
      "        ...,\n",
      "        [-0.1759, -0.0299,  0.3706,  ..., -1.0106,  0.0515, -1.2347],\n",
      "        [ 0.3659,  0.1123, -0.2109,  ..., -0.3713, -0.2768, -0.4481],\n",
      "        [-0.2240,  0.2947, -0.0063,  ...,  0.4699, -0.1766,  0.4061]],\n",
      "       device='cuda:0')\n",
      "tensor([0.2066, 0.1878, 0.1486, 0.2025, 0.1906, 0.1608, 0.0438, 0.1853, 0.1532,\n",
      "        0.2400, 0.2210, 0.0805, 0.1741, 0.1395, 0.1661, 0.1944, 0.1622, 0.1486,\n",
      "        0.1304, 0.1258, 0.1433, 0.1158, 0.1740, 0.1921, 0.1412, 0.1433, 0.1135,\n",
      "        0.1836, 0.1555, 0.1584, 0.1904, 0.1986, 0.1698, 0.1401, 0.1663, 0.1771,\n",
      "        0.1803, 0.1648, 0.1604, 0.1345, 0.1445, 0.1513, 0.1983, 0.1336, 0.1615,\n",
      "        0.1804, 0.1574, 0.2208, 0.1572, 0.1916, 0.1424, 0.2020, 0.1581, 0.2066,\n",
      "        0.1840, 0.2082, 0.1691, 0.1934, 0.1609, 0.1305, 0.1846, 0.1869, 0.1585,\n",
      "        0.1731, 0.1858, 0.2106, 0.1338, 0.1871, 0.1726, 0.1464, 0.1785, 0.1515,\n",
      "        0.1800, 0.1671, 0.1414, 0.1586, 0.1510, 0.2209, 0.0812, 0.1589, 0.1736,\n",
      "        0.1514, 0.1699, 0.1582, 0.1835, 0.1839, 0.1669, 0.1722, 0.1710, 0.1931,\n",
      "        0.1498, 0.1557, 0.1583, 0.1573, 0.2127, 0.1733, 0.1542, 0.1849, 0.1247,\n",
      "        0.1499, 0.1484, 0.1677, 0.1681, 0.1393, 0.1455, 0.1382, 0.1860, 0.1704,\n",
      "        0.1215, 0.1657, 0.1278, 0.1863, 0.2117, 0.1356, 0.1629, 0.1620, 0.1032,\n",
      "        0.1620, 0.1543, 0.2002, 0.1479, 0.1642, 0.1643, 0.1943, 0.1423, 0.1781,\n",
      "        0.1622, 0.1434, 0.1441, 0.1310, 0.1586, 0.1431, 0.1530, 0.1174, 0.1253,\n",
      "        0.1684, 0.0457, 0.1667, 0.1656, 0.1696, 0.1400, 0.1901, 0.1717, 0.1923,\n",
      "        0.1799, 0.2316, 0.1839, 0.1638, 0.1506, 0.1584, 0.1740, 0.1893, 0.1602,\n",
      "        0.2194, 0.1578, 0.1625, 0.1685, 0.1603, 0.1605, 0.1527, 0.1593, 0.1907,\n",
      "        0.1726, 0.0710, 0.1553, 0.1500, 0.1519, 0.2180, 0.1588, 0.2113, 0.1999,\n",
      "        0.1282, 0.1826, 0.1678, 0.1786, 0.1587, 0.1756, 0.1468, 0.1654, 0.1562,\n",
      "        0.1368, 0.1391, 0.1688, 0.1652, 0.1601, 0.1722, 0.1660, 0.1578, 0.1834,\n",
      "        0.1377, 0.1664, 0.1554, 0.1660, 0.1777, 0.1779, 0.1311, 0.1493, 0.2096,\n",
      "        0.1679, 0.1418, 0.1423, 0.1662, 0.1614, 0.1440, 0.1487, 0.1434, 0.1350,\n",
      "        0.1438, 0.1859, 0.1569, 0.2024, 0.1417, 0.1761, 0.1368, 0.1962, 0.1766,\n",
      "        0.1801, 0.1575, 0.1457, 0.1753, 0.1369, 0.1525, 0.1688, 0.1607, 0.1788,\n",
      "        0.1256, 0.1813, 0.1301, 0.1411, 0.1824, 0.1557, 0.1693, 0.1458, 0.1463,\n",
      "        0.1983, 0.1578, 0.1749, 0.1653, 0.1760, 0.1773, 0.1673, 0.1624, 0.1560,\n",
      "        0.1547, 0.1492, 0.1809, 0.1613, 0.1377, 0.1285, 0.1779, 0.1291, 0.1564,\n",
      "        0.1583, 0.1671, 0.1551, 0.1765, 0.1643, 0.1730, 0.1803, 0.1970, 0.1538,\n",
      "        0.1326, 0.1381, 0.1681, 0.1957, 0.1718, 0.1897, 0.2022, 0.1380, 0.1531,\n",
      "        0.1574, 0.1703, 0.1677, 0.1383, 0.1685, 0.1580, 0.1489, 0.1829, 0.1457,\n",
      "        0.1608, 0.1473, 0.1498, 0.1344, 0.1610, 0.1838, 0.1419, 0.1709, 0.1522,\n",
      "        0.1969, 0.1666, 0.1946, 0.1627, 0.1680, 0.1619, 0.1627, 0.1013, 0.1652,\n",
      "        0.1327, 0.1784, 0.1544, 0.1718, 0.1845, 0.1452, 0.1964, 0.1656, 0.1752,\n",
      "        0.1963, 0.1369, 0.1131, 0.1699, 0.1608, 0.1810, 0.1578, 0.1636, 0.1990,\n",
      "        0.1818, 0.1882, 0.1962, 0.1591, 0.1474, 0.2108, 0.1559, 0.1671, 0.1892,\n",
      "        0.1776, 0.1512, 0.1901, 0.1487, 0.1672, 0.1745, 0.1516, 0.1492, 0.1772,\n",
      "        0.1061, 0.1707, 0.1493, 0.1463, 0.2093, 0.1160, 0.1816, 0.1723, 0.1966,\n",
      "        0.1744, 0.1411, 0.1852, 0.1582, 0.1789, 0.1503, 0.1717, 0.1479, 0.1597,\n",
      "        0.1823, 0.1384, 0.1693, 0.1867, 0.1773, 0.1773, 0.1628, 0.1720, 0.1288,\n",
      "        0.1637, 0.1695, 0.1748, 0.1407, 0.1316, 0.1735, 0.1751, 0.0430, 0.1790,\n",
      "        0.2151, 0.1896, 0.1509, 0.2009, 0.1920, 0.1300, 0.1923, 0.1489, 0.1671,\n",
      "        0.1819, 0.1828, 0.1836, 0.1769, 0.1771, 0.1721, 0.1611, 0.2057, 0.2069,\n",
      "        0.1711, 0.1690, 0.1709, 0.1887, 0.1611, 0.1570, 0.1757, 0.2011, 0.1575,\n",
      "        0.1794, 0.1843, 0.1593, 0.1854, 0.1604, 0.1369, 0.1863, 0.1730, 0.1545,\n",
      "        0.1745, 0.1619, 0.1445, 0.1432, 0.1802, 0.1676, 0.1799, 0.0893, 0.1623,\n",
      "        0.0692, 0.1873, 0.1841, 0.1518, 0.1390, 0.1915, 0.1655, 0.1934, 0.1611,\n",
      "        0.1338, 0.1192, 0.1631, 0.1691, 0.1607, 0.1304, 0.1481, 0.1582, 0.2360,\n",
      "        0.1570, 0.1892, 0.1625, 0.1371, 0.1615, 0.1677, 0.1522, 0.1337, 0.1743,\n",
      "        0.1327, 0.1527, 0.1830, 0.1738, 0.1692, 0.1276, 0.2175, 0.1554, 0.1709,\n",
      "        0.1279, 0.1739, 0.1722, 0.1483, 0.1815, 0.1563, 0.1865, 0.1870, 0.1306,\n",
      "        0.1631, 0.1736, 0.1434, 0.1413, 0.1252, 0.1253, 0.1933, 0.1482, 0.1142,\n",
      "        0.1735, 0.2115, 0.1491, 0.1796, 0.1366, 0.1572, 0.1820, 0.2030, 0.1764,\n",
      "        0.1758, 0.1284, 0.1825, 0.1729, 0.1529, 0.1959, 0.1757, 0.1678, 0.2008,\n",
      "        0.2042, 0.1740, 0.1907, 0.1933, 0.1988, 0.1454, 0.1776, 0.1589, 0.1779,\n",
      "        0.1967, 0.1620, 0.2291, 0.1617, 0.1702, 0.1810, 0.2005, 0.1619, 0.1873,\n",
      "        0.1759, 0.1418, 0.1727, 0.2011, 0.1460, 0.1613, 0.1281, 0.1650],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.0184, -0.1111,  0.2639,  ...,  0.4999, -0.2042,  0.3077],\n",
      "        [ 0.4968, -0.0209, -0.0779,  ..., -0.0638, -0.4442,  0.3755],\n",
      "        [ 0.2175,  0.4695,  0.0700,  ..., -0.1076, -0.0068, -0.4468],\n",
      "        ...,\n",
      "        [ 0.4758, -0.6323, -0.5035,  ...,  0.0160, -0.2483, -0.1239],\n",
      "        [-0.1644, -0.2216, -0.6758,  ...,  0.3245,  0.6900, -0.4027],\n",
      "        [-0.0781,  0.5103,  0.4812,  ..., -0.2026,  0.0840,  0.7606]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.2833,  1.3043, -0.3497,  ...,  0.5779, -1.6250,  0.2020],\n",
      "        [-1.9465, -0.2380,  1.7111,  ...,  0.7471, -2.3915,  0.1128],\n",
      "        [ 0.9490,  0.2915,  0.7108,  ...,  1.8200,  1.7505,  1.1643],\n",
      "        ...,\n",
      "        [-2.0312,  1.8047, -0.5741,  ...,  0.9256,  0.0804,  0.5158],\n",
      "        [-0.7888,  0.7930, -0.2370,  ...,  0.3597, -0.0872,  0.6122],\n",
      "        [ 0.8705,  0.2532, -0.3974,  ..., -0.3378,  0.2578,  0.7434]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.7147, -0.0499, -0.6684,  ..., -1.0159, -0.1073,  0.7298],\n",
      "        [ 0.4680, -0.0863, -0.4405,  ...,  0.5575, -0.1282,  0.2518],\n",
      "        [ 0.0761, -0.0323,  0.2000,  ..., -0.3706,  0.4226,  0.2718],\n",
      "        ...,\n",
      "        [ 0.4324, -0.5998,  0.0618,  ...,  0.5855, -0.2245,  0.6210],\n",
      "        [ 0.3186,  0.4199, -0.6870,  ...,  0.3379, -0.9388,  0.6257],\n",
      "        [-0.6003, -0.1092,  0.1058,  ..., -0.0199, -0.2420, -0.3780]],\n",
      "       device='cuda:0')\n",
      "tensor([0.1329, 0.1151, 0.0933, 0.1174, 0.1303, 0.1117, 0.0435, 0.1002, 0.0955,\n",
      "        0.1258, 0.1117, 0.0447, 0.1085, 0.0905, 0.1052, 0.1424, 0.0921, 0.0932,\n",
      "        0.0982, 0.1035, 0.0835, 0.0767, 0.1095, 0.1001, 0.0829, 0.0828, 0.0982,\n",
      "        0.1032, 0.1037, 0.0803, 0.0931, 0.1057, 0.1273, 0.0982, 0.1060, 0.1121,\n",
      "        0.1113, 0.0954, 0.1090, 0.0849, 0.0954, 0.0977, 0.1181, 0.0904, 0.1096,\n",
      "        0.1119, 0.0983, 0.1338, 0.0980, 0.1290, 0.0975, 0.1114, 0.1017, 0.1253,\n",
      "        0.1173, 0.1375, 0.1000, 0.1118, 0.1025, 0.0941, 0.1155, 0.1109, 0.1086,\n",
      "        0.1176, 0.1345, 0.1118, 0.0789, 0.1114, 0.1291, 0.0878, 0.1263, 0.0888,\n",
      "        0.1132, 0.1014, 0.0873, 0.1016, 0.0972, 0.1359, 0.0490, 0.1223, 0.1180,\n",
      "        0.1102, 0.0768, 0.1058, 0.1137, 0.1303, 0.1035, 0.1064, 0.1217, 0.1085,\n",
      "        0.0932, 0.0838, 0.1024, 0.1161, 0.1164, 0.1020, 0.1117, 0.1348, 0.0828,\n",
      "        0.0865, 0.0853, 0.1015, 0.1058, 0.1143, 0.1045, 0.0909, 0.1099, 0.0940,\n",
      "        0.0774, 0.1078, 0.0792, 0.1111, 0.1150, 0.0983, 0.1069, 0.1046, 0.0787,\n",
      "        0.1102, 0.0905, 0.1217, 0.0884, 0.0961, 0.0906, 0.1242, 0.0951, 0.1063,\n",
      "        0.1110, 0.1033, 0.1031, 0.0924, 0.1061, 0.0925, 0.1027, 0.0859, 0.0949,\n",
      "        0.0979, 0.2404, 0.1066, 0.1026, 0.1085, 0.0966, 0.1038, 0.0900, 0.1159,\n",
      "        0.1027, 0.1377, 0.0971, 0.0922, 0.0932, 0.1102, 0.1095, 0.0960, 0.0990,\n",
      "        0.0964, 0.0961, 0.0917, 0.1114, 0.1162, 0.1052, 0.0935, 0.1005, 0.1275,\n",
      "        0.0978, 0.0198, 0.1101, 0.1049, 0.0997, 0.1145, 0.0934, 0.1044, 0.1273,\n",
      "        0.1017, 0.1017, 0.0923, 0.1256, 0.1038, 0.1156, 0.0908, 0.0986, 0.1124,\n",
      "        0.0812, 0.0833, 0.1026, 0.0894, 0.1054, 0.1082, 0.1075, 0.1267, 0.1155,\n",
      "        0.0845, 0.0825, 0.0929, 0.0960, 0.1143, 0.1135, 0.0815, 0.1162, 0.1178,\n",
      "        0.1040, 0.1003, 0.0958, 0.0948, 0.1057, 0.1021, 0.0931, 0.0911, 0.0969,\n",
      "        0.1011, 0.1212, 0.1145, 0.1295, 0.0976, 0.1231, 0.0948, 0.1183, 0.1041,\n",
      "        0.1086, 0.1060, 0.1112, 0.1162, 0.0883, 0.0982, 0.1120, 0.1048, 0.0988,\n",
      "        0.0916, 0.0922, 0.0822, 0.0861, 0.1185, 0.0840, 0.1155, 0.0940, 0.0992,\n",
      "        0.1111, 0.1101, 0.1169, 0.1123, 0.1230, 0.1174, 0.1341, 0.0983, 0.0993,\n",
      "        0.0940, 0.0938, 0.1193, 0.1016, 0.0914, 0.0851, 0.1124, 0.1032, 0.1061,\n",
      "        0.1053, 0.1029, 0.0881, 0.0806, 0.0887, 0.1043, 0.1249, 0.1302, 0.0858,\n",
      "        0.0945, 0.0945, 0.1249, 0.1288, 0.1112, 0.1017, 0.1109, 0.1020, 0.1058,\n",
      "        0.1098, 0.1140, 0.1061, 0.1018, 0.1085, 0.1182, 0.0827, 0.1361, 0.0931,\n",
      "        0.0973, 0.0864, 0.1157, 0.1058, 0.1105, 0.1119, 0.0871, 0.1050, 0.0981,\n",
      "        0.1149, 0.0984, 0.1013, 0.0865, 0.1144, 0.0919, 0.0982, 0.0849, 0.1046,\n",
      "        0.0892, 0.0976, 0.0908, 0.1208, 0.0996, 0.1080, 0.1141, 0.0841, 0.1303,\n",
      "        0.1212, 0.0950, 0.0811, 0.0906, 0.0946, 0.1086, 0.0956, 0.0963, 0.1109,\n",
      "        0.1218, 0.1062, 0.1188, 0.0974, 0.0975, 0.1121, 0.1023, 0.0827, 0.1117,\n",
      "        0.0963, 0.0913, 0.1230, 0.0951, 0.1153, 0.1215, 0.1024, 0.0859, 0.1262,\n",
      "        0.0555, 0.1190, 0.0812, 0.0975, 0.1274, 0.0921, 0.1179, 0.1065, 0.1034,\n",
      "        0.1085, 0.1162, 0.1228, 0.1047, 0.0991, 0.1135, 0.1215, 0.0979, 0.1115,\n",
      "        0.1082, 0.0931, 0.0957, 0.1076, 0.0961, 0.1172, 0.0966, 0.0952, 0.0886,\n",
      "        0.0932, 0.0987, 0.1056, 0.0918, 0.0838, 0.1283, 0.1080, 0.0215, 0.1030,\n",
      "        0.1193, 0.1302, 0.0997, 0.1119, 0.1219, 0.0814, 0.1242, 0.0893, 0.1093,\n",
      "        0.0867, 0.1014, 0.1125, 0.1005, 0.0892, 0.1015, 0.1079, 0.1111, 0.1393,\n",
      "        0.1140, 0.1040, 0.0931, 0.1140, 0.0864, 0.0842, 0.0976, 0.1205, 0.0954,\n",
      "        0.1094, 0.1023, 0.1172, 0.1157, 0.0872, 0.0999, 0.1232, 0.1071, 0.1105,\n",
      "        0.0983, 0.1007, 0.1177, 0.1166, 0.0908, 0.1107, 0.1066, 0.0411, 0.1007,\n",
      "        0.0378, 0.1010, 0.1138, 0.1061, 0.1142, 0.1061, 0.1136, 0.1248, 0.0872,\n",
      "        0.1084, 0.0950, 0.1130, 0.1139, 0.0894, 0.0955, 0.1075, 0.1192, 0.1183,\n",
      "        0.1098, 0.1193, 0.1147, 0.0809, 0.1065, 0.1131, 0.1015, 0.0810, 0.0974,\n",
      "        0.1047, 0.0883, 0.1095, 0.1054, 0.1091, 0.1003, 0.1241, 0.0830, 0.0986,\n",
      "        0.0725, 0.1126, 0.0940, 0.0988, 0.1163, 0.0938, 0.1077, 0.0903, 0.0877,\n",
      "        0.1095, 0.0983, 0.0946, 0.0902, 0.0896, 0.1082, 0.1224, 0.0993, 0.0999,\n",
      "        0.1017, 0.1137, 0.0947, 0.1205, 0.0834, 0.0958, 0.1310, 0.0990, 0.1023,\n",
      "        0.1250, 0.0900, 0.1105, 0.1078, 0.1105, 0.1156, 0.1132, 0.1145, 0.1197,\n",
      "        0.1066, 0.1129, 0.1195, 0.1107, 0.1203, 0.1091, 0.0996, 0.0981, 0.1097,\n",
      "        0.1123, 0.1073, 0.0956, 0.1006, 0.1176, 0.1104, 0.1157, 0.1041, 0.1022,\n",
      "        0.1137, 0.1094, 0.1063, 0.1189, 0.0807, 0.0997, 0.0971, 0.1698],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.0342, -0.0202,  0.0046,  ..., -0.0183, -0.0313, -0.0989],\n",
      "        [ 0.0195,  0.0476, -0.0534,  ..., -0.0560, -0.0034,  0.0484],\n",
      "        [ 0.0338,  0.0304,  0.0410,  ..., -0.0250,  0.0058,  0.0196],\n",
      "        ...,\n",
      "        [ 0.0170, -0.0029, -0.0742,  ..., -0.0044, -0.0018, -0.0019],\n",
      "        [-0.0183,  0.0157, -0.0561,  ...,  0.0704, -0.0719,  0.0024],\n",
      "        [ 0.0202,  0.0029,  0.0146,  ...,  0.0059,  0.0916, -0.0168]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.2029, -0.3160, -0.2033,  ...,  0.1848, -0.1352, -0.8079],\n",
      "        [-0.2222, -0.0838, -0.4047,  ..., -0.1527,  0.0492, -0.2605],\n",
      "        [ 0.0847,  0.1295, -0.1371,  ...,  0.4046,  0.3013,  0.4135],\n",
      "        ...,\n",
      "        [ 0.4028, -0.2252, -0.3271,  ..., -0.5237, -0.2160, -0.0094],\n",
      "        [-0.4127,  0.0620, -0.0988,  ...,  0.3546, -0.5781, -0.1179],\n",
      "        [ 0.0593, -0.0416, -0.2786,  ...,  0.1595,  0.4064, -0.7073]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 1.3030, -0.2698, -0.7344,  ..., -0.2278,  1.2212,  0.3918],\n",
      "        [-0.5391,  0.1458,  0.3416,  ..., -0.1081,  1.1653,  0.4506],\n",
      "        [ 0.4874, -0.0499,  0.5356,  ...,  0.3859,  0.9309,  0.0997],\n",
      "        ...,\n",
      "        [ 1.0778,  0.0863, -0.8007,  ...,  0.7261,  0.4694, -0.0694],\n",
      "        [-0.2581,  0.3071,  0.7453,  ..., -0.6999, -0.0845, -0.7585],\n",
      "        [ 0.1406, -0.0231,  0.0448,  ...,  0.2102,  0.5553,  0.6610]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.1034,  1.4014,  0.8218,  ...,  0.7182,  1.7875, -0.0885],\n",
      "        [ 0.3685, -0.2968,  1.1009,  ...,  0.3105,  0.4997,  1.4846],\n",
      "        [-0.9800, -0.1845, -0.0546,  ...,  0.9649, -0.6243, -0.4551],\n",
      "        ...,\n",
      "        [-0.8197, -0.2521, -0.3992,  ...,  0.5475,  0.8252, -0.0234],\n",
      "        [ 0.9418, -0.4012,  0.7809,  ..., -0.3536,  0.5158,  0.6325],\n",
      "        [-0.5160, -0.6273,  0.1453,  ...,  0.3001,  0.5058, -0.1246]],\n",
      "       device='cuda:0')\n",
      "tensor([0.1958, 0.1747, 0.1679, 0.2003, 0.1832, 0.1987, 0.0419, 0.1832, 0.1624,\n",
      "        0.2057, 0.2290, 0.0671, 0.1499, 0.1500, 0.1587, 0.2202, 0.1660, 0.1536,\n",
      "        0.1829, 0.1385, 0.1531, 0.1249, 0.1642, 0.2073, 0.1614, 0.1425, 0.1305,\n",
      "        0.1761, 0.1806, 0.1508, 0.1607, 0.1758, 0.2156, 0.1386, 0.1764, 0.1799,\n",
      "        0.1588, 0.1838, 0.1738, 0.1509, 0.1641, 0.1564, 0.1893, 0.1466, 0.1515,\n",
      "        0.1860, 0.1491, 0.2004, 0.1574, 0.1775, 0.1641, 0.1704, 0.1492, 0.1967,\n",
      "        0.1627, 0.1887, 0.1730, 0.1705, 0.1514, 0.1456, 0.1563, 0.1755, 0.1876,\n",
      "        0.1800, 0.1762, 0.1953, 0.1540, 0.1824, 0.1710, 0.1516, 0.1847, 0.1559,\n",
      "        0.1714, 0.1581, 0.1428, 0.1697, 0.1529, 0.1750, 0.0722, 0.1687, 0.1901,\n",
      "        0.1461, 0.1832, 0.1629, 0.1786, 0.1976, 0.1520, 0.1689, 0.1864, 0.1712,\n",
      "        0.1474, 0.1315, 0.1686, 0.1588, 0.1903, 0.2011, 0.1459, 0.1745, 0.1670,\n",
      "        0.1224, 0.1522, 0.1631, 0.1794, 0.1630, 0.1672, 0.1632, 0.1911, 0.1743,\n",
      "        0.1424, 0.1794, 0.1491, 0.1418, 0.1653, 0.1587, 0.1505, 0.1726, 0.1319,\n",
      "        0.1548, 0.1501, 0.1954, 0.1690, 0.1770, 0.1596, 0.1728, 0.1526, 0.1741,\n",
      "        0.1667, 0.1796, 0.1593, 0.1313, 0.1378, 0.1445, 0.1639, 0.1537, 0.1566,\n",
      "        0.1523, 0.0264, 0.1806, 0.1660, 0.1482, 0.1638, 0.2000, 0.1641, 0.1695,\n",
      "        0.1739, 0.2164, 0.1505, 0.1477, 0.1527, 0.1752, 0.1740, 0.1854, 0.1498,\n",
      "        0.1735, 0.1731, 0.1590, 0.1895, 0.1712, 0.1621, 0.1606, 0.1802, 0.1710,\n",
      "        0.1501, 0.0632, 0.1639, 0.1468, 0.1789, 0.2118, 0.1396, 0.1914, 0.2150,\n",
      "        0.1382, 0.1676, 0.1573, 0.1902, 0.1664, 0.1622, 0.1508, 0.1565, 0.1848,\n",
      "        0.1399, 0.1607, 0.1764, 0.1843, 0.1676, 0.1694, 0.1602, 0.1792, 0.1804,\n",
      "        0.1412, 0.1693, 0.1255, 0.1664, 0.1738, 0.1771, 0.1497, 0.1693, 0.1986,\n",
      "        0.1670, 0.1579, 0.1530, 0.1667, 0.1785, 0.1563, 0.1597, 0.1501, 0.1512,\n",
      "        0.1624, 0.1724, 0.1578, 0.1983, 0.1727, 0.1615, 0.1501, 0.1896, 0.1627,\n",
      "        0.1707, 0.1929, 0.1645, 0.1742, 0.1411, 0.1390, 0.1646, 0.1721, 0.1789,\n",
      "        0.1612, 0.1768, 0.1437, 0.1489, 0.1510, 0.1413, 0.1737, 0.1345, 0.1447,\n",
      "        0.1836, 0.1441, 0.1819, 0.1717, 0.1764, 0.1625, 0.1709, 0.1538, 0.1625,\n",
      "        0.1399, 0.1677, 0.1687, 0.1890, 0.1532, 0.1583, 0.1849, 0.1369, 0.1586,\n",
      "        0.1419, 0.1614, 0.1479, 0.1868, 0.1793, 0.1654, 0.1758, 0.1985, 0.1817,\n",
      "        0.1562, 0.1335, 0.1832, 0.1888, 0.1814, 0.1994, 0.1832, 0.1556, 0.1417,\n",
      "        0.1715, 0.1705, 0.1672, 0.1638, 0.1651, 0.1589, 0.1685, 0.1929, 0.1600,\n",
      "        0.1686, 0.1410, 0.1640, 0.1504, 0.1535, 0.1759, 0.1679, 0.1664, 0.1668,\n",
      "        0.1996, 0.1385, 0.2122, 0.1438, 0.1714, 0.1592, 0.1674, 0.1266, 0.1867,\n",
      "        0.1475, 0.1722, 0.1755, 0.1920, 0.1778, 0.1729, 0.1842, 0.1755, 0.1868,\n",
      "        0.1791, 0.1527, 0.1464, 0.1732, 0.1602, 0.1766, 0.1532, 0.1699, 0.2045,\n",
      "        0.1785, 0.1809, 0.1838, 0.1812, 0.1788, 0.1728, 0.1502, 0.1612, 0.2228,\n",
      "        0.1783, 0.1559, 0.1758, 0.1687, 0.1734, 0.1673, 0.1452, 0.1381, 0.1818,\n",
      "        0.1103, 0.1859, 0.1682, 0.1913, 0.1908, 0.1377, 0.2023, 0.1671, 0.1652,\n",
      "        0.1574, 0.1396, 0.1831, 0.1290, 0.1916, 0.1461, 0.1705, 0.1366, 0.1461,\n",
      "        0.1724, 0.1405, 0.1521, 0.1748, 0.1653, 0.1608, 0.1530, 0.1573, 0.1480,\n",
      "        0.1692, 0.1732, 0.1557, 0.1637, 0.1373, 0.1798, 0.1431, 0.0599, 0.1804,\n",
      "        0.2105, 0.1782, 0.1677, 0.1896, 0.1846, 0.1454, 0.1750, 0.1667, 0.1638,\n",
      "        0.1748, 0.1807, 0.2021, 0.1693, 0.1464, 0.1822, 0.1340, 0.1689, 0.2031,\n",
      "        0.1635, 0.1749, 0.1725, 0.1860, 0.1461, 0.1654, 0.1680, 0.1956, 0.1545,\n",
      "        0.1739, 0.1592, 0.1714, 0.1730, 0.1425, 0.1654, 0.1746, 0.1948, 0.1591,\n",
      "        0.1671, 0.1611, 0.1710, 0.1615, 0.1574, 0.1564, 0.1633, 0.1036, 0.1811,\n",
      "        0.0580, 0.1399, 0.1824, 0.1546, 0.1542, 0.1642, 0.1648, 0.1776, 0.1499,\n",
      "        0.1593, 0.1370, 0.1438, 0.1685, 0.1564, 0.1469, 0.1626, 0.1741, 0.1879,\n",
      "        0.1557, 0.1669, 0.1618, 0.1492, 0.1556, 0.1788, 0.1552, 0.1295, 0.1521,\n",
      "        0.1466, 0.1750, 0.1795, 0.1760, 0.1799, 0.1628, 0.2142, 0.1502, 0.1754,\n",
      "        0.1519, 0.1576, 0.1576, 0.1680, 0.1701, 0.1672, 0.1673, 0.1916, 0.1710,\n",
      "        0.1506, 0.1631, 0.1667, 0.1672, 0.1433, 0.1179, 0.1839, 0.1614, 0.1463,\n",
      "        0.1748, 0.1898, 0.1737, 0.1618, 0.1371, 0.1559, 0.1767, 0.2102, 0.1443,\n",
      "        0.1681, 0.1789, 0.1845, 0.1732, 0.1788, 0.1608, 0.1679, 0.1597, 0.1740,\n",
      "        0.1981, 0.1686, 0.1863, 0.1857, 0.1784, 0.1541, 0.1612, 0.1667, 0.1785,\n",
      "        0.1742, 0.1621, 0.1964, 0.1641, 0.1783, 0.1859, 0.1759, 0.1804, 0.1724,\n",
      "        0.1545, 0.1489, 0.1729, 0.1843, 0.1584, 0.1547, 0.1640, 0.1323],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.1095,  0.2246, -0.5115,  ..., -0.1694, -0.4500, -0.3614],\n",
      "        [ 0.0862, -0.2296,  0.0083,  ...,  0.4519, -0.2377, -0.1061],\n",
      "        [-0.2994, -0.4237, -0.1077,  ...,  0.0917,  0.2478, -0.2968],\n",
      "        ...,\n",
      "        [-0.2165, -0.2940, -0.0046,  ..., -0.4670, -0.4752,  0.1026],\n",
      "        [-0.2540,  0.0991, -0.6010,  ..., -0.1772,  0.0019, -0.4864],\n",
      "        [-0.4250, -0.1817,  0.1271,  ...,  0.1090,  0.3983, -0.7197]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.3204,  0.9212, -0.9767,  ...,  1.0621, -1.1953, -1.3128],\n",
      "        [ 0.3711, -0.0960, -0.1827,  ..., -0.6556,  0.5620,  0.7224],\n",
      "        [ 0.6677, -0.0373, -0.0067,  ..., -0.7264, -0.6284,  0.5126],\n",
      "        ...,\n",
      "        [ 1.6016, -1.3281, -2.0314,  ..., -2.1874,  1.7658,  0.7937],\n",
      "        [ 0.2954,  0.8355,  0.2653,  ..., -0.4595,  0.2911, -1.5471],\n",
      "        [ 0.1716,  0.6748, -0.1792,  ..., -1.3136,  0.2482, -0.5149]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.6366,  0.1943,  0.7264,  ...,  0.6090, -0.3118,  0.3259],\n",
      "        [-0.3596,  0.1858, -0.0438,  ..., -0.4589, -0.5703, -0.0638],\n",
      "        [ 0.7846,  0.1493, -0.1880,  ...,  0.0709,  0.9217,  0.4843],\n",
      "        ...,\n",
      "        [ 0.0399,  1.0226, -1.3902,  ..., -0.0033,  0.0785,  0.4422],\n",
      "        [ 0.1621, -0.1194, -0.9060,  ...,  0.0188, -0.3458, -0.7666],\n",
      "        [-0.1385,  0.0896,  0.1440,  ...,  0.2540, -0.3614, -0.1276]],\n",
      "       device='cuda:0')\n",
      "tensor([0.1208, 0.1263, 0.0788, 0.1180, 0.1004, 0.1135, 0.0645, 0.1123, 0.0978,\n",
      "        0.1173, 0.1337, 0.0570, 0.1193, 0.0958, 0.1031, 0.1477, 0.0996, 0.0959,\n",
      "        0.1109, 0.1112, 0.1082, 0.0826, 0.1138, 0.0987, 0.1020, 0.0859, 0.0928,\n",
      "        0.1239, 0.1205, 0.1014, 0.1108, 0.1163, 0.1720, 0.0980, 0.1096, 0.1217,\n",
      "        0.0962, 0.1127, 0.1214, 0.0920, 0.1042, 0.1143, 0.1210, 0.0967, 0.1152,\n",
      "        0.1120, 0.1145, 0.1308, 0.1016, 0.1305, 0.0918, 0.1180, 0.1034, 0.1321,\n",
      "        0.1068, 0.1186, 0.0933, 0.1301, 0.1155, 0.1088, 0.1277, 0.1062, 0.1145,\n",
      "        0.0983, 0.1287, 0.0990, 0.0881, 0.1143, 0.1198, 0.0929, 0.1361, 0.1193,\n",
      "        0.1225, 0.1011, 0.1052, 0.1130, 0.0965, 0.1242, 0.0520, 0.1206, 0.1082,\n",
      "        0.1189, 0.0906, 0.1179, 0.1271, 0.1234, 0.1065, 0.1026, 0.1227, 0.1221,\n",
      "        0.1009, 0.0926, 0.1203, 0.1029, 0.1216, 0.1060, 0.1045, 0.1115, 0.1028,\n",
      "        0.1027, 0.0846, 0.0900, 0.1093, 0.1090, 0.1045, 0.0879, 0.1215, 0.0962,\n",
      "        0.0951, 0.0969, 0.1023, 0.1009, 0.1039, 0.0930, 0.1026, 0.1108, 0.0972,\n",
      "        0.0984, 0.0825, 0.1140, 0.1204, 0.1123, 0.1173, 0.1088, 0.0992, 0.1185,\n",
      "        0.0967, 0.0991, 0.1079, 0.0921, 0.1147, 0.1026, 0.1058, 0.0941, 0.0924,\n",
      "        0.1005, 0.2285, 0.1188, 0.0996, 0.1018, 0.1068, 0.1102, 0.0943, 0.1126,\n",
      "        0.0981, 0.1363, 0.0985, 0.1090, 0.0941, 0.0995, 0.1041, 0.1144, 0.1035,\n",
      "        0.1118, 0.1030, 0.0946, 0.1160, 0.1155, 0.1029, 0.1106, 0.1167, 0.1129,\n",
      "        0.1064, 0.0324, 0.0975, 0.1088, 0.0994, 0.0995, 0.0863, 0.1151, 0.0997,\n",
      "        0.1062, 0.1170, 0.0898, 0.1307, 0.1077, 0.1033, 0.0969, 0.1124, 0.1160,\n",
      "        0.0757, 0.0729, 0.1032, 0.1090, 0.0993, 0.1282, 0.1057, 0.1082, 0.1151,\n",
      "        0.0900, 0.1105, 0.1073, 0.1056, 0.0905, 0.0944, 0.1156, 0.1235, 0.1200,\n",
      "        0.1004, 0.1036, 0.0932, 0.1012, 0.1129, 0.0890, 0.1056, 0.1202, 0.1017,\n",
      "        0.0974, 0.1222, 0.1097, 0.1168, 0.0958, 0.1013, 0.0882, 0.1197, 0.1320,\n",
      "        0.1161, 0.1087, 0.0956, 0.1148, 0.0969, 0.0922, 0.1013, 0.1269, 0.0980,\n",
      "        0.0910, 0.0965, 0.1065, 0.1154, 0.1140, 0.0854, 0.0953, 0.0842, 0.1028,\n",
      "        0.1229, 0.1012, 0.1060, 0.1068, 0.1013, 0.1051, 0.1120, 0.1082, 0.0939,\n",
      "        0.1032, 0.0942, 0.1253, 0.1053, 0.0950, 0.1041, 0.1179, 0.1080, 0.0931,\n",
      "        0.1030, 0.1001, 0.0894, 0.0990, 0.1246, 0.0942, 0.1045, 0.1145, 0.1009,\n",
      "        0.0873, 0.0968, 0.1208, 0.1124, 0.1077, 0.1169, 0.1146, 0.1091, 0.0818,\n",
      "        0.1005, 0.1082, 0.1020, 0.1037, 0.0909, 0.1130, 0.1020, 0.1181, 0.1044,\n",
      "        0.1069, 0.0892, 0.1098, 0.1083, 0.1048, 0.1179, 0.0770, 0.1126, 0.1037,\n",
      "        0.1157, 0.1113, 0.1160, 0.0998, 0.1151, 0.1091, 0.0996, 0.0724, 0.1171,\n",
      "        0.0879, 0.0984, 0.0919, 0.1044, 0.1053, 0.1042, 0.1132, 0.1165, 0.1218,\n",
      "        0.1035, 0.0984, 0.0972, 0.1014, 0.1108, 0.0966, 0.0795, 0.0962, 0.1272,\n",
      "        0.1130, 0.1054, 0.1242, 0.1169, 0.1014, 0.1088, 0.0889, 0.0924, 0.1057,\n",
      "        0.0992, 0.0881, 0.1170, 0.0899, 0.1025, 0.1185, 0.1017, 0.0898, 0.0957,\n",
      "        0.0555, 0.1053, 0.0905, 0.0958, 0.1198, 0.0844, 0.1377, 0.1009, 0.1144,\n",
      "        0.1190, 0.0985, 0.1228, 0.0982, 0.1077, 0.0997, 0.1068, 0.1056, 0.1174,\n",
      "        0.1024, 0.1000, 0.1028, 0.1189, 0.1182, 0.1111, 0.1108, 0.1008, 0.1223,\n",
      "        0.1105, 0.1144, 0.1049, 0.0938, 0.0942, 0.0987, 0.0868, 0.0467, 0.1021,\n",
      "        0.1078, 0.1337, 0.1168, 0.1367, 0.1202, 0.1017, 0.1132, 0.0785, 0.1003,\n",
      "        0.1148, 0.1021, 0.1112, 0.0994, 0.0987, 0.1147, 0.0947, 0.1196, 0.1168,\n",
      "        0.1338, 0.1133, 0.1070, 0.1189, 0.0887, 0.1096, 0.1188, 0.1160, 0.0914,\n",
      "        0.1103, 0.0964, 0.0862, 0.0999, 0.0871, 0.1077, 0.1276, 0.1038, 0.1219,\n",
      "        0.1070, 0.1183, 0.0997, 0.1118, 0.1033, 0.1198, 0.1228, 0.0513, 0.1093,\n",
      "        0.0492, 0.1065, 0.1049, 0.1053, 0.0889, 0.1013, 0.1069, 0.1221, 0.1063,\n",
      "        0.0961, 0.0960, 0.1029, 0.1125, 0.1086, 0.1043, 0.0844, 0.0967, 0.1115,\n",
      "        0.1050, 0.1249, 0.1119, 0.0962, 0.1150, 0.1276, 0.1030, 0.0923, 0.0900,\n",
      "        0.0959, 0.0925, 0.1183, 0.1119, 0.1089, 0.1075, 0.1041, 0.1057, 0.1026,\n",
      "        0.1008, 0.1054, 0.1055, 0.1116, 0.1205, 0.1025, 0.1199, 0.1228, 0.0874,\n",
      "        0.0929, 0.1102, 0.1144, 0.0932, 0.0944, 0.0821, 0.1011, 0.1079, 0.0820,\n",
      "        0.1068, 0.1150, 0.1117, 0.1090, 0.1013, 0.1065, 0.0959, 0.1241, 0.1021,\n",
      "        0.1000, 0.1011, 0.1193, 0.0942, 0.1115, 0.1322, 0.1147, 0.1067, 0.1152,\n",
      "        0.1169, 0.1274, 0.1037, 0.1169, 0.1256, 0.0956, 0.0975, 0.1108, 0.1091,\n",
      "        0.1179, 0.1193, 0.1207, 0.1111, 0.1119, 0.1038, 0.1204, 0.1031, 0.1077,\n",
      "        0.1050, 0.0990, 0.1181, 0.1212, 0.0948, 0.0986, 0.1028, 0.1924],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.0092,  0.0025,  0.0016,  ..., -0.0330, -0.0389,  0.0749],\n",
      "        [ 0.0385,  0.0434, -0.0438,  ...,  0.0108,  0.0268, -0.0829],\n",
      "        [ 0.0215, -0.0079, -0.0192,  ..., -0.0078,  0.0544,  0.0035],\n",
      "        ...,\n",
      "        [ 0.0652, -0.0073, -0.0140,  ..., -0.0350,  0.0364, -0.0395],\n",
      "        [ 0.0494,  0.0221, -0.0146,  ...,  0.0074,  0.0357, -0.0315],\n",
      "        [-0.0038, -0.0121, -0.0155,  ..., -0.0304,  0.0091,  0.0624]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.3662,  0.1028, -0.1336,  ..., -0.2619,  0.1240,  0.1395],\n",
      "        [-0.2467,  0.1702, -0.0389,  ..., -0.1893, -0.1471, -0.4274],\n",
      "        [ 0.0061, -0.0800,  0.4393,  ...,  0.3852, -0.0338, -0.0795],\n",
      "        ...,\n",
      "        [-0.2478, -0.0230,  0.2194,  ..., -0.2730,  0.0137, -0.3391],\n",
      "        [-0.2808, -0.5230, -0.3650,  ...,  0.1126, -0.1655, -0.3114],\n",
      "        [ 0.0954, -0.2989,  0.1263,  ...,  0.7221,  0.9804, -0.3928]],\n",
      "       device='cuda:0')\n",
      "tensor([[-1.0006,  0.3119,  1.0232,  ...,  0.4929, -0.1917, -0.9056],\n",
      "        [ 0.1449,  0.3331,  0.4416,  ..., -0.2080, -1.2263, -0.6416],\n",
      "        [ 0.5940,  0.0315,  0.4433,  ..., -0.3724,  1.1951, -0.2573],\n",
      "        ...,\n",
      "        [ 0.5545,  0.3832, -0.2326,  ...,  0.2428,  0.3461,  0.7560],\n",
      "        [-0.4450,  0.6612,  0.8876,  ...,  0.4057,  0.2911, -0.1738],\n",
      "        [ 0.5916, -1.1103, -0.0444,  ...,  0.9615, -0.3386, -0.3248]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.8633, -0.7771, -1.1011,  ..., -0.9835, -0.1739,  0.1306],\n",
      "        [-0.9999,  0.0127,  0.3349,  ...,  0.0796, -1.0230,  0.6665],\n",
      "        [ 0.4025, -0.6408, -0.4145,  ..., -0.9000, -0.3649, -0.1360],\n",
      "        ...,\n",
      "        [-0.3692,  0.7811, -0.6369,  ...,  0.1330, -0.3278,  0.2007],\n",
      "        [ 0.6952,  0.4211,  0.5188,  ..., -0.6056,  0.0280,  0.1762],\n",
      "        [ 1.1249,  0.1920, -0.2659,  ..., -0.5731,  0.2738, -0.2176]],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.1806,  0.1666,  0.1646,  0.1767,  0.1541,  0.1730,  0.0576,  0.1766,\n",
      "         0.1590,  0.1749,  0.2074,  0.0857,  0.1581,  0.1457,  0.1549,  0.2159,\n",
      "         0.1791,  0.1660,  0.1792,  0.1637,  0.1372,  0.1392,  0.1673,  0.1898,\n",
      "         0.1911,  0.1687,  0.1665,  0.1827,  0.1625,  0.1459,  0.1682,  0.1618,\n",
      "         0.2189,  0.1752,  0.1524,  0.1812,  0.1702,  0.1685,  0.1838,  0.1505,\n",
      "         0.1570,  0.1629,  0.1862,  0.1585,  0.1739,  0.1606,  0.1726,  0.1956,\n",
      "         0.1620,  0.1855,  0.1754,  0.1634,  0.1576,  0.1908,  0.1622,  0.1704,\n",
      "         0.1405,  0.1600,  0.1701,  0.1563,  0.1446,  0.1721,  0.1787,  0.1694,\n",
      "         0.1836,  0.1839,  0.1539,  0.1575,  0.1811,  0.1622,  0.1677,  0.1575,\n",
      "         0.1937,  0.1576,  0.1227,  0.1525,  0.1812,  0.1577,  0.0757,  0.1756,\n",
      "         0.1740,  0.1533,  0.1852,  0.1993,  0.1804,  0.1887,  0.1551,  0.1652,\n",
      "         0.1919,  0.1592,  0.1549,  0.1688,  0.1861,  0.1696,  0.1990,  0.1803,\n",
      "         0.1641,  0.1564,  0.1645,  0.1465,  0.1578,  0.1749,  0.1812,  0.1788,\n",
      "         0.1893,  0.1568,  0.1925,  0.1703,  0.1403,  0.1758,  0.1493,  0.1538,\n",
      "         0.1757,  0.1850,  0.1649,  0.1798,  0.1444,  0.1516,  0.1938,  0.1866,\n",
      "         0.1565,  0.1781,  0.1519,  0.1882,  0.1758,  0.1559,  0.1658,  0.1861,\n",
      "         0.1797,  0.1663,  0.1433,  0.1582,  0.1574,  0.1544,  0.1714,  0.1877,\n",
      "        -0.0016,  0.1842,  0.1592,  0.1990,  0.1693,  0.1812,  0.1587,  0.1675,\n",
      "         0.1676,  0.1933,  0.1480,  0.1350,  0.1580,  0.1830,  0.1806,  0.1942,\n",
      "         0.1467,  0.1355,  0.1446,  0.1613,  0.1549,  0.1515,  0.1746,  0.1483,\n",
      "         0.1556,  0.1340,  0.1572,  0.0524,  0.1535,  0.1755,  0.1792,  0.1848,\n",
      "         0.1529,  0.1837,  0.1787,  0.1528,  0.1739,  0.1716,  0.1643,  0.1546,\n",
      "         0.1736,  0.1656,  0.1548,  0.1682,  0.1267,  0.1403,  0.1518,  0.1809,\n",
      "         0.1696,  0.1496,  0.1678,  0.1886,  0.1828,  0.1383,  0.1777,  0.0919,\n",
      "         0.1509,  0.1960,  0.1409,  0.1472,  0.1892,  0.1903,  0.1822,  0.1270,\n",
      "         0.1581,  0.1488,  0.1810,  0.1682,  0.1858,  0.1729,  0.1570,  0.1492,\n",
      "         0.1821,  0.1635,  0.1705,  0.1567,  0.1483,  0.1689,  0.1867,  0.1703,\n",
      "         0.1778,  0.1723,  0.1672,  0.1683,  0.1457,  0.1475,  0.1527,  0.1646,\n",
      "         0.2010,  0.1582,  0.1870,  0.1595,  0.1668,  0.1824,  0.1632,  0.1636,\n",
      "         0.1549,  0.1564,  0.1702,  0.1472,  0.2093,  0.1776,  0.2042,  0.1526,\n",
      "         0.1775,  0.1508,  0.1542,  0.1566,  0.1384,  0.1875,  0.1724,  0.1585,\n",
      "         0.1657,  0.1697,  0.1722,  0.1681,  0.1678,  0.1609,  0.1532,  0.1743,\n",
      "         0.1726,  0.1543,  0.1830,  0.2090,  0.1796,  0.1778,  0.1582,  0.1703,\n",
      "         0.1885,  0.1981,  0.1784,  0.1942,  0.1828,  0.1539,  0.1760,  0.1720,\n",
      "         0.1711,  0.1498,  0.1753,  0.1617,  0.1677,  0.1919,  0.1476,  0.1683,\n",
      "         0.1442,  0.1765,  0.1368,  0.1527,  0.1649,  0.2077,  0.1699,  0.1832,\n",
      "         0.1927,  0.1531,  0.2018,  0.1623,  0.1781,  0.1643,  0.1570,  0.1800,\n",
      "         0.1675,  0.1535,  0.1597,  0.1569,  0.1683,  0.1423,  0.1710,  0.1969,\n",
      "         0.1560,  0.1629,  0.1756,  0.1377,  0.1776,  0.1649,  0.1655,  0.1780,\n",
      "         0.1722,  0.1410,  0.1823,  0.1973,  0.1779,  0.2009,  0.1634,  0.1649,\n",
      "         0.1588,  0.1612,  0.1595,  0.1818,  0.1714,  0.1761,  0.1949,  0.1690,\n",
      "         0.1471,  0.1552,  0.1289,  0.1619,  0.2007,  0.1092,  0.1554,  0.1740,\n",
      "         0.1899,  0.2046,  0.1364,  0.1789,  0.1642,  0.1896,  0.1554,  0.1381,\n",
      "         0.2140,  0.1647,  0.1792,  0.1826,  0.1644,  0.1558,  0.1562,  0.1580,\n",
      "         0.1639,  0.1776,  0.1518,  0.1936,  0.1727,  0.1403,  0.1989,  0.1553,\n",
      "         0.1697,  0.1915,  0.1480,  0.1639,  0.1561,  0.1639,  0.1510,  0.0424,\n",
      "         0.2140,  0.2254,  0.1031,  0.1967,  0.1726,  0.1716,  0.1485,  0.1701,\n",
      "         0.1450,  0.1574,  0.1637,  0.1676,  0.1912,  0.1746,  0.1932,  0.1629,\n",
      "         0.1454,  0.1857,  0.1900,  0.1565,  0.1763,  0.1629,  0.1937,  0.1515,\n",
      "         0.1849,  0.1536,  0.1888,  0.1559,  0.1646,  0.1799,  0.1416,  0.1804,\n",
      "         0.1598,  0.1716,  0.1843,  0.2000,  0.1607,  0.1887,  0.1459,  0.1653,\n",
      "         0.1586,  0.1716,  0.1601,  0.1746,  0.0856,  0.1782,  0.0656,  0.1511,\n",
      "         0.1555,  0.1928,  0.1455,  0.1539,  0.1802,  0.1626,  0.1725,  0.1698,\n",
      "         0.1658,  0.1481,  0.1661,  0.2001,  0.1549,  0.1506,  0.1700,  0.1797,\n",
      "         0.1430,  0.1801,  0.1508,  0.1510,  0.1502,  0.1792,  0.1677,  0.1413,\n",
      "         0.1766,  0.1471,  0.1714,  0.1644,  0.1569,  0.1621,  0.1431,  0.2169,\n",
      "         0.1619,  0.1820,  0.1641,  0.1723,  0.1850,  0.1489,  0.1488,  0.1484,\n",
      "         0.1735,  0.1815,  0.1978,  0.1351,  0.1585,  0.1788,  0.1549,  0.1543,\n",
      "         0.1407,  0.1678,  0.1735,  0.1402,  0.1685,  0.1849,  0.1830,  0.1752,\n",
      "         0.1420,  0.1608,  0.1931,  0.1759,  0.1536,  0.1828,  0.1563,  0.1742,\n",
      "         0.1602,  0.1656,  0.1486,  0.1726,  0.1623,  0.1774,  0.1660,  0.1469,\n",
      "         0.1857,  0.2060,  0.1564,  0.1467,  0.1753,  0.1798,  0.1729,  0.1922,\n",
      "         0.1567,  0.2293,  0.1692,  0.1930,  0.1579,  0.1965,  0.1698,  0.1669,\n",
      "         0.1823,  0.1595,  0.1524,  0.1634,  0.1675,  0.1582,  0.1270,  0.1245],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.1600, -0.2255,  0.0110,  ...,  0.2886, -0.2106,  0.0535],\n",
      "        [ 0.0746, -0.0086,  0.2619,  ...,  0.2051,  0.0523,  0.0331],\n",
      "        [-0.4937, -0.1055,  0.0413,  ..., -0.4299, -0.2814, -0.1548],\n",
      "        ...,\n",
      "        [ 0.0483, -0.2237,  0.2617,  ...,  0.0143,  0.1457, -0.2209],\n",
      "        [-0.3190, -0.3974, -0.4510,  ...,  0.0247, -0.0843, -0.2421],\n",
      "        [-0.3335, -0.0422,  0.0833,  ..., -0.2878, -0.3940, -0.1766]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.1709,  0.8749,  2.0625,  ..., -0.2177, -0.7577, -0.8826],\n",
      "        [-0.7851, -0.4224, -0.9531,  ..., -0.2104,  0.4322,  0.2505],\n",
      "        [-0.2325,  0.8358,  1.1406,  ...,  0.0789,  1.6015, -0.7621],\n",
      "        ...,\n",
      "        [-2.0153,  0.6245, -0.4687,  ..., -0.3187, -0.3396, -0.5205],\n",
      "        [-1.6563,  0.4415,  0.1640,  ..., -0.3766,  0.6092, -1.8586],\n",
      "        [-0.6291,  0.1062,  0.5898,  ..., -0.8553, -2.4532,  0.5552]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.6835, -0.3867,  0.3122,  ..., -0.5195,  0.5273, -0.6797],\n",
      "        [-0.3028,  0.6753,  0.0442,  ..., -0.4416, -0.9373, -0.5974],\n",
      "        [-0.2101,  0.2033, -0.2931,  ..., -1.4062, -0.1495,  0.1211],\n",
      "        ...,\n",
      "        [-0.9687,  0.7969,  0.4786,  ...,  0.0680, -0.1417, -0.4705],\n",
      "        [ 0.1422, -0.1795,  0.2536,  ..., -1.3982,  0.6759, -0.0866],\n",
      "        [ 0.3596, -0.5783,  0.2697,  ...,  0.9294,  0.9024,  0.0618]],\n",
      "       device='cuda:0')\n",
      "tensor([0.1063, 0.1163, 0.1081, 0.1150, 0.1091, 0.1006, 0.0772, 0.1044, 0.1236,\n",
      "        0.1212, 0.1243, 0.0790, 0.1316, 0.0884, 0.1289, 0.1550, 0.1058, 0.0934,\n",
      "        0.1268, 0.1051, 0.0905, 0.1042, 0.1046, 0.1008, 0.1007, 0.1111, 0.1122,\n",
      "        0.1120, 0.0997, 0.1051, 0.1139, 0.1361, 0.2279, 0.1165, 0.1198, 0.1087,\n",
      "        0.0994, 0.1153, 0.1404, 0.1120, 0.1060, 0.1070, 0.1182, 0.1231, 0.1038,\n",
      "        0.1379, 0.1137, 0.1254, 0.1256, 0.1160, 0.1122, 0.1123, 0.1134, 0.1407,\n",
      "        0.1091, 0.1075, 0.1092, 0.1000, 0.1190, 0.1009, 0.1174, 0.1004, 0.1214,\n",
      "        0.1131, 0.1374, 0.0929, 0.1091, 0.1213, 0.1055, 0.1137, 0.1163, 0.1181,\n",
      "        0.1182, 0.0973, 0.1074, 0.1128, 0.0986, 0.1178, 0.0740, 0.1274, 0.1068,\n",
      "        0.1116, 0.1124, 0.1339, 0.1380, 0.1027, 0.1178, 0.1099, 0.1598, 0.1261,\n",
      "        0.1230, 0.1109, 0.1084, 0.1195, 0.1323, 0.1084, 0.1201, 0.1166, 0.1070,\n",
      "        0.1176, 0.0942, 0.1080, 0.1158, 0.1294, 0.1274, 0.1119, 0.1330, 0.0863,\n",
      "        0.1047, 0.1209, 0.1035, 0.1074, 0.1223, 0.1086, 0.1246, 0.1043, 0.1194,\n",
      "        0.1000, 0.1157, 0.0960, 0.0929, 0.1111, 0.1170, 0.0972, 0.1025, 0.0940,\n",
      "        0.0945, 0.1268, 0.1092, 0.1196, 0.1362, 0.0884, 0.1046, 0.1226, 0.1210,\n",
      "        0.1006, 0.6538, 0.1127, 0.1071, 0.1067, 0.1049, 0.1264, 0.1139, 0.1017,\n",
      "        0.1095, 0.1482, 0.1195, 0.1280, 0.0945, 0.1312, 0.0940, 0.1136, 0.1216,\n",
      "        0.1319, 0.1183, 0.1017, 0.1282, 0.1077, 0.1084, 0.1159, 0.1446, 0.1399,\n",
      "        0.0945, 0.0475, 0.1209, 0.1003, 0.1032, 0.1282, 0.0936, 0.1246, 0.1226,\n",
      "        0.1014, 0.1130, 0.1100, 0.1272, 0.1186, 0.1119, 0.1148, 0.1086, 0.1051,\n",
      "        0.1099, 0.1102, 0.1270, 0.0958, 0.1180, 0.1087, 0.0989, 0.1291, 0.1091,\n",
      "        0.1130, 0.1181, 0.0764, 0.0936, 0.1047, 0.1134, 0.1285, 0.1237, 0.1080,\n",
      "        0.1225, 0.1022, 0.1052, 0.1183, 0.1087, 0.1109, 0.1202, 0.1139, 0.1134,\n",
      "        0.1161, 0.1119, 0.1001, 0.1232, 0.0877, 0.1229, 0.1004, 0.1254, 0.1037,\n",
      "        0.1250, 0.1324, 0.1321, 0.1176, 0.0977, 0.1143, 0.1022, 0.1004, 0.1090,\n",
      "        0.0964, 0.1176, 0.0914, 0.1227, 0.1295, 0.0972, 0.1104, 0.0976, 0.1086,\n",
      "        0.1387, 0.1153, 0.1219, 0.1221, 0.1247, 0.0866, 0.1388, 0.0986, 0.1066,\n",
      "        0.1114, 0.0967, 0.1322, 0.0856, 0.1062, 0.1108, 0.1115, 0.1348, 0.1111,\n",
      "        0.1241, 0.1273, 0.1049, 0.1069, 0.1187, 0.1240, 0.1202, 0.1211, 0.1053,\n",
      "        0.1095, 0.1128, 0.1293, 0.1221, 0.1129, 0.1197, 0.1098, 0.1125, 0.1021,\n",
      "        0.1170, 0.1148, 0.1189, 0.1115, 0.1052, 0.1171, 0.0998, 0.1018, 0.0914,\n",
      "        0.1312, 0.0961, 0.1179, 0.1038, 0.1161, 0.1070, 0.0885, 0.1025, 0.1165,\n",
      "        0.1115, 0.1123, 0.1310, 0.1056, 0.1042, 0.1114, 0.1160, 0.1145, 0.1271,\n",
      "        0.1067, 0.1375, 0.1157, 0.1096, 0.1067, 0.1174, 0.1201, 0.0921, 0.1435,\n",
      "        0.1146, 0.0927, 0.0937, 0.1138, 0.1031, 0.1193, 0.1104, 0.1265, 0.1120,\n",
      "        0.1143, 0.0905, 0.1205, 0.1173, 0.1115, 0.0927, 0.0993, 0.1070, 0.1349,\n",
      "        0.1226, 0.1024, 0.1159, 0.1081, 0.1134, 0.1013, 0.1046, 0.1054, 0.1185,\n",
      "        0.0756, 0.0929, 0.1163, 0.1194, 0.1270, 0.1032, 0.1509, 0.1280, 0.1454,\n",
      "        0.1081, 0.1058, 0.1169, 0.1023, 0.0995, 0.1020, 0.1283, 0.1180, 0.0963,\n",
      "        0.1111, 0.1165, 0.1031, 0.1115, 0.1135, 0.1148, 0.1099, 0.0873, 0.1184,\n",
      "        0.1160, 0.1186, 0.1207, 0.1116, 0.1260, 0.1234, 0.1118, 0.0352, 0.1080,\n",
      "        0.1453, 0.1475, 0.1237, 0.1090, 0.0924, 0.1119, 0.1153, 0.1058, 0.1099,\n",
      "        0.1007, 0.0983, 0.1145, 0.1165, 0.1007, 0.1051, 0.1114, 0.1252, 0.1015,\n",
      "        0.1408, 0.1257, 0.1137, 0.1204, 0.1286, 0.1105, 0.1046, 0.1195, 0.0928,\n",
      "        0.1217, 0.1263, 0.1061, 0.1172, 0.1120, 0.1240, 0.1055, 0.1148, 0.1223,\n",
      "        0.1082, 0.1117, 0.1014, 0.1098, 0.1305, 0.1343, 0.1115, 0.0817, 0.1065,\n",
      "        0.0464, 0.1292, 0.1011, 0.1166, 0.1118, 0.1227, 0.1332, 0.1075, 0.1155,\n",
      "        0.0980, 0.1138, 0.1104, 0.1276, 0.1107, 0.1167, 0.1243, 0.1233, 0.1028,\n",
      "        0.0896, 0.1127, 0.1034, 0.1066, 0.1352, 0.1066, 0.1133, 0.0909, 0.1002,\n",
      "        0.1086, 0.1204, 0.1080, 0.1121, 0.1278, 0.1220, 0.1307, 0.1281, 0.1113,\n",
      "        0.1044, 0.0933, 0.1060, 0.1163, 0.0944, 0.0928, 0.1196, 0.1251, 0.1223,\n",
      "        0.1100, 0.1110, 0.1264, 0.0820, 0.0948, 0.0899, 0.1266, 0.1013, 0.1055,\n",
      "        0.1190, 0.1288, 0.1104, 0.1224, 0.1154, 0.1316, 0.1144, 0.1157, 0.1158,\n",
      "        0.1163, 0.1159, 0.1040, 0.1129, 0.1050, 0.0973, 0.1144, 0.1031, 0.1179,\n",
      "        0.1282, 0.1094, 0.1187, 0.0985, 0.1308, 0.1124, 0.1160, 0.1338, 0.0972,\n",
      "        0.1253, 0.1172, 0.1237, 0.1136, 0.1109, 0.1267, 0.1512, 0.0866, 0.1212,\n",
      "        0.1230, 0.1220, 0.1078, 0.1392, 0.1127, 0.1006, 0.1237, 0.4023],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.0054,  0.0119, -0.0056,  ...,  0.0087, -0.0263,  0.0422],\n",
      "        [ 0.0159,  0.0434, -0.0012,  ..., -0.0059,  0.0084, -0.0168],\n",
      "        [ 0.0354,  0.0129,  0.0002,  ..., -0.0112, -0.0474, -0.0212],\n",
      "        ...,\n",
      "        [-0.0142,  0.0032,  0.0095,  ..., -0.0129,  0.0181,  0.0305],\n",
      "        [ 0.0105,  0.0135,  0.0089,  ...,  0.0065,  0.0309,  0.0145],\n",
      "        [ 0.0138,  0.0357, -0.0048,  ...,  0.0219, -0.0398,  0.0426]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.0168,  0.1215,  0.2617,  ..., -0.1113,  0.2442,  0.0936],\n",
      "        [ 0.0345, -0.0332, -0.1485,  ...,  0.0708,  0.0889, -0.1661],\n",
      "        [ 0.2393,  0.2944, -0.0644,  ..., -0.0750,  0.1034,  0.4502],\n",
      "        ...,\n",
      "        [ 0.1963,  0.0217, -0.0642,  ...,  0.0919,  0.0089,  0.0086],\n",
      "        [-0.2349,  0.0475, -0.2769,  ..., -0.1519,  0.0481,  0.0581],\n",
      "        [ 0.1487, -0.0666, -0.1344,  ...,  0.0358, -0.2595,  0.2908]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.8711, -0.0346,  1.0312,  ...,  0.8633, -1.0936,  0.7229],\n",
      "        [-0.3631, -0.4998, -1.0313,  ..., -0.8320, -0.6564, -1.1324],\n",
      "        [ 1.1954, -0.6009,  0.9023,  ..., -0.4373, -0.0960,  1.1706],\n",
      "        ...,\n",
      "        [ 0.0049, -0.1226, -1.0087,  ...,  0.5351,  0.0240,  1.4694],\n",
      "        [ 1.2403, -0.4261, -1.9298,  ...,  0.2640, -0.9079,  0.7236],\n",
      "        [ 0.8607,  0.8252,  0.1408,  ...,  0.3472,  1.3724,  0.4519]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.5078,  0.4532, -0.9180,  ...,  0.1310, -0.4668,  0.3632],\n",
      "        [ 0.5859, -0.5626,  0.3809,  ..., -1.7475, -1.7884, -2.3285],\n",
      "        [ 0.7069,  1.1093, -0.3925,  ...,  1.2049, -0.3319,  0.8164],\n",
      "        ...,\n",
      "        [ 1.0703, -0.9336,  0.0870,  ..., -0.5488, -0.0592, -0.1975],\n",
      "        [ 0.2090,  0.4690, -0.7227,  ..., -0.1525, -0.3436,  1.5856],\n",
      "        [ 0.4551, -0.2580,  0.1407,  ...,  0.3367, -0.9022, -0.2299]],\n",
      "       device='cuda:0')\n",
      "tensor([0.1956, 0.1775, 0.1735, 0.1824, 0.1905, 0.1728, 0.0181, 0.1888, 0.1897,\n",
      "        0.1779, 0.2394, 0.0945, 0.2052, 0.1570, 0.1742, 0.2288, 0.1895, 0.1900,\n",
      "        0.1592, 0.1810, 0.1797, 0.1395, 0.1922, 0.2006, 0.2068, 0.1760, 0.1706,\n",
      "        0.1741, 0.1871, 0.1892, 0.1848, 0.1464, 0.1748, 0.1804, 0.1695, 0.1946,\n",
      "        0.1818, 0.1898, 0.1867, 0.1689, 0.1965, 0.1715, 0.2002, 0.1733, 0.1587,\n",
      "        0.1629, 0.1762, 0.2015, 0.1851, 0.1812, 0.1924, 0.1756, 0.1901, 0.2338,\n",
      "        0.1739, 0.1958, 0.1758, 0.1826, 0.1953, 0.1615, 0.1917, 0.1968, 0.2102,\n",
      "        0.1751, 0.1829, 0.2056, 0.2055, 0.1729, 0.1622, 0.1848, 0.1590, 0.1628,\n",
      "        0.1901, 0.1921, 0.1364, 0.1865, 0.1976, 0.1903, 0.0349, 0.2084, 0.1888,\n",
      "        0.1826, 0.2193, 0.2325, 0.1957, 0.2041, 0.1795, 0.2173, 0.2284, 0.1578,\n",
      "        0.1550, 0.1701, 0.2006, 0.1862, 0.1967, 0.2308, 0.1719, 0.1992, 0.1555,\n",
      "        0.2043, 0.1856, 0.1803, 0.1977, 0.1962, 0.2176, 0.1685, 0.2016, 0.1874,\n",
      "        0.1764, 0.1636, 0.1749, 0.1760, 0.1659, 0.1920, 0.1919, 0.1859, 0.1748,\n",
      "        0.1794, 0.1972, 0.2042, 0.1911, 0.2351, 0.1593, 0.1895, 0.1802, 0.1801,\n",
      "        0.1841, 0.2234, 0.1748, 0.1855, 0.1698, 0.1560, 0.1865, 0.1892, 0.2054,\n",
      "        0.1936, 0.0382, 0.2221, 0.2054, 0.1967, 0.1696, 0.2059, 0.1931, 0.1751,\n",
      "        0.1952, 0.2280, 0.2052, 0.1655, 0.2095, 0.1878, 0.1590, 0.2223, 0.2108,\n",
      "        0.1586, 0.1845, 0.1744, 0.1525, 0.1703, 0.1876, 0.1458, 0.1894, 0.1558,\n",
      "        0.1777, 0.0717, 0.1796, 0.1717, 0.1989, 0.2257, 0.1499, 0.2023, 0.2075,\n",
      "        0.1903, 0.2048, 0.1958, 0.1833, 0.1834, 0.1829, 0.2031, 0.1797, 0.1817,\n",
      "        0.1490, 0.1846, 0.1875, 0.2156, 0.1938, 0.1853, 0.1190, 0.2089, 0.2120,\n",
      "        0.1708, 0.2057, 0.0821, 0.1860, 0.2050, 0.1744, 0.1783, 0.1827, 0.1986,\n",
      "        0.1949, 0.1814, 0.1706, 0.1883, 0.2127, 0.1711, 0.2163, 0.1886, 0.2087,\n",
      "        0.1836, 0.1746, 0.1474, 0.1942, 0.1763, 0.1714, 0.1985, 0.2037, 0.1553,\n",
      "        0.2144, 0.1844, 0.2151, 0.1943, 0.1867, 0.1550, 0.1666, 0.1662, 0.2300,\n",
      "        0.1805, 0.2058, 0.1855, 0.1846, 0.1921, 0.1916, 0.1832, 0.1652, 0.1536,\n",
      "        0.1544, 0.1877, 0.1922, 0.1858, 0.1630, 0.1702, 0.1940, 0.2026, 0.1945,\n",
      "        0.1793, 0.1669, 0.1821, 0.2161, 0.1777, 0.1737, 0.1927, 0.1980, 0.1705,\n",
      "        0.1946, 0.2054, 0.1691, 0.2088, 0.1798, 0.1772, 0.1896, 0.2306, 0.1987,\n",
      "        0.1765, 0.1822, 0.1672, 0.1964, 0.2053, 0.2001, 0.1881, 0.2033, 0.1871,\n",
      "        0.1846, 0.1917, 0.1952, 0.1703, 0.1879, 0.1726, 0.1806, 0.1981, 0.1573,\n",
      "        0.1831, 0.1774, 0.2090, 0.1694, 0.1626, 0.1710, 0.2040, 0.1656, 0.1834,\n",
      "        0.1904, 0.1656, 0.1757, 0.1949, 0.1794, 0.2061, 0.1895, 0.2083, 0.2125,\n",
      "        0.1850, 0.1866, 0.1740, 0.1983, 0.2048, 0.1863, 0.2009, 0.1697, 0.1907,\n",
      "        0.1703, 0.1630, 0.2005, 0.1677, 0.1878, 0.1960, 0.1589, 0.1965, 0.1982,\n",
      "        0.2162, 0.1918, 0.2152, 0.1604, 0.2021, 0.1981, 0.1850, 0.1738, 0.2177,\n",
      "        0.2074, 0.2007, 0.1946, 0.2063, 0.1600, 0.1924, 0.1565, 0.1998, 0.1769,\n",
      "        0.1256, 0.1720, 0.2312, 0.2251, 0.2125, 0.1614, 0.2126, 0.1872, 0.1825,\n",
      "        0.2287, 0.1707, 0.2082, 0.1834, 0.2175, 0.1934, 0.1804, 0.1679, 0.1897,\n",
      "        0.2150, 0.1811, 0.1768, 0.1977, 0.1920, 0.1626, 0.2004, 0.1863, 0.1899,\n",
      "        0.1956, 0.2311, 0.1848, 0.1455, 0.1629, 0.1881, 0.1781, 0.0443, 0.2196,\n",
      "        0.2019, 0.0048, 0.2220, 0.1980, 0.1930, 0.1666, 0.2028, 0.1726, 0.1556,\n",
      "        0.1820, 0.2000, 0.1949, 0.1827, 0.2064, 0.1954, 0.1752, 0.1934, 0.2059,\n",
      "        0.1643, 0.2207, 0.1785, 0.2079, 0.2010, 0.2121, 0.1910, 0.2155, 0.1685,\n",
      "        0.1812, 0.1791, 0.1831, 0.1635, 0.1832, 0.2070, 0.1842, 0.1781, 0.1579,\n",
      "        0.1904, 0.1652, 0.1754, 0.1850, 0.1793, 0.1947, 0.1893, 0.0835, 0.1870,\n",
      "        0.0749, 0.1682, 0.1678, 0.2011, 0.1756, 0.1957, 0.1987, 0.1403, 0.1908,\n",
      "        0.1909, 0.2064, 0.1730, 0.1999, 0.1910, 0.1718, 0.1948, 0.1958, 0.1809,\n",
      "        0.1654, 0.1903, 0.1418, 0.1840, 0.1582, 0.1957, 0.1991, 0.1639, 0.1995,\n",
      "        0.1753, 0.1930, 0.1358, 0.1849, 0.1790, 0.1600, 0.2460, 0.1950, 0.1984,\n",
      "        0.1666, 0.1644, 0.2042, 0.2031, 0.1448, 0.1864, 0.2017, 0.2101, 0.2329,\n",
      "        0.1801, 0.1886, 0.2044, 0.1815, 0.2011, 0.1657, 0.2059, 0.2070, 0.2068,\n",
      "        0.1997, 0.2123, 0.2071, 0.1486, 0.1810, 0.1597, 0.2083, 0.2114, 0.1703,\n",
      "        0.1867, 0.2093, 0.1721, 0.1773, 0.1921, 0.1419, 0.1927, 0.1922, 0.1651,\n",
      "        0.1858, 0.2001, 0.1814, 0.2040, 0.1856, 0.1716, 0.1747, 0.2058, 0.1858,\n",
      "        0.2065, 0.1810, 0.2245, 0.1753, 0.2272, 0.1763, 0.2047, 0.2149, 0.1973,\n",
      "        0.1871, 0.1897, 0.1839, 0.1740, 0.1742, 0.1374, 0.1755, 0.0937],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.2239, -0.0716,  0.0574,  ..., -0.0084,  0.0607,  0.1066],\n",
      "        [-0.1901, -0.1734,  0.4375,  ...,  0.3022,  0.1790,  0.3147],\n",
      "        [ 0.1063,  0.0412, -0.0915,  ...,  0.0318, -0.1600, -0.0891],\n",
      "        ...,\n",
      "        [-0.1270,  0.1057, -0.1572,  ...,  0.1119, -0.1387,  0.1535],\n",
      "        [ 0.0107, -0.2774, -0.3185,  ..., -0.1919,  0.2277,  0.1546],\n",
      "        [-0.0498, -0.0824,  0.7576,  ..., -0.2547,  0.6489,  0.1096]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.1372,  0.6826,  1.3200,  ...,  1.0146, -0.7187, -0.6779],\n",
      "        [-0.9258,  0.1622, -1.2969,  ...,  1.8751,  0.1806, -0.7418],\n",
      "        [-0.1552, -0.0050, -0.6680,  ...,  0.9882,  2.3750,  0.5349],\n",
      "        ...,\n",
      "        [ 0.4687,  1.7032,  1.5391,  ..., -1.3828,  0.1533, -0.4178],\n",
      "        [-0.4200, -0.5861, -0.9414,  ...,  0.1904,  0.6016,  0.9373],\n",
      "        [ 0.6406,  0.2452, -0.4649,  ..., -2.2969,  2.3281, -0.4667]],\n",
      "       device='cuda:0')\n",
      "tensor([[-5.9265e-01, -3.0085e-01,  5.1194e-01,  ..., -4.1209e-01,\n",
      "          8.0874e-01,  7.6952e-01],\n",
      "        [-5.6721e-01, -2.3623e-01, -1.2346e+00,  ..., -6.8752e-01,\n",
      "          9.6503e-02, -2.0038e-02],\n",
      "        [-1.7042e-01,  2.1979e-01,  3.8653e-01,  ...,  1.0255e-01,\n",
      "         -2.2778e-01, -6.3656e-01],\n",
      "        ...,\n",
      "        [ 1.2580e+00,  3.4185e-01,  6.3267e-01,  ..., -4.3513e-04,\n",
      "         -7.0340e-01,  5.1175e-01],\n",
      "        [ 8.0669e-02, -2.1303e-01, -8.3554e-01,  ...,  4.3754e-01,\n",
      "          7.0343e-01, -3.4609e-01],\n",
      "        [-1.6865e-01,  4.8656e-02, -1.5242e-01,  ...,  3.4758e-01,\n",
      "         -5.5486e-01, -8.9280e-02]], device='cuda:0')\n",
      "tensor([0.0912, 0.1154, 0.0999, 0.0837, 0.1237, 0.1181, 0.0845, 0.0903, 0.1004,\n",
      "        0.0853, 0.0764, 0.0662, 0.1089, 0.1103, 0.1100, 0.1250, 0.0960, 0.1172,\n",
      "        0.1295, 0.1122, 0.1070, 0.0963, 0.0845, 0.0750, 0.1460, 0.1237, 0.1128,\n",
      "        0.1277, 0.0963, 0.0999, 0.1083, 0.0871, 0.3494, 0.1153, 0.1037, 0.1154,\n",
      "        0.0782, 0.1246, 0.1192, 0.1059, 0.0971, 0.0855, 0.1299, 0.0915, 0.0952,\n",
      "        0.1070, 0.1006, 0.1016, 0.1108, 0.1124, 0.1035, 0.0936, 0.1103, 0.1065,\n",
      "        0.1079, 0.0968, 0.0902, 0.1010, 0.0926, 0.0918, 0.1006, 0.0925, 0.1164,\n",
      "        0.0768, 0.1081, 0.0804, 0.1208, 0.0911, 0.0877, 0.1094, 0.1028, 0.1029,\n",
      "        0.1062, 0.0977, 0.1061, 0.1062, 0.1057, 0.1197, 0.0978, 0.1120, 0.0855,\n",
      "        0.1275, 0.1066, 0.1125, 0.1075, 0.0897, 0.1229, 0.1233, 0.1380, 0.0958,\n",
      "        0.1066, 0.0999, 0.0952, 0.0992, 0.1101, 0.1248, 0.1186, 0.0775, 0.1112,\n",
      "        0.1046, 0.1053, 0.1218, 0.0929, 0.0933, 0.1035, 0.1034, 0.1125, 0.1000,\n",
      "        0.1036, 0.0814, 0.1015, 0.0831, 0.1026, 0.1035, 0.0932, 0.1022, 0.1093,\n",
      "        0.1035, 0.0939, 0.1180, 0.0878, 0.1167, 0.1167, 0.0935, 0.1088, 0.0809,\n",
      "        0.1022, 0.1173, 0.1050, 0.1078, 0.1042, 0.1093, 0.0850, 0.0989, 0.1079,\n",
      "        0.1055, 1.1391, 0.1023, 0.1003, 0.1018, 0.1157, 0.0955, 0.0909, 0.1027,\n",
      "        0.0887, 0.1143, 0.0884, 0.1024, 0.1047, 0.0986, 0.0937, 0.0982, 0.1009,\n",
      "        0.1070, 0.1038, 0.1078, 0.0936, 0.0969, 0.1063, 0.0969, 0.1077, 0.0968,\n",
      "        0.0885, 0.0660, 0.1154, 0.1018, 0.0994, 0.0840, 0.0866, 0.1008, 0.1084,\n",
      "        0.1077, 0.1158, 0.0931, 0.0996, 0.1032, 0.0949, 0.0942, 0.1050, 0.1061,\n",
      "        0.0943, 0.1300, 0.1205, 0.1005, 0.1254, 0.1054, 0.0744, 0.1164, 0.1076,\n",
      "        0.0845, 0.1198, 0.0638, 0.1032, 0.0878, 0.1121, 0.1123, 0.1161, 0.1078,\n",
      "        0.1342, 0.0920, 0.0998, 0.1050, 0.1134, 0.1004, 0.1083, 0.0966, 0.1052,\n",
      "        0.1054, 0.0932, 0.1033, 0.0834, 0.1089, 0.0898, 0.0925, 0.1047, 0.1029,\n",
      "        0.1326, 0.1225, 0.1124, 0.0975, 0.1061, 0.1015, 0.1160, 0.1092, 0.1174,\n",
      "        0.0986, 0.1019, 0.1121, 0.1253, 0.1107, 0.0874, 0.1079, 0.0895, 0.1045,\n",
      "        0.0829, 0.0888, 0.1208, 0.0952, 0.1082, 0.0979, 0.1192, 0.1076, 0.0948,\n",
      "        0.0961, 0.1039, 0.1034, 0.0838, 0.0967, 0.1158, 0.1058, 0.1342, 0.1094,\n",
      "        0.0942, 0.0935, 0.1083, 0.0990, 0.1197, 0.1054, 0.1035, 0.1002, 0.0966,\n",
      "        0.1113, 0.1116, 0.0847, 0.0701, 0.1123, 0.0998, 0.1002, 0.1264, 0.1008,\n",
      "        0.1048, 0.0983, 0.0901, 0.0918, 0.1091, 0.1064, 0.1140, 0.1124, 0.0944,\n",
      "        0.0985, 0.1056, 0.1142, 0.1011, 0.0822, 0.0912, 0.1131, 0.1105, 0.1015,\n",
      "        0.1066, 0.1030, 0.1146, 0.1060, 0.0998, 0.0912, 0.1054, 0.1564, 0.1034,\n",
      "        0.1141, 0.1102, 0.0820, 0.1101, 0.0998, 0.0967, 0.0878, 0.1115, 0.1100,\n",
      "        0.1052, 0.0881, 0.1329, 0.0928, 0.1105, 0.1021, 0.0945, 0.0895, 0.0970,\n",
      "        0.1023, 0.0939, 0.1195, 0.1015, 0.1060, 0.0853, 0.1024, 0.0903, 0.0786,\n",
      "        0.1002, 0.1013, 0.1221, 0.0912, 0.1070, 0.1040, 0.1018, 0.1186, 0.0917,\n",
      "        0.1099, 0.1065, 0.1349, 0.1274, 0.1209, 0.0991, 0.1644, 0.1126, 0.0859,\n",
      "        0.1109, 0.1069, 0.0951, 0.0980, 0.1163, 0.1098, 0.0789, 0.1072, 0.1003,\n",
      "        0.1016, 0.1264, 0.1144, 0.0933, 0.0940, 0.0979, 0.1129, 0.0939, 0.1539,\n",
      "        0.1208, 0.0991, 0.0844, 0.0925, 0.1065, 0.0932, 0.1121, 0.0646, 0.1169,\n",
      "        0.1116, 0.1864, 0.1173, 0.1148, 0.0971, 0.0952, 0.1179, 0.0925, 0.1002,\n",
      "        0.0985, 0.1062, 0.1096, 0.0934, 0.1056, 0.0947, 0.0944, 0.1148, 0.0975,\n",
      "        0.1151, 0.1014, 0.0977, 0.1162, 0.1120, 0.1078, 0.1114, 0.1273, 0.0993,\n",
      "        0.1029, 0.0763, 0.1071, 0.0948, 0.1041, 0.1262, 0.0902, 0.0851, 0.0850,\n",
      "        0.1015, 0.1127, 0.1244, 0.1230, 0.1009, 0.0970, 0.1083, 0.1214, 0.0978,\n",
      "        0.0608, 0.1069, 0.0911, 0.1104, 0.1118, 0.0921, 0.1313, 0.0740, 0.1048,\n",
      "        0.1141, 0.1062, 0.1066, 0.1167, 0.1051, 0.1211, 0.0968, 0.1220, 0.0831,\n",
      "        0.0977, 0.1138, 0.0841, 0.1090, 0.0945, 0.0980, 0.1041, 0.0999, 0.1067,\n",
      "        0.1028, 0.1069, 0.0572, 0.1216, 0.0843, 0.1079, 0.1043, 0.0839, 0.1177,\n",
      "        0.1062, 0.0943, 0.1376, 0.0943, 0.1041, 0.0899, 0.0993, 0.0997, 0.1481,\n",
      "        0.1109, 0.1008, 0.1084, 0.0992, 0.1269, 0.1138, 0.0972, 0.1096, 0.1093,\n",
      "        0.1015, 0.0970, 0.0992, 0.0811, 0.1231, 0.0948, 0.1030, 0.0848, 0.1121,\n",
      "        0.1110, 0.1190, 0.0961, 0.0833, 0.0856, 0.0819, 0.1143, 0.0934, 0.0969,\n",
      "        0.1133, 0.1041, 0.0922, 0.0993, 0.1005, 0.1270, 0.0986, 0.1425, 0.1022,\n",
      "        0.0989, 0.0940, 0.0917, 0.1292, 0.0985, 0.0937, 0.1133, 0.1063, 0.1128,\n",
      "        0.1043, 0.1147, 0.1076, 0.0641, 0.1091, 0.1119, 0.0893, 0.2434],\n",
      "       device='cuda:0')\n",
      "tensor([0.1721, 0.1441, 0.1905, 0.0999, 0.1806, 0.1596, 0.0136, 0.1469, 0.2098,\n",
      "        0.1471, 0.1189, 0.0602, 0.1700, 0.1569, 0.1694, 0.1933, 0.1692, 0.1904,\n",
      "        0.1341, 0.1747, 0.1647, 0.1563, 0.1494, 0.1089, 0.2129, 0.2163, 0.1859,\n",
      "        0.1767, 0.1450, 0.1612, 0.1662, 0.1131, 0.2742, 0.1844, 0.1671, 0.1723,\n",
      "        0.1584, 0.1706, 0.1734, 0.1747, 0.1884, 0.1393, 0.1932, 0.1654, 0.1580,\n",
      "        0.1297, 0.1573, 0.1196, 0.1848, 0.1562, 0.1917, 0.1439, 0.1658, 0.1811,\n",
      "        0.1736, 0.1371, 0.1588, 0.1532, 0.1530, 0.1550, 0.1415, 0.1767, 0.1518,\n",
      "        0.1277, 0.1239, 0.1395, 0.1987, 0.1348, 0.1352, 0.2014, 0.1264, 0.1833,\n",
      "        0.1755, 0.1630, 0.1548, 0.1983, 0.1931, 0.1401, 0.0329, 0.1738, 0.1294,\n",
      "        0.1572, 0.1760, 0.1693, 0.1723, 0.1532, 0.1696, 0.1412, 0.1926, 0.1431,\n",
      "        0.1641, 0.1592, 0.1903, 0.1498, 0.1488, 0.1984, 0.1590, 0.1284, 0.1655,\n",
      "        0.2003, 0.1689, 0.1494, 0.1625, 0.1518, 0.1922, 0.1609, 0.1598, 0.1604,\n",
      "        0.1868, 0.1486, 0.1762, 0.1541, 0.1174, 0.2076, 0.1678, 0.1712, 0.2031,\n",
      "        0.1670, 0.1737, 0.1564, 0.1633, 0.1676, 0.1611, 0.1552, 0.1668, 0.1641,\n",
      "        0.1534, 0.2001, 0.1919, 0.2176, 0.1405, 0.1522, 0.1557, 0.1765, 0.1911,\n",
      "        0.1451, 0.0175, 0.1942, 0.1894, 0.1539, 0.1681, 0.1488, 0.1719, 0.1356,\n",
      "        0.1645, 0.1334, 0.1779, 0.1696, 0.1696, 0.1685, 0.1138, 0.1470, 0.1770,\n",
      "        0.1050, 0.1708, 0.1691, 0.1603, 0.1488, 0.1693, 0.1837, 0.1954, 0.1370,\n",
      "        0.1437, 0.0151, 0.1604, 0.1806, 0.1759, 0.1608, 0.1640, 0.1510, 0.1494,\n",
      "        0.1739, 0.1327, 0.1895, 0.1594, 0.1809, 0.1726, 0.1792, 0.1672, 0.1736,\n",
      "        0.1786, 0.1952, 0.1607, 0.1737, 0.1777, 0.1583, 0.0819, 0.1804, 0.1504,\n",
      "        0.1670, 0.1649, 0.0694, 0.1580, 0.1616, 0.1409, 0.1934, 0.1632, 0.1452,\n",
      "        0.1450, 0.1480, 0.1855, 0.1728, 0.1930, 0.1945, 0.1928, 0.1600, 0.1858,\n",
      "        0.1840, 0.1471, 0.1168, 0.1410, 0.1574, 0.1548, 0.1812, 0.1524, 0.1639,\n",
      "        0.1653, 0.1550, 0.1994, 0.1560, 0.1849, 0.1615, 0.1454, 0.1687, 0.2118,\n",
      "        0.1874, 0.1523, 0.1798, 0.1782, 0.1707, 0.1750, 0.1743, 0.1734, 0.1607,\n",
      "        0.1161, 0.1568, 0.1835, 0.1512, 0.1478, 0.1624, 0.1959, 0.1533, 0.1652,\n",
      "        0.1740, 0.1672, 0.1507, 0.1644, 0.2065, 0.1690, 0.1622, 0.1061, 0.1397,\n",
      "        0.1619, 0.1617, 0.1742, 0.1718, 0.1896, 0.1555, 0.1552, 0.1595, 0.1628,\n",
      "        0.1673, 0.1855, 0.1576, 0.1644, 0.1535, 0.1486, 0.1442, 0.2293, 0.1720,\n",
      "        0.1391, 0.1716, 0.1667, 0.1906, 0.1316, 0.1602, 0.1801, 0.1524, 0.1398,\n",
      "        0.1712, 0.1819, 0.1877, 0.1947, 0.1651, 0.1450, 0.1570, 0.1431, 0.1617,\n",
      "        0.1628, 0.1499, 0.1630, 0.1920, 0.1529, 0.1875, 0.1710, 0.1678, 0.1409,\n",
      "        0.1752, 0.1484, 0.1695, 0.1134, 0.1537, 0.1601, 0.1633, 0.1609, 0.1863,\n",
      "        0.1576, 0.1636, 0.2065, 0.1516, 0.1783, 0.1948, 0.1698, 0.1431, 0.1626,\n",
      "        0.1412, 0.1338, 0.1616, 0.1615, 0.1765, 0.1511, 0.1706, 0.1563, 0.1555,\n",
      "        0.1523, 0.1930, 0.1535, 0.1832, 0.1853, 0.1445, 0.1618, 0.1572, 0.1585,\n",
      "        0.1043, 0.1532, 0.1667, 0.1654, 0.1878, 0.1430, 0.1327, 0.1585, 0.1604,\n",
      "        0.1794, 0.1715, 0.1508, 0.1567, 0.1694, 0.1999, 0.1647, 0.1452, 0.1488,\n",
      "        0.1840, 0.1617, 0.1611, 0.1806, 0.1577, 0.1386, 0.1692, 0.1524, 0.1799,\n",
      "        0.1701, 0.1785, 0.1475, 0.1998, 0.2327, 0.1451, 0.1849, 0.0194, 0.1704,\n",
      "        0.1396, 0.0099, 0.1621, 0.1481, 0.1301, 0.1796, 0.1535, 0.1411, 0.1667,\n",
      "        0.1493, 0.1563, 0.1637, 0.1207, 0.1576, 0.1671, 0.1997, 0.1269, 0.1301,\n",
      "        0.1525, 0.1782, 0.1824, 0.1646, 0.1937, 0.1719, 0.1601, 0.1790, 0.1536,\n",
      "        0.1642, 0.1619, 0.1546, 0.1349, 0.1915, 0.1888, 0.1506, 0.1450, 0.1542,\n",
      "        0.1563, 0.1609, 0.1689, 0.1564, 0.1730, 0.1665, 0.1661, 0.0541, 0.1601,\n",
      "        0.0533, 0.1515, 0.1555, 0.1706, 0.2030, 0.1721, 0.1750, 0.0878, 0.1780,\n",
      "        0.1862, 0.2121, 0.1428, 0.1598, 0.1750, 0.1848, 0.1662, 0.1598, 0.1232,\n",
      "        0.1616, 0.1519, 0.1308, 0.1563, 0.1620, 0.1822, 0.1663, 0.1899, 0.1826,\n",
      "        0.1542, 0.1935, 0.1054, 0.1678, 0.1641, 0.2015, 0.1003, 0.1767, 0.1804,\n",
      "        0.1917, 0.1536, 0.1750, 0.1718, 0.1565, 0.1651, 0.1538, 0.1350, 0.2180,\n",
      "        0.1442, 0.1520, 0.1954, 0.1704, 0.1903, 0.1601, 0.1587, 0.1770, 0.2281,\n",
      "        0.1652, 0.1570, 0.1578, 0.1542, 0.2060, 0.1933, 0.1443, 0.1393, 0.1628,\n",
      "        0.1578, 0.2206, 0.1319, 0.1249, 0.1545, 0.1174, 0.1770, 0.1898, 0.0980,\n",
      "        0.1500, 0.1437, 0.1403, 0.1555, 0.1380, 0.1749, 0.1567, 0.1197, 0.1573,\n",
      "        0.1808, 0.1550, 0.0958, 0.1470, 0.1846, 0.1650, 0.1681, 0.1842, 0.1584,\n",
      "        0.1477, 0.1815, 0.1447, 0.1097, 0.1888, 0.1528, 0.1859, 0.1384],\n",
      "       device='cuda:0')\n",
      "tensor([[ 2.2612e+00, -5.0510e-01, -2.0163e-01,  ...,  3.6311e-01,\n",
      "          3.5611e-01,  3.3635e+00],\n",
      "        [-1.3540e+01,  8.8943e+00, -9.9648e-02,  ...,  1.1266e+01,\n",
      "          5.5487e+00,  9.2038e+01],\n",
      "        [ 9.7682e+00,  5.0630e+00, -4.2403e+00,  ..., -7.4956e+00,\n",
      "          1.2895e+01,  1.8840e+01],\n",
      "        ...,\n",
      "        [-4.5117e-01, -3.3594e-01, -3.8867e-01,  ..., -2.0996e-01,\n",
      "         -2.0000e+00, -9.1406e-01],\n",
      "        [-1.0234e+00, -8.0859e-01,  4.3555e-01,  ..., -5.9326e-02,\n",
      "         -9.2188e-01, -9.2969e-01],\n",
      "        [ 1.0078e+00,  1.5234e-01, -2.4902e-01,  ..., -1.8555e-01,\n",
      "         -2.7148e-01,  1.7969e+00]], device='cuda:0')\n",
      "tensor([[-0.0493,  0.0534, -0.1051,  ..., -0.1398, -0.0887,  0.0353],\n",
      "        [ 0.1229,  0.0755,  0.0197,  ..., -0.0324,  0.0246, -0.0932],\n",
      "        [-0.0700, -0.0450,  0.0033,  ...,  0.1464,  0.0623,  0.0349],\n",
      "        ...,\n",
      "        [-0.0399, -0.0385, -0.1130,  ...,  0.0229,  0.0999, -0.0116],\n",
      "        [ 0.0423, -0.0116, -0.0079,  ...,  0.0193, -0.0296,  0.0486],\n",
      "        [ 0.0526,  0.0088, -0.0120,  ..., -0.0601, -0.0938, -0.0714]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.1214,  0.3711,  0.3998,  ..., -0.5313,  0.4006,  0.1017],\n",
      "        [-0.4615, -1.1538, -0.0227,  ..., -1.7086, -0.2874, -1.1977],\n",
      "        [-0.1730, -0.8575, -0.2482,  ...,  0.4457, -0.3597,  0.0795],\n",
      "        ...,\n",
      "        [-0.5221, -0.2542,  0.0105,  ..., -0.4767, -0.4877, -0.1248],\n",
      "        [-0.2479,  0.1726, -0.5126,  ..., -0.0292, -0.2057,  0.3513],\n",
      "        [ 0.4006, -0.1158, -0.1345,  ..., -0.1354, -0.1884, -0.0384]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.6815,  0.3545,  0.0733,  ...,  0.3052,  0.3607, -0.0345],\n",
      "        [ 0.0545, -0.0082,  0.5568,  ...,  0.8871,  0.1873, -0.3819],\n",
      "        [-0.2876, -0.3857,  0.2526,  ..., -0.0410,  0.2370,  0.0787],\n",
      "        ...,\n",
      "        [ 0.6888, -0.6642,  0.1263,  ...,  0.2886,  0.2760,  0.0919],\n",
      "        [ 0.5249,  0.3609, -0.1208,  ..., -0.2495,  0.0263,  0.3077],\n",
      "        [-0.0891, -0.4077, -0.2639,  ...,  0.0837, -0.0125, -0.1956]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.5285, -0.2271,  0.3508,  ..., -0.1423,  0.2744,  0.6410],\n",
      "        [-0.6267, -0.0707,  0.5303,  ..., -0.1888, -0.5177,  0.2239],\n",
      "        [ 0.1855, -0.1772, -1.1100,  ..., -0.1411, -0.6805, -0.1321],\n",
      "        ...,\n",
      "        [ 0.2655, -0.7485,  0.0885,  ...,  0.1411, -0.2191, -0.2423],\n",
      "        [-0.4195,  1.0981, -0.2591,  ..., -0.2449,  0.4184, -0.5003],\n",
      "        [ 0.3686,  0.0991,  0.1656,  ...,  0.0049, -0.2815,  0.7586]],\n",
      "       device='cuda:0')\n",
      "tensor([[  5.5776,  -8.1249,   2.7229,  -9.4982,   4.6799, -17.8732],\n",
      "        [  7.5503,   8.0617,   0.7960,   3.3750,   7.4479,   5.5092],\n",
      "        [  5.8437,   6.3806,   1.1074,   3.5353,   7.3229,   5.6590],\n",
      "        [  4.8973,   5.3912,   1.0911,   3.6899,   7.0515,   5.5589],\n",
      "        [  4.2533,   4.7086,   1.1509,   3.8005,   6.7838,   5.4824],\n",
      "        [  3.8326,   4.1548,   1.1139,   3.8626,   6.5110,   5.4038],\n",
      "        [  3.5095,   3.7296,   1.1260,   3.9033,   6.2907,   5.3460],\n",
      "        [  3.2873,   3.3633,   1.1657,   3.9245,   6.0867,   5.2880],\n",
      "        [  2.7181,   2.5102,   1.0889,   3.9838,   5.6011,   5.2050],\n",
      "        [  2.2631,   1.6293,   1.1200,   3.9954,   4.9426,   5.0271],\n",
      "        [  1.8507,   0.8390,   0.9452,   4.0344,   4.3251,   4.8436],\n",
      "        [  1.4831,   0.1398,   0.7861,   4.0571,   3.5683,   4.5716],\n",
      "        [  1.1011,  -0.2766,   0.5632,   4.0870,   2.7550,   4.2748],\n",
      "        [  0.6727,  -1.0077,   0.2513,   4.1695,   1.9524,   3.7951],\n",
      "        [  0.3583,  -1.8263,   0.0890,   4.3330,   1.2904,   3.2288],\n",
      "        [ -1.4003,  -1.0013,  -1.6665,   4.2103,  -0.6896,   2.3596],\n",
      "        [  0.0801,  -0.0801,   0.3340,  -0.3594,   0.3145,  -0.2793],\n",
      "        [  3.7078,   0.1356,   8.6430,   4.2118,   1.1883, -16.8768],\n",
      "        [  3.3155,   0.2600,   7.4879,   4.4258,   1.3519,   2.5956],\n",
      "        [  3.1643,   0.3402,   6.7827,   4.5119,   1.4860,   2.6655],\n",
      "        [  3.0573,   0.3803,   6.3043,   4.5941,   1.4598,   2.6641],\n",
      "        [  2.9052,   0.2649,   5.9561,   4.6197,   1.2391,   2.6574],\n",
      "        [  2.8535,   0.3915,   5.6589,   4.6200,   1.5220,   2.6670],\n",
      "        [  2.8575,   0.3427,   5.4229,   4.6349,   1.3804,   2.6228],\n",
      "        [  2.7724,   0.4102,   4.9318,   4.6733,   1.4304,   2.5774],\n",
      "        [  2.7027,   0.3791,   4.3059,   4.6932,   1.4116,   2.4403],\n",
      "        [  2.4949,   0.3912,   3.7714,   4.6782,   1.3243,   2.3335],\n",
      "        [  2.1389,   0.3582,   3.1905,   4.6238,   1.2248,   2.2783],\n",
      "        [  1.6348,   0.3357,   2.6342,   4.5922,   1.0754,   2.1428],\n",
      "        [  0.9473,   0.2824,   2.0625,   4.5486,   0.9895,   2.0836],\n",
      "        [  0.2504,   0.2049,   1.6234,   4.4257,   0.8652,   2.2077],\n",
      "        [ -4.6472,   0.1903,   0.4338,   4.5304,   0.2526,   2.1269]],\n",
      "       device='cuda:0')\n",
      "tensor([0.0764, 0.0959, 0.0704, 0.0816, 0.0695, 0.0814, 0.0950, 0.0908, 0.0625,\n",
      "        0.1068, 0.0719, 0.0646, 0.0918, 0.0709, 0.0575, 0.0850, 0.0678, 0.0791,\n",
      "        0.0819, 0.0726, 0.0778, 0.0627, 0.1056, 0.0731, 0.0691, 0.0467, 0.0724,\n",
      "        0.0922, 0.0701, 0.0889, 0.0668, 0.0863, 0.0955, 0.0831, 0.0469, 0.0733,\n",
      "        0.0996, 0.0731, 0.0776, 0.0513, 0.0755, 0.0698, 0.0851, 0.0703, 0.0854,\n",
      "        0.1117, 0.0899, 0.0716, 0.0710, 0.0500, 0.0496, 0.0787, 0.0810, 0.0834,\n",
      "        0.0879, 0.0551, 0.0532, 0.0869, 0.0657, 0.0731, 0.0500, 0.0741, 0.0896,\n",
      "        0.0694, 0.0718, 0.0825, 0.0651, 0.0411, 0.0957, 0.0817, 0.0747, 0.0689,\n",
      "        0.0554, 0.0835, 0.0941, 0.0690, 0.0715, 0.0620, 0.0420, 0.0573, 0.0881,\n",
      "        0.0682, 0.0772, 0.0903, 0.0625, 0.0742, 0.0522, 0.0882, 0.0749, 0.0885,\n",
      "        0.0606, 0.0490, 0.0901, 0.0764, 0.0723, 0.0683, 0.0669, 0.0717, 0.0855,\n",
      "        0.0640, 0.0638, 0.0859, 0.0638, 0.0473, 0.0772, 0.0792, 0.0505, 0.0743,\n",
      "        0.0546, 0.0814, 0.0574, 0.0904, 0.0913, 0.0592, 0.0552, 0.0779, 0.0459,\n",
      "        0.0671, 0.0878, 0.0695, 0.0737, 0.1071, 0.0764, 0.0647, 0.0665, 0.0730,\n",
      "        0.0898, 0.0850, 0.0638, 0.0679, 0.0753, 0.0867, 0.0769, 0.0778, 0.0712,\n",
      "        0.0660, 0.1299, 0.0516, 0.0559, 0.0773, 0.0657, 0.0989, 0.0870, 0.0907,\n",
      "        0.0645, 0.0640, 0.0572, 0.0813, 0.0832, 0.0653, 0.1008, 0.0657, 0.0825,\n",
      "        0.0723, 0.0658, 0.0934, 0.0837, 0.1080, 0.0880, 0.0881, 0.0675, 0.0844,\n",
      "        0.0850, 0.0266, 0.0646, 0.0921, 0.0464, 0.0791, 0.0657, 0.0998, 0.0512,\n",
      "        0.0699, 0.0739, 0.0513, 0.0899, 0.0840, 0.0715, 0.0487, 0.0847, 0.0658,\n",
      "        0.0933, 0.0574, 0.0867, 0.0693, 0.0927, 0.0780, 0.0779, 0.0947, 0.0904,\n",
      "        0.0755, 0.0652, 0.0822, 0.0717, 0.1149, 0.0714, 0.0574, 0.0943, 0.0792,\n",
      "        0.0810, 0.0703, 0.0595, 0.0867, 0.0726, 0.1000, 0.0296, 0.0757, 0.0767,\n",
      "        0.0729, 0.0805, 0.0781, 0.1009, 0.0733, 0.0816, 0.0602, 0.0598, 0.0689,\n",
      "        0.0786, 0.0620, 0.0914, 0.1317, 0.0843, 0.0503, 0.0758, 0.0766, 0.0758,\n",
      "        0.0650, 0.0748, 0.0554, 0.0732, 0.0855, 0.0447, 0.0726, 0.0623, 0.0747,\n",
      "        0.0858, 0.0609, 0.0814, 0.0675, 0.1062, 0.0783, 0.0671, 0.0591, 0.0696,\n",
      "        0.0725, 0.0865, 0.0701, 0.0857, 0.0784, 0.0668, 0.0526, 0.0692, 0.0773,\n",
      "        0.0804, 0.0678, 0.0729, 0.0553, 0.0783, 0.0768, 0.0682, 0.0912, 0.0664,\n",
      "        0.0587, 0.0782, 0.0634, 0.1187, 0.0748, 0.0688, 0.0790, 0.0541, 0.0630,\n",
      "        0.0712, 0.0764, 0.0591, 0.0759, 0.0743, 0.0594, 0.0828, 0.0683, 0.0626,\n",
      "        0.0927, 0.0553, 0.0701, 0.0739, 0.0957, 0.0570, 0.0748, 0.0759, 0.0621,\n",
      "        0.0936, 0.0674, 0.0678, 0.0579, 0.0681, 0.0693, 0.0745, 0.0648, 0.0611,\n",
      "        0.0426, 0.0959, 0.0520, 0.1195, 0.0842, 0.0832, 0.0960, 0.0618, 0.1058,\n",
      "        0.1101, 0.0584, 0.0451, 0.0611, 0.0674, 0.0856, 0.0768, 0.0762, 0.0797,\n",
      "        0.0791, 0.0776, 0.0698, 0.1089, 0.0575, 0.1089, 0.0793, 0.0568, 0.1157,\n",
      "        0.0597, 0.0598, 0.0708, 0.0686, 0.0818, 0.0729, 0.0812, 0.0702, 0.0774,\n",
      "        0.0357, 0.0744, 0.0503, 0.0574, 0.0726, 0.0657, 0.0420, 0.0595, 0.0637,\n",
      "        0.0693, 0.0797, 0.0750, 0.0760, 0.0974, 0.0800, 0.0706, 0.0717, 0.0681,\n",
      "        0.0891, 0.0617, 0.0737, 0.0822, 0.0722, 0.0934, 0.0834, 0.0955, 0.0669,\n",
      "        0.0605, 0.0683, 0.0828, 0.0621, 0.0405, 0.0968, 0.0830, 0.0203, 0.0772,\n",
      "        0.0875, 0.0910, 0.0924, 0.1121, 0.0926, 0.0711, 0.0651, 0.0938, 0.0754,\n",
      "        0.0724, 0.0568, 0.0793, 0.0574, 0.0724, 0.0602, 0.0738, 0.0705, 0.1124,\n",
      "        0.0798, 0.0868, 0.0608, 0.0712, 0.0745, 0.0748, 0.0701, 0.0977, 0.0795,\n",
      "        0.0731, 0.0716, 0.0639, 0.0795, 0.0671, 0.0478, 0.0904, 0.0619, 0.0874,\n",
      "        0.0878, 0.0775, 0.0949, 0.0926, 0.0658, 0.0571, 0.0686, 0.0630, 0.0719,\n",
      "        0.0368, 0.0910, 0.0749, 0.0706, 0.0538, 0.0854, 0.0849, 0.0945, 0.0773,\n",
      "        0.0615, 0.0522, 0.0674, 0.0900, 0.0942, 0.0603, 0.0595, 0.0543, 0.0583,\n",
      "        0.0924, 0.0781, 0.0791, 0.0906, 0.0805, 0.0760, 0.0645, 0.0885, 0.0723,\n",
      "        0.0674, 0.0596, 0.0705, 0.0872, 0.0802, 0.0540, 0.0659, 0.0982, 0.0643,\n",
      "        0.0491, 0.0831, 0.0524, 0.0778, 0.1201, 0.0602, 0.0473, 0.0612, 0.0729,\n",
      "        0.0496, 0.0786, 0.0738, 0.0517, 0.0489, 0.0623, 0.0896, 0.0526, 0.0662,\n",
      "        0.0712, 0.0758, 0.0707, 0.0567, 0.0761, 0.0638, 0.0601, 0.1277, 0.0752,\n",
      "        0.0747, 0.0470, 0.0599, 0.0781, 0.0757, 0.0812, 0.0819, 0.0600, 0.0811,\n",
      "        0.1232, 0.0872, 0.0856, 0.0767, 0.0678, 0.0638, 0.0806, 0.1143, 0.0865,\n",
      "        0.0667, 0.0844, 0.1068, 0.0875, 0.1041, 0.0940, 0.1054, 0.0786, 0.0852,\n",
      "        0.0828, 0.0722, 0.0774, 0.0716, 0.0628, 0.0883, 0.0733, 0.0801],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.1846,  0.3553,  0.5900,  ..., -0.6015, -0.2695,  1.0131],\n",
      "        [ 0.1427, -0.0815, -0.1324,  ..., -1.0396, -0.6772, -0.0527],\n",
      "        [-0.5231,  0.7268, -0.7714,  ..., -0.6788, -0.1336, -0.3207],\n",
      "        ...,\n",
      "        [-0.8820, -0.9675, -0.7987,  ...,  0.3789, -0.0509,  0.0197],\n",
      "        [-0.0727, -0.0315,  0.1915,  ..., -0.8397, -0.0991, -0.3796],\n",
      "        [-0.4126,  0.1416, -0.1267,  ..., -0.2779,  0.1718, -0.4618]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.2374, -0.5630,  0.0295,  ..., -0.1794, -0.4412, -0.1442],\n",
      "        [ 0.2851, -0.5254,  1.2082,  ..., -0.8107,  0.6477,  0.2349],\n",
      "        [-0.0131,  1.1826,  0.4733,  ...,  0.7623,  0.0634, -0.1726],\n",
      "        ...,\n",
      "        [ 0.0565,  0.0136,  0.4396,  ...,  0.3037,  0.3982,  0.0300],\n",
      "        [-0.8522, -0.3149, -0.6661,  ...,  0.6002, -1.1455,  0.1406],\n",
      "        [ 0.2759,  0.5508, -0.0333,  ...,  0.8811,  0.2520, -0.1671]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.0185, -0.0464,  0.3224,  ...,  0.3179,  0.2030, -0.2200],\n",
      "        [-0.1038,  0.4048,  0.0135,  ..., -0.2878,  0.2290,  0.1097],\n",
      "        [ 0.3239, -0.1601, -0.3362,  ..., -0.1218, -0.0180, -0.2413],\n",
      "        ...,\n",
      "        [ 0.0127, -0.2036, -0.1194,  ...,  0.0106, -0.1467, -0.0152],\n",
      "        [ 0.2901, -0.0237,  0.4537,  ...,  0.1465,  0.2965,  0.4006],\n",
      "        [ 1.1295,  0.1024, -0.3608,  ..., -0.2687,  0.2773,  0.1581]],\n",
      "       device='cuda:0')\n",
      "tensor([0.1152, 0.1124, 0.0594, 0.0815, 0.0789, 0.0780, 0.1236, 0.1037, 0.0675,\n",
      "        0.0781, 0.0823, 0.0458, 0.0692, 0.0802, 0.0687, 0.0978, 0.0917, 0.0595,\n",
      "        0.0758, 0.0679, 0.0972, 0.0750, 0.1022, 0.0955, 0.0739, 0.0667, 0.0625,\n",
      "        0.0823, 0.0644, 0.0649, 0.0940, 0.1217, 0.1302, 0.0732, 0.0669, 0.0742,\n",
      "        0.0850, 0.0624, 0.0772, 0.0635, 0.0966, 0.0786, 0.0893, 0.0550, 0.0862,\n",
      "        0.0868, 0.1043, 0.0703, 0.0615, 0.0682, 0.0706, 0.1003, 0.0721, 0.0775,\n",
      "        0.0707, 0.0573, 0.0914, 0.0911, 0.0786, 0.0897, 0.0700, 0.0726, 0.0995,\n",
      "        0.0997, 0.1381, 0.0911, 0.0712, 0.0625, 0.0800, 0.0758, 0.1057, 0.0732,\n",
      "        0.1076, 0.0725, 0.1096, 0.1084, 0.0509, 0.0821, 0.0260, 0.0620, 0.0837,\n",
      "        0.0759, 0.0969, 0.0813, 0.0501, 0.0757, 0.0896, 0.0780, 0.0639, 0.1071,\n",
      "        0.0631, 0.0601, 0.1120, 0.0903, 0.0802, 0.0974, 0.0799, 0.0894, 0.0589,\n",
      "        0.0763, 0.0767, 0.0652, 0.0782, 0.0636, 0.0783, 0.0670, 0.0815, 0.0681,\n",
      "        0.0663, 0.0820, 0.0527, 0.0848, 0.1375, 0.0655, 0.0547, 0.0718, 0.0477,\n",
      "        0.0800, 0.0712, 0.0779, 0.0649, 0.0900, 0.0819, 0.0728, 0.0694, 0.0627,\n",
      "        0.0824, 0.0847, 0.0727, 0.0581, 0.1023, 0.0917, 0.0798, 0.0828, 0.0642,\n",
      "        0.0791, 0.1766, 0.0598, 0.0775, 0.1092, 0.0656, 0.0976, 0.0785, 0.0772,\n",
      "        0.0767, 0.0558, 0.0817, 0.0766, 0.0848, 0.0578, 0.0997, 0.0853, 0.0743,\n",
      "        0.0771, 0.0714, 0.0868, 0.0825, 0.1107, 0.1063, 0.0901, 0.0802, 0.0960,\n",
      "        0.1076, 0.0202, 0.0681, 0.0824, 0.0672, 0.0985, 0.0755, 0.1193, 0.0804,\n",
      "        0.0936, 0.0763, 0.0620, 0.1176, 0.0698, 0.0936, 0.0608, 0.1021, 0.1128,\n",
      "        0.0777, 0.0510, 0.0923, 0.0762, 0.0850, 0.0872, 0.0790, 0.0787, 0.0880,\n",
      "        0.0885, 0.0660, 0.1037, 0.0972, 0.1180, 0.0628, 0.0551, 0.0872, 0.0791,\n",
      "        0.1009, 0.0836, 0.0877, 0.0827, 0.0813, 0.0835, 0.0813, 0.0973, 0.0819,\n",
      "        0.0668, 0.0898, 0.0926, 0.0994, 0.0768, 0.0865, 0.0741, 0.0842, 0.0871,\n",
      "        0.0832, 0.0812, 0.0698, 0.0821, 0.0850, 0.0403, 0.0732, 0.0841, 0.0630,\n",
      "        0.0913, 0.0775, 0.0849, 0.0630, 0.0826, 0.0684, 0.0604, 0.0764, 0.0810,\n",
      "        0.0853, 0.0763, 0.0855, 0.0962, 0.1090, 0.0749, 0.0436, 0.0629, 0.0701,\n",
      "        0.0755, 0.0809, 0.0878, 0.0845, 0.0856, 0.0778, 0.0763, 0.0944, 0.0785,\n",
      "        0.0631, 0.0563, 0.0533, 0.0753, 0.0807, 0.0880, 0.0878, 0.0734, 0.0779,\n",
      "        0.0548, 0.0727, 0.0903, 0.1091, 0.0815, 0.0878, 0.0900, 0.0810, 0.0703,\n",
      "        0.0792, 0.0713, 0.0694, 0.0780, 0.0470, 0.0720, 0.0756, 0.0594, 0.0834,\n",
      "        0.0756, 0.0694, 0.0823, 0.0642, 0.0939, 0.0747, 0.0703, 0.0950, 0.0600,\n",
      "        0.1005, 0.0844, 0.0582, 0.0502, 0.0932, 0.0820, 0.0720, 0.0740, 0.0719,\n",
      "        0.0534, 0.1155, 0.0737, 0.1003, 0.0802, 0.0700, 0.1086, 0.0757, 0.1224,\n",
      "        0.0964, 0.0643, 0.0433, 0.0552, 0.0694, 0.0930, 0.1155, 0.0874, 0.0766,\n",
      "        0.0957, 0.0780, 0.0840, 0.1132, 0.0755, 0.0859, 0.0812, 0.0538, 0.1067,\n",
      "        0.0719, 0.0634, 0.0877, 0.0832, 0.0721, 0.0729, 0.0802, 0.0701, 0.1048,\n",
      "        0.0312, 0.0958, 0.0710, 0.0740, 0.0997, 0.0703, 0.0989, 0.0682, 0.0500,\n",
      "        0.0698, 0.0798, 0.0734, 0.0912, 0.0951, 0.0771, 0.0710, 0.0663, 0.0885,\n",
      "        0.0865, 0.1077, 0.0777, 0.0661, 0.0618, 0.0615, 0.0817, 0.1069, 0.0770,\n",
      "        0.0875, 0.1044, 0.0760, 0.0801, 0.0692, 0.0857, 0.0800, 0.0171, 0.0827,\n",
      "        0.0894, 0.1322, 0.0717, 0.1132, 0.0925, 0.0896, 0.0678, 0.1110, 0.0676,\n",
      "        0.0652, 0.0731, 0.0804, 0.0783, 0.0756, 0.0702, 0.0759, 0.0699, 0.1133,\n",
      "        0.1089, 0.0697, 0.0616, 0.0710, 0.0552, 0.0933, 0.0884, 0.0967, 0.0797,\n",
      "        0.0868, 0.0811, 0.0788, 0.0812, 0.0535, 0.0721, 0.0667, 0.0732, 0.0769,\n",
      "        0.0873, 0.0995, 0.0641, 0.1033, 0.0803, 0.0822, 0.0718, 0.0498, 0.0513,\n",
      "        0.0174, 0.0921, 0.0565, 0.0978, 0.0631, 0.1113, 0.0727, 0.0939, 0.0881,\n",
      "        0.0586, 0.0525, 0.0777, 0.0744, 0.0732, 0.0866, 0.0700, 0.0597, 0.0656,\n",
      "        0.0737, 0.0748, 0.0813, 0.0828, 0.1040, 0.0913, 0.0799, 0.0657, 0.0551,\n",
      "        0.0496, 0.0522, 0.0621, 0.0692, 0.0783, 0.0666, 0.1021, 0.0858, 0.0725,\n",
      "        0.0770, 0.0701, 0.0865, 0.0642, 0.1098, 0.0758, 0.0740, 0.0762, 0.0821,\n",
      "        0.0608, 0.0994, 0.0964, 0.0615, 0.0617, 0.0737, 0.0753, 0.0694, 0.0444,\n",
      "        0.0711, 0.0871, 0.0773, 0.0917, 0.0842, 0.0823, 0.0802, 0.1044, 0.0797,\n",
      "        0.0852, 0.0546, 0.0789, 0.0704, 0.0853, 0.0840, 0.0720, 0.0829, 0.0770,\n",
      "        0.1137, 0.0652, 0.1176, 0.1067, 0.0721, 0.0711, 0.0721, 0.0855, 0.0777,\n",
      "        0.0666, 0.0717, 0.0871, 0.0994, 0.0966, 0.0878, 0.1084, 0.0795, 0.0890,\n",
      "        0.1048, 0.0620, 0.0671, 0.0865, 0.0769, 0.0729, 0.0656, 0.1497],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.0080, -0.0118, -0.0374,  ...,  0.0348, -0.0957, -0.1464],\n",
      "        [ 0.0801, -0.0598, -0.0102,  ...,  0.0564,  0.0074, -0.0965],\n",
      "        [-0.0410,  0.0648, -0.0442,  ...,  0.0754, -0.0156, -0.0591],\n",
      "        ...,\n",
      "        [-0.0232, -0.1285, -0.0215,  ...,  0.0317, -0.0255,  0.0491],\n",
      "        [ 0.0530,  0.0463,  0.0095,  ..., -0.0399,  0.0276,  0.0600],\n",
      "        [ 0.0754,  0.0295,  0.0847,  ...,  0.0560,  0.0387, -0.0144]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.7610, -0.3105,  0.0487,  ..., -0.4835,  0.5493,  0.0351],\n",
      "        [ 1.0585, -0.4401,  0.0190,  ..., -0.9755,  0.0736, -0.5548],\n",
      "        [ 0.2146, -0.3699,  0.2727,  ...,  0.5698, -0.3936,  0.1029],\n",
      "        ...,\n",
      "        [ 0.2598,  0.0576, -0.2801,  ...,  0.2890,  0.1033,  0.0564],\n",
      "        [ 0.1750, -0.0207, -0.4801,  ...,  0.1891, -0.2669,  0.3570],\n",
      "        [-0.2218,  0.2913,  0.5566,  ...,  0.5165,  0.6422, -0.1373]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.6565, -0.2581,  0.1172,  ..., -0.0215,  0.0732, -0.0148],\n",
      "        [-0.2115, -0.1879,  0.9467,  ...,  0.8699, -0.2498,  0.0194],\n",
      "        [-0.4438, -0.0423,  0.2954,  ...,  0.5473,  0.4547,  0.1183],\n",
      "        ...,\n",
      "        [ 0.2413,  0.0429,  0.2084,  ...,  0.1228,  0.3304, -0.1546],\n",
      "        [-0.0650, -0.5535,  0.5147,  ...,  0.2441, -0.0129, -0.1619],\n",
      "        [-0.0444, -0.4502, -0.4436,  ..., -0.1679, -0.2420,  0.0321]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.3374,  0.0292,  0.3241,  ..., -0.1699,  0.7273,  0.2039],\n",
      "        [ 0.6613,  0.2477, -0.1792,  ..., -0.3703, -0.9126,  0.6648],\n",
      "        [ 0.3322, -0.3176, -0.1070,  ...,  0.0438,  0.1599,  0.0343],\n",
      "        ...,\n",
      "        [-0.2865,  0.1915,  0.5491,  ...,  1.1488, -0.7904, -0.1795],\n",
      "        [ 1.0267,  0.9218,  0.5924,  ..., -0.2771,  0.2634,  0.0475],\n",
      "        [ 0.4272, -0.1243, -0.1359,  ..., -0.0415, -0.1181,  0.3854]],\n",
      "       device='cuda:0')\n",
      "tensor([0.1061, 0.1053, 0.0968, 0.1159, 0.1018, 0.1081, 0.0610, 0.0997, 0.0890,\n",
      "        0.1508, 0.1218, 0.0287, 0.1156, 0.1241, 0.1053, 0.1462, 0.0976, 0.1001,\n",
      "        0.1355, 0.0926, 0.1012, 0.0887, 0.1357, 0.0853, 0.0863, 0.0531, 0.0898,\n",
      "        0.1042, 0.1400, 0.1121, 0.1304, 0.1354, 0.1059, 0.1068, 0.1128, 0.1058,\n",
      "        0.1384, 0.0943, 0.1179, 0.1023, 0.0878, 0.0988, 0.1472, 0.0750, 0.0746,\n",
      "        0.1265, 0.1092, 0.0991, 0.1053, 0.1026, 0.0988, 0.1166, 0.1043, 0.1048,\n",
      "        0.1215, 0.1238, 0.0882, 0.1228, 0.1036, 0.0945, 0.0770, 0.1238, 0.1257,\n",
      "        0.1239, 0.1563, 0.1411, 0.0856, 0.0955, 0.1183, 0.1003, 0.1386, 0.0792,\n",
      "        0.1013, 0.1160, 0.1184, 0.1025, 0.1089, 0.1358, 0.0152, 0.0872, 0.1352,\n",
      "        0.1058, 0.1230, 0.1096, 0.0807, 0.1311, 0.1001, 0.1211, 0.0822, 0.1203,\n",
      "        0.0946, 0.0916, 0.1325, 0.1286, 0.1160, 0.1058, 0.0932, 0.1160, 0.0963,\n",
      "        0.0860, 0.0970, 0.1057, 0.1020, 0.1229, 0.0982, 0.1093, 0.0790, 0.1108,\n",
      "        0.0599, 0.0910, 0.0919, 0.1128, 0.1152, 0.1010, 0.0971, 0.0944, 0.0786,\n",
      "        0.0924, 0.1123, 0.1129, 0.0941, 0.1447, 0.1093, 0.1263, 0.0925, 0.1186,\n",
      "        0.1176, 0.1136, 0.0914, 0.0820, 0.1107, 0.1167, 0.1024, 0.0879, 0.0892,\n",
      "        0.1120, 0.0860, 0.0831, 0.0849, 0.1232, 0.0830, 0.1306, 0.1073, 0.0936,\n",
      "        0.1116, 0.1063, 0.0952, 0.0903, 0.1129, 0.0923, 0.1105, 0.1119, 0.1010,\n",
      "        0.1285, 0.1076, 0.1173, 0.1261, 0.1751, 0.1112, 0.1096, 0.1170, 0.1320,\n",
      "        0.1175, 0.0361, 0.1107, 0.1268, 0.0945, 0.1054, 0.0915, 0.1329, 0.0851,\n",
      "        0.1003, 0.0988, 0.1089, 0.1161, 0.0982, 0.1222, 0.0900, 0.1116, 0.1316,\n",
      "        0.0898, 0.1054, 0.1230, 0.1077, 0.1265, 0.0983, 0.1272, 0.1584, 0.0874,\n",
      "        0.1033, 0.1047, 0.1094, 0.1012, 0.1424, 0.1192, 0.1066, 0.0983, 0.1186,\n",
      "        0.1010, 0.1256, 0.0947, 0.1011, 0.0973, 0.0972, 0.0596, 0.1033, 0.1212,\n",
      "        0.0893, 0.1124, 0.1366, 0.1321, 0.1005, 0.0979, 0.0799, 0.1014, 0.1101,\n",
      "        0.1078, 0.1268, 0.0948, 0.1505, 0.0888, 0.0727, 0.1058, 0.1068, 0.0861,\n",
      "        0.0685, 0.1238, 0.1135, 0.1262, 0.1300, 0.1000, 0.1084, 0.1167, 0.0960,\n",
      "        0.1412, 0.1042, 0.1239, 0.0854, 0.1418, 0.1075, 0.0862, 0.0933, 0.1180,\n",
      "        0.0870, 0.1108, 0.1046, 0.1333, 0.0931, 0.0820, 0.1089, 0.0753, 0.1047,\n",
      "        0.0881, 0.0902, 0.0909, 0.0895, 0.0988, 0.1033, 0.1219, 0.1230, 0.1176,\n",
      "        0.0815, 0.1007, 0.0845, 0.1206, 0.1412, 0.0998, 0.1035, 0.0802, 0.0740,\n",
      "        0.1213, 0.0904, 0.0980, 0.1049, 0.0896, 0.0969, 0.0999, 0.1040, 0.1264,\n",
      "        0.1288, 0.1104, 0.1248, 0.0977, 0.1493, 0.1274, 0.0804, 0.1187, 0.0877,\n",
      "        0.1602, 0.1075, 0.1175, 0.0974, 0.1290, 0.0893, 0.1080, 0.0602, 0.1040,\n",
      "        0.0786, 0.1228, 0.1249, 0.1299, 0.1071, 0.1039, 0.1376, 0.1024, 0.1623,\n",
      "        0.1154, 0.0827, 0.0484, 0.0815, 0.1247, 0.1365, 0.1273, 0.1129, 0.1294,\n",
      "        0.1325, 0.1234, 0.1194, 0.1424, 0.1129, 0.1349, 0.0896, 0.0904, 0.1208,\n",
      "        0.0635, 0.0778, 0.1122, 0.0963, 0.1116, 0.1132, 0.1117, 0.1244, 0.1202,\n",
      "        0.0297, 0.1210, 0.0779, 0.1094, 0.1151, 0.0826, 0.0931, 0.1098, 0.0939,\n",
      "        0.0931, 0.0911, 0.1013, 0.1280, 0.1319, 0.0898, 0.1085, 0.0889, 0.1275,\n",
      "        0.1219, 0.0891, 0.0940, 0.1381, 0.1105, 0.1295, 0.1240, 0.1286, 0.0921,\n",
      "        0.1298, 0.1112, 0.1205, 0.0969, 0.0801, 0.1404, 0.1059, 0.0237, 0.1522,\n",
      "        0.1245, 0.1527, 0.1039, 0.1630, 0.1214, 0.1119, 0.0967, 0.1172, 0.0876,\n",
      "        0.0963, 0.1080, 0.1446, 0.0963, 0.1218, 0.0868, 0.1029, 0.1105, 0.1528,\n",
      "        0.1523, 0.1063, 0.1260, 0.1100, 0.1047, 0.1087, 0.1177, 0.1533, 0.1187,\n",
      "        0.1028, 0.1424, 0.0958, 0.1112, 0.0977, 0.0996, 0.1345, 0.1091, 0.1050,\n",
      "        0.1181, 0.1480, 0.0996, 0.1141, 0.1325, 0.1172, 0.0866, 0.0532, 0.1138,\n",
      "        0.0331, 0.0962, 0.1353, 0.1244, 0.1074, 0.1327, 0.1318, 0.1405, 0.1328,\n",
      "        0.0753, 0.0830, 0.0852, 0.1244, 0.0889, 0.0699, 0.0913, 0.0751, 0.1233,\n",
      "        0.0926, 0.1290, 0.1201, 0.1121, 0.1000, 0.1137, 0.1325, 0.0869, 0.1015,\n",
      "        0.0848, 0.0922, 0.1078, 0.1144, 0.1238, 0.0710, 0.1680, 0.1088, 0.0671,\n",
      "        0.0863, 0.1266, 0.0844, 0.0944, 0.1293, 0.0880, 0.1022, 0.1110, 0.0562,\n",
      "        0.0821, 0.1413, 0.1281, 0.0978, 0.0651, 0.0985, 0.1156, 0.1125, 0.1010,\n",
      "        0.1355, 0.1292, 0.1123, 0.0916, 0.1029, 0.1016, 0.0861, 0.1280, 0.1036,\n",
      "        0.1133, 0.0782, 0.1177, 0.1201, 0.1048, 0.1237, 0.1290, 0.1050, 0.1296,\n",
      "        0.1237, 0.1070, 0.1068, 0.1063, 0.0994, 0.1003, 0.1225, 0.1469, 0.1052,\n",
      "        0.1163, 0.1427, 0.1393, 0.1164, 0.1376, 0.0953, 0.1334, 0.1230, 0.1222,\n",
      "        0.1114, 0.1012, 0.1479, 0.1034, 0.0821, 0.1216, 0.1370, 0.1015],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.3190,  0.0101,  0.5946,  ...,  0.2101, -0.1477, -1.1157],\n",
      "        [ 0.0802,  0.3940,  0.1736,  ..., -0.2013,  1.2639, -0.5759],\n",
      "        [-0.6397, -0.6911, -0.3815,  ...,  0.1498, -0.5134,  0.1398],\n",
      "        ...,\n",
      "        [-0.3965, -0.2569, -0.8307,  ..., -0.3042, -0.5705,  0.2481],\n",
      "        [ 0.6111,  0.4536,  0.7674,  ...,  0.8558, -0.2537,  0.7436],\n",
      "        [ 0.1389, -0.0778, -0.2091,  ...,  0.1611, -0.5820, -0.0966]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.1752,  0.8139,  0.2041,  ...,  0.2203, -0.0745,  0.8627],\n",
      "        [-0.1825, -0.3293, -0.8210,  ..., -0.3825, -0.9451, -0.3357],\n",
      "        [ 0.1740, -0.6272,  0.1835,  ...,  0.1341,  1.0548,  0.9803],\n",
      "        ...,\n",
      "        [-0.6867, -0.4582, -0.2151,  ...,  0.6930, -0.2903,  0.3167],\n",
      "        [-0.0421, -0.1092,  0.6693,  ..., -0.7386,  1.1359,  0.6278],\n",
      "        [-0.0759, -0.3351,  0.0052,  ..., -0.1278,  0.6655, -0.2201]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.0145, -0.4719,  0.3851,  ...,  0.3847, -0.6722,  0.3994],\n",
      "        [-0.3469, -0.1041,  0.4074,  ..., -0.0785, -0.2434,  0.0806],\n",
      "        [ 0.4511, -0.0171, -0.2346,  ...,  0.2481,  0.1885,  0.0403],\n",
      "        ...,\n",
      "        [ 0.2902, -0.3574,  0.4657,  ...,  0.0255,  0.0261, -0.4115],\n",
      "        [ 0.1029, -0.4415,  0.4549,  ..., -0.1438, -0.5457, -0.3642],\n",
      "        [ 0.1951,  0.1016, -0.0596,  ..., -0.0496, -0.2157, -0.1095]],\n",
      "       device='cuda:0')\n",
      "tensor([0.1523, 0.1244, 0.0868, 0.0928, 0.1095, 0.0970, 0.1215, 0.0957, 0.0984,\n",
      "        0.1247, 0.0877, 0.0328, 0.1039, 0.0946, 0.0905, 0.1312, 0.1305, 0.0775,\n",
      "        0.1047, 0.0931, 0.0922, 0.0861, 0.0931, 0.1040, 0.0913, 0.0614, 0.0606,\n",
      "        0.0991, 0.1099, 0.1139, 0.1044, 0.1204, 0.1860, 0.0945, 0.0839, 0.0978,\n",
      "        0.1068, 0.0911, 0.1023, 0.1006, 0.1079, 0.0931, 0.1223, 0.0562, 0.0920,\n",
      "        0.0957, 0.1059, 0.1031, 0.0751, 0.0786, 0.0793, 0.0861, 0.0797, 0.1087,\n",
      "        0.1303, 0.1036, 0.1010, 0.1347, 0.1036, 0.0884, 0.0863, 0.1019, 0.1183,\n",
      "        0.0970, 0.1346, 0.1040, 0.0820, 0.0781, 0.1187, 0.1164, 0.1159, 0.0796,\n",
      "        0.1230, 0.1059, 0.0868, 0.1070, 0.0687, 0.1145, 0.0252, 0.0872, 0.1206,\n",
      "        0.0806, 0.0919, 0.1101, 0.0921, 0.1062, 0.0933, 0.1047, 0.1088, 0.1222,\n",
      "        0.0833, 0.0886, 0.1097, 0.0899, 0.0962, 0.0974, 0.1230, 0.1131, 0.0953,\n",
      "        0.0927, 0.0892, 0.1112, 0.0819, 0.0828, 0.0816, 0.1035, 0.1014, 0.0902,\n",
      "        0.0697, 0.1115, 0.0772, 0.0890, 0.1210, 0.0863, 0.0867, 0.0704, 0.0628,\n",
      "        0.0984, 0.0773, 0.1082, 0.0869, 0.1253, 0.1309, 0.0906, 0.1038, 0.0998,\n",
      "        0.1052, 0.1023, 0.0820, 0.0848, 0.1070, 0.0986, 0.0986, 0.0839, 0.0819,\n",
      "        0.0884, 0.3462, 0.0809, 0.0928, 0.1084, 0.0969, 0.1408, 0.0825, 0.1232,\n",
      "        0.0913, 0.1067, 0.0822, 0.1166, 0.1080, 0.0729, 0.1046, 0.1016, 0.1125,\n",
      "        0.1105, 0.1128, 0.0776, 0.1034, 0.1236, 0.0894, 0.1050, 0.0942, 0.0987,\n",
      "        0.1149, 0.0219, 0.0920, 0.0982, 0.0784, 0.1066, 0.0792, 0.1050, 0.1221,\n",
      "        0.0908, 0.0701, 0.0967, 0.1291, 0.0781, 0.1150, 0.0679, 0.1051, 0.1095,\n",
      "        0.1170, 0.0760, 0.1331, 0.0681, 0.0874, 0.1007, 0.1244, 0.1131, 0.1084,\n",
      "        0.0882, 0.0681, 0.1190, 0.0840, 0.1215, 0.1320, 0.0650, 0.1018, 0.0826,\n",
      "        0.1088, 0.1108, 0.0816, 0.1110, 0.0975, 0.0970, 0.1028, 0.0958, 0.0818,\n",
      "        0.0847, 0.0997, 0.0936, 0.1244, 0.1066, 0.1214, 0.0901, 0.0948, 0.1450,\n",
      "        0.1092, 0.1328, 0.1024, 0.1118, 0.0696, 0.0620, 0.0826, 0.1025, 0.0919,\n",
      "        0.0800, 0.0857, 0.0946, 0.0971, 0.1319, 0.0615, 0.0927, 0.0664, 0.0904,\n",
      "        0.1032, 0.0789, 0.1013, 0.1440, 0.0967, 0.1027, 0.0876, 0.0910, 0.0846,\n",
      "        0.0959, 0.0913, 0.0871, 0.1010, 0.0980, 0.0811, 0.0951, 0.0673, 0.1107,\n",
      "        0.1041, 0.0681, 0.0690, 0.1034, 0.0953, 0.1127, 0.0974, 0.1294, 0.0954,\n",
      "        0.0722, 0.0848, 0.1212, 0.0979, 0.1152, 0.1096, 0.1204, 0.0786, 0.0806,\n",
      "        0.1124, 0.1036, 0.0856, 0.0904, 0.0910, 0.0943, 0.1084, 0.0855, 0.0984,\n",
      "        0.0919, 0.0956, 0.0722, 0.0737, 0.1423, 0.1108, 0.0968, 0.0882, 0.0982,\n",
      "        0.0982, 0.0942, 0.1007, 0.0903, 0.1042, 0.0675, 0.0689, 0.0625, 0.1001,\n",
      "        0.0596, 0.1082, 0.0990, 0.1323, 0.0976, 0.1116, 0.1085, 0.1086, 0.1141,\n",
      "        0.1102, 0.0771, 0.0756, 0.0917, 0.1165, 0.0995, 0.1268, 0.0968, 0.1068,\n",
      "        0.1363, 0.0946, 0.0910, 0.1189, 0.0749, 0.1193, 0.0928, 0.1158, 0.1337,\n",
      "        0.1034, 0.0858, 0.1227, 0.0912, 0.0856, 0.1037, 0.0805, 0.1303, 0.1202,\n",
      "        0.0521, 0.0828, 0.0795, 0.0813, 0.1225, 0.0764, 0.1299, 0.0985, 0.0812,\n",
      "        0.0742, 0.1049, 0.0816, 0.1030, 0.1058, 0.0930, 0.0919, 0.0798, 0.0869,\n",
      "        0.1030, 0.1210, 0.0899, 0.1036, 0.0991, 0.1158, 0.0920, 0.1038, 0.0808,\n",
      "        0.0901, 0.0958, 0.1028, 0.0937, 0.0977, 0.1034, 0.0744, 0.0349, 0.1214,\n",
      "        0.0780, 0.1357, 0.1031, 0.1504, 0.1274, 0.0807, 0.1084, 0.1162, 0.0946,\n",
      "        0.0761, 0.1006, 0.1217, 0.1091, 0.0898, 0.0933, 0.0867, 0.1069, 0.1493,\n",
      "        0.1170, 0.0938, 0.0888, 0.1087, 0.0728, 0.1021, 0.0946, 0.1155, 0.1057,\n",
      "        0.0958, 0.1042, 0.0968, 0.1079, 0.0884, 0.0803, 0.1060, 0.1008, 0.0992,\n",
      "        0.1099, 0.0987, 0.1083, 0.0915, 0.0877, 0.0805, 0.1094, 0.0222, 0.0793,\n",
      "        0.0248, 0.0976, 0.1014, 0.0856, 0.0737, 0.1326, 0.0930, 0.1156, 0.1114,\n",
      "        0.0759, 0.0714, 0.1005, 0.1165, 0.0944, 0.0787, 0.0959, 0.0683, 0.0961,\n",
      "        0.0689, 0.1002, 0.1222, 0.0962, 0.0981, 0.0933, 0.1021, 0.0855, 0.0828,\n",
      "        0.0682, 0.0760, 0.0950, 0.1080, 0.1289, 0.0863, 0.0851, 0.0946, 0.0838,\n",
      "        0.0880, 0.1181, 0.0833, 0.0823, 0.1407, 0.1043, 0.0765, 0.0946, 0.0717,\n",
      "        0.0815, 0.1370, 0.0998, 0.0631, 0.0727, 0.0800, 0.0988, 0.0856, 0.0776,\n",
      "        0.0968, 0.1249, 0.0956, 0.0811, 0.0853, 0.1154, 0.0943, 0.1223, 0.0998,\n",
      "        0.1086, 0.0718, 0.0926, 0.1112, 0.1008, 0.1236, 0.1198, 0.0888, 0.0879,\n",
      "        0.1341, 0.1048, 0.1295, 0.1283, 0.0742, 0.0954, 0.0810, 0.0927, 0.0986,\n",
      "        0.0777, 0.0836, 0.1217, 0.1123, 0.1126, 0.1034, 0.1414, 0.0899, 0.1188,\n",
      "        0.0987, 0.0976, 0.1214, 0.0887, 0.0879, 0.1072, 0.0962, 0.1670],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.0559, -0.0252,  0.0141,  ...,  0.0486, -0.0053, -0.0697],\n",
      "        [ 0.1105,  0.0417,  0.0320,  ...,  0.0459, -0.0051, -0.0147],\n",
      "        [-0.1051, -0.0168,  0.0816,  ...,  0.0005,  0.0503,  0.0468],\n",
      "        ...,\n",
      "        [ 0.0622,  0.0211, -0.0017,  ...,  0.0396, -0.0195, -0.0178],\n",
      "        [ 0.0074,  0.0893, -0.0379,  ...,  0.0198, -0.1306, -0.0122],\n",
      "        [ 0.0781,  0.0238,  0.0036,  ..., -0.0203,  0.0217,  0.1018]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.0816, -0.3646,  0.4915,  ...,  0.5411,  0.5569, -0.3500],\n",
      "        [-0.2154,  0.1775, -0.2916,  ...,  0.0583, -1.0386, -0.5087],\n",
      "        [-0.2436,  0.1523, -0.2195,  ...,  0.0589, -0.4888,  0.2334],\n",
      "        ...,\n",
      "        [ 0.2452, -0.4702,  0.0688,  ..., -0.1808, -0.4172, -0.3171],\n",
      "        [ 0.2856,  0.5642, -0.8373,  ...,  0.1919, -0.5603, -0.1167],\n",
      "        [ 0.5038, -0.5672,  0.4749,  ..., -0.0589, -0.0735,  0.1580]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.0701,  0.7868,  0.8874,  ...,  0.5715,  0.9076, -0.2253],\n",
      "        [-0.2340, -0.6946, -0.0973,  ..., -0.2782,  0.1175,  0.0143],\n",
      "        [-0.2635,  0.4813,  1.1703,  ...,  0.8914,  0.4043,  0.0069],\n",
      "        ...,\n",
      "        [-0.0584,  0.9230,  0.5521,  ..., -0.5991, -0.5724,  0.2397],\n",
      "        [-0.3932,  0.3887,  0.3503,  ...,  0.9365,  0.4323,  0.3146],\n",
      "        [-0.4240, -0.3551,  0.0545,  ...,  0.1091,  0.3358, -0.0950]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.1408, -0.4908,  0.2749,  ..., -0.4330, -0.4589,  0.8672],\n",
      "        [-0.1692,  0.2901,  0.0382,  ..., -0.0851,  0.1267,  0.2517],\n",
      "        [ 0.1833,  0.2314, -0.8431,  ..., -0.1027,  0.1248, -0.5375],\n",
      "        ...,\n",
      "        [-0.1328, -0.4792,  0.1162,  ...,  0.2263, -0.5869, -1.3212],\n",
      "        [ 0.5930, -0.4317, -1.1419,  ...,  0.0087, -0.0413, -0.3762],\n",
      "        [ 0.5744,  0.5324, -0.5657,  ...,  0.0151,  0.6150,  0.0544]],\n",
      "       device='cuda:0')\n",
      "tensor([0.1234, 0.1098, 0.0838, 0.1321, 0.1079, 0.1000, 0.0484, 0.1164, 0.0893,\n",
      "        0.1600, 0.1412, 0.0459, 0.0843, 0.1174, 0.1252, 0.1368, 0.1204, 0.1137,\n",
      "        0.1244, 0.0692, 0.1167, 0.0975, 0.0976, 0.1239, 0.1108, 0.0843, 0.0806,\n",
      "        0.1134, 0.1198, 0.1032, 0.1062, 0.1505, 0.0822, 0.1152, 0.1063, 0.0899,\n",
      "        0.1031, 0.0990, 0.1209, 0.0788, 0.1009, 0.1084, 0.1413, 0.0857, 0.0753,\n",
      "        0.1442, 0.1275, 0.1278, 0.0960, 0.0865, 0.1065, 0.1261, 0.1091, 0.0926,\n",
      "        0.1207, 0.0843, 0.0980, 0.0978, 0.1060, 0.0844, 0.0990, 0.1170, 0.1243,\n",
      "        0.1055, 0.1510, 0.1339, 0.0802, 0.1161, 0.1002, 0.0928, 0.1328, 0.0719,\n",
      "        0.0992, 0.0977, 0.1011, 0.0939, 0.1169, 0.1091, 0.0349, 0.1008, 0.1620,\n",
      "        0.1125, 0.1040, 0.0941, 0.1087, 0.1106, 0.1213, 0.1025, 0.1135, 0.1153,\n",
      "        0.0757, 0.0854, 0.1373, 0.1069, 0.1359, 0.1054, 0.0808, 0.0936, 0.0866,\n",
      "        0.1258, 0.0897, 0.0894, 0.1071, 0.0931, 0.0982, 0.0860, 0.1177, 0.1197,\n",
      "        0.0633, 0.1072, 0.0873, 0.1344, 0.1547, 0.0893, 0.0955, 0.1022, 0.0775,\n",
      "        0.1143, 0.0926, 0.1128, 0.0853, 0.1322, 0.1106, 0.1480, 0.1006, 0.1133,\n",
      "        0.0959, 0.0974, 0.0810, 0.0632, 0.1056, 0.1097, 0.1188, 0.0888, 0.0862,\n",
      "        0.1080, 0.0643, 0.1132, 0.0655, 0.1402, 0.1067, 0.1102, 0.1086, 0.1232,\n",
      "        0.0844, 0.1018, 0.0992, 0.0950, 0.0688, 0.1019, 0.1104, 0.1207, 0.0963,\n",
      "        0.1284, 0.0855, 0.0996, 0.1219, 0.1498, 0.1313, 0.1182, 0.1074, 0.1083,\n",
      "        0.1396, 0.0421, 0.0841, 0.1059, 0.1183, 0.1523, 0.0883, 0.1289, 0.1321,\n",
      "        0.0915, 0.1101, 0.1062, 0.1350, 0.0884, 0.1210, 0.0717, 0.0947, 0.1178,\n",
      "        0.1106, 0.0998, 0.1402, 0.0876, 0.1292, 0.1075, 0.1283, 0.1416, 0.1052,\n",
      "        0.1018, 0.0860, 0.1297, 0.1123, 0.1190, 0.0959, 0.1125, 0.1287, 0.0935,\n",
      "        0.1432, 0.1076, 0.0817, 0.0917, 0.0981, 0.1074, 0.0735, 0.1133, 0.0834,\n",
      "        0.0968, 0.0940, 0.1011, 0.1421, 0.1074, 0.1106, 0.0787, 0.1189, 0.1091,\n",
      "        0.1160, 0.1450, 0.1345, 0.1091, 0.0813, 0.1152, 0.1127, 0.1177, 0.0941,\n",
      "        0.0986, 0.1309, 0.0915, 0.1026, 0.1199, 0.0771, 0.1015, 0.1037, 0.1186,\n",
      "        0.1359, 0.1133, 0.1065, 0.1172, 0.1096, 0.1056, 0.1036, 0.1051, 0.1083,\n",
      "        0.1084, 0.1213, 0.1060, 0.1122, 0.1078, 0.0686, 0.1116, 0.0865, 0.1087,\n",
      "        0.0934, 0.1088, 0.0893, 0.1043, 0.1057, 0.1167, 0.0962, 0.1216, 0.1172,\n",
      "        0.1158, 0.0986, 0.1196, 0.1342, 0.1125, 0.0995, 0.1175, 0.1164, 0.0746,\n",
      "        0.1075, 0.0941, 0.0879, 0.1066, 0.1077, 0.1111, 0.0890, 0.1133, 0.1012,\n",
      "        0.1237, 0.0892, 0.1108, 0.0846, 0.1072, 0.1077, 0.1069, 0.1321, 0.1134,\n",
      "        0.1258, 0.0870, 0.1012, 0.0768, 0.1083, 0.0933, 0.1096, 0.0678, 0.0940,\n",
      "        0.0942, 0.1025, 0.1093, 0.1442, 0.1100, 0.1032, 0.1182, 0.0778, 0.1441,\n",
      "        0.1276, 0.0952, 0.0727, 0.0949, 0.1082, 0.1271, 0.1013, 0.1015, 0.1144,\n",
      "        0.1309, 0.1269, 0.1229, 0.1158, 0.1022, 0.1613, 0.0769, 0.1286, 0.1081,\n",
      "        0.1008, 0.0920, 0.1431, 0.1000, 0.1086, 0.1215, 0.1264, 0.1078, 0.0939,\n",
      "        0.0560, 0.1062, 0.1055, 0.1453, 0.1184, 0.0932, 0.1070, 0.1063, 0.1150,\n",
      "        0.1277, 0.1248, 0.1047, 0.1054, 0.1122, 0.0770, 0.0873, 0.0870, 0.0800,\n",
      "        0.1351, 0.0974, 0.1079, 0.1186, 0.0977, 0.0802, 0.1007, 0.1097, 0.0965,\n",
      "        0.0655, 0.0847, 0.1356, 0.0747, 0.0952, 0.1316, 0.1107, 0.0248, 0.1132,\n",
      "        0.1570, 0.1214, 0.0993, 0.1623, 0.1137, 0.0849, 0.1183, 0.1128, 0.0993,\n",
      "        0.0988, 0.1050, 0.1152, 0.1061, 0.1130, 0.0931, 0.1163, 0.1278, 0.1652,\n",
      "        0.1162, 0.1037, 0.0921, 0.1005, 0.0947, 0.1162, 0.1100, 0.1360, 0.1145,\n",
      "        0.1137, 0.0953, 0.1128, 0.1311, 0.0929, 0.0981, 0.1198, 0.1012, 0.1186,\n",
      "        0.1443, 0.0971, 0.1263, 0.0979, 0.1180, 0.0911, 0.1191, 0.0556, 0.1252,\n",
      "        0.0406, 0.1071, 0.1046, 0.1260, 0.0655, 0.1570, 0.1005, 0.1096, 0.1238,\n",
      "        0.0813, 0.0859, 0.0794, 0.0896, 0.0844, 0.0912, 0.1073, 0.1056, 0.1210,\n",
      "        0.0916, 0.1127, 0.1171, 0.0862, 0.1030, 0.1318, 0.1009, 0.0862, 0.1094,\n",
      "        0.0845, 0.0895, 0.1334, 0.0930, 0.0991, 0.0611, 0.1482, 0.1034, 0.0834,\n",
      "        0.0827, 0.0945, 0.0948, 0.0879, 0.1447, 0.0994, 0.0958, 0.0902, 0.0772,\n",
      "        0.0737, 0.1494, 0.1026, 0.1143, 0.0526, 0.0772, 0.1249, 0.0953, 0.0866,\n",
      "        0.1212, 0.1221, 0.0950, 0.0882, 0.1033, 0.1094, 0.1223, 0.1073, 0.1126,\n",
      "        0.1178, 0.0786, 0.0861, 0.1014, 0.0979, 0.1095, 0.1207, 0.0820, 0.1082,\n",
      "        0.1235, 0.1041, 0.1196, 0.1157, 0.1124, 0.0716, 0.0982, 0.1504, 0.1190,\n",
      "        0.1164, 0.1057, 0.1549, 0.1064, 0.1380, 0.1287, 0.1173, 0.0933, 0.1064,\n",
      "        0.1125, 0.0732, 0.1108, 0.0996, 0.0982, 0.1129, 0.0923, 0.1023],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.5818, -0.7897, -0.3142,  ...,  0.1121, -0.4245, -0.1487],\n",
      "        [ 0.0535, -0.1322,  0.6383,  ..., -0.0256, -0.2380,  0.3184],\n",
      "        [ 0.0279,  0.0322,  0.0636,  ..., -0.0683,  0.1299, -0.1434],\n",
      "        ...,\n",
      "        [-0.5252, -0.7983, -0.4275,  ..., -0.2380, -0.4194,  1.8252],\n",
      "        [-0.5196,  0.0809,  0.2376,  ..., -0.0514,  0.9983, -0.5308],\n",
      "        [ 0.3054, -0.1861, -0.4720,  ..., -0.3754, -0.7324, -0.2189]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.6207, -0.3227, -0.9031,  ...,  1.1840,  0.2527, -0.0555],\n",
      "        [ 0.2392, -0.8292, -0.0134,  ...,  0.2171, -0.1024,  0.4995],\n",
      "        [ 0.1872, -0.8092,  0.2670,  ...,  0.2242, -0.2724,  0.2110],\n",
      "        ...,\n",
      "        [ 0.6315,  0.1569, -0.3281,  ..., -0.9133,  0.9793,  2.4641],\n",
      "        [ 0.6917,  0.8017, -0.7391,  ...,  0.0497, -0.2077,  0.3079],\n",
      "        [-0.2343, -1.5544,  0.7474,  ...,  0.3807, -0.2569,  0.2259]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.0589,  0.0969,  0.3524,  ..., -0.2998, -0.8154,  0.5096],\n",
      "        [ 0.1848,  0.4633, -0.0407,  ...,  0.1491,  0.5269,  0.2066],\n",
      "        [-0.7476,  0.0658, -0.0479,  ..., -0.0223,  0.2133,  0.2536],\n",
      "        ...,\n",
      "        [ 0.3026, -0.4278, -0.0626,  ...,  0.4624,  0.6920,  0.4077],\n",
      "        [ 0.3624, -0.0201, -0.0379,  ..., -0.1045, -0.3358, -0.1706],\n",
      "        [ 0.3763, -0.3005,  0.0313,  ..., -0.1865, -0.7418,  0.3155]],\n",
      "       device='cuda:0')\n",
      "tensor([0.1306, 0.1038, 0.0683, 0.1063, 0.1103, 0.0893, 0.1139, 0.1005, 0.0962,\n",
      "        0.1248, 0.1065, 0.0404, 0.1060, 0.1027, 0.0835, 0.1229, 0.0965, 0.1030,\n",
      "        0.1164, 0.0855, 0.0963, 0.0614, 0.1174, 0.0875, 0.0805, 0.0678, 0.0772,\n",
      "        0.1062, 0.0968, 0.1100, 0.0904, 0.1080, 0.2016, 0.0774, 0.0913, 0.1051,\n",
      "        0.0954, 0.0843, 0.0821, 0.0763, 0.0961, 0.0907, 0.1257, 0.0908, 0.1191,\n",
      "        0.1194, 0.0921, 0.1171, 0.0967, 0.0949, 0.0919, 0.1057, 0.1036, 0.0966,\n",
      "        0.1062, 0.0973, 0.0995, 0.1285, 0.0983, 0.0989, 0.0697, 0.0922, 0.1032,\n",
      "        0.1006, 0.1322, 0.1175, 0.0797, 0.0988, 0.0972, 0.0831, 0.1275, 0.0773,\n",
      "        0.0886, 0.0838, 0.1016, 0.0984, 0.1025, 0.1276, 0.0469, 0.0943, 0.1166,\n",
      "        0.1086, 0.1018, 0.0638, 0.0962, 0.1052, 0.0962, 0.1206, 0.1192, 0.1181,\n",
      "        0.1249, 0.1031, 0.0903, 0.0808, 0.1153, 0.1117, 0.0901, 0.0895, 0.0976,\n",
      "        0.0873, 0.0718, 0.0842, 0.0790, 0.0971, 0.0824, 0.0994, 0.0975, 0.0940,\n",
      "        0.0865, 0.0956, 0.0837, 0.1049, 0.1286, 0.0913, 0.0874, 0.0893, 0.0611,\n",
      "        0.0807, 0.0701, 0.1113, 0.0876, 0.0795, 0.0932, 0.0958, 0.1124, 0.0944,\n",
      "        0.1069, 0.0801, 0.1008, 0.0745, 0.1010, 0.1118, 0.0863, 0.0691, 0.0891,\n",
      "        0.0995, 0.6824, 0.0843, 0.1128, 0.1078, 0.0937, 0.1425, 0.0900, 0.1384,\n",
      "        0.0842, 0.1345, 0.0857, 0.0863, 0.0846, 0.0939, 0.1025, 0.0920, 0.1075,\n",
      "        0.1013, 0.0813, 0.0976, 0.0939, 0.1130, 0.0967, 0.1101, 0.0999, 0.1132,\n",
      "        0.1223, 0.0029, 0.0853, 0.1044, 0.1035, 0.1124, 0.0997, 0.0972, 0.1026,\n",
      "        0.1095, 0.0806, 0.0887, 0.1165, 0.0929, 0.0992, 0.0780, 0.0965, 0.0954,\n",
      "        0.0878, 0.0864, 0.1101, 0.0757, 0.1055, 0.1098, 0.1285, 0.1305, 0.0985,\n",
      "        0.1072, 0.0869, 0.1238, 0.0821, 0.1019, 0.1085, 0.0879, 0.1212, 0.1110,\n",
      "        0.0919, 0.1011, 0.0854, 0.0976, 0.1169, 0.1045, 0.1156, 0.0993, 0.0989,\n",
      "        0.0814, 0.1224, 0.1088, 0.1306, 0.1012, 0.1106, 0.0868, 0.0992, 0.0952,\n",
      "        0.1190, 0.1168, 0.1018, 0.1169, 0.0695, 0.0709, 0.0923, 0.0902, 0.0778,\n",
      "        0.0991, 0.1028, 0.0929, 0.0854, 0.1169, 0.0828, 0.1010, 0.0870, 0.0738,\n",
      "        0.1157, 0.0994, 0.0931, 0.1256, 0.0998, 0.0997, 0.1005, 0.0898, 0.0784,\n",
      "        0.1021, 0.0948, 0.0962, 0.1215, 0.0827, 0.0934, 0.1001, 0.0888, 0.1003,\n",
      "        0.0908, 0.0923, 0.0753, 0.0966, 0.1017, 0.1069, 0.1002, 0.1221, 0.1001,\n",
      "        0.0714, 0.0862, 0.1096, 0.1001, 0.1046, 0.0974, 0.1261, 0.0608, 0.0815,\n",
      "        0.0882, 0.0918, 0.1014, 0.0957, 0.0973, 0.1035, 0.1096, 0.0782, 0.0785,\n",
      "        0.1182, 0.1063, 0.0901, 0.1000, 0.1238, 0.1179, 0.0838, 0.1081, 0.1022,\n",
      "        0.1141, 0.1015, 0.1049, 0.0812, 0.1115, 0.0963, 0.1092, 0.0756, 0.0881,\n",
      "        0.0713, 0.0977, 0.1018, 0.1355, 0.0909, 0.0891, 0.1264, 0.1255, 0.1289,\n",
      "        0.0986, 0.0767, 0.1005, 0.0811, 0.1068, 0.1060, 0.0953, 0.1013, 0.0870,\n",
      "        0.1029, 0.0912, 0.0860, 0.1078, 0.1040, 0.1265, 0.0941, 0.0874, 0.1202,\n",
      "        0.0913, 0.1071, 0.1267, 0.0912, 0.1096, 0.1049, 0.1116, 0.0750, 0.1228,\n",
      "        0.0537, 0.1138, 0.0962, 0.0956, 0.1116, 0.0863, 0.1114, 0.1025, 0.0944,\n",
      "        0.1054, 0.0810, 0.1001, 0.0910, 0.1277, 0.0994, 0.0983, 0.0967, 0.1039,\n",
      "        0.0971, 0.1053, 0.0934, 0.1008, 0.0901, 0.1199, 0.1164, 0.0949, 0.0725,\n",
      "        0.1090, 0.1013, 0.0943, 0.0835, 0.0886, 0.1039, 0.0862, 0.0407, 0.1062,\n",
      "        0.1022, 0.1269, 0.0807, 0.1177, 0.1066, 0.0955, 0.1173, 0.1017, 0.0955,\n",
      "        0.1144, 0.0993, 0.1223, 0.0924, 0.0928, 0.0989, 0.0903, 0.1168, 0.1455,\n",
      "        0.1300, 0.1120, 0.0829, 0.1156, 0.0752, 0.1102, 0.0977, 0.1296, 0.0971,\n",
      "        0.1097, 0.1059, 0.1093, 0.1170, 0.0865, 0.0894, 0.1242, 0.1024, 0.0850,\n",
      "        0.1107, 0.1072, 0.1091, 0.1141, 0.1123, 0.0951, 0.0976, 0.0409, 0.0876,\n",
      "        0.0323, 0.0894, 0.0943, 0.0886, 0.0795, 0.1114, 0.1149, 0.1233, 0.1066,\n",
      "        0.0820, 0.0789, 0.1168, 0.0942, 0.0854, 0.0947, 0.0957, 0.0858, 0.1048,\n",
      "        0.0883, 0.1296, 0.1213, 0.0756, 0.0960, 0.1140, 0.1111, 0.0892, 0.0961,\n",
      "        0.0763, 0.0781, 0.1124, 0.0840, 0.1132, 0.0960, 0.0818, 0.0914, 0.1003,\n",
      "        0.0831, 0.1060, 0.0793, 0.0699, 0.1258, 0.1034, 0.0876, 0.1088, 0.0775,\n",
      "        0.1039, 0.0887, 0.0927, 0.0783, 0.0841, 0.0837, 0.1076, 0.0948, 0.0635,\n",
      "        0.1065, 0.1268, 0.1120, 0.1002, 0.0907, 0.0980, 0.1042, 0.1206, 0.0826,\n",
      "        0.0935, 0.0724, 0.1102, 0.0981, 0.1135, 0.1205, 0.1055, 0.1151, 0.1014,\n",
      "        0.1439, 0.1118, 0.1282, 0.1027, 0.1124, 0.0978, 0.0988, 0.1026, 0.1091,\n",
      "        0.0854, 0.0905, 0.1136, 0.1000, 0.1192, 0.1122, 0.1106, 0.1240, 0.0940,\n",
      "        0.0909, 0.1063, 0.1212, 0.1105, 0.0847, 0.0927, 0.1093, 0.2146],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.0443, -0.0154,  0.0488,  ...,  0.1212, -0.0246, -0.0120],\n",
      "        [-0.0156,  0.1564,  0.0013,  ..., -0.1448, -0.1194,  0.0456],\n",
      "        [-0.0441, -0.0011,  0.0372,  ..., -0.0268, -0.1030,  0.0419],\n",
      "        ...,\n",
      "        [-0.0085, -0.0086, -0.0521,  ..., -0.0610,  0.0387,  0.0393],\n",
      "        [ 0.0818, -0.0069,  0.0555,  ...,  0.0728, -0.0268,  0.0908],\n",
      "        [-0.0776, -0.0145, -0.0208,  ..., -0.0797, -0.0141, -0.0231]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.0731, -0.6520, -0.2359,  ..., -0.0310,  0.3938, -0.3975],\n",
      "        [ 0.2436, -0.1947, -0.2575,  ...,  0.3932,  0.2599, -0.3987],\n",
      "        [-0.2592,  0.4722, -0.1090,  ..., -0.4756, -0.3802,  0.5483],\n",
      "        ...,\n",
      "        [-0.1032,  0.5185,  0.3290,  ..., -0.2023, -0.1744, -0.1016],\n",
      "        [ 0.2013, -0.2231,  0.0800,  ...,  0.2166, -0.1486,  0.2047],\n",
      "        [-0.2582,  0.5810, -0.3322,  ..., -0.3034, -0.0805, -0.0937]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.2308, -0.0263,  0.2220,  ..., -0.7663,  0.3059,  0.7995],\n",
      "        [ 0.2966, -0.5405, -0.3514,  ..., -0.0397,  0.4063, -0.0912],\n",
      "        [-0.2761, -0.4997, -0.0871,  ...,  0.7838,  0.0526,  0.0240],\n",
      "        ...,\n",
      "        [-0.7463, -0.1843,  0.6906,  ...,  0.0178, -0.5314, -0.2472],\n",
      "        [ 0.9360, -0.0910,  1.2187,  ..., -1.0794,  1.0250,  0.5290],\n",
      "        [ 0.0950, -0.1560,  0.4038,  ...,  0.7979,  0.4378,  0.1580]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.6632, -0.3619, -0.1105,  ..., -0.9776, -0.1741, -0.5596],\n",
      "        [-0.1397,  0.1148,  0.0748,  ..., -0.9291, -0.6276,  0.4535],\n",
      "        [ 0.5134, -0.2812, -0.8988,  ...,  0.4407,  1.3827,  0.2855],\n",
      "        ...,\n",
      "        [-0.7496,  0.3849,  0.4110,  ...,  0.6750, -1.1254,  0.6694],\n",
      "        [ 0.8604,  0.5402,  0.0523,  ..., -0.2269, -0.0181,  0.0225],\n",
      "        [-0.1994,  0.2964,  0.2785,  ..., -0.0636,  0.7766, -0.1812]],\n",
      "       device='cuda:0')\n",
      "tensor([0.1810, 0.1293, 0.1262, 0.1475, 0.1485, 0.1405, 0.0502, 0.1631, 0.1264,\n",
      "        0.2070, 0.1592, 0.0650, 0.1614, 0.1325, 0.1545, 0.1815, 0.1616, 0.1458,\n",
      "        0.1765, 0.1118, 0.1392, 0.1295, 0.1208, 0.2076, 0.1489, 0.0928, 0.1222,\n",
      "        0.1552, 0.1453, 0.1443, 0.1507, 0.1522, 0.1483, 0.1484, 0.1233, 0.1579,\n",
      "        0.1436, 0.1393, 0.1326, 0.1380, 0.1396, 0.1086, 0.1777, 0.1287, 0.1409,\n",
      "        0.1451, 0.1345, 0.1678, 0.1150, 0.1394, 0.1330, 0.1386, 0.1389, 0.1369,\n",
      "        0.1489, 0.1581, 0.1465, 0.1544, 0.1515, 0.1186, 0.1446, 0.1445, 0.1556,\n",
      "        0.1222, 0.1654, 0.1506, 0.1015, 0.1456, 0.1412, 0.1321, 0.1948, 0.1160,\n",
      "        0.1391, 0.1384, 0.1144, 0.1253, 0.1236, 0.1548, 0.0318, 0.1606, 0.1667,\n",
      "        0.1618, 0.1451, 0.1493, 0.1504, 0.1493, 0.1487, 0.1735, 0.1574, 0.1199,\n",
      "        0.1158, 0.1302, 0.1418, 0.1483, 0.1516, 0.1346, 0.1402, 0.1263, 0.1379,\n",
      "        0.1343, 0.1376, 0.1418, 0.1543, 0.1574, 0.1539, 0.1323, 0.1515, 0.1087,\n",
      "        0.1293, 0.1223, 0.1088, 0.1439, 0.1684, 0.1189, 0.1408, 0.1737, 0.1097,\n",
      "        0.1136, 0.1347, 0.1723, 0.1461, 0.1491, 0.1765, 0.1505, 0.1225, 0.1015,\n",
      "        0.1400, 0.1457, 0.1394, 0.1186, 0.1568, 0.1210, 0.1501, 0.1006, 0.1228,\n",
      "        0.1496, 0.0505, 0.1217, 0.1305, 0.1423, 0.1366, 0.1629, 0.1169, 0.1218,\n",
      "        0.1465, 0.1446, 0.1672, 0.1507, 0.1591, 0.1439, 0.1515, 0.1301, 0.1383,\n",
      "        0.1349, 0.1272, 0.1611, 0.1381, 0.1408, 0.1463, 0.1668, 0.1415, 0.1757,\n",
      "        0.1603, 0.0556, 0.1302, 0.1473, 0.1487, 0.1687, 0.1216, 0.1855, 0.1551,\n",
      "        0.1412, 0.1535, 0.1450, 0.1720, 0.1433, 0.1432, 0.1075, 0.1609, 0.1517,\n",
      "        0.1373, 0.1109, 0.1860, 0.1292, 0.1500, 0.1487, 0.1602, 0.1651, 0.1418,\n",
      "        0.1348, 0.1310, 0.1586, 0.1427, 0.1738, 0.1281, 0.1203, 0.1609, 0.1546,\n",
      "        0.1326, 0.1486, 0.1360, 0.1220, 0.1473, 0.1251, 0.1152, 0.1279, 0.1089,\n",
      "        0.1490, 0.1505, 0.1446, 0.1772, 0.1522, 0.1693, 0.1296, 0.1223, 0.1425,\n",
      "        0.1318, 0.1762, 0.1147, 0.1881, 0.1397, 0.1310, 0.1428, 0.1480, 0.1577,\n",
      "        0.1046, 0.1399, 0.1292, 0.1578, 0.1292, 0.1113, 0.1233, 0.1254, 0.1475,\n",
      "        0.1547, 0.1487, 0.1387, 0.1614, 0.1829, 0.1559, 0.1017, 0.1266, 0.1430,\n",
      "        0.1399, 0.0994, 0.1561, 0.1567, 0.1527, 0.1069, 0.1635, 0.1162, 0.1274,\n",
      "        0.1462, 0.1332, 0.1372, 0.1278, 0.1342, 0.1651, 0.1765, 0.1557, 0.1484,\n",
      "        0.1191, 0.1413, 0.1478, 0.1690, 0.1521, 0.1260, 0.1745, 0.1479, 0.0948,\n",
      "        0.1441, 0.1572, 0.1245, 0.1329, 0.1470, 0.1500, 0.1179, 0.1282, 0.1392,\n",
      "        0.1695, 0.1470, 0.1593, 0.1389, 0.1496, 0.1578, 0.1007, 0.1591, 0.1406,\n",
      "        0.1716, 0.1484, 0.1386, 0.1112, 0.1429, 0.1233, 0.1503, 0.0901, 0.1187,\n",
      "        0.1214, 0.1561, 0.1543, 0.1570, 0.1327, 0.1175, 0.1581, 0.1561, 0.1493,\n",
      "        0.1510, 0.0927, 0.1095, 0.1225, 0.1277, 0.1712, 0.1353, 0.1496, 0.1059,\n",
      "        0.1533, 0.1212, 0.1275, 0.1546, 0.1356, 0.1864, 0.1425, 0.1226, 0.1816,\n",
      "        0.1228, 0.1386, 0.1290, 0.1520, 0.1403, 0.1274, 0.1274, 0.1263, 0.1575,\n",
      "        0.0612, 0.1296, 0.1465, 0.1521, 0.1400, 0.1415, 0.1399, 0.1582, 0.1302,\n",
      "        0.1444, 0.1330, 0.1533, 0.1436, 0.1690, 0.1413, 0.1456, 0.0968, 0.1250,\n",
      "        0.1628, 0.1406, 0.1414, 0.1629, 0.1334, 0.1439, 0.1584, 0.1427, 0.1014,\n",
      "        0.1567, 0.1307, 0.1585, 0.1303, 0.1278, 0.1347, 0.1381, 0.0289, 0.1730,\n",
      "        0.1796, 0.1454, 0.1441, 0.1703, 0.1235, 0.1212, 0.1689, 0.1454, 0.1856,\n",
      "        0.1228, 0.1539, 0.1517, 0.1461, 0.1350, 0.1169, 0.1183, 0.1571, 0.1621,\n",
      "        0.1320, 0.1442, 0.1450, 0.1559, 0.1252, 0.1537, 0.1734, 0.1805, 0.1040,\n",
      "        0.1482, 0.1413, 0.1533, 0.1362, 0.1176, 0.1140, 0.1361, 0.1343, 0.1275,\n",
      "        0.1390, 0.1274, 0.1355, 0.1499, 0.1245, 0.1596, 0.1537, 0.0854, 0.1488,\n",
      "        0.0397, 0.1198, 0.1350, 0.1633, 0.1230, 0.1754, 0.1293, 0.1528, 0.1587,\n",
      "        0.1292, 0.1302, 0.1166, 0.1571, 0.1180, 0.1170, 0.1116, 0.1224, 0.1656,\n",
      "        0.1187, 0.1516, 0.1440, 0.1123, 0.1162, 0.1457, 0.1562, 0.1303, 0.1492,\n",
      "        0.1117, 0.1055, 0.1644, 0.1162, 0.1634, 0.1106, 0.1904, 0.1166, 0.1090,\n",
      "        0.1297, 0.1270, 0.1361, 0.1149, 0.1651, 0.1326, 0.1295, 0.1581, 0.1178,\n",
      "        0.1256, 0.1505, 0.1396, 0.0917, 0.1094, 0.1190, 0.1562, 0.1259, 0.1183,\n",
      "        0.1475, 0.1259, 0.1479, 0.1298, 0.1074, 0.1391, 0.1663, 0.2206, 0.1532,\n",
      "        0.1433, 0.1033, 0.1498, 0.1539, 0.1419, 0.1658, 0.1764, 0.1186, 0.1608,\n",
      "        0.1939, 0.1235, 0.1522, 0.1474, 0.1703, 0.1444, 0.1436, 0.1267, 0.1580,\n",
      "        0.1353, 0.1339, 0.1951, 0.1526, 0.1676, 0.1475, 0.1649, 0.1369, 0.1324,\n",
      "        0.1656, 0.1365, 0.1624, 0.1641, 0.1232, 0.1491, 0.1559, 0.1201],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.5234, -0.3384, -0.1957,  ...,  0.0770,  0.0249, -0.1597],\n",
      "        [-0.2105, -0.2973,  0.4796,  ..., -0.4182,  0.3311,  0.1064],\n",
      "        [-0.0156,  0.2606,  0.4316,  ...,  0.1827, -0.0388,  0.2569],\n",
      "        ...,\n",
      "        [ 0.3395,  0.2522,  0.2861,  ...,  0.5518, -0.3498, -0.0529],\n",
      "        [-0.2848, -0.4256,  0.5312,  ...,  0.4652, -0.0708, -0.4056],\n",
      "        [-0.8342, -0.2120, -0.4265,  ...,  0.5517,  0.4071, -0.3329]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.1378, -1.2156,  0.6996,  ...,  0.1113,  0.9319, -0.1540],\n",
      "        [ 0.0266, -0.2833,  0.6666,  ..., -0.2854,  1.1453,  0.3559],\n",
      "        [ 0.1258, -0.5168,  0.7851,  ...,  0.4126, -0.1097, -1.1941],\n",
      "        ...,\n",
      "        [-0.5467,  0.9882,  0.3646,  ...,  0.0057,  0.4163,  0.5881],\n",
      "        [-2.7786,  2.0390,  2.1972,  ...,  0.8259,  1.1897,  1.0318],\n",
      "        [ 0.2804, -1.2478,  0.0532,  ...,  0.3888,  0.8188,  0.2503]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.9383, -0.2343,  0.1068,  ...,  1.0583, -0.4143, -0.0312],\n",
      "        [ 0.0972, -0.0916,  0.6618,  ..., -0.6900, -0.0032, -0.2733],\n",
      "        [ 0.0957,  0.3356, -0.3246,  ...,  1.1212,  1.0852,  0.1877],\n",
      "        ...,\n",
      "        [-0.3901,  0.6288, -0.7232,  ...,  0.3202, -0.0303,  0.3635],\n",
      "        [-0.1132,  0.9393, -0.3354,  ...,  0.3586, -0.5801, -0.1179],\n",
      "        [ 0.0911, -0.0884, -0.1362,  ..., -0.4489, -0.3280,  0.4923]],\n",
      "       device='cuda:0')\n",
      "tensor([0.1136, 0.1126, 0.0972, 0.1070, 0.1056, 0.0989, 0.0348, 0.1123, 0.0998,\n",
      "        0.1243, 0.1036, 0.0505, 0.1075, 0.0949, 0.0979, 0.1215, 0.1069, 0.0916,\n",
      "        0.1023, 0.0939, 0.0884, 0.0726, 0.1085, 0.0963, 0.1053, 0.0790, 0.0647,\n",
      "        0.0923, 0.1006, 0.0918, 0.0976, 0.1138, 0.1466, 0.0920, 0.0831, 0.0885,\n",
      "        0.1112, 0.0871, 0.0875, 0.0698, 0.1265, 0.1011, 0.1210, 0.0769, 0.1176,\n",
      "        0.1233, 0.1229, 0.1378, 0.1031, 0.0995, 0.0979, 0.1051, 0.1235, 0.1056,\n",
      "        0.1158, 0.1092, 0.0915, 0.1348, 0.1105, 0.0821, 0.1083, 0.0933, 0.1070,\n",
      "        0.1054, 0.1245, 0.1198, 0.0902, 0.1101, 0.1215, 0.0920, 0.1310, 0.0924,\n",
      "        0.0882, 0.0830, 0.0970, 0.1057, 0.0969, 0.1270, 0.0493, 0.1024, 0.1088,\n",
      "        0.1186, 0.0952, 0.1239, 0.1065, 0.1127, 0.0990, 0.1197, 0.1152, 0.1021,\n",
      "        0.0844, 0.1009, 0.1092, 0.1147, 0.1214, 0.1225, 0.1109, 0.0996, 0.0933,\n",
      "        0.0717, 0.0813, 0.0926, 0.1008, 0.1038, 0.1089, 0.1054, 0.1123, 0.0894,\n",
      "        0.0825, 0.1018, 0.0952, 0.1094, 0.1210, 0.0638, 0.0941, 0.0963, 0.0853,\n",
      "        0.0848, 0.0858, 0.1198, 0.0962, 0.1033, 0.0986, 0.1101, 0.1057, 0.1133,\n",
      "        0.0957, 0.0992, 0.1080, 0.0950, 0.1265, 0.0931, 0.1001, 0.0748, 0.1096,\n",
      "        0.0995, 0.2576, 0.1105, 0.1019, 0.1110, 0.0858, 0.1067, 0.0914, 0.1299,\n",
      "        0.0989, 0.1278, 0.0971, 0.1018, 0.0935, 0.0909, 0.1082, 0.0986, 0.0995,\n",
      "        0.1130, 0.0989, 0.1181, 0.1015, 0.1071, 0.0918, 0.1143, 0.1022, 0.1249,\n",
      "        0.1110, 0.0171, 0.0968, 0.1028, 0.1054, 0.0998, 0.0820, 0.0950, 0.1204,\n",
      "        0.0939, 0.1222, 0.0862, 0.1303, 0.0986, 0.0953, 0.0817, 0.1222, 0.1113,\n",
      "        0.0762, 0.0891, 0.1249, 0.0972, 0.1103, 0.0948, 0.0976, 0.1169, 0.1053,\n",
      "        0.0725, 0.0816, 0.1138, 0.0968, 0.1169, 0.1097, 0.0888, 0.0928, 0.1060,\n",
      "        0.1095, 0.1143, 0.0874, 0.0949, 0.0919, 0.0797, 0.1070, 0.0807, 0.1066,\n",
      "        0.0845, 0.0963, 0.1130, 0.0853, 0.1092, 0.0962, 0.0724, 0.1061, 0.1195,\n",
      "        0.0792, 0.1150, 0.0907, 0.1519, 0.0892, 0.0802, 0.1014, 0.1010, 0.0987,\n",
      "        0.0892, 0.0964, 0.1072, 0.0890, 0.1256, 0.0921, 0.0992, 0.0955, 0.0938,\n",
      "        0.1218, 0.0982, 0.1012, 0.1274, 0.1078, 0.1044, 0.1205, 0.0955, 0.0907,\n",
      "        0.1044, 0.1048, 0.1132, 0.1016, 0.0894, 0.0871, 0.0998, 0.0908, 0.1052,\n",
      "        0.0946, 0.0906, 0.0886, 0.1134, 0.0927, 0.1137, 0.1034, 0.1201, 0.1006,\n",
      "        0.0893, 0.0937, 0.1131, 0.1139, 0.1213, 0.0816, 0.1314, 0.0997, 0.0975,\n",
      "        0.1123, 0.1041, 0.1099, 0.0865, 0.1124, 0.1062, 0.0872, 0.1143, 0.0905,\n",
      "        0.0908, 0.0917, 0.0948, 0.0922, 0.1298, 0.1165, 0.0776, 0.0839, 0.0966,\n",
      "        0.0970, 0.1121, 0.0939, 0.1062, 0.1027, 0.0961, 0.1134, 0.0874, 0.1050,\n",
      "        0.0922, 0.1013, 0.1111, 0.1095, 0.0824, 0.1040, 0.1147, 0.1254, 0.1087,\n",
      "        0.1254, 0.0727, 0.0992, 0.0688, 0.1086, 0.1192, 0.1052, 0.1109, 0.1005,\n",
      "        0.1124, 0.1185, 0.1069, 0.1115, 0.0887, 0.1121, 0.0972, 0.0993, 0.1102,\n",
      "        0.1073, 0.0816, 0.1232, 0.0929, 0.0970, 0.1258, 0.0828, 0.0875, 0.1176,\n",
      "        0.0476, 0.1166, 0.0795, 0.0941, 0.1229, 0.0836, 0.1220, 0.1079, 0.1264,\n",
      "        0.0977, 0.1151, 0.1116, 0.1171, 0.1098, 0.1001, 0.0945, 0.0804, 0.0892,\n",
      "        0.1058, 0.0999, 0.0948, 0.1021, 0.1079, 0.1104, 0.0942, 0.1067, 0.1027,\n",
      "        0.0875, 0.0901, 0.1014, 0.0778, 0.0940, 0.1195, 0.0862, 0.0323, 0.1145,\n",
      "        0.0940, 0.1276, 0.1009, 0.1257, 0.0951, 0.0730, 0.1162, 0.0989, 0.0966,\n",
      "        0.0901, 0.1029, 0.0995, 0.0767, 0.1117, 0.1109, 0.0985, 0.1138, 0.1064,\n",
      "        0.1133, 0.0973, 0.0818, 0.1216, 0.0865, 0.1103, 0.1130, 0.1284, 0.1017,\n",
      "        0.1132, 0.1140, 0.1080, 0.1048, 0.0918, 0.1094, 0.0888, 0.0964, 0.1177,\n",
      "        0.1168, 0.1105, 0.1060, 0.0964, 0.0889, 0.0941, 0.1130, 0.0407, 0.0924,\n",
      "        0.0258, 0.0837, 0.1005, 0.1064, 0.0882, 0.1014, 0.1201, 0.1285, 0.0914,\n",
      "        0.0899, 0.0744, 0.0960, 0.0993, 0.1095, 0.1022, 0.0861, 0.0990, 0.1251,\n",
      "        0.0859, 0.1110, 0.1118, 0.0866, 0.1059, 0.1062, 0.0990, 0.0881, 0.1079,\n",
      "        0.0880, 0.0757, 0.1087, 0.1021, 0.1092, 0.0955, 0.1117, 0.0949, 0.1080,\n",
      "        0.0887, 0.1048, 0.1109, 0.0987, 0.1071, 0.0846, 0.0885, 0.1161, 0.0771,\n",
      "        0.1109, 0.1178, 0.1125, 0.0899, 0.0916, 0.0909, 0.1051, 0.0678, 0.0898,\n",
      "        0.1001, 0.1081, 0.0927, 0.0967, 0.0842, 0.1086, 0.1304, 0.1178, 0.0946,\n",
      "        0.0847, 0.0879, 0.1160, 0.1211, 0.1038, 0.1174, 0.1004, 0.1051, 0.1155,\n",
      "        0.1470, 0.1129, 0.1274, 0.1065, 0.0965, 0.0767, 0.0911, 0.1133, 0.1198,\n",
      "        0.0943, 0.0906, 0.1337, 0.1002, 0.1224, 0.0979, 0.1304, 0.0884, 0.1278,\n",
      "        0.0990, 0.0963, 0.1001, 0.1096, 0.0679, 0.0972, 0.0990, 0.1492],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.0385,  0.0013,  0.0038,  ...,  0.0036, -0.0388, -0.0253],\n",
      "        [-0.0110,  0.0149,  0.0036,  ...,  0.0430,  0.0418, -0.0069],\n",
      "        [ 0.0240,  0.0703, -0.0084,  ...,  0.0660,  0.0286,  0.0180],\n",
      "        ...,\n",
      "        [-0.0048,  0.0025,  0.0218,  ...,  0.0141,  0.0381, -0.0732],\n",
      "        [ 0.0258,  0.0033, -0.0098,  ...,  0.0975,  0.0066,  0.0182],\n",
      "        [-0.0705, -0.0277, -0.0516,  ...,  0.0133,  0.0670, -0.0648]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.8494, -0.8594,  0.2992,  ...,  0.6348, -0.2717, -0.2996],\n",
      "        [-0.4389, -0.1210,  0.0221,  ...,  0.5830, -0.3488, -0.7561],\n",
      "        [ 0.5743,  0.1189,  0.3782,  ..., -0.0416,  0.1993,  0.1205],\n",
      "        ...,\n",
      "        [-0.0755, -0.4012,  0.1627,  ..., -0.2158,  0.0948, -0.3855],\n",
      "        [ 0.2105,  0.3590,  0.1578,  ...,  1.0241, -0.4841, -0.0554],\n",
      "        [-0.0778,  0.0174,  0.2967,  ..., -0.3057,  0.4808, -0.3152]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.3406,  1.2834, -0.1414,  ..., -0.1679,  0.3320, -0.5507],\n",
      "        [ 0.1507, -0.3671, -0.3964,  ..., -0.5915,  0.0258, -0.4929],\n",
      "        [ 0.6085,  1.4142,  0.5949,  ..., -0.0515,  0.8012,  0.3104],\n",
      "        ...,\n",
      "        [ 0.2898,  0.1186,  0.1560,  ..., -0.5847,  0.9746,  0.3970],\n",
      "        [ 1.4530,  0.7815, -0.1282,  ..., -0.9188,  0.2168, -0.0829],\n",
      "        [ 0.8077, -0.3941,  0.7503,  ...,  0.7337,  0.5033,  0.0520]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.2161,  0.3536, -0.2388,  ...,  0.4390,  0.0075, -1.0040],\n",
      "        [ 0.2192,  0.5915,  0.1698,  ..., -0.2067, -0.3296,  0.3473],\n",
      "        [ 0.4987,  0.2693,  0.4683,  ...,  0.2106, -0.7550, -0.0024],\n",
      "        ...,\n",
      "        [-0.2245, -0.0726,  0.2913,  ..., -0.9900,  0.0739, -1.2330],\n",
      "        [ 0.3907,  0.0375, -0.2233,  ..., -0.3859, -0.3237, -0.3932],\n",
      "        [-0.1377,  0.3671,  0.0176,  ...,  0.4528, -0.0732,  0.4548]],\n",
      "       device='cuda:0')\n",
      "tensor([0.1821, 0.1613, 0.1532, 0.1763, 0.1678, 0.1712, 0.0266, 0.1829, 0.1420,\n",
      "        0.2260, 0.1849, 0.0641, 0.1663, 0.1331, 0.1487, 0.1812, 0.1525, 0.1360,\n",
      "        0.1179, 0.1255, 0.1393, 0.1315, 0.1421, 0.2090, 0.1253, 0.1164, 0.1017,\n",
      "        0.1636, 0.1554, 0.1443, 0.1540, 0.2023, 0.1384, 0.1595, 0.1530, 0.1914,\n",
      "        0.1803, 0.1448, 0.1583, 0.1413, 0.1421, 0.1667, 0.1443, 0.1265, 0.1780,\n",
      "        0.1627, 0.1480, 0.2279, 0.1436, 0.1728, 0.1335, 0.1893, 0.1672, 0.1907,\n",
      "        0.1856, 0.1488, 0.1564, 0.1836, 0.1373, 0.1249, 0.1480, 0.1622, 0.1719,\n",
      "        0.1541, 0.1875, 0.2028, 0.1252, 0.1609, 0.1501, 0.1419, 0.1603, 0.1300,\n",
      "        0.1634, 0.1371, 0.1402, 0.1484, 0.1581, 0.2088, 0.0502, 0.1390, 0.1927,\n",
      "        0.1184, 0.1579, 0.1611, 0.1607, 0.1655, 0.1647, 0.1482, 0.1809, 0.1512,\n",
      "        0.1364, 0.1418, 0.1525, 0.1479, 0.2106, 0.1814, 0.1683, 0.1606, 0.1239,\n",
      "        0.1441, 0.1379, 0.1463, 0.1730, 0.1489, 0.1334, 0.1542, 0.1849, 0.1656,\n",
      "        0.1244, 0.1859, 0.1328, 0.1790, 0.1856, 0.1126, 0.1570, 0.1516, 0.1235,\n",
      "        0.1590, 0.1397, 0.1501, 0.1622, 0.1522, 0.1691, 0.1908, 0.1294, 0.1746,\n",
      "        0.1452, 0.1614, 0.1284, 0.1362, 0.1463, 0.1590, 0.1412, 0.1201, 0.1510,\n",
      "        0.1682, 0.0374, 0.1597, 0.1515, 0.1780, 0.1405, 0.1834, 0.1567, 0.1924,\n",
      "        0.1558, 0.2294, 0.1528, 0.1588, 0.1093, 0.1403, 0.1511, 0.1946, 0.1364,\n",
      "        0.2004, 0.1571, 0.1663, 0.1619, 0.1798, 0.1778, 0.1606, 0.1675, 0.1799,\n",
      "        0.1732, 0.0510, 0.1548, 0.1659, 0.1359, 0.2159, 0.1395, 0.1995, 0.1767,\n",
      "        0.1217, 0.1966, 0.1552, 0.1941, 0.1434, 0.1808, 0.1378, 0.1359, 0.1455,\n",
      "        0.1116, 0.1472, 0.1456, 0.1397, 0.1469, 0.1516, 0.1622, 0.1776, 0.1710,\n",
      "        0.1188, 0.1703, 0.1477, 0.1521, 0.1769, 0.1587, 0.1254, 0.1618, 0.2089,\n",
      "        0.1549, 0.1333, 0.1708, 0.1651, 0.1670, 0.1356, 0.1399, 0.1315, 0.1804,\n",
      "        0.1498, 0.1674, 0.1214, 0.2063, 0.1719, 0.1689, 0.1504, 0.2111, 0.1768,\n",
      "        0.1746, 0.1634, 0.1294, 0.2037, 0.1417, 0.1199, 0.1690, 0.1643, 0.1636,\n",
      "        0.1460, 0.1575, 0.1383, 0.1422, 0.1807, 0.1213, 0.1832, 0.1601, 0.1188,\n",
      "        0.1958, 0.1663, 0.1582, 0.1804, 0.1740, 0.1496, 0.1364, 0.1499, 0.1837,\n",
      "        0.1552, 0.1431, 0.1557, 0.1598, 0.1315, 0.1390, 0.1759, 0.1018, 0.1512,\n",
      "        0.1832, 0.1541, 0.1471, 0.1782, 0.1669, 0.1561, 0.1832, 0.1996, 0.1668,\n",
      "        0.1451, 0.1531, 0.1540, 0.2123, 0.1848, 0.1898, 0.1842, 0.1260, 0.1439,\n",
      "        0.1466, 0.1759, 0.1534, 0.1313, 0.1522, 0.1649, 0.1378, 0.1867, 0.1533,\n",
      "        0.1702, 0.1561, 0.1454, 0.1460, 0.1286, 0.1600, 0.1168, 0.1386, 0.1653,\n",
      "        0.2036, 0.1590, 0.1775, 0.1677, 0.1521, 0.1205, 0.1419, 0.0938, 0.1574,\n",
      "        0.1004, 0.1548, 0.1547, 0.1863, 0.1591, 0.1511, 0.1690, 0.1317, 0.1470,\n",
      "        0.1741, 0.1414, 0.1168, 0.1394, 0.1714, 0.1806, 0.1273, 0.1716, 0.1809,\n",
      "        0.1701, 0.1777, 0.1803, 0.1534, 0.1490, 0.1724, 0.1382, 0.1595, 0.1781,\n",
      "        0.1481, 0.1352, 0.1734, 0.1504, 0.1650, 0.1725, 0.1543, 0.1574, 0.1577,\n",
      "        0.0887, 0.1561, 0.1213, 0.1658, 0.1775, 0.1095, 0.1513, 0.1735, 0.1667,\n",
      "        0.1462, 0.1412, 0.1668, 0.1694, 0.1636, 0.1528, 0.1657, 0.1632, 0.1625,\n",
      "        0.2010, 0.1611, 0.1728, 0.1500, 0.1597, 0.1486, 0.1701, 0.1464, 0.1146,\n",
      "        0.1532, 0.1670, 0.1568, 0.1395, 0.1343, 0.1532, 0.1596, 0.0366, 0.1771,\n",
      "        0.1911, 0.1582, 0.1351, 0.1604, 0.1816, 0.1360, 0.1690, 0.1400, 0.1434,\n",
      "        0.1456, 0.1805, 0.1581, 0.1714, 0.1910, 0.1414, 0.1296, 0.1957, 0.2067,\n",
      "        0.2178, 0.1840, 0.1359, 0.1811, 0.1302, 0.1692, 0.1416, 0.1924, 0.1325,\n",
      "        0.1807, 0.1697, 0.1604, 0.1838, 0.1452, 0.1575, 0.1618, 0.1758, 0.1399,\n",
      "        0.1715, 0.1480, 0.1717, 0.1403, 0.1764, 0.1517, 0.1642, 0.0565, 0.1649,\n",
      "        0.0498, 0.1348, 0.1783, 0.1715, 0.1444, 0.1780, 0.1751, 0.1212, 0.1607,\n",
      "        0.1669, 0.1451, 0.1753, 0.1401, 0.1267, 0.0997, 0.1111, 0.1645, 0.1930,\n",
      "        0.1395, 0.1626, 0.1765, 0.1102, 0.1223, 0.1766, 0.1639, 0.1184, 0.1561,\n",
      "        0.1214, 0.1498, 0.1599, 0.1545, 0.1635, 0.1417, 0.2070, 0.1367, 0.1426,\n",
      "        0.1380, 0.1503, 0.1637, 0.1617, 0.1702, 0.1523, 0.1734, 0.1737, 0.1443,\n",
      "        0.1267, 0.1765, 0.1667, 0.1112, 0.1130, 0.1366, 0.1913, 0.1368, 0.1289,\n",
      "        0.1817, 0.2239, 0.1416, 0.1816, 0.1280, 0.1769, 0.1937, 0.1898, 0.1548,\n",
      "        0.1835, 0.1124, 0.1708, 0.1360, 0.1550, 0.1683, 0.1755, 0.1612, 0.1777,\n",
      "        0.1932, 0.1577, 0.1820, 0.1896, 0.1882, 0.1392, 0.1669, 0.1336, 0.1698,\n",
      "        0.1691, 0.1484, 0.2101, 0.1559, 0.1778, 0.1589, 0.1682, 0.1695, 0.1837,\n",
      "        0.1713, 0.1394, 0.1934, 0.2026, 0.1377, 0.1664, 0.1269, 0.1321],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.0230, -0.0710,  0.2844,  ...,  0.5620, -0.1706,  0.2931],\n",
      "        [ 0.6779,  0.0381, -0.0080,  ..., -0.1697, -0.4003,  0.3526],\n",
      "        [ 0.1619,  0.4117,  0.1199,  ..., -0.0639, -0.1812, -0.4318],\n",
      "        ...,\n",
      "        [ 0.3586, -0.6550, -0.3814,  ...,  0.0430, -0.1679, -0.0894],\n",
      "        [-0.1705, -0.1184, -0.6527,  ...,  0.3425,  0.6270, -0.4216],\n",
      "        [ 0.0070,  0.4481,  0.4660,  ..., -0.1944,  0.0728,  0.7636]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.3013,  1.1251, -0.4047,  ...,  0.4832, -1.6559,  0.1260],\n",
      "        [-1.8833, -0.2423,  1.8235,  ...,  0.7284, -2.3694,  0.1611],\n",
      "        [ 0.9620,  0.2808,  0.8288,  ...,  1.8615,  1.7146,  1.1767],\n",
      "        ...,\n",
      "        [-1.9432,  1.8708, -0.6516,  ...,  0.9653, -0.0605,  0.5826],\n",
      "        [-0.7667,  0.7447, -0.2698,  ...,  0.3628, -0.0767,  0.5889],\n",
      "        [ 0.8807,  0.3227, -0.3475,  ..., -0.4251,  0.2772,  0.8669]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.7370, -0.0085, -0.6178,  ..., -1.0499, -0.1016,  0.6688],\n",
      "        [ 0.4568, -0.1189, -0.3728,  ...,  0.5104, -0.2044,  0.1952],\n",
      "        [ 0.0801,  0.0023,  0.1189,  ..., -0.3980,  0.4375,  0.3347],\n",
      "        ...,\n",
      "        [ 0.4572, -0.5289,  0.0787,  ...,  0.5625, -0.2016,  0.6397],\n",
      "        [ 0.3098,  0.3674, -0.8428,  ...,  0.2762, -0.9142,  0.5925],\n",
      "        [-0.5143, -0.1297,  0.0893,  ..., -0.0119, -0.2569, -0.3853]],\n",
      "       device='cuda:0')\n",
      "tensor([0.1232, 0.1127, 0.0925, 0.1106, 0.0951, 0.1275, 0.0328, 0.1034, 0.0824,\n",
      "        0.1308, 0.1092, 0.0501, 0.1064, 0.1085, 0.1007, 0.1486, 0.1305, 0.1011,\n",
      "        0.1028, 0.0955, 0.1139, 0.0811, 0.1054, 0.1077, 0.1094, 0.1051, 0.0905,\n",
      "        0.1099, 0.1044, 0.0777, 0.1025, 0.1101, 0.1510, 0.1006, 0.1139, 0.1121,\n",
      "        0.1092, 0.0976, 0.1183, 0.1159, 0.1207, 0.1298, 0.1307, 0.0915, 0.1075,\n",
      "        0.1123, 0.1034, 0.1257, 0.1084, 0.1277, 0.0999, 0.1186, 0.1082, 0.1201,\n",
      "        0.1062, 0.1094, 0.1082, 0.1126, 0.1014, 0.1095, 0.1196, 0.1083, 0.1225,\n",
      "        0.0962, 0.1352, 0.1018, 0.1038, 0.0953, 0.1184, 0.1015, 0.1521, 0.1091,\n",
      "        0.0996, 0.1128, 0.0950, 0.1091, 0.1029, 0.1135, 0.0430, 0.1078, 0.1161,\n",
      "        0.1131, 0.0926, 0.1030, 0.1137, 0.1097, 0.1091, 0.1186, 0.1158, 0.1078,\n",
      "        0.0962, 0.1091, 0.0914, 0.1064, 0.1175, 0.1145, 0.0983, 0.1003, 0.0941,\n",
      "        0.1046, 0.1000, 0.1129, 0.1116, 0.1052, 0.0960, 0.0957, 0.1148, 0.1129,\n",
      "        0.0922, 0.1159, 0.0950, 0.1025, 0.1312, 0.0990, 0.1169, 0.1130, 0.0764,\n",
      "        0.0973, 0.1157, 0.1197, 0.0924, 0.1082, 0.1060, 0.1134, 0.1070, 0.0977,\n",
      "        0.1062, 0.1104, 0.0998, 0.1118, 0.0998, 0.1200, 0.1092, 0.1018, 0.1012,\n",
      "        0.0959, 0.2457, 0.0974, 0.1187, 0.1251, 0.1175, 0.1165, 0.0990, 0.1132,\n",
      "        0.1056, 0.1122, 0.1048, 0.0964, 0.0930, 0.0973, 0.1105, 0.1169, 0.1063,\n",
      "        0.1083, 0.0970, 0.1104, 0.1022, 0.1115, 0.1001, 0.1017, 0.0856, 0.1171,\n",
      "        0.1018, 0.0208, 0.1268, 0.1244, 0.1119, 0.1118, 0.1010, 0.1072, 0.1038,\n",
      "        0.1009, 0.0915, 0.1116, 0.1126, 0.0924, 0.1183, 0.0749, 0.1282, 0.1172,\n",
      "        0.0914, 0.0892, 0.1209, 0.1017, 0.1011, 0.1123, 0.1084, 0.1220, 0.1011,\n",
      "        0.0950, 0.0972, 0.1043, 0.0898, 0.1088, 0.0902, 0.0811, 0.1146, 0.1024,\n",
      "        0.1015, 0.1183, 0.0988, 0.1018, 0.1037, 0.1145, 0.1033, 0.1104, 0.1095,\n",
      "        0.1041, 0.1081, 0.1263, 0.1205, 0.1050, 0.1023, 0.1063, 0.1122, 0.1121,\n",
      "        0.0921, 0.1236, 0.1228, 0.1077, 0.0819, 0.0809, 0.1064, 0.0855, 0.1164,\n",
      "        0.1019, 0.0918, 0.1025, 0.1088, 0.1120, 0.0930, 0.1080, 0.1074, 0.0997,\n",
      "        0.1169, 0.0844, 0.1185, 0.1042, 0.1154, 0.1102, 0.1074, 0.1037, 0.1063,\n",
      "        0.0939, 0.1061, 0.1221, 0.1036, 0.0933, 0.0928, 0.1085, 0.0900, 0.1153,\n",
      "        0.1118, 0.1092, 0.0823, 0.1029, 0.1030, 0.1079, 0.0970, 0.1281, 0.0998,\n",
      "        0.0883, 0.1056, 0.1145, 0.0993, 0.1249, 0.1222, 0.1111, 0.1142, 0.1125,\n",
      "        0.1211, 0.1051, 0.1130, 0.0940, 0.0894, 0.1067, 0.1122, 0.1206, 0.0987,\n",
      "        0.1136, 0.0966, 0.1079, 0.0848, 0.1125, 0.1014, 0.1211, 0.1129, 0.1102,\n",
      "        0.1145, 0.1015, 0.1143, 0.1029, 0.1095, 0.0914, 0.0903, 0.0895, 0.0978,\n",
      "        0.1081, 0.0888, 0.0869, 0.1094, 0.1317, 0.0847, 0.0981, 0.1005, 0.1245,\n",
      "        0.0940, 0.0820, 0.0893, 0.0857, 0.0961, 0.1131, 0.0919, 0.1082, 0.1276,\n",
      "        0.1237, 0.1148, 0.1213, 0.1208, 0.1088, 0.1063, 0.0987, 0.1047, 0.1232,\n",
      "        0.1138, 0.1042, 0.1119, 0.1169, 0.1123, 0.1327, 0.0970, 0.0998, 0.1181,\n",
      "        0.0559, 0.1293, 0.0830, 0.1095, 0.1134, 0.0759, 0.1103, 0.1161, 0.1087,\n",
      "        0.1180, 0.0867, 0.1070, 0.1115, 0.1178, 0.1036, 0.1016, 0.0915, 0.1067,\n",
      "        0.1228, 0.1121, 0.0876, 0.1141, 0.0969, 0.1227, 0.1108, 0.1032, 0.1120,\n",
      "        0.1053, 0.1051, 0.1096, 0.0900, 0.0936, 0.1125, 0.1038, 0.0280, 0.1022,\n",
      "        0.1252, 0.1360, 0.1022, 0.1155, 0.1012, 0.1035, 0.1060, 0.1082, 0.1150,\n",
      "        0.1094, 0.0854, 0.1001, 0.1075, 0.1048, 0.1085, 0.1019, 0.1351, 0.1330,\n",
      "        0.1164, 0.1093, 0.1056, 0.1290, 0.0890, 0.0938, 0.1051, 0.1182, 0.1117,\n",
      "        0.1266, 0.1114, 0.1086, 0.1035, 0.1007, 0.0939, 0.1029, 0.0936, 0.0871,\n",
      "        0.1104, 0.0963, 0.1198, 0.1063, 0.1183, 0.1213, 0.1200, 0.0412, 0.1201,\n",
      "        0.0420, 0.0933, 0.1010, 0.1165, 0.0966, 0.1083, 0.1098, 0.1077, 0.0957,\n",
      "        0.1111, 0.1137, 0.0898, 0.0990, 0.1080, 0.1117, 0.1016, 0.1176, 0.1281,\n",
      "        0.0952, 0.1048, 0.1215, 0.0993, 0.1019, 0.1221, 0.0907, 0.0803, 0.0951,\n",
      "        0.1018, 0.0955, 0.1064, 0.0953, 0.1095, 0.1008, 0.1144, 0.0996, 0.1055,\n",
      "        0.0852, 0.1184, 0.1147, 0.0962, 0.1264, 0.0981, 0.1135, 0.1188, 0.1024,\n",
      "        0.1211, 0.1158, 0.1028, 0.0992, 0.0915, 0.0934, 0.1085, 0.0815, 0.0941,\n",
      "        0.1301, 0.1128, 0.0916, 0.1116, 0.1051, 0.1075, 0.0915, 0.1068, 0.0910,\n",
      "        0.1055, 0.1038, 0.1025, 0.1067, 0.1032, 0.1155, 0.1123, 0.1068, 0.1145,\n",
      "        0.1214, 0.1073, 0.1113, 0.1096, 0.1252, 0.1234, 0.0958, 0.1153, 0.0932,\n",
      "        0.1089, 0.1141, 0.1184, 0.1047, 0.1289, 0.1180, 0.1210, 0.1081, 0.1000,\n",
      "        0.1098, 0.0971, 0.1016, 0.1202, 0.0992, 0.0759, 0.1128, 0.1705],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.0296,  0.0116,  0.0006,  ..., -0.0527, -0.0430, -0.0989],\n",
      "        [ 0.0458,  0.0422, -0.0009,  ..., -0.0301,  0.0362,  0.0481],\n",
      "        [ 0.0211,  0.0229,  0.0374,  ..., -0.0238,  0.0089,  0.0207],\n",
      "        ...,\n",
      "        [ 0.0454, -0.0648, -0.0775,  ...,  0.0103, -0.0188,  0.0353],\n",
      "        [-0.0313,  0.0546, -0.0419,  ...,  0.0469, -0.0692, -0.0434],\n",
      "        [-0.0175, -0.0251,  0.0349,  ..., -0.0139,  0.0681, -0.0586]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.1929, -0.3215, -0.2293,  ...,  0.1532, -0.0943, -0.8153],\n",
      "        [-0.1941, -0.0916, -0.3931,  ..., -0.1224,  0.0189, -0.2694],\n",
      "        [ 0.0787,  0.1191, -0.1289,  ...,  0.4136,  0.3041,  0.4122],\n",
      "        ...,\n",
      "        [ 0.4559, -0.2430, -0.3030,  ..., -0.4460, -0.2209,  0.0163],\n",
      "        [-0.3941,  0.0760, -0.0949,  ...,  0.3294, -0.5855, -0.1295],\n",
      "        [ 0.0363, -0.0219, -0.3075,  ...,  0.1229,  0.4039, -0.7101]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 1.2191, -0.2695, -0.7469,  ..., -0.2569,  1.1799,  0.4202],\n",
      "        [-0.5676,  0.1329,  0.3566,  ..., -0.1939,  1.1341,  0.4494],\n",
      "        [ 0.4016,  0.0072,  0.5335,  ...,  0.3752,  0.9870,  0.0329],\n",
      "        ...,\n",
      "        [ 1.0742,  0.0229, -0.8374,  ...,  0.6666,  0.5212, -0.0617],\n",
      "        [-0.2458,  0.2879,  0.6540,  ..., -0.7319, -0.1034, -0.7039],\n",
      "        [ 0.0880, -0.0090,  0.1097,  ...,  0.2104,  0.5318,  0.6484]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.0534,  1.4201,  0.8182,  ...,  0.7263,  1.7757, -0.1338],\n",
      "        [ 0.4596, -0.2153,  1.1054,  ...,  0.3383,  0.5752,  1.5294],\n",
      "        [-0.8414, -0.1804, -0.1197,  ...,  0.9777, -0.5575, -0.3992],\n",
      "        ...,\n",
      "        [-0.7585, -0.2401, -0.3390,  ...,  0.4781,  0.8036, -0.0187],\n",
      "        [ 0.8519, -0.3775,  0.7495,  ..., -0.4233,  0.4301,  0.5727],\n",
      "        [-0.4677, -0.6046,  0.1056,  ...,  0.3093,  0.4790, -0.0975]],\n",
      "       device='cuda:0')\n",
      "tensor([0.1942, 0.1605, 0.1594, 0.1737, 0.1584, 0.1874, 0.0528, 0.1853, 0.1558,\n",
      "        0.2133, 0.1902, 0.0778, 0.1594, 0.1387, 0.1695, 0.2099, 0.1524, 0.1415,\n",
      "        0.1791, 0.1235, 0.1422, 0.1429, 0.1541, 0.2279, 0.1493, 0.1308, 0.1188,\n",
      "        0.1966, 0.1635, 0.1578, 0.1499, 0.1513, 0.2034, 0.1277, 0.1800, 0.1665,\n",
      "        0.1378, 0.1807, 0.1698, 0.1327, 0.1668, 0.1658, 0.1728, 0.1334, 0.1295,\n",
      "        0.1511, 0.1448, 0.2111, 0.1577, 0.1974, 0.1433, 0.1595, 0.1537, 0.2042,\n",
      "        0.1811, 0.1786, 0.1380, 0.1633, 0.1285, 0.1352, 0.1574, 0.1404, 0.2041,\n",
      "        0.1641, 0.1792, 0.1878, 0.1378, 0.1800, 0.1711, 0.1328, 0.1889, 0.1411,\n",
      "        0.1534, 0.1472, 0.1292, 0.1529, 0.1515, 0.1939, 0.0476, 0.1778, 0.1930,\n",
      "        0.1306, 0.1577, 0.1578, 0.1737, 0.1806, 0.1363, 0.1589, 0.1767, 0.1481,\n",
      "        0.1521, 0.1160, 0.1599, 0.1462, 0.1970, 0.1803, 0.1469, 0.1868, 0.1387,\n",
      "        0.1462, 0.1430, 0.1525, 0.1623, 0.1365, 0.1581, 0.1456, 0.1895, 0.1522,\n",
      "        0.1329, 0.1734, 0.1268, 0.1454, 0.1293, 0.1235, 0.1472, 0.1542, 0.1238,\n",
      "        0.1490, 0.1767, 0.1865, 0.1695, 0.1898, 0.1188, 0.1640, 0.1387, 0.1659,\n",
      "        0.1717, 0.1373, 0.1480, 0.1191, 0.1399, 0.1407, 0.1532, 0.1231, 0.1524,\n",
      "        0.1554, 0.0330, 0.1827, 0.1397, 0.1399, 0.1749, 0.1835, 0.1461, 0.1572,\n",
      "        0.1500, 0.2168, 0.1443, 0.1615, 0.1604, 0.1464, 0.1626, 0.1772, 0.1193,\n",
      "        0.1688, 0.1727, 0.1602, 0.1817, 0.1325, 0.1483, 0.1562, 0.1785, 0.1428,\n",
      "        0.1330, 0.0445, 0.1583, 0.1445, 0.1450, 0.1727, 0.1506, 0.1514, 0.1772,\n",
      "        0.1570, 0.1441, 0.1380, 0.1514, 0.1495, 0.1756, 0.1279, 0.1492, 0.1841,\n",
      "        0.1354, 0.1656, 0.1680, 0.1422, 0.1566, 0.1657, 0.1364, 0.1497, 0.1802,\n",
      "        0.1413, 0.1579, 0.1373, 0.1758, 0.1937, 0.1462, 0.1256, 0.1433, 0.1768,\n",
      "        0.1520, 0.1418, 0.1314, 0.1606, 0.1804, 0.1734, 0.1350, 0.1645, 0.1632,\n",
      "        0.1402, 0.1716, 0.1392, 0.1828, 0.1711, 0.1577, 0.1443, 0.1644, 0.1529,\n",
      "        0.1705, 0.1712, 0.1539, 0.1999, 0.1586, 0.1411, 0.1803, 0.1707, 0.2043,\n",
      "        0.1458, 0.1558, 0.1285, 0.1441, 0.1627, 0.1459, 0.1616, 0.1226, 0.1659,\n",
      "        0.1793, 0.1232, 0.1645, 0.1693, 0.1825, 0.1444, 0.1342, 0.1365, 0.1831,\n",
      "        0.1127, 0.1519, 0.1622, 0.1666, 0.1427, 0.1511, 0.1511, 0.1362, 0.1491,\n",
      "        0.1578, 0.1636, 0.1440, 0.1609, 0.1642, 0.1784, 0.1827, 0.1997, 0.1733,\n",
      "        0.1483, 0.1493, 0.1768, 0.2032, 0.1698, 0.1819, 0.1874, 0.1579, 0.1392,\n",
      "        0.1529, 0.1698, 0.1533, 0.1616, 0.1444, 0.1486, 0.1744, 0.1759, 0.1578,\n",
      "        0.1823, 0.1434, 0.1295, 0.1245, 0.1365, 0.1475, 0.1625, 0.1624, 0.1609,\n",
      "        0.1829, 0.1257, 0.1769, 0.1430, 0.1678, 0.1511, 0.1447, 0.1212, 0.1678,\n",
      "        0.1319, 0.1668, 0.1779, 0.1554, 0.1531, 0.1582, 0.1814, 0.1460, 0.1762,\n",
      "        0.1669, 0.1241, 0.1235, 0.1482, 0.1469, 0.1688, 0.1349, 0.1693, 0.2168,\n",
      "        0.1881, 0.1712, 0.1418, 0.1659, 0.1379, 0.1548, 0.1425, 0.1396, 0.2034,\n",
      "        0.1500, 0.1373, 0.1847, 0.1492, 0.1678, 0.1303, 0.1405, 0.1347, 0.1512,\n",
      "        0.0782, 0.1825, 0.1723, 0.1796, 0.1560, 0.1407, 0.1732, 0.1386, 0.1432,\n",
      "        0.1506, 0.1440, 0.1776, 0.1369, 0.1891, 0.1476, 0.1590, 0.1318, 0.1450,\n",
      "        0.1503, 0.1379, 0.1636, 0.1625, 0.1600, 0.1404, 0.1475, 0.1602, 0.1367,\n",
      "        0.1659, 0.1968, 0.1530, 0.1423, 0.1299, 0.1915, 0.1360, 0.0486, 0.1444,\n",
      "        0.1781, 0.1740, 0.1620, 0.1671, 0.1769, 0.1432, 0.1380, 0.1645, 0.1640,\n",
      "        0.1700, 0.1737, 0.2045, 0.1324, 0.1215, 0.1886, 0.1223, 0.1966, 0.1961,\n",
      "        0.1783, 0.1693, 0.1828, 0.1996, 0.1463, 0.1623, 0.1683, 0.1719, 0.1442,\n",
      "        0.1675, 0.1689, 0.1622, 0.1679, 0.1292, 0.1317, 0.1773, 0.1535, 0.1349,\n",
      "        0.1591, 0.1682, 0.1796, 0.1268, 0.1564, 0.1616, 0.1666, 0.0882, 0.1629,\n",
      "        0.0614, 0.1322, 0.1493, 0.1599, 0.1410, 0.1703, 0.1685, 0.1476, 0.1439,\n",
      "        0.1393, 0.1317, 0.1500, 0.1464, 0.1555, 0.1356, 0.1533, 0.1432, 0.2154,\n",
      "        0.1656, 0.1419, 0.1621, 0.1340, 0.1418, 0.1598, 0.1381, 0.1396, 0.1352,\n",
      "        0.1729, 0.1444, 0.1560, 0.1407, 0.1627, 0.1767, 0.2124, 0.1383, 0.1763,\n",
      "        0.1392, 0.1625, 0.1584, 0.1446, 0.1700, 0.1260, 0.1801, 0.1564, 0.1355,\n",
      "        0.1332, 0.1732, 0.1277, 0.1266, 0.1473, 0.1342, 0.1824, 0.1328, 0.1347,\n",
      "        0.1628, 0.2030, 0.1553, 0.1797, 0.1427, 0.1520, 0.1761, 0.1855, 0.1504,\n",
      "        0.1463, 0.1455, 0.1870, 0.1644, 0.1863, 0.1755, 0.1830, 0.1683, 0.1781,\n",
      "        0.1972, 0.1659, 0.1819, 0.1667, 0.1955, 0.1619, 0.1688, 0.1596, 0.1665,\n",
      "        0.1791, 0.1288, 0.1796, 0.1686, 0.1651, 0.1499, 0.1649, 0.1645, 0.1583,\n",
      "        0.1724, 0.1351, 0.1712, 0.1500, 0.1401, 0.1434, 0.1435, 0.1241],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.1054,  0.1538, -0.5982,  ..., -0.0944, -0.4249, -0.4025],\n",
      "        [ 0.1215, -0.1733, -0.1078,  ...,  0.4639, -0.2310, -0.2021],\n",
      "        [-0.2877, -0.4137, -0.0182,  ...,  0.1178,  0.2248, -0.2221],\n",
      "        ...,\n",
      "        [-0.1090, -0.2388, -0.0308,  ..., -0.4781, -0.4913,  0.1057],\n",
      "        [-0.2794,  0.0624, -0.5493,  ..., -0.2158, -0.0360, -0.5135],\n",
      "        [-0.3184, -0.1827,  0.0653,  ...,  0.0490,  0.3724, -0.7620]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.2691,  0.9184, -1.0228,  ...,  1.0768, -1.3342, -1.1933],\n",
      "        [ 0.4323, -0.1161, -0.2116,  ..., -0.6886,  0.5536,  0.6920],\n",
      "        [ 0.6426, -0.0625, -0.0732,  ..., -0.6659, -0.6150,  0.4896],\n",
      "        ...,\n",
      "        [ 1.6698, -1.2995, -2.0133,  ..., -2.1555,  1.7878,  0.8185],\n",
      "        [ 0.1657,  0.8831,  0.2582,  ..., -0.3816,  0.2150, -1.5438],\n",
      "        [ 0.0961,  0.6729, -0.1435,  ..., -1.3300,  0.3215, -0.5108]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 6.4640e-01,  2.3067e-01,  7.7565e-01,  ...,  6.1611e-01,\n",
      "         -3.8776e-01,  2.3204e-01],\n",
      "        [-3.8636e-01,  1.9172e-01, -3.4505e-02,  ..., -4.1475e-01,\n",
      "         -4.6836e-01,  6.5517e-03],\n",
      "        [ 8.5121e-01,  1.6918e-01, -1.9259e-01,  ...,  8.9170e-02,\n",
      "          8.8171e-01,  5.1218e-01],\n",
      "        ...,\n",
      "        [-7.0105e-04,  1.0075e+00, -1.3750e+00,  ..., -3.6319e-02,\n",
      "          3.8751e-02,  4.0341e-01],\n",
      "        [ 1.9614e-01, -1.1280e-01, -9.0702e-01,  ...,  3.9621e-02,\n",
      "         -4.0999e-01, -8.1497e-01],\n",
      "        [-5.8833e-02,  1.3856e-01,  7.5030e-02,  ...,  2.5468e-01,\n",
      "         -3.3595e-01, -1.6024e-01]], device='cuda:0')\n",
      "tensor([0.1263, 0.1237, 0.1008, 0.1110, 0.1118, 0.1031, 0.0618, 0.1276, 0.1079,\n",
      "        0.1241, 0.1083, 0.0728, 0.1295, 0.1071, 0.1184, 0.1569, 0.1097, 0.1105,\n",
      "        0.1243, 0.0987, 0.1021, 0.0908, 0.1075, 0.1168, 0.0984, 0.1144, 0.1018,\n",
      "        0.1162, 0.1110, 0.1134, 0.1030, 0.1256, 0.1894, 0.1213, 0.1089, 0.1329,\n",
      "        0.1060, 0.1040, 0.1121, 0.1109, 0.1088, 0.1217, 0.1197, 0.1030, 0.1092,\n",
      "        0.1052, 0.1126, 0.1192, 0.0908, 0.1342, 0.1106, 0.1166, 0.1053, 0.1284,\n",
      "        0.1158, 0.1093, 0.1170, 0.1032, 0.1070, 0.1001, 0.1152, 0.1064, 0.1217,\n",
      "        0.1096, 0.1122, 0.0979, 0.0897, 0.1021, 0.1109, 0.0990, 0.1402, 0.0813,\n",
      "        0.1299, 0.1075, 0.1035, 0.1049, 0.1066, 0.1243, 0.0500, 0.1001, 0.1092,\n",
      "        0.0996, 0.1050, 0.1178, 0.1076, 0.1160, 0.1190, 0.1201, 0.1224, 0.1109,\n",
      "        0.1160, 0.1105, 0.1106, 0.1102, 0.1212, 0.1113, 0.1078, 0.1173, 0.1029,\n",
      "        0.1107, 0.0996, 0.1176, 0.1189, 0.0992, 0.1055, 0.1025, 0.1075, 0.0965,\n",
      "        0.1052, 0.0939, 0.1027, 0.1124, 0.1277, 0.1019, 0.1076, 0.1145, 0.0965,\n",
      "        0.1243, 0.1088, 0.1275, 0.1108, 0.1090, 0.1012, 0.1278, 0.1010, 0.0993,\n",
      "        0.0957, 0.1260, 0.1129, 0.1122, 0.1357, 0.1245, 0.1115, 0.0909, 0.0964,\n",
      "        0.1262, 0.2272, 0.1149, 0.1241, 0.1016, 0.1034, 0.1128, 0.1056, 0.1388,\n",
      "        0.0947, 0.1315, 0.1166, 0.1015, 0.1197, 0.1163, 0.1104, 0.1150, 0.1152,\n",
      "        0.1106, 0.1099, 0.1394, 0.1261, 0.1192, 0.1166, 0.1225, 0.1078, 0.1058,\n",
      "        0.1236, 0.0552, 0.1061, 0.1010, 0.1178, 0.1199, 0.1014, 0.1201, 0.1223,\n",
      "        0.1069, 0.1166, 0.1006, 0.1157, 0.1078, 0.1028, 0.1010, 0.1235, 0.1100,\n",
      "        0.0956, 0.1016, 0.1148, 0.1072, 0.1214, 0.1079, 0.0968, 0.1066, 0.1133,\n",
      "        0.0843, 0.1057, 0.0998, 0.1231, 0.1261, 0.0955, 0.1145, 0.1028, 0.1343,\n",
      "        0.1146, 0.1148, 0.1119, 0.1111, 0.1027, 0.1076, 0.1255, 0.1180, 0.1193,\n",
      "        0.1029, 0.1182, 0.1246, 0.1217, 0.1095, 0.1067, 0.0825, 0.1141, 0.1248,\n",
      "        0.1117, 0.1283, 0.1122, 0.1128, 0.1055, 0.1261, 0.0939, 0.1100, 0.1134,\n",
      "        0.1305, 0.0855, 0.1056, 0.1264, 0.1122, 0.0962, 0.1033, 0.0990, 0.1066,\n",
      "        0.1133, 0.1032, 0.1022, 0.1315, 0.1120, 0.1142, 0.1228, 0.0990, 0.1081,\n",
      "        0.1024, 0.1134, 0.1077, 0.1176, 0.0888, 0.0937, 0.1039, 0.0955, 0.1119,\n",
      "        0.1049, 0.0981, 0.0902, 0.1001, 0.1185, 0.0960, 0.0987, 0.1149, 0.0980,\n",
      "        0.1099, 0.1054, 0.1185, 0.1001, 0.1241, 0.1221, 0.1293, 0.1116, 0.0903,\n",
      "        0.1089, 0.1266, 0.0907, 0.1042, 0.1059, 0.1226, 0.1284, 0.1128, 0.1010,\n",
      "        0.1123, 0.0935, 0.1058, 0.0964, 0.1105, 0.1134, 0.1316, 0.1091, 0.1260,\n",
      "        0.0994, 0.1149, 0.1020, 0.1070, 0.1070, 0.0935, 0.1184, 0.1040, 0.1233,\n",
      "        0.1021, 0.1159, 0.0944, 0.1157, 0.0912, 0.1078, 0.1340, 0.1215, 0.1298,\n",
      "        0.0990, 0.0945, 0.1235, 0.0893, 0.0974, 0.1261, 0.1087, 0.1260, 0.1051,\n",
      "        0.1213, 0.1236, 0.1549, 0.1070, 0.1062, 0.1032, 0.1091, 0.1003, 0.1112,\n",
      "        0.1141, 0.1081, 0.0956, 0.1223, 0.1038, 0.1194, 0.1057, 0.0764, 0.1145,\n",
      "        0.0775, 0.1176, 0.1148, 0.1084, 0.1235, 0.0938, 0.1306, 0.0997, 0.1119,\n",
      "        0.1050, 0.0959, 0.1231, 0.1062, 0.1120, 0.1152, 0.1156, 0.1052, 0.1137,\n",
      "        0.1161, 0.1353, 0.0867, 0.1296, 0.1198, 0.1151, 0.1099, 0.0984, 0.1286,\n",
      "        0.0862, 0.1123, 0.1034, 0.1167, 0.1146, 0.1051, 0.1097, 0.0492, 0.1311,\n",
      "        0.1090, 0.1269, 0.1136, 0.1294, 0.1061, 0.0876, 0.1158, 0.0931, 0.0944,\n",
      "        0.0798, 0.1177, 0.1099, 0.0985, 0.1142, 0.1057, 0.1022, 0.1246, 0.1150,\n",
      "        0.1331, 0.1250, 0.1116, 0.1255, 0.1046, 0.1243, 0.1070, 0.1219, 0.1023,\n",
      "        0.0998, 0.1068, 0.1103, 0.1258, 0.1075, 0.1015, 0.1080, 0.1088, 0.0983,\n",
      "        0.1110, 0.1064, 0.1188, 0.1215, 0.1118, 0.1259, 0.1044, 0.0621, 0.1036,\n",
      "        0.0574, 0.1000, 0.1172, 0.0999, 0.1098, 0.1141, 0.1051, 0.1024, 0.1067,\n",
      "        0.0905, 0.1162, 0.1125, 0.1325, 0.1244, 0.1096, 0.1430, 0.1121, 0.1109,\n",
      "        0.1033, 0.1050, 0.1402, 0.1181, 0.1089, 0.1126, 0.1162, 0.0958, 0.1029,\n",
      "        0.1217, 0.1175, 0.1104, 0.1100, 0.0982, 0.1197, 0.1177, 0.1077, 0.1096,\n",
      "        0.1037, 0.1073, 0.1247, 0.1047, 0.1029, 0.1081, 0.1147, 0.1173, 0.1124,\n",
      "        0.1016, 0.1013, 0.1261, 0.1073, 0.0918, 0.0838, 0.0880, 0.0933, 0.1094,\n",
      "        0.1389, 0.1044, 0.1207, 0.1113, 0.1070, 0.1096, 0.1099, 0.1228, 0.0976,\n",
      "        0.1224, 0.1003, 0.1073, 0.0973, 0.1246, 0.1280, 0.1128, 0.1135, 0.1265,\n",
      "        0.1352, 0.1112, 0.1330, 0.1080, 0.1085, 0.1045, 0.1126, 0.1127, 0.1154,\n",
      "        0.1392, 0.0978, 0.1263, 0.1012, 0.0989, 0.1115, 0.1327, 0.1094, 0.1174,\n",
      "        0.1123, 0.0885, 0.1023, 0.1224, 0.1088, 0.0957, 0.1123, 0.1933],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.0095,  0.0171,  0.0271,  ..., -0.0637, -0.0258,  0.0800],\n",
      "        [ 0.0051,  0.0167, -0.0415,  ..., -0.0187,  0.0291, -0.1160],\n",
      "        [ 0.0026, -0.0073, -0.0272,  ...,  0.0285,  0.0569, -0.0124],\n",
      "        ...,\n",
      "        [ 0.0640, -0.0245,  0.0046,  ..., -0.0537,  0.0272, -0.0512],\n",
      "        [ 0.0111,  0.0708, -0.0464,  ...,  0.0139,  0.0144, -0.0089],\n",
      "        [-0.0187, -0.0124, -0.0350,  ..., -0.0347, -0.0026,  0.0418]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.3502,  0.1234, -0.1416,  ..., -0.2940,  0.1476,  0.1263],\n",
      "        [-0.2035,  0.1918, -0.0117,  ..., -0.2190, -0.1533, -0.4154],\n",
      "        [-0.0042, -0.0945,  0.4525,  ...,  0.3805, -0.0494, -0.0504],\n",
      "        ...,\n",
      "        [-0.2397, -0.0033,  0.2642,  ..., -0.3098, -0.0014, -0.3124],\n",
      "        [-0.3041, -0.5261, -0.3374,  ...,  0.1098, -0.1218, -0.3262],\n",
      "        [ 0.0352, -0.3201,  0.1801,  ...,  0.6802,  0.9949, -0.3933]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.8736,  0.2930,  1.0043,  ...,  0.5473, -0.1541, -0.9191],\n",
      "        [ 0.1222,  0.2856,  0.4367,  ..., -0.2573, -1.1956, -0.6107],\n",
      "        [ 0.5319, -0.0318,  0.4690,  ..., -0.3841,  1.2000, -0.3023],\n",
      "        ...,\n",
      "        [ 0.5675,  0.4023, -0.1622,  ...,  0.2667,  0.3683,  0.7574],\n",
      "        [-0.3759,  0.7314,  1.0229,  ...,  0.4810,  0.2541, -0.1967],\n",
      "        [ 0.5718, -1.0677, -0.0555,  ...,  1.0623, -0.3491, -0.3630]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.8338, -0.8219, -1.0525,  ..., -0.9248, -0.1176,  0.0861],\n",
      "        [-0.9570,  0.0627,  0.3532,  ...,  0.0484, -1.0376,  0.6172],\n",
      "        [ 0.4081, -0.6587, -0.3888,  ..., -0.8942, -0.4217, -0.1454],\n",
      "        ...,\n",
      "        [-0.4024,  0.8189, -0.7056,  ...,  0.1318, -0.3868,  0.1947],\n",
      "        [ 0.6713,  0.4099,  0.4271,  ..., -0.5568,  0.0347,  0.2522],\n",
      "        [ 1.1622,  0.1604, -0.2608,  ..., -0.5504,  0.2654, -0.2371]],\n",
      "       device='cuda:0')\n",
      "tensor([0.1442, 0.1808, 0.1498, 0.1695, 0.1476, 0.1642, 0.0676, 0.1514, 0.1409,\n",
      "        0.1721, 0.2028, 0.0810, 0.1428, 0.1158, 0.1738, 0.2138, 0.1608, 0.1619,\n",
      "        0.1603, 0.1395, 0.1265, 0.1075, 0.1736, 0.2109, 0.1949, 0.1550, 0.1588,\n",
      "        0.1720, 0.1696, 0.1478, 0.1591, 0.1395, 0.2156, 0.1281, 0.1746, 0.1749,\n",
      "        0.1386, 0.1671, 0.1610, 0.1524, 0.1602, 0.1343, 0.1675, 0.1420, 0.1413,\n",
      "        0.1783, 0.1606, 0.1744, 0.1605, 0.1819, 0.1479, 0.1623, 0.1625, 0.1444,\n",
      "        0.1665, 0.1551, 0.1405, 0.1525, 0.1567, 0.1473, 0.1502, 0.1324, 0.1831,\n",
      "        0.1645, 0.2087, 0.1873, 0.1718, 0.1632, 0.1400, 0.1546, 0.1435, 0.1322,\n",
      "        0.2011, 0.1690, 0.1051, 0.1570, 0.1718, 0.1664, 0.0709, 0.1525, 0.1870,\n",
      "        0.1538, 0.1788, 0.1782, 0.1502, 0.1610, 0.1547, 0.1811, 0.1867, 0.1421,\n",
      "        0.1536, 0.1530, 0.1687, 0.1860, 0.2092, 0.1816, 0.1774, 0.1540, 0.1488,\n",
      "        0.1355, 0.1519, 0.1583, 0.1729, 0.1817, 0.1767, 0.1573, 0.1612, 0.1651,\n",
      "        0.1235, 0.1477, 0.1283, 0.1439, 0.1783, 0.1641, 0.1607, 0.1477, 0.1439,\n",
      "        0.1678, 0.1994, 0.1969, 0.1461, 0.1809, 0.1468, 0.1929, 0.1274, 0.1590,\n",
      "        0.1473, 0.1746, 0.1379, 0.1557, 0.1355, 0.1535, 0.1677, 0.1722, 0.1518,\n",
      "        0.1483, 0.0037, 0.1633, 0.1621, 0.1755, 0.1817, 0.1674, 0.1368, 0.1667,\n",
      "        0.1700, 0.1927, 0.1861, 0.1187, 0.1521, 0.1727, 0.1667, 0.1516, 0.1312,\n",
      "        0.1526, 0.1442, 0.1447, 0.1075, 0.1870, 0.1674, 0.1732, 0.1626, 0.1514,\n",
      "        0.1394, 0.0459, 0.1604, 0.1570, 0.1707, 0.1850, 0.1468, 0.1673, 0.1816,\n",
      "        0.1826, 0.1812, 0.1592, 0.1434, 0.1644, 0.1674, 0.1712, 0.1650, 0.1581,\n",
      "        0.1318, 0.1632, 0.1434, 0.1740, 0.1431, 0.1631, 0.1564, 0.1548, 0.1638,\n",
      "        0.1639, 0.1773, 0.0763, 0.1736, 0.1837, 0.1410, 0.1532, 0.1956, 0.1667,\n",
      "        0.1642, 0.1217, 0.1410, 0.1325, 0.1237, 0.1684, 0.1512, 0.1713, 0.1744,\n",
      "        0.1388, 0.1717, 0.1154, 0.1713, 0.1640, 0.1360, 0.1416, 0.1696, 0.1485,\n",
      "        0.1965, 0.1635, 0.1549, 0.1847, 0.1355, 0.1542, 0.1651, 0.1496, 0.1653,\n",
      "        0.1455, 0.1907, 0.1789, 0.1572, 0.1413, 0.1197, 0.1500, 0.1424, 0.1486,\n",
      "        0.1689, 0.1419, 0.1922, 0.1651, 0.1702, 0.1288, 0.1648, 0.1720, 0.1777,\n",
      "        0.1350, 0.1504, 0.1855, 0.1649, 0.1456, 0.1465, 0.1622, 0.1666, 0.1679,\n",
      "        0.1722, 0.1589, 0.1618, 0.1658, 0.1704, 0.1514, 0.1779, 0.1679, 0.1613,\n",
      "        0.1387, 0.1409, 0.1722, 0.2071, 0.1617, 0.1524, 0.1788, 0.1728, 0.1439,\n",
      "        0.1702, 0.1425, 0.1551, 0.1624, 0.1711, 0.1541, 0.1715, 0.1786, 0.1255,\n",
      "        0.1768, 0.1252, 0.2075, 0.1472, 0.1441, 0.1520, 0.1731, 0.1437, 0.1488,\n",
      "        0.1989, 0.1227, 0.1820, 0.1340, 0.1636, 0.1618, 0.1594, 0.1600, 0.1740,\n",
      "        0.1596, 0.1482, 0.1430, 0.1673, 0.1522, 0.1396, 0.1863, 0.1779, 0.1408,\n",
      "        0.1615, 0.1571, 0.1524, 0.1432, 0.1515, 0.2016, 0.1671, 0.1382, 0.1711,\n",
      "        0.1710, 0.1600, 0.1789, 0.1652, 0.1527, 0.1425, 0.1661, 0.1576, 0.1471,\n",
      "        0.1653, 0.1628, 0.1571, 0.1547, 0.1453, 0.1824, 0.1272, 0.1691, 0.1664,\n",
      "        0.0936, 0.1420, 0.1795, 0.2107, 0.1813, 0.1435, 0.1986, 0.1323, 0.1679,\n",
      "        0.1467, 0.1080, 0.1978, 0.1436, 0.1873, 0.1663, 0.1735, 0.1400, 0.1745,\n",
      "        0.1352, 0.1614, 0.1629, 0.1606, 0.1814, 0.1478, 0.1421, 0.1817, 0.1776,\n",
      "        0.1486, 0.1657, 0.1483, 0.1770, 0.1526, 0.1610, 0.1604, 0.0316, 0.1748,\n",
      "        0.2066, 0.0956, 0.1641, 0.1609, 0.1266, 0.1221, 0.1543, 0.1286, 0.1356,\n",
      "        0.1449, 0.1534, 0.1671, 0.1535, 0.1490, 0.1861, 0.1419, 0.1744, 0.2001,\n",
      "        0.1363, 0.1532, 0.1336, 0.1666, 0.1394, 0.1604, 0.1257, 0.1841, 0.1543,\n",
      "        0.1723, 0.1593, 0.1520, 0.1887, 0.1565, 0.1348, 0.1645, 0.1796, 0.1582,\n",
      "        0.1817, 0.1477, 0.1713, 0.1413, 0.1557, 0.1450, 0.1486, 0.0888, 0.1814,\n",
      "        0.0703, 0.1435, 0.1739, 0.1799, 0.1208, 0.1662, 0.1848, 0.1427, 0.1885,\n",
      "        0.1498, 0.1365, 0.1687, 0.1611, 0.1683, 0.1361, 0.1419, 0.1609, 0.2121,\n",
      "        0.1132, 0.1585, 0.1233, 0.1470, 0.1543, 0.1710, 0.1787, 0.1423, 0.1649,\n",
      "        0.1479, 0.1436, 0.1348, 0.1578, 0.1666, 0.1214, 0.2128, 0.1318, 0.1564,\n",
      "        0.1569, 0.1301, 0.1483, 0.1552, 0.1308, 0.1383, 0.1441, 0.1750, 0.1700,\n",
      "        0.1380, 0.1584, 0.1741, 0.1364, 0.1405, 0.1108, 0.1929, 0.1703, 0.1315,\n",
      "        0.1593, 0.2021, 0.1654, 0.1417, 0.1548, 0.1335, 0.1947, 0.1566, 0.1445,\n",
      "        0.1710, 0.1568, 0.1598, 0.1621, 0.1613, 0.1651, 0.1898, 0.1715, 0.1759,\n",
      "        0.1618, 0.1579, 0.1739, 0.2014, 0.1976, 0.1232, 0.1489, 0.1993, 0.1642,\n",
      "        0.1467, 0.1613, 0.2350, 0.1605, 0.1784, 0.1856, 0.1906, 0.1777, 0.1876,\n",
      "        0.1893, 0.1562, 0.1793, 0.1272, 0.1662, 0.1544, 0.1311, 0.1324],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.1455, -0.1963,  0.0742,  ...,  0.2980, -0.2516,  0.0630],\n",
      "        [ 0.0274,  0.0242,  0.1764,  ...,  0.2456,  0.1024, -0.0069],\n",
      "        [-0.5507,  0.0117, -0.1271,  ..., -0.3875, -0.2990, -0.1763],\n",
      "        ...,\n",
      "        [ 0.0701, -0.2569,  0.2619,  ..., -0.0066,  0.1828, -0.1952],\n",
      "        [-0.3062, -0.4428, -0.4783,  ..., -0.0726, -0.0202, -0.3000],\n",
      "        [-0.3825, -0.0764,  0.0264,  ..., -0.3621, -0.4083, -0.2172]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.3419,  0.8267,  2.0531,  ..., -0.1422, -0.8513, -0.8456],\n",
      "        [-0.7332, -0.4469, -1.0129,  ..., -0.2486,  0.5221,  0.2022],\n",
      "        [-0.2474,  0.7311,  1.2656,  ...,  0.0550,  1.6105, -0.7364],\n",
      "        ...,\n",
      "        [-2.0335,  0.6453, -0.4817,  ..., -0.2708, -0.3649, -0.5522],\n",
      "        [-1.6002,  0.5023,  0.1956,  ..., -0.3542,  0.6120, -1.8666],\n",
      "        [-0.6866,  0.0471,  0.5726,  ..., -0.7862, -2.4831,  0.5107]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.7073, -0.2887,  0.3107,  ..., -0.4672,  0.5153, -0.7066],\n",
      "        [-0.3007,  0.6502,  0.0371,  ..., -0.5069, -0.8900, -0.5436],\n",
      "        [-0.2140,  0.2317, -0.1853,  ..., -1.3883, -0.0921,  0.1337],\n",
      "        ...,\n",
      "        [-1.0014,  0.8196,  0.3957,  ...,  0.0500, -0.1932, -0.4611],\n",
      "        [ 0.1685, -0.2085,  0.2950,  ..., -1.4738,  0.6142, -0.0565],\n",
      "        [ 0.2779, -0.5419,  0.3043,  ...,  0.8454,  0.8187,  0.0270]],\n",
      "       device='cuda:0')\n",
      "tensor([0.1387, 0.1400, 0.1330, 0.1055, 0.1356, 0.0973, 0.0541, 0.1275, 0.1243,\n",
      "        0.1216, 0.1357, 0.0635, 0.1333, 0.0952, 0.1276, 0.1317, 0.1226, 0.1214,\n",
      "        0.1362, 0.0968, 0.1244, 0.0975, 0.1089, 0.1061, 0.1143, 0.1340, 0.1324,\n",
      "        0.1140, 0.1092, 0.1044, 0.1331, 0.1230, 0.2755, 0.1113, 0.1265, 0.1115,\n",
      "        0.1010, 0.1231, 0.1210, 0.1195, 0.1022, 0.0994, 0.1218, 0.1367, 0.1096,\n",
      "        0.1222, 0.1324, 0.1244, 0.1358, 0.1161, 0.1113, 0.1246, 0.1125, 0.1154,\n",
      "        0.1177, 0.1028, 0.1112, 0.1273, 0.1013, 0.0880, 0.1182, 0.1018, 0.1155,\n",
      "        0.0827, 0.1218, 0.0972, 0.1172, 0.1134, 0.1264, 0.1172, 0.1332, 0.1149,\n",
      "        0.1320, 0.0944, 0.0877, 0.1347, 0.0998, 0.1084, 0.0907, 0.1258, 0.1156,\n",
      "        0.1266, 0.1386, 0.1327, 0.1115, 0.1337, 0.1310, 0.1380, 0.1447, 0.1259,\n",
      "        0.1188, 0.1332, 0.1083, 0.1320, 0.1186, 0.1326, 0.1229, 0.1197, 0.1184,\n",
      "        0.1230, 0.0935, 0.1160, 0.1137, 0.1120, 0.1169, 0.1493, 0.1420, 0.1025,\n",
      "        0.1215, 0.0997, 0.1122, 0.1031, 0.1331, 0.0919, 0.1205, 0.1195, 0.1345,\n",
      "        0.1261, 0.0983, 0.0956, 0.1072, 0.1156, 0.1147, 0.1056, 0.1047, 0.1111,\n",
      "        0.1085, 0.1259, 0.1106, 0.1218, 0.1281, 0.1041, 0.1080, 0.1255, 0.1289,\n",
      "        0.1089, 0.5421, 0.1263, 0.1247, 0.1111, 0.1250, 0.0941, 0.1206, 0.1225,\n",
      "        0.1037, 0.1411, 0.1303, 0.1065, 0.1131, 0.1118, 0.1094, 0.1023, 0.1114,\n",
      "        0.1046, 0.1207, 0.1161, 0.1020, 0.0728, 0.1152, 0.1201, 0.1469, 0.1270,\n",
      "        0.1015, 0.0806, 0.1217, 0.1098, 0.1151, 0.1465, 0.0986, 0.1115, 0.1381,\n",
      "        0.0896, 0.1131, 0.0943, 0.1120, 0.1091, 0.1281, 0.1090, 0.1192, 0.1211,\n",
      "        0.1316, 0.1227, 0.1193, 0.1089, 0.1081, 0.1039, 0.0899, 0.1106, 0.1256,\n",
      "        0.1200, 0.0929, 0.0995, 0.1122, 0.1380, 0.1241, 0.1050, 0.1231, 0.1027,\n",
      "        0.1192, 0.1266, 0.0995, 0.1194, 0.1165, 0.1232, 0.1523, 0.1316, 0.1121,\n",
      "        0.1243, 0.1135, 0.1124, 0.1227, 0.1080, 0.1411, 0.1145, 0.1255, 0.1237,\n",
      "        0.1148, 0.1174, 0.1354, 0.1136, 0.1152, 0.0990, 0.1178, 0.1229, 0.1178,\n",
      "        0.1115, 0.1124, 0.1182, 0.1094, 0.1072, 0.1135, 0.1180, 0.1189, 0.1076,\n",
      "        0.1138, 0.1041, 0.1316, 0.1324, 0.1056, 0.0979, 0.1098, 0.1017, 0.1123,\n",
      "        0.1046, 0.1128, 0.1316, 0.1030, 0.1048, 0.1292, 0.1380, 0.1243, 0.1122,\n",
      "        0.0811, 0.1023, 0.1053, 0.1055, 0.1252, 0.1110, 0.0903, 0.1050, 0.0845,\n",
      "        0.1102, 0.1141, 0.0995, 0.1105, 0.1247, 0.1520, 0.1038, 0.1416, 0.1225,\n",
      "        0.1300, 0.1164, 0.1218, 0.1030, 0.1048, 0.1222, 0.1491, 0.1160, 0.1040,\n",
      "        0.1325, 0.1075, 0.1242, 0.1143, 0.1045, 0.1248, 0.1045, 0.1242, 0.1087,\n",
      "        0.1125, 0.1328, 0.1479, 0.1253, 0.0914, 0.1332, 0.1210, 0.1266, 0.1463,\n",
      "        0.1232, 0.1087, 0.1192, 0.1307, 0.1186, 0.1213, 0.1115, 0.1076, 0.1479,\n",
      "        0.1069, 0.1091, 0.1023, 0.1154, 0.1035, 0.1286, 0.1101, 0.1150, 0.1079,\n",
      "        0.1020, 0.1094, 0.1435, 0.1200, 0.1324, 0.0941, 0.1396, 0.1138, 0.1247,\n",
      "        0.1235, 0.1187, 0.0956, 0.1080, 0.1264, 0.1023, 0.1147, 0.1274, 0.0964,\n",
      "        0.0837, 0.1144, 0.1180, 0.1195, 0.1253, 0.1128, 0.1606, 0.1069, 0.1076,\n",
      "        0.1325, 0.1128, 0.1161, 0.1111, 0.0938, 0.1355, 0.1323, 0.1135, 0.1433,\n",
      "        0.1257, 0.1254, 0.0998, 0.1255, 0.1174, 0.1198, 0.0904, 0.0954, 0.1057,\n",
      "        0.1295, 0.1080, 0.0828, 0.1221, 0.1208, 0.1056, 0.1233, 0.0734, 0.1112,\n",
      "        0.1386, 0.1523, 0.1262, 0.0965, 0.1191, 0.0937, 0.1067, 0.1004, 0.1412,\n",
      "        0.1447, 0.1059, 0.1227, 0.1005, 0.1014, 0.1373, 0.1295, 0.1049, 0.1394,\n",
      "        0.1463, 0.1196, 0.1189, 0.1537, 0.1269, 0.1253, 0.1086, 0.0962, 0.1181,\n",
      "        0.1181, 0.1133, 0.1091, 0.1014, 0.1458, 0.1221, 0.1101, 0.1082, 0.1087,\n",
      "        0.1315, 0.1285, 0.1258, 0.1184, 0.1111, 0.1096, 0.1259, 0.0843, 0.1305,\n",
      "        0.0500, 0.1241, 0.1127, 0.1079, 0.1316, 0.1354, 0.1203, 0.1300, 0.1185,\n",
      "        0.1045, 0.1328, 0.1207, 0.1137, 0.1349, 0.1385, 0.1191, 0.0918, 0.1261,\n",
      "        0.0996, 0.1241, 0.1107, 0.1232, 0.1245, 0.1272, 0.1294, 0.1037, 0.1142,\n",
      "        0.0941, 0.1190, 0.1209, 0.1271, 0.1139, 0.1187, 0.1147, 0.1173, 0.1194,\n",
      "        0.1122, 0.0817, 0.1205, 0.0948, 0.1162, 0.1024, 0.1323, 0.1169, 0.1308,\n",
      "        0.1092, 0.1175, 0.1294, 0.0986, 0.1197, 0.0992, 0.1132, 0.1025, 0.1132,\n",
      "        0.1133, 0.1036, 0.1023, 0.1280, 0.1412, 0.1272, 0.1041, 0.1298, 0.1178,\n",
      "        0.1173, 0.1336, 0.1061, 0.1137, 0.1233, 0.1198, 0.1145, 0.1132, 0.1119,\n",
      "        0.1452, 0.1216, 0.1371, 0.1150, 0.1166, 0.1087, 0.1245, 0.1273, 0.1098,\n",
      "        0.1515, 0.1036, 0.1147, 0.1123, 0.1261, 0.1152, 0.1555, 0.1266, 0.1110,\n",
      "        0.1244, 0.1247, 0.1104, 0.1268, 0.1291, 0.1081, 0.1400, 0.3745],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.0149, -0.0305,  0.0035,  ...,  0.0153, -0.0313,  0.0541],\n",
      "        [ 0.0144,  0.0495, -0.0144,  ...,  0.0110, -0.0008, -0.0238],\n",
      "        [ 0.0497,  0.0220, -0.0033,  ..., -0.0431, -0.0532, -0.0367],\n",
      "        ...,\n",
      "        [ 0.0013,  0.0007,  0.0241,  ..., -0.0393,  0.0253,  0.0331],\n",
      "        [ 0.0022,  0.0187,  0.0292,  ...,  0.0072,  0.0180,  0.0388],\n",
      "        [ 0.0166,  0.0464, -0.0141,  ...,  0.0150, -0.0368,  0.0600]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.0108,  0.1056,  0.2329,  ..., -0.1351,  0.2415,  0.0985],\n",
      "        [ 0.0356,  0.0262, -0.1691,  ...,  0.0650,  0.1284, -0.1561],\n",
      "        [ 0.2545,  0.2741, -0.0530,  ..., -0.0839,  0.1543,  0.4569],\n",
      "        ...,\n",
      "        [ 0.2313,  0.0418, -0.0786,  ...,  0.1156, -0.0061, -0.0253],\n",
      "        [-0.2015,  0.0211, -0.2194,  ..., -0.1741,  0.0834,  0.1050],\n",
      "        [ 0.1494, -0.0770, -0.1528,  ...,  0.1007, -0.3063,  0.2548]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.8060, -0.0618,  1.0012,  ...,  0.8880, -1.0053,  0.6818],\n",
      "        [-0.3076, -0.4140, -1.0441,  ..., -0.8168, -0.7093, -1.1185],\n",
      "        [ 1.1671, -0.5396,  0.8840,  ..., -0.3582, -0.1587,  1.1729],\n",
      "        ...,\n",
      "        [-0.0468, -0.1897, -1.0627,  ...,  0.5821,  0.0883,  1.4279],\n",
      "        [ 1.1775, -0.4526, -1.8912,  ...,  0.3011, -0.9490,  0.6667],\n",
      "        [ 0.8559,  0.8071,  0.1390,  ...,  0.3140,  1.3186,  0.4232]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.4946,  0.4353, -0.8547,  ...,  0.1562, -0.4691,  0.4337],\n",
      "        [ 0.5648, -0.5116,  0.3791,  ..., -1.8699, -1.8202, -2.2911],\n",
      "        [ 0.7001,  1.1402, -0.4139,  ...,  1.1650, -0.2904,  0.8226],\n",
      "        ...,\n",
      "        [ 1.0012, -0.8852,  0.0845,  ..., -0.4728, -0.1097, -0.1621],\n",
      "        [ 0.2427,  0.4414, -0.6966,  ..., -0.1931, -0.4026,  1.5279],\n",
      "        [ 0.3536, -0.1902,  0.2654,  ...,  0.3491, -0.9030, -0.2909]],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.2370,  0.1853,  0.1834,  0.1713,  0.1843,  0.1992,  0.0260,  0.1823,\n",
      "         0.1680,  0.1752,  0.2306,  0.0869,  0.1978,  0.1859,  0.1721,  0.2130,\n",
      "         0.1884,  0.1980,  0.1670,  0.1808,  0.1489,  0.1687,  0.1858,  0.2179,\n",
      "         0.2041,  0.1762,  0.1749,  0.1882,  0.1980,  0.2028,  0.1747,  0.1488,\n",
      "         0.2012,  0.1712,  0.1770,  0.2181,  0.1880,  0.1795,  0.1988,  0.1889,\n",
      "         0.2053,  0.1676,  0.2180,  0.1658,  0.1910,  0.1821,  0.1906,  0.2033,\n",
      "         0.1930,  0.1975,  0.2232,  0.1909,  0.1915,  0.2185,  0.1843,  0.1977,\n",
      "         0.1838,  0.2069,  0.1718,  0.1654,  0.1761,  0.2258,  0.2109,  0.2123,\n",
      "         0.1805,  0.2284,  0.1819,  0.1631,  0.1814,  0.1797,  0.1510,  0.1774,\n",
      "         0.1804,  0.1942,  0.1638,  0.1802,  0.2258,  0.2154,  0.0322,  0.1907,\n",
      "         0.2112,  0.1705,  0.1868,  0.2256,  0.2091,  0.2284,  0.1823,  0.1876,\n",
      "         0.2247,  0.1738,  0.1724,  0.1668,  0.2031,  0.1925,  0.2088,  0.2368,\n",
      "         0.2027,  0.2128,  0.1608,  0.1906,  0.1998,  0.1879,  0.1747,  0.1892,\n",
      "         0.2136,  0.1537,  0.2091,  0.2094,  0.1495,  0.1896,  0.1609,  0.1804,\n",
      "         0.1382,  0.1937,  0.2099,  0.1832,  0.1595,  0.1715,  0.1974,  0.2024,\n",
      "         0.1826,  0.2138,  0.1821,  0.2283,  0.1874,  0.1807,  0.1896,  0.2159,\n",
      "         0.2114,  0.2158,  0.1998,  0.1753,  0.1962,  0.1372,  0.1731,  0.1674,\n",
      "         0.0239,  0.2418,  0.2394,  0.2135,  0.2051,  0.2057,  0.1999,  0.1792,\n",
      "         0.2164,  0.2362,  0.1960,  0.1828,  0.1521,  0.1945,  0.1668,  0.2293,\n",
      "         0.1755,  0.1356,  0.2120,  0.1812,  0.1837,  0.2063,  0.1876,  0.1969,\n",
      "         0.1640,  0.1357,  0.1641,  0.0377,  0.1519,  0.1827,  0.2237,  0.2249,\n",
      "         0.1634,  0.1861,  0.2180,  0.1801,  0.2047,  0.1997,  0.1895,  0.1761,\n",
      "         0.2216,  0.1703,  0.2033,  0.1733,  0.1575,  0.1941,  0.1978,  0.1966,\n",
      "         0.1733,  0.1795,  0.1221,  0.2190,  0.2167,  0.1811,  0.1812,  0.0575,\n",
      "         0.1634,  0.2393,  0.1365,  0.1861,  0.2222,  0.2178,  0.1796,  0.1801,\n",
      "         0.1662,  0.1890,  0.2034,  0.1634,  0.1964,  0.1804,  0.2347,  0.1830,\n",
      "         0.2035,  0.1925,  0.2253,  0.1869,  0.1422,  0.2045,  0.2120,  0.1390,\n",
      "         0.2416,  0.1989,  0.1623,  0.1986,  0.1789,  0.1569,  0.1735,  0.1734,\n",
      "         0.2152,  0.1915,  0.2080,  0.1716,  0.1619,  0.1677,  0.2238,  0.2169,\n",
      "         0.1749,  0.1620,  0.1661,  0.1580,  0.1874,  0.1788,  0.2147,  0.1934,\n",
      "         0.2065,  0.2136,  0.1945,  0.1730,  0.2009,  0.2018,  0.2045,  0.1846,\n",
      "         0.2006,  0.1911,  0.1815,  0.1610,  0.2099,  0.1916,  0.1782,  0.2074,\n",
      "         0.1699,  0.1775,  0.1804,  0.2129,  0.2192,  0.1988,  0.1799,  0.1959,\n",
      "         0.2233,  0.1952,  0.2041,  0.2174,  0.2344,  0.1949,  0.1665,  0.2002,\n",
      "         0.2178,  0.1710,  0.1914,  0.2277,  0.1976,  0.2068,  0.1926,  0.1924,\n",
      "         0.1761,  0.1909,  0.1556,  0.1434,  0.2381,  0.1667,  0.1629,  0.1899,\n",
      "         0.1837,  0.1650,  0.1771,  0.1967,  0.1603,  0.2033,  0.1831,  0.2092,\n",
      "         0.2023,  0.1713,  0.1677,  0.1859,  0.1784,  0.2038,  0.1872,  0.2086,\n",
      "         0.1517,  0.1909,  0.1850,  0.1716,  0.2196,  0.1651,  0.1745,  0.2013,\n",
      "         0.1308,  0.1813,  0.2095,  0.2159,  0.1925,  0.2158,  0.1576,  0.2049,\n",
      "         0.2140,  0.2099,  0.1666,  0.2014,  0.2603,  0.2010,  0.2118,  0.2216,\n",
      "         0.1797,  0.2526,  0.1783,  0.1813,  0.1952,  0.1518,  0.1889,  0.2195,\n",
      "         0.2322,  0.2164,  0.1852,  0.1939,  0.2147,  0.1952,  0.2022,  0.2022,\n",
      "         0.2327,  0.1675,  0.2199,  0.1966,  0.1944,  0.1916,  0.1544,  0.2439,\n",
      "         0.1874,  0.2010,  0.1756,  0.2040,  0.1793,  0.1604,  0.1828,  0.2022,\n",
      "         0.2160,  0.2111,  0.1826,  0.1591,  0.1641,  0.1935,  0.1773,  0.0443,\n",
      "         0.2279,  0.2280, -0.0070,  0.1725,  0.1983,  0.1664,  0.1874,  0.1958,\n",
      "         0.1708,  0.1672,  0.1554,  0.1986,  0.2160,  0.1795,  0.2144,  0.1924,\n",
      "         0.1783,  0.1864,  0.2221,  0.1854,  0.1965,  0.1947,  0.2327,  0.2146,\n",
      "         0.2081,  0.1865,  0.2471,  0.1321,  0.1583,  0.1861,  0.1965,  0.1929,\n",
      "         0.2147,  0.1869,  0.1776,  0.1809,  0.2023,  0.1883,  0.1490,  0.2473,\n",
      "         0.1515,  0.2276,  0.2154,  0.1905,  0.0662,  0.2127,  0.0871,  0.1443,\n",
      "         0.1740,  0.1903,  0.1688,  0.1834,  0.1841,  0.1363,  0.2193,  0.2056,\n",
      "         0.2015,  0.1864,  0.1500,  0.2013,  0.1866,  0.1498,  0.2073,  0.2075,\n",
      "         0.1727,  0.1788,  0.1435,  0.1627,  0.1975,  0.1702,  0.1817,  0.1508,\n",
      "         0.1935,  0.2126,  0.2094,  0.1537,  0.1474,  0.1869,  0.1837,  0.2466,\n",
      "         0.1601,  0.1960,  0.1741,  0.1318,  0.2078,  0.1803,  0.1555,  0.1844,\n",
      "         0.2365,  0.2141,  0.2261,  0.1735,  0.2249,  0.1888,  0.1686,  0.2119,\n",
      "         0.1360,  0.2271,  0.1999,  0.1856,  0.2136,  0.2429,  0.1915,  0.1614,\n",
      "         0.1839,  0.1590,  0.2479,  0.1755,  0.1611,  0.2005,  0.1803,  0.1631,\n",
      "         0.1821,  0.1781,  0.1471,  0.1744,  0.1800,  0.1584,  0.1530,  0.1885,\n",
      "         0.1691,  0.2117,  0.2300,  0.1768,  0.2189,  0.2328,  0.1723,  0.1623,\n",
      "         0.1851,  0.2005,  0.1711,  0.1969,  0.1787,  0.1948,  0.1985,  0.1861,\n",
      "         0.1845,  0.2044,  0.2217,  0.1583,  0.1871,  0.1469,  0.2378,  0.1458],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.2593,  0.0092,  0.0264,  ...,  0.0681, -0.0129,  0.1355],\n",
      "        [-0.1810, -0.1638,  0.4324,  ...,  0.3112,  0.1856,  0.2865],\n",
      "        [ 0.1211,  0.0340, -0.1193,  ..., -0.0062, -0.2538, -0.1132],\n",
      "        ...,\n",
      "        [-0.1214,  0.1472, -0.2157,  ...,  0.1486, -0.1229,  0.1823],\n",
      "        [ 0.0140, -0.3171, -0.3766,  ..., -0.1211,  0.2781,  0.0839],\n",
      "        [-0.0973, -0.1128,  0.7342,  ..., -0.3054,  0.7265,  0.1433]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.1635,  0.7087,  1.3490,  ...,  1.0358, -0.6975, -0.6651],\n",
      "        [-0.9158,  0.1264, -1.3216,  ...,  1.8443,  0.1793, -0.7889],\n",
      "        [-0.1957,  0.0204, -0.7037,  ...,  1.0193,  2.3900,  0.5602],\n",
      "        ...,\n",
      "        [ 0.4522,  1.7046,  1.5011,  ..., -1.3418,  0.0768, -0.4364],\n",
      "        [-0.4395, -0.5280, -1.0232,  ...,  0.1067,  0.6287,  0.8972],\n",
      "        [ 0.6162,  0.2249, -0.4634,  ..., -2.3485,  2.3671, -0.4857]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.6033, -0.3176,  0.4901,  ..., -0.3204,  0.8506,  0.8085],\n",
      "        [-0.5741, -0.1806, -1.2887,  ..., -0.6827,  0.0527, -0.1515],\n",
      "        [-0.1892,  0.1940,  0.3168,  ...,  0.1689, -0.2152, -0.6771],\n",
      "        ...,\n",
      "        [ 1.1972,  0.2960,  0.7552,  ..., -0.0258, -0.6896,  0.4803],\n",
      "        [ 0.0870, -0.2064, -0.7920,  ...,  0.4757,  0.7425, -0.3535],\n",
      "        [-0.1424,  0.1074, -0.2610,  ...,  0.4171, -0.6245, -0.1161]],\n",
      "       device='cuda:0')\n",
      "tensor([0.0995, 0.1091, 0.0966, 0.0739, 0.1283, 0.1019, 0.0881, 0.0880, 0.1095,\n",
      "        0.0947, 0.0703, 0.0726, 0.1102, 0.1076, 0.1107, 0.1184, 0.0973, 0.1166,\n",
      "        0.1325, 0.0868, 0.1171, 0.0968, 0.1049, 0.0439, 0.1208, 0.1390, 0.1242,\n",
      "        0.1197, 0.0933, 0.1064, 0.1200, 0.1183, 0.4092, 0.1070, 0.0968, 0.1132,\n",
      "        0.0609, 0.1075, 0.0838, 0.1069, 0.1153, 0.0979, 0.1156, 0.1107, 0.0810,\n",
      "        0.0912, 0.0924, 0.1146, 0.1142, 0.0839, 0.1086, 0.1020, 0.1076, 0.0918,\n",
      "        0.1046, 0.0917, 0.0862, 0.0808, 0.0705, 0.1075, 0.0979, 0.1137, 0.0960,\n",
      "        0.0819, 0.1206, 0.1179, 0.1178, 0.0946, 0.0913, 0.0962, 0.1356, 0.0930,\n",
      "        0.1051, 0.0915, 0.1225, 0.1274, 0.1128, 0.1229, 0.1099, 0.1093, 0.0716,\n",
      "        0.0957, 0.1154, 0.0951, 0.0992, 0.1009, 0.1217, 0.0952, 0.1422, 0.1054,\n",
      "        0.1299, 0.0823, 0.0982, 0.1017, 0.0946, 0.1281, 0.1118, 0.0910, 0.1056,\n",
      "        0.1061, 0.1104, 0.1160, 0.0842, 0.0885, 0.1170, 0.1099, 0.1211, 0.0973,\n",
      "        0.1190, 0.1042, 0.1086, 0.0963, 0.1301, 0.1270, 0.1052, 0.0818, 0.1288,\n",
      "        0.0903, 0.1145, 0.0930, 0.0963, 0.1257, 0.1007, 0.0954, 0.1246, 0.0846,\n",
      "        0.0965, 0.1149, 0.1138, 0.1253, 0.1026, 0.1010, 0.0911, 0.1103, 0.1180,\n",
      "        0.0986, 0.9678, 0.1095, 0.1198, 0.0841, 0.1456, 0.1109, 0.1033, 0.0849,\n",
      "        0.0816, 0.0978, 0.0887, 0.0956, 0.1148, 0.1119, 0.1274, 0.1170, 0.1028,\n",
      "        0.1200, 0.1164, 0.0976, 0.0999, 0.1086, 0.1244, 0.1049, 0.1257, 0.1243,\n",
      "        0.0936, 0.0900, 0.0958, 0.1031, 0.1063, 0.1070, 0.0946, 0.0995, 0.0918,\n",
      "        0.0974, 0.1240, 0.0915, 0.1009, 0.0976, 0.1027, 0.1227, 0.1028, 0.0895,\n",
      "        0.1051, 0.1241, 0.1083, 0.1121, 0.1320, 0.1397, 0.0564, 0.1075, 0.0811,\n",
      "        0.1089, 0.1258, 0.0469, 0.0937, 0.0985, 0.0787, 0.1204, 0.0932, 0.1058,\n",
      "        0.0926, 0.1074, 0.1069, 0.1154, 0.1310, 0.0880, 0.1111, 0.1133, 0.1147,\n",
      "        0.1041, 0.0882, 0.1077, 0.1214, 0.1027, 0.1183, 0.1097, 0.1043, 0.0964,\n",
      "        0.1325, 0.1324, 0.1441, 0.0823, 0.1382, 0.1159, 0.0884, 0.1010, 0.1390,\n",
      "        0.1090, 0.0985, 0.1303, 0.1125, 0.0893, 0.1236, 0.1243, 0.1027, 0.0930,\n",
      "        0.0907, 0.0814, 0.1270, 0.0893, 0.0730, 0.1027, 0.1248, 0.0950, 0.1018,\n",
      "        0.1042, 0.1181, 0.1230, 0.0804, 0.0919, 0.1287, 0.0918, 0.1156, 0.1011,\n",
      "        0.0902, 0.1015, 0.1104, 0.0938, 0.1097, 0.1401, 0.1003, 0.0917, 0.0943,\n",
      "        0.1000, 0.1114, 0.0920, 0.0953, 0.0845, 0.1260, 0.1091, 0.1207, 0.0993,\n",
      "        0.0913, 0.1347, 0.1081, 0.0779, 0.1075, 0.0838, 0.1072, 0.0956, 0.0868,\n",
      "        0.0983, 0.1131, 0.0968, 0.1083, 0.0887, 0.1095, 0.1121, 0.1218, 0.0947,\n",
      "        0.0880, 0.1075, 0.1226, 0.0984, 0.1029, 0.1075, 0.1333, 0.1737, 0.1139,\n",
      "        0.1189, 0.1241, 0.0981, 0.0981, 0.0964, 0.0904, 0.0916, 0.1269, 0.0976,\n",
      "        0.0876, 0.1014, 0.1565, 0.1029, 0.0968, 0.1075, 0.0996, 0.0952, 0.0971,\n",
      "        0.0746, 0.0957, 0.1048, 0.1171, 0.1128, 0.0981, 0.1068, 0.1089, 0.0957,\n",
      "        0.0882, 0.1032, 0.1155, 0.1077, 0.1059, 0.1028, 0.1003, 0.1006, 0.0894,\n",
      "        0.0964, 0.0991, 0.1154, 0.1127, 0.1170, 0.0971, 0.1715, 0.1227, 0.1124,\n",
      "        0.1130, 0.1138, 0.0999, 0.0902, 0.0976, 0.1145, 0.1001, 0.1234, 0.0982,\n",
      "        0.1104, 0.1277, 0.1103, 0.1221, 0.1125, 0.0959, 0.0973, 0.0673, 0.1643,\n",
      "        0.1074, 0.1150, 0.0852, 0.1018, 0.1138, 0.1002, 0.1096, 0.0710, 0.1126,\n",
      "        0.1250, 0.1876, 0.1173, 0.0895, 0.0843, 0.0946, 0.1073, 0.1026, 0.1046,\n",
      "        0.0879, 0.0936, 0.1061, 0.0857, 0.1123, 0.0934, 0.1076, 0.0978, 0.1120,\n",
      "        0.1147, 0.1175, 0.0822, 0.1150, 0.1157, 0.1057, 0.1021, 0.1131, 0.1042,\n",
      "        0.0997, 0.1014, 0.1133, 0.0860, 0.1353, 0.1038, 0.1035, 0.0883, 0.0750,\n",
      "        0.1012, 0.1007, 0.1259, 0.0987, 0.0865, 0.1044, 0.1013, 0.1554, 0.0937,\n",
      "        0.0498, 0.0914, 0.0938, 0.0856, 0.0956, 0.1048, 0.1202, 0.0723, 0.1293,\n",
      "        0.1223, 0.1367, 0.1216, 0.1121, 0.1012, 0.1256, 0.1176, 0.0684, 0.0985,\n",
      "        0.0927, 0.0787, 0.1218, 0.1265, 0.0885, 0.1069, 0.1204, 0.1127, 0.0769,\n",
      "        0.0957, 0.1198, 0.1159, 0.1060, 0.1076, 0.1113, 0.1036, 0.1136, 0.1127,\n",
      "        0.1003, 0.0918, 0.1156, 0.1059, 0.0761, 0.0937, 0.1076, 0.1289, 0.1593,\n",
      "        0.1045, 0.1067, 0.1451, 0.1008, 0.1114, 0.1189, 0.0789, 0.0905, 0.1147,\n",
      "        0.0868, 0.0974, 0.1060, 0.1059, 0.1268, 0.1160, 0.0977, 0.1250, 0.1140,\n",
      "        0.0961, 0.1326, 0.0953, 0.0986, 0.0973, 0.1247, 0.1410, 0.0973, 0.1016,\n",
      "        0.0959, 0.0816, 0.0974, 0.0992, 0.1090, 0.1222, 0.1138, 0.1294, 0.0857,\n",
      "        0.0938, 0.1000, 0.0999, 0.0808, 0.1030, 0.1043, 0.1016, 0.1235, 0.0892,\n",
      "        0.1028, 0.1164, 0.1152, 0.1094, 0.1368, 0.1099, 0.1012, 0.2730],\n",
      "       device='cuda:0')\n",
      "tensor([0.1744, 0.1376, 0.1904, 0.1201, 0.1570, 0.1726, 0.0331, 0.1377, 0.1816,\n",
      "        0.1678, 0.0943, 0.0663, 0.1734, 0.1590, 0.1680, 0.1815, 0.1782, 0.1683,\n",
      "        0.1488, 0.1849, 0.1586, 0.1391, 0.1625, 0.1390, 0.2296, 0.1960, 0.1782,\n",
      "        0.2023, 0.1310, 0.1560, 0.1582, 0.0868, 0.2960, 0.1823, 0.1571, 0.1702,\n",
      "        0.1634, 0.1796, 0.1671, 0.1861, 0.1628, 0.1277, 0.1807, 0.1468, 0.1575,\n",
      "        0.1108, 0.1383, 0.1177, 0.1864, 0.1697, 0.1694, 0.1355, 0.1523, 0.1715,\n",
      "        0.1669, 0.1275, 0.1803, 0.1523, 0.1402, 0.1389, 0.1213, 0.1559, 0.1604,\n",
      "        0.1285, 0.1156, 0.1377, 0.1870, 0.1491, 0.1665, 0.2106, 0.1342, 0.1863,\n",
      "        0.1886, 0.1893, 0.1333, 0.1926, 0.1686, 0.1430, 0.0366, 0.1762, 0.1252,\n",
      "        0.1604, 0.1497, 0.1497, 0.1324, 0.1449, 0.1662, 0.1459, 0.2153, 0.1305,\n",
      "        0.1600, 0.1709, 0.1691, 0.1607, 0.1369, 0.2017, 0.1352, 0.1279, 0.1547,\n",
      "        0.1797, 0.1686, 0.1468, 0.1463, 0.1514, 0.1672, 0.1485, 0.1442, 0.1635,\n",
      "        0.1921, 0.1335, 0.1920, 0.1438, 0.1350, 0.1936, 0.1772, 0.1859, 0.1873,\n",
      "        0.1546, 0.1629, 0.1225, 0.1462, 0.1520, 0.1648, 0.1336, 0.1507, 0.1416,\n",
      "        0.1434, 0.1830, 0.1867, 0.1934, 0.1424, 0.1373, 0.1529, 0.1648, 0.1894,\n",
      "        0.1392, 0.0214, 0.1696, 0.2201, 0.1368, 0.2095, 0.1685, 0.1586, 0.1278,\n",
      "        0.1857, 0.1183, 0.1527, 0.1466, 0.1571, 0.1757, 0.1426, 0.1515, 0.1624,\n",
      "        0.1158, 0.1717, 0.1779, 0.1583, 0.1372, 0.1648, 0.1875, 0.2003, 0.1123,\n",
      "        0.1516, 0.0272, 0.1520, 0.1754, 0.1745, 0.1683, 0.1632, 0.1362, 0.1382,\n",
      "        0.1428, 0.1555, 0.1962, 0.1291, 0.1827, 0.1648, 0.1812, 0.1722, 0.1542,\n",
      "        0.1748, 0.1820, 0.1513, 0.1767, 0.1722, 0.1501, 0.0883, 0.1737, 0.1515,\n",
      "        0.1630, 0.1759, 0.0774, 0.1460, 0.1630, 0.1414, 0.1755, 0.1646, 0.1901,\n",
      "        0.1619, 0.1379, 0.1658, 0.1958, 0.1833, 0.1597, 0.1884, 0.1440, 0.1749,\n",
      "        0.1539, 0.1430, 0.1111, 0.1269, 0.1535, 0.1397, 0.1672, 0.1301, 0.1513,\n",
      "        0.1800, 0.1877, 0.1807, 0.1539, 0.1697, 0.1686, 0.1404, 0.1424, 0.2211,\n",
      "        0.1777, 0.1438, 0.1489, 0.2155, 0.1689, 0.1726, 0.1847, 0.1778, 0.1694,\n",
      "        0.0926, 0.1809, 0.1457, 0.1387, 0.1839, 0.1372, 0.1539, 0.1451, 0.1411,\n",
      "        0.1462, 0.1862, 0.1782, 0.1951, 0.1641, 0.1382, 0.1599, 0.1159, 0.1351,\n",
      "        0.1871, 0.1338, 0.1652, 0.2028, 0.1716, 0.1768, 0.1738, 0.1445, 0.1676,\n",
      "        0.1571, 0.1865, 0.1505, 0.1601, 0.1560, 0.1504, 0.1342, 0.2025, 0.1650,\n",
      "        0.1336, 0.1621, 0.1442, 0.2022, 0.1145, 0.1995, 0.1866, 0.1617, 0.1478,\n",
      "        0.1514, 0.1561, 0.1747, 0.1805, 0.1852, 0.1584, 0.1464, 0.1385, 0.1542,\n",
      "        0.1570, 0.1505, 0.1435, 0.1940, 0.1342, 0.1977, 0.1405, 0.1489, 0.1221,\n",
      "        0.1868, 0.1328, 0.1613, 0.1229, 0.1200, 0.1423, 0.1453, 0.1746, 0.1781,\n",
      "        0.1383, 0.1501, 0.1971, 0.1276, 0.1626, 0.1795, 0.1551, 0.1371, 0.1451,\n",
      "        0.1743, 0.1122, 0.1575, 0.1470, 0.1678, 0.1401, 0.1796, 0.1506, 0.1641,\n",
      "        0.1361, 0.1814, 0.1375, 0.1605, 0.1492, 0.1325, 0.1592, 0.1618, 0.1648,\n",
      "        0.1143, 0.1621, 0.1534, 0.1655, 0.1841, 0.1568, 0.1415, 0.1734, 0.1428,\n",
      "        0.1666, 0.1611, 0.1448, 0.1504, 0.1533, 0.2030, 0.1354, 0.1555, 0.1916,\n",
      "        0.1829, 0.1587, 0.1625, 0.1663, 0.1498, 0.1540, 0.1985, 0.1612, 0.1925,\n",
      "        0.1561, 0.1736, 0.1306, 0.2102, 0.2092, 0.1525, 0.1953, 0.0079, 0.1730,\n",
      "        0.1817, 0.0316, 0.1824, 0.1502, 0.1423, 0.1869, 0.1653, 0.1240, 0.1815,\n",
      "        0.1479, 0.1432, 0.1747, 0.1147, 0.1724, 0.1552, 0.1878, 0.1462, 0.1338,\n",
      "        0.1301, 0.1534, 0.2026, 0.1652, 0.1749, 0.1562, 0.1697, 0.1692, 0.1645,\n",
      "        0.1763, 0.1331, 0.1298, 0.1147, 0.2046, 0.2028, 0.1678, 0.1299, 0.1718,\n",
      "        0.1765, 0.1298, 0.1814, 0.1684, 0.1867, 0.1651, 0.1524, 0.0546, 0.1941,\n",
      "        0.0564, 0.1583, 0.1421, 0.1525, 0.1977, 0.1747, 0.1596, 0.0875, 0.1677,\n",
      "        0.1838, 0.2105, 0.1567, 0.1748, 0.1840, 0.1637, 0.1486, 0.2010, 0.1315,\n",
      "        0.1348, 0.1594, 0.1312, 0.1588, 0.1655, 0.1783, 0.1656, 0.1755, 0.2056,\n",
      "        0.1712, 0.1815, 0.1271, 0.1625, 0.1610, 0.1825, 0.0805, 0.1873, 0.1714,\n",
      "        0.1787, 0.1473, 0.1734, 0.1581, 0.1357, 0.1690, 0.1463, 0.1583, 0.2181,\n",
      "        0.1599, 0.1540, 0.1873, 0.1564, 0.1935, 0.1596, 0.1761, 0.1770, 0.2317,\n",
      "        0.1975, 0.1878, 0.1578, 0.1547, 0.1855, 0.1712, 0.1691, 0.1554, 0.1661,\n",
      "        0.1575, 0.2237, 0.1213, 0.1317, 0.1371, 0.0938, 0.1556, 0.1831, 0.1308,\n",
      "        0.1230, 0.1488, 0.1351, 0.1417, 0.1514, 0.1706, 0.1325, 0.1186, 0.1381,\n",
      "        0.1478, 0.1594, 0.1200, 0.1303, 0.1657, 0.1642, 0.1478, 0.1773, 0.1639,\n",
      "        0.1804, 0.1691, 0.1452, 0.0999, 0.1845, 0.1455, 0.2015, 0.1697],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.0172, -0.0219,  0.0187,  ...,  0.0148,  0.0601, -0.0384],\n",
      "        [-0.0180,  0.0053,  0.0211,  ..., -0.0255,  0.0030,  0.0130],\n",
      "        [-0.0172, -0.0321, -0.0190,  ..., -0.0281, -0.0195,  0.0137],\n",
      "        ...,\n",
      "        [-0.0208,  0.0249,  0.0187,  ..., -0.0245, -0.0229,  0.0165],\n",
      "        [-0.0162,  0.0006,  0.0062,  ..., -0.0239,  0.0486,  0.0035],\n",
      "        [ 0.0295, -0.0186, -0.0094,  ..., -0.0200,  0.0184, -0.0045]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.0621, -0.0519,  0.0429,  0.0333, -0.0730,  0.0737, -0.0174,  0.0665,\n",
      "         -0.0179,  0.0606,  0.0556, -0.0463, -0.0452, -0.0373, -0.0519,  0.0512,\n",
      "          0.0406, -0.0307,  0.0245, -0.0609, -0.0006, -0.0506,  0.0184,  0.0274,\n",
      "          0.0235, -0.0585,  0.0461,  0.0291, -0.0641,  0.0308, -0.0363, -0.0405,\n",
      "         -0.0426,  0.0529,  0.0397, -0.0702,  0.0439, -0.0537,  0.0207, -0.0735,\n",
      "         -0.0735,  0.0239,  0.0483,  0.0213,  0.0236,  0.0526, -0.0493, -0.0714,\n",
      "          0.0398,  0.0354,  0.0567, -0.0484,  0.0220,  0.0298,  0.0323, -0.0493,\n",
      "         -0.0010, -0.0639, -0.0478, -0.0772, -0.0538, -0.0694, -0.0547,  0.0410,\n",
      "         -0.0704,  0.0090,  0.0256,  0.0474,  0.0639,  0.0136,  0.0577, -0.0371,\n",
      "          0.0434, -0.0519, -0.0602, -0.0406,  0.0461, -0.0344, -0.0441, -0.0027,\n",
      "         -0.0468, -0.0731,  0.0291, -0.0469, -0.0472, -0.0433, -0.0562, -0.0388,\n",
      "         -0.0578,  0.0452,  0.0267, -0.0223, -0.0484, -0.0680, -0.0470, -0.0540,\n",
      "          0.0359, -0.0642,  0.0586, -0.0738,  0.0275,  0.0518, -0.0650,  0.0331,\n",
      "          0.0378,  0.0637, -0.0423, -0.0565,  0.0354,  0.0541, -0.0084,  0.0329,\n",
      "         -0.0412, -0.0294, -0.0304, -0.0695, -0.0125,  0.0596,  0.0431, -0.0549,\n",
      "          0.0306, -0.0633,  0.0371, -0.0533,  0.0336,  0.0585,  0.0305, -0.0583,\n",
      "          0.0340, -0.0331, -0.0588,  0.0232,  0.0630, -0.0132,  0.0485,  0.0389,\n",
      "         -0.0582,  0.0229,  0.0414,  0.0619, -0.0731, -0.0517,  0.0346,  0.0589,\n",
      "         -0.0318,  0.0241,  0.0333,  0.0553,  0.0004,  0.0638, -0.0473, -0.0504,\n",
      "          0.0580, -0.0260, -0.0236, -0.0349, -0.0632,  0.0324, -0.0128, -0.0645,\n",
      "         -0.0444,  0.0365,  0.0503,  0.0155, -0.0145, -0.0386, -0.0225,  0.0274,\n",
      "          0.0519,  0.0430, -0.0599, -0.0104,  0.0087, -0.0607, -0.0570, -0.0648,\n",
      "          0.0362,  0.0601, -0.0471,  0.0635, -0.0553,  0.0182,  0.0329, -0.0237,\n",
      "          0.0190, -0.0667, -0.0562,  0.0280, -0.0590, -0.0346, -0.0760, -0.0353,\n",
      "         -0.0455, -0.0496, -0.0199, -0.0430,  0.0601,  0.0357,  0.0207, -0.0052,\n",
      "         -0.0412, -0.0637,  0.0502,  0.0347,  0.0259, -0.0573, -0.0668, -0.0714,\n",
      "         -0.0276, -0.0593, -0.0684, -0.0532, -0.0466, -0.0711, -0.0605,  0.0500,\n",
      "         -0.0401, -0.0487,  0.0361,  0.0206,  0.0583, -0.0603,  0.0278, -0.0543,\n",
      "         -0.0475, -0.0509, -0.0661,  0.0393, -0.0787,  0.0358, -0.0549, -0.0619,\n",
      "         -0.0473,  0.0232, -0.0683,  0.0350,  0.0119,  0.0002, -0.0168, -0.0549,\n",
      "          0.0468, -0.0513,  0.0418, -0.0463,  0.0304,  0.0510, -0.0427, -0.0650,\n",
      "          0.0653,  0.0731,  0.0574,  0.0514,  0.0553,  0.0207, -0.0660, -0.0570,\n",
      "         -0.0535, -0.0545, -0.0498, -0.0498, -0.0613, -0.0588,  0.0465, -0.0399,\n",
      "         -0.0682, -0.0583, -0.0546,  0.0239, -0.0614,  0.0614,  0.0435, -0.0158,\n",
      "         -0.0457, -0.0734, -0.0433,  0.0157, -0.0321,  0.0675,  0.0349,  0.0461,\n",
      "          0.0371, -0.0660,  0.0560,  0.0186,  0.0637, -0.0519,  0.0314,  0.0496,\n",
      "         -0.0560, -0.0398, -0.0723,  0.0324,  0.0377,  0.0382,  0.0664,  0.0442,\n",
      "          0.0610,  0.0266, -0.0085, -0.0367,  0.0274, -0.0640, -0.0480, -0.0617,\n",
      "         -0.0116,  0.0243, -0.0310, -0.0340, -0.0348, -0.0340, -0.0556,  0.0419,\n",
      "         -0.0059,  0.0143, -0.0370, -0.0434,  0.0422, -0.0561, -0.0602,  0.0291,\n",
      "         -0.0710, -0.0391,  0.0353,  0.0395,  0.0035, -0.0382, -0.0314,  0.0618,\n",
      "          0.0408, -0.0650,  0.0271, -0.0624, -0.0360, -0.0432,  0.0466, -0.0463,\n",
      "          0.0248, -0.0238, -0.0171,  0.0317, -0.0593, -0.0036,  0.0165,  0.0345,\n",
      "         -0.0528,  0.0482, -0.0384, -0.0508,  0.0236,  0.0541,  0.0206,  0.0519,\n",
      "          0.0483,  0.0388,  0.0631, -0.0616, -0.0578,  0.0378, -0.0604,  0.0021,\n",
      "         -0.0323,  0.0539, -0.0414, -0.0377,  0.0555,  0.0209,  0.0104, -0.0717,\n",
      "          0.0460,  0.0139,  0.0376,  0.0427, -0.0629,  0.0466,  0.0606, -0.0634,\n",
      "          0.0155,  0.0362, -0.0594,  0.0283, -0.0675,  0.0471, -0.0206, -0.0540,\n",
      "          0.0419,  0.0569,  0.0455, -0.0469,  0.0522,  0.0669,  0.0273, -0.0371,\n",
      "          0.0486,  0.0457,  0.0328, -0.0530, -0.0309, -0.0175, -0.0386, -0.0230,\n",
      "          0.0586, -0.0303,  0.0119, -0.0639,  0.0555,  0.0234, -0.0685,  0.0296,\n",
      "          0.0029,  0.0679,  0.0225,  0.0470,  0.0084,  0.0186,  0.0355,  0.0159,\n",
      "          0.0352, -0.0611, -0.0597, -0.0049,  0.0420, -0.0153, -0.0695,  0.0332,\n",
      "         -0.0433, -0.0592, -0.0651,  0.0151, -0.0455,  0.0330, -0.0318,  0.0614,\n",
      "         -0.0031, -0.0521, -0.0593, -0.0577,  0.0035, -0.0607, -0.0621,  0.0410,\n",
      "          0.0392,  0.0553, -0.0351, -0.0385, -0.0410, -0.0656, -0.0162,  0.0389,\n",
      "         -0.0707, -0.0738, -0.0756, -0.0353,  0.0472, -0.0628, -0.0493, -0.0563,\n",
      "         -0.0356, -0.0054, -0.0622,  0.0381,  0.0256,  0.0518,  0.0071, -0.0295,\n",
      "         -0.0369,  0.0113,  0.0010, -0.0353,  0.0325,  0.0423, -0.0750,  0.0095,\n",
      "         -0.0531,  0.0372,  0.0516,  0.0340, -0.0346,  0.0649,  0.0308, -0.0618,\n",
      "         -0.0210, -0.0714, -0.0621, -0.0257, -0.0606, -0.0393,  0.0674, -0.0455,\n",
      "          0.0283,  0.0455,  0.0627,  0.0375,  0.0378,  0.0367, -0.0488,  0.0462,\n",
      "          0.0336,  0.0425, -0.0800, -0.0558, -0.0445,  0.0509, -0.0472, -0.0403,\n",
      "          0.0386, -0.0426, -0.0526, -0.0215, -0.0731, -0.0340, -0.0528,  0.0086]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for x in B.values():\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('python38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d33c3b0ef123e851f98887a8750ca7da758e4ff258891935cfe6ff9c0394387"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
