{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd() \n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from T5 import *\n",
    "import torch\n",
    "from datasets import load_dataset,load_metric\n",
    "from transformers import T5Tokenizer,AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import torch_optimizer as optim\n",
    "from transformers.optimization import Adafactor, AdafactorSchedule\n",
    "from MT_hyperparams import seed_,max_length,target_language\n",
    "import torch.backends.cudnn as cudnn\n",
    "from utils import *\n",
    "from attention_params import *\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, SubsetRandomSampler\n",
    "from torch.autograd import Variable\n",
    "from losses import *\n",
    "from architect import *\n",
    "import logging\n",
    "import sys\n",
    "import transformers\n",
    "import time\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from os.path import exists\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(\"main\")\n",
    "\n",
    "\n",
    "parser.add_argument('--valid_num_points', type=int,             default = 10, help='validation data number')\n",
    "parser.add_argument('--train_num_points', type=int,             default = 100, help='train data number')\n",
    "parser.add_argument('--test_num_points', type=int,              default = 50, help='train data number')\n",
    "\n",
    "parser.add_argument('--batch_size', type=int,                   default=16,     help='Batch size')\n",
    "parser.add_argument('--train_w_num_points', type=int,           default=4,      help='train_w_num_points for each batch')\n",
    "parser.add_argument('--train_v_synthetic_num_points', type=int, default=8,      help='train_v_synthetic_num_points for each batch')\n",
    "parser.add_argument('--train_v_num_points', type=int,           default=0,      help='train_v_num_points for each batch')\n",
    "parser.add_argument('--train_A_num_points', type=int,           default=4,      help='train_A_num_points decay for each batch')\n",
    "\n",
    "parser.add_argument('--gpu', type=int,                          default=0,      help='gpu device id')\n",
    "parser.add_argument('--num_workers', type=int,                  default=0,      help='num_workers')\n",
    "parser.add_argument('--model_name_teacher', type=str,           default='google/t5-small-lm-adapt',      help='model_name')\n",
    "parser.add_argument('--model_name_student', type=str,           default='google/t5-small-lm-adapt',      help='model_name')\n",
    "parser.add_argument('--model_name_de2en', type=str,             default='Onlydrinkwater/t5-small-de-en-mt',      help='model_name')\n",
    "parser.add_argument('--exp_name', type=str,                     default='T5spec',      help='experiment name')\n",
    "parser.add_argument('--rep_num', type=int,                      default=50,      help='report times for 1 epoch')\n",
    "parser.add_argument('--test_num', type=int,                     default=8000,      help='test times for 1 epoch')\n",
    "\n",
    "parser.add_argument('--epochs', type=int,                       default=500,     help='num of training epochs')\n",
    "parser.add_argument('--pre_epochs', type=int,                   default=0,      help='train model W for x epoch first')\n",
    "parser.add_argument('--grad_clip', type=float,                  default=1,      help='gradient clipping')\n",
    "parser.add_argument('--grad_acc_count', type=float,             default=-1,      help='gradient accumulate steps')\n",
    "\n",
    "parser.add_argument('--w_lr', type=float,                       default=1e-3,   help='learning rate for w')\n",
    "parser.add_argument('--unrolled_w_lr', type=float,              default=1e-3,   help='learning rate for w')\n",
    "parser.add_argument('--v_lr', type=float,                       default=1e-3,   help='learning rate for v')\n",
    "parser.add_argument('--unrolled_v_lr', type=float,              default=1e-3,   help='learning rate for v')\n",
    "parser.add_argument('--A_lr', type=float,                       default=1e-3,   help='learning rate for A')\n",
    "parser.add_argument('--learning_rate_min', type=float,          default=1e-8,   help='learning_rate_min')\n",
    "parser.add_argument('--decay', type=float,                      default=1e-3,   help='weight decay')\n",
    "parser.add_argument('--beta1', type=float,                      default=0,    help='momentum')\n",
    "parser.add_argument('--beta2', type=float,                      default=0,    help='momentum')\n",
    "parser.add_argument('--warm', type=float,                       default=10,    help='warmup step')\n",
    "parser.add_argument('--num_step_lr', type=float,                default=2,    help='warmup step')\n",
    "parser.add_argument('--decay_lr', type=float,                   default=0.7,    help='warmup step')\n",
    "# parser.add_argument('--smoothing', type=float,                  default=0.1,    help='labelsmoothing')\n",
    "\n",
    "\n",
    "parser.add_argument('--traindata_loss_ratio', type=float,       default=0,    help='human translated data ratio')\n",
    "parser.add_argument('--syndata_loss_ratio', type=float,         default=1,    help='augmented dataset ratio')\n",
    "\n",
    "parser.add_argument('--valid_begin', type=int,                  default=1,      help='whether valid before train')\n",
    "parser.add_argument('--train_A', type=int,                      default=1 ,     help='whether train A')\n",
    "\n",
    "\n",
    "\n",
    "args = parser.parse_args(args=[])#(args=['--batch_size', '8',  '--no_cuda'])#used in ipynb\n",
    "args.test_num = args.test_num//args.batch_size * args.batch_size\n",
    "args.rep_num = args.rep_num//args.batch_size * args.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33monlydrinkwater\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.18 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.17"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>g:\\GitCode\\Self-teaching-for-machine-translation\\T5_newA\\wandb\\run-20220621_183042-xynxmp4g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/onlydrinkwater/Selftraining/runs/xynxmp4g\" target=\"_blank\">T5spec</a></strong> to <a href=\"https://wandb.ai/onlydrinkwater/Selftraining\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/onlydrinkwater/Selftraining/runs/xynxmp4g?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x2424d878550>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://wandb.ai/ check the running status online\n",
    "import wandb\n",
    "os.environ['WANDB_API_KEY']='a166474b1b7ad33a0549adaaec19a2f6d3f91d87'\n",
    "os.environ['WANDB_NAME']=args.exp_name\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "wandb.init(project=\"Selftraining\",config=args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/21 06:30:46 PM |\t  Reusing dataset wmt14 (C:\\Users\\kevin\\.cache\\huggingface\\datasets\\wmt14\\de-en\\1.0.0\\d239eaf0ff090d28da19b6bc9758e24634d84de0a1ef092f0b5c54e6f132d7e2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 14.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/21 06:30:46 PM |\t  Namespace(A_lr=0.001, batch_size=16, beta1=0, beta2=0, decay=0.001, decay_lr=0.7, epochs=500, exp_name='T5spec', gpu=0, grad_acc_count=-1, grad_clip=1, learning_rate_min=1e-08, model_name_de2en='Onlydrinkwater/t5-small-de-en-mt', model_name_student='google/t5-small-lm-adapt', model_name_teacher='google/t5-small-lm-adapt', num_step_lr=2, num_workers=0, pre_epochs=0, rep_num=48, syndata_loss_ratio=1, test_num=8000, test_num_points=50, train_A=1, train_A_num_points=4, train_num_points=100, train_v_num_points=0, train_v_synthetic_num_points=8, train_w_num_points=4, traindata_loss_ratio=0, unrolled_v_lr=0.001, unrolled_w_lr=0.001, v_lr=0.001, valid_begin=1, valid_num_points=10, w_lr=0.001, warm=10)\n",
      "06/21 06:30:46 PM |\t  DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 4508785\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 3000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 3003\n",
      "    })\n",
      "})\n",
      "06/21 06:30:46 PM |\t  {'translation': {'de': 'Ich bitte Sie, sich zu einer Schweigeminute zu erheben.', 'en': \"Please rise, then, for this minute' s silence.\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# logging file\n",
    "now = time.strftime(\"%Y-%m-%d-%H_%M_%S\", time.localtime(time.time()))\n",
    "\n",
    "log_format = '%(asctime)s |\\t  %(message)s'\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO,\n",
    "                    format=log_format, datefmt='%m/%d %I:%M:%S %p')\n",
    "fh = logging.FileHandler(os.path.join(\n",
    "    \"./log/\", now+'.txt'), 'w', encoding=\"UTF-8\")\n",
    "fh.setFormatter(logging.Formatter(log_format))\n",
    "logging.getLogger().addHandler(fh)\n",
    "dataset = load_dataset('wmt14', 'de-en')\n",
    "\n",
    "logging.info(args)\n",
    "logging.info(dataset)\n",
    "logging.info(dataset['train'][5])\n",
    "\n",
    "\n",
    "# Setting the seeds\n",
    "np.random.seed(seed_)\n",
    "torch.cuda.set_device(args.gpu)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cudnn.benchmark = True\n",
    "torch.manual_seed(seed_)\n",
    "cudnn.enabled = True\n",
    "torch.cuda.manual_seed(seed_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/21 06:30:47 PM |\t  modelsize:76.961152MB\n",
      "06/21 06:30:48 PM |\t  modelsize:76.961152MB\n",
      "06/21 06:30:50 PM |\t  modelsize:76.961152MB\n"
     ]
    }
   ],
   "source": [
    "modelname = args.model_name_teacher\n",
    "pretrained  =  AutoModelForSeq2SeqLM.from_pretrained(modelname)\n",
    "pathname = modelname.replace('/','')\n",
    "logging.info(f'modelsize:{count_parameters_in_MB(pretrained)}MB')\n",
    "\n",
    "if(exists(pathname+'.pt')==False):\n",
    "    logging.info(f'saving to {pathname}')\n",
    "    torch.save(pretrained,pathname+'.pt')\n",
    "\n",
    "modelname = args.model_name_student\n",
    "pretrained  =  AutoModelForSeq2SeqLM.from_pretrained(modelname)\n",
    "pathname = modelname.replace('/','')\n",
    "logging.info(f'modelsize:{count_parameters_in_MB(pretrained)}MB')\n",
    "if(exists(pathname+'.pt')==False):\n",
    "    logging.info(f'saving to {pathname}')\n",
    "    torch.save(pretrained,pathname+'.pt')\n",
    "\n",
    "modelname = args.model_name_de2en\n",
    "pretrained  =  AutoModelForSeq2SeqLM.from_pretrained(modelname)\n",
    "pathname = modelname.replace('/','')\n",
    "logging.info(f'modelsize:{count_parameters_in_MB(pretrained)}MB')\n",
    "if(exists(pathname+'.pt')==False):\n",
    "    logging.info(f'saving to {pathname}')\n",
    "    torch.save(pretrained,pathname+'.pt')\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/21 06:30:52 PM |\t  Loading cached shuffled indices for dataset at C:\\Users\\kevin\\.cache\\huggingface\\datasets\\wmt14\\de-en\\1.0.0\\d239eaf0ff090d28da19b6bc9758e24634d84de0a1ef092f0b5c54e6f132d7e2\\cache-8a0e8ff6dde4594c.arrow\n",
      "06/21 06:30:53 PM |\t  Loading cached shuffled indices for dataset at C:\\Users\\kevin\\.cache\\huggingface\\datasets\\wmt14\\de-en\\1.0.0\\d239eaf0ff090d28da19b6bc9758e24634d84de0a1ef092f0b5c54e6f132d7e2\\cache-5fa876205460c4a9.arrow\n",
      "06/21 06:30:53 PM |\t  Loading cached shuffled indices for dataset at C:\\Users\\kevin\\.cache\\huggingface\\datasets\\wmt14\\de-en\\1.0.0\\d239eaf0ff090d28da19b6bc9758e24634d84de0a1ef092f0b5c54e6f132d7e2\\cache-fd5b6295b346fe99.arrow\n",
      "06/21 06:30:53 PM |\t  train len: 96\n",
      "06/21 06:30:53 PM |\t  train_w_num_points_len: 24\n",
      "06/21 06:30:53 PM |\t  train_v_synthetic_num_points_len: 48\n",
      "06/21 06:30:53 PM |\t  train_v_num_points_len: 0\n",
      "06/21 06:30:53 PM |\t  train_A_num_points_len: 24\n",
      "06/21 06:30:53 PM |\t  valid len: 10\n",
      "06/21 06:30:53 PM |\t  test len: 50\n",
      "06/21 06:30:53 PM |\t  {'de': 'Der Konflikt vom Juni 1998 ist zurückgekehrt, und die Bevölkerung befindet sich erneut in Massen auf der Flucht.', 'en': 'translate English to German: The conflict of June 1998 has returned and people are once again fleeing in large numbers.'}\n",
      "06/21 06:30:53 PM |\t  {'de': 'Er wird von Co-Trainern wie Claude Makelele unterstützt, der auf derselben Position spielte wie ich.', 'en': \"translate English to German: He's supported by deputies like Claude Makelele, who played in the same position as me.\"}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# preprocess the data, make a dataloader\n",
    "import random\n",
    "modelname = args.model_name_teacher\n",
    "tokenizer = AutoTokenizer.from_pretrained('t5-small')\n",
    "criterion = torch.nn.CrossEntropyLoss( reduction='none')#teacher shouldn't have label smoothing, especially when student got same size.\n",
    "criterion_v = torch.nn.CrossEntropyLoss( reduction='none')#,label_smoothing=args.smoothing) #without LS, V may be too confident to that syn data, and LS do well for real data also.\n",
    "\n",
    "\n",
    "\n",
    "train = dataset['train'].shuffle(seed=seed_).select(range(args.train_num_points))\n",
    "valid = dataset['validation'].shuffle(seed=seed_).select(range(args.valid_num_points))\n",
    "test = dataset['test'].shuffle(seed=seed_).select(range(args.test_num_points))#[L_t+L_v:L_t+L_v+L_test]\n",
    "train = train['translation']\n",
    "valid = valid['translation']\n",
    "test = test['translation']\n",
    "def preprocess(dat):\n",
    "    for t in dat:\n",
    "        t['en'] = \"translate English to German: \" + t['en']  #needed for T5\n",
    "preprocess(train)\n",
    "preprocess(valid)\n",
    "preprocess(test)\n",
    "#TODO: Syn_input should be monolingual data, should try en-fo's en. cuz wmt may align\n",
    "num_batch = args.train_num_points//args.batch_size\n",
    "train = train[:args.batch_size*num_batch]\n",
    "logging.info(\"train len: %d\",len(train))\n",
    "\n",
    "'''\n",
    "each mini batch consist of : \n",
    "1. data to train W\n",
    "2. monolingual data to generate parallel data\n",
    "3. data to train V\n",
    "4. data to train A\n",
    "'''\n",
    "train_w_num_points_len = num_batch * args.train_w_num_points\n",
    "train_v_synthetic_num_points_len = num_batch * args.train_v_synthetic_num_points\n",
    "train_v_num_points_len = num_batch * args.train_v_num_points\n",
    "train_A_num_points_len = num_batch * args.train_A_num_points\n",
    "logging.info(\"train_w_num_points_len: %d\",train_w_num_points_len)\n",
    "logging.info(\"train_v_synthetic_num_points_len: %d\",train_v_synthetic_num_points_len)\n",
    "logging.info(\"train_v_num_points_len: %d\",train_v_num_points_len)\n",
    "logging.info(\"train_A_num_points_len: %d\",train_A_num_points_len)\n",
    "\n",
    "attn_idx_list = torch.arange(train_w_num_points_len).cuda()\n",
    "logging.info(\"valid len: %d\",len(valid))\n",
    "logging.info(\"test len: %d\" ,len(test))\n",
    "logging.info(train[2])\n",
    "logging.info(valid[2])\n",
    "# logging.info(test[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get train data start\n",
      "get train data end\n",
      "06/21 06:30:53 PM |\t  train data get\n",
      "06/21 06:30:53 PM |\t  train data loader get\n",
      "06/21 06:30:53 PM |\t  valid data loader get\n",
      "06/21 06:30:53 PM |\t  test data loader get\n"
     ]
    }
   ],
   "source": [
    "target_language  = 'de'\n",
    "train_data = get_train_Dataset(train, tokenizer)# Create the DataLoader for our training set.\n",
    "logging.info('train data get')\n",
    "train_dataloader = DataLoader(train_data, sampler= SequentialSampler(train_data), \n",
    "                        batch_size=args.batch_size, pin_memory=args.num_workers>0, num_workers=args.num_workers)\n",
    "logging.info('train data loader get')\n",
    "valid_data = get_aux_dataset(valid, tokenizer)# Create the DataLoader for our training set.\n",
    "valid_dataloader = DataLoader(valid_data, sampler=SequentialSampler(valid_data), \n",
    "                        batch_size=args.batch_size, pin_memory=args.num_workers>0, num_workers=args.num_workers)\n",
    "logging.info('valid data loader get')\n",
    "test_data = get_aux_dataset(test, tokenizer)# Create the DataLoader for our training set.\n",
    "test_dataloader = DataLoader(test_data, sampler=SequentialSampler(test_data),\n",
    "                        batch_size=args.batch_size, pin_memory=args.num_workers>0, num_workers=args.num_workers)#, sampler=RandomSampler(test_data)\n",
    "logging.info('test data loader get')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "A = attention_params(args)#half of train regarded as u\n",
    "A = A.cuda()\n",
    "\n",
    "\n",
    "\n",
    "# TODO: model loaded from saved model\n",
    "model_w = T5(criterion=criterion, tokenizer= tokenizer, args = args, name = 'model_w_in_main')\n",
    "model_w = model_w.cuda()\n",
    "w_optimizer = torch.optim.Adam(model_w.parameters(),  lr= args.w_lr ,  betas=(args.beta1, args.beta2) ,eps=1e-9 )\n",
    "# w_optimizer = Adafactor(model_w.parameters(), lr = args.w_lr ,scale_parameter=False, relative_step=False , warmup_init=False,clip_threshold=1,beta1=0,eps=( 1e-30,0.001))\n",
    "scheduler_w  =   StepLR(w_optimizer, step_size=1e10, gamma=args.decay_lr)\n",
    "# scheduler_w  = Scheduler(w_optimizer,dim_embed=512, warmup_steps=args.warm, initlr = args.w_lr)\n",
    "\n",
    "\n",
    "\n",
    "model_v = T5(criterion=criterion_v, tokenizer= tokenizer, args = args, name = 'model_v_in_main')\n",
    "model_v = model_v.cuda()\n",
    "v_optimizer = torch.optim.Adam(model_v.parameters(),  lr= args.v_lr ,  betas=(args.beta1,args.beta2) ,eps=1e-9  )\n",
    "# v_optimizer =Adafactor(model_v.parameters(), lr = args.v_lr ,scale_parameter=False, relative_step=False , warmup_init=False,clip_threshold=1,beta1=0,eps=( 1e-30,0.001))\n",
    "scheduler_v  =   StepLR(v_optimizer, step_size=1e10, gamma=args.decay_lr)\n",
    "# scheduler_v  = Scheduler(v_optimizer,dim_embed=512, warmup_steps=args.warm, initlr = args.v_lr)\n",
    "\n",
    "\n",
    "architect = Architect(model_w, model_v,  A, args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def my_test(_dataloader,model,epoch):\n",
    "    # logging.info(f\"GPU mem before test:{getGPUMem(device)}%\")\n",
    "    acc = 0\n",
    "    counter = 0\n",
    "    model.eval()\n",
    "    metric_sacrebleu =  load_metric('sacrebleu')\n",
    "    # metric_bleu =  load_metric('bleu')\n",
    "    \n",
    "    for step, batch in enumerate(_dataloader):\n",
    "        \n",
    "        test_dataloaderx = Variable(batch[0], requires_grad=False).to(device, non_blocking=False)[:args.train_w_num_points]\n",
    "        test_dataloaderx_attn = Variable(batch[1], requires_grad=False).to(device, non_blocking=False)[:args.train_w_num_points]\n",
    "        test_dataloadery = Variable(batch[2], requires_grad=False).to(device, non_blocking=False)[:args.train_w_num_points]\n",
    "        test_dataloadery_attn = Variable(batch[3], requires_grad=False).to(device, non_blocking=False)[:args.train_w_num_points]\n",
    "        ls = my_loss(test_dataloaderx,test_dataloaderx_attn,test_dataloadery,test_dataloadery_attn,model)\n",
    "        acc+= ls.item()\n",
    "        counter+= 1\n",
    "        pre = model.generate(test_dataloaderx)\n",
    "        x_decoded = tokenizer.batch_decode(test_dataloaderx,skip_special_tokens=True)\n",
    "        pred_decoded = tokenizer.batch_decode(pre,skip_special_tokens=True)\n",
    "        label_decoded =  tokenizer.batch_decode(test_dataloadery,skip_special_tokens=True)\n",
    "        \n",
    "        pred_str = [x  for x in pred_decoded]\n",
    "        label_str = [[x] for x in label_decoded]\n",
    "        # pred_list = [x.split()  for x in pred_decoded]\n",
    "        # label_list = [[x.split()] for x in label_decoded]\n",
    "        metric_sacrebleu.add_batch(predictions=pred_str, references=label_str)\n",
    "        # metric_bleu.add_batch(predictions=pred_list, references=label_list)\n",
    "        if  step==0:\n",
    "            logging.info(f'x_decoded[:2]:{x_decoded[:2]}')\n",
    "            logging.info(f'pred_decoded[:2]:{pred_decoded[:2]}')\n",
    "            logging.info(f'label_decoded[:2]:{label_decoded[:2]}')\n",
    "            \n",
    "            \n",
    "    logging.info('computing score...') \n",
    "    sacrebleu_score = metric_sacrebleu.compute()\n",
    "    # bleu_score = metric_bleu.compute()\n",
    "    logging.info('%s sacreBLEU : %f',model.name,sacrebleu_score['score'])#TODO:bleu may be wrong cuz max length\n",
    "    # logging.info('%s BLEU : %f',model.name,bleu_score['bleu'])\n",
    "    logging.info('%s test loss : %f',model.name,acc/(counter))\n",
    "    wandb.log({'sacreBLEU'+model.name: sacrebleu_score['score']})\n",
    "    wandb.log({'test_loss'+model.name: acc/counter})\n",
    "    # del test_dataloaderx,acc,counter,test_dataloaderx_attn,sacrebleu_score,bleu_score,test_dataloadery,test_dataloadery_attn,ls,pre,x_decoded,pred_decoded,label_decoded,pred_str,label_str,pred_list,label_list\n",
    "    # gc.collect()\n",
    "    # torch.cuda.empty_cache()\n",
    "    model.eval()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_train(epoch, _dataloader, validdataloader, w_model, v_model, architect, A, w_optimizer, v_optimizer, lr_w, lr_v, tot_iter):\n",
    "\n",
    "    objs_w = AvgrageMeter()\n",
    "    objs_v_syn = AvgrageMeter()\n",
    "    objs_v_train = AvgrageMeter()\n",
    "    objs_v_star_val = AvgrageMeter()\n",
    "    objs_v_val = AvgrageMeter()\n",
    "    improvement = 0\n",
    "    w_trainloss_acc = 0\n",
    "    # now  train_x is [num of batch, datasize], so its seperate batch for the code below\n",
    "    wsize = args.train_w_num_points\n",
    "    synsize = args.train_v_synthetic_num_points\n",
    "    vsize = args.train_v_num_points\n",
    "    vtrainsize = vsize+synsize\n",
    "    vtrainsize_total = train_v_num_points_len+train_v_synthetic_num_points_len\n",
    "    Asize = args.train_A_num_points\n",
    "    loader_len = len(_dataloader)\n",
    "    split_size = [wsize, synsize, vsize, Asize]\n",
    "    bs = args.batch_size\n",
    "    w_model.eval()\n",
    "    v_model.eval()\n",
    "\n",
    "    # w_model.reset()\n",
    "    # w_optimizer = torch.optim.Adam(model_w.parameters(),  lr= args.w_lr ,  betas=(args.beta1, args.beta2) ,eps=1e-9 )\n",
    "    # v_model.reset()\n",
    "    # v_optimizer = torch.optim.Adam(model_v.parameters(),  lr= args.w_lr ,  betas=(args.beta1, args.beta2) ,eps=1e-9 )\n",
    "    logging.info(f\"split size:{split_size}\")\n",
    "    for step, batch in enumerate(_dataloader):\n",
    "        tot_iter[0] += bs\n",
    "        \n",
    "\n",
    "        # logging.info(f\"GPU mem :{getGPUMem(device)}%\")\n",
    "        train_x = Variable(batch[0], requires_grad=False).to(\n",
    "            device, non_blocking=False)\n",
    "        train_x_attn = Variable(batch[1], requires_grad=False).to(\n",
    "            device, non_blocking=False)\n",
    "        train_y = Variable(batch[2], requires_grad=False).to(\n",
    "            device, non_blocking=False)\n",
    "        train_y_attn = Variable(batch[3], requires_grad=False).to(\n",
    "            device, non_blocking=False)\n",
    "        (input_w, input_syn, input_v, input_A_v) = torch.split(train_x, split_size)\n",
    "        (input_w_attn, input_syn_attn, input_v_attn,\n",
    "         input_A_v_attn) = torch.split(train_x_attn, split_size)\n",
    "        (output_w, _, output_v, output_A_v) = torch.split(train_y, split_size)\n",
    "        (output_w_attn, _, output_v_attn, output_A_v_attn) = torch.split(\n",
    "            train_y_attn, split_size)\n",
    "        # attn_idx = attn_idx_list[wsize*step:(wsize*step+wsize)]\n",
    "        if(True):# let v train on syn data and w data\n",
    "            input_v = input_w\n",
    "            input_v_attn = input_w_attn\n",
    "            output_v = output_w\n",
    "            output_v_attn = output_w_attn\n",
    "            vsize = wsize\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if (args.train_A == 1):\n",
    "            epsilon_w = args.unrolled_w_lr\n",
    "            epsilon_v  = args.unrolled_v_lr\n",
    "            v_star_val_loss = architect.step(input_w,  output_w, input_w_attn, output_w_attn, w_optimizer,\n",
    "                                             input_v, input_v_attn, output_v, output_v_attn, input_syn, input_syn_attn,\n",
    "                                             input_A_v, input_A_v_attn, output_A_v, output_A_v_attn, v_optimizer,\n",
    "                                             epsilon_w, epsilon_v)\n",
    "            objs_v_star_val.update(v_star_val_loss, Asize)\n",
    "                            \n",
    "        w_optimizer.zero_grad()\n",
    "        loss_w = CTG_loss(input_w, input_w_attn, output_w,\n",
    "                          output_w_attn, A, w_model)\n",
    "        w_trainloss_acc += loss_w.item()\n",
    "        loss_w.backward()\n",
    "        objs_w.update(loss_w.item(), wsize)\n",
    "        w_optimizer.step()\n",
    "\n",
    "        v_optimizer.zero_grad()\n",
    "        loss_aug = calc_loss_aug(input_syn, input_syn_attn, w_model, v_model)\n",
    "\n",
    "        loss = my_loss2(input_v, input_v_attn, output_v,\n",
    "                        output_v_attn, v_model)\n",
    "        v_loss = (args.traindata_loss_ratio*loss +\n",
    "                  loss_aug*args.syndata_loss_ratio)\n",
    "        v_loss.backward()\n",
    "        objs_v_syn.update(loss_aug.item(), synsize)\n",
    "        objs_v_train.update(loss.item(), vsize)\n",
    "        v_optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            valloss = my_loss2(input_A_v, input_A_v_attn,  output_A_v, output_A_v_attn,v_model)\n",
    "            objs_v_val.update(valloss.item(), Asize)\n",
    "            improvement += (v_star_val_loss-valloss.item())\n",
    "        progress = 100*(step)/(loader_len-1)\n",
    "        if(tot_iter[0] % args.test_num == 0 and tot_iter[0] != 0):\n",
    "            my_test(validdataloader, model_w, epoch)\n",
    "            my_test(validdataloader, model_v, epoch)\n",
    "            # logging.info(str((\"Attention Weights A : \", A.ReLU(A.alpha))))\n",
    "            torch.save(model_w,'./model/'+'model_w.pt')#+now+\n",
    "            torch.save(model_v,'./model/'+'model_v.pt')\n",
    "            torch.save(A,'./model/'+'A.pt')\n",
    "            torch.save(model_w.state_dict(),os.path.join(wandb.run.dir, \"model_w.pt\"))\n",
    "            torch.save(model_v.state_dict(),os.path.join(wandb.run.dir, \"model_v.pt\"))\n",
    "            torch.save(A.state_dict(),os.path.join(wandb.run.dir, \"A.pt\"))\n",
    "            wandb.save(\"./files/*.pt\", base_path=\"./files\", policy=\"live\")\n",
    "\n",
    "        if(tot_iter[0] % args.rep_num == 0 and tot_iter[0] != 0):\n",
    "            logging.info(f\"{progress:5.3}%:\\t  W_train_loss:{objs_w.avg:^.7f}\\tV_train_syn_loss:{objs_v_syn.avg:^.7f}\\tV_train_loss:{objs_v_train.avg:^.7f}\\t  V_star_val_loss:{objs_v_star_val.avg:^.7f}\\t  improvement:{(objs_v_star_val.avg-objs_v_val.avg):^.7f}\")\n",
    "            logging.info(f\"{A(input_w, input_w_attn, output_w,output_w_attn)}\")\n",
    "        \n",
    "            wandb.log({'W_train_loss': objs_w.avg})\n",
    "            wandb.log({'V_train_syn_loss': objs_v_syn.avg})\n",
    "            wandb.log({'V_train_loss': objs_v_train.avg})\n",
    "            wandb.log({'V_star_val_loss': objs_v_star_val.avg})\n",
    "            wandb.log({'V_val_loss': objs_v_val.avg})\n",
    "            objs_v_syn.reset()\n",
    "            objs_v_train.reset()\n",
    "            objs_w.reset()\n",
    "            objs_v_star_val.reset()\n",
    "            objs_v_val.reset()\n",
    "    return w_trainloss_acc, improvement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/21 06:30:54 PM |\t  \n",
      "\n",
      "  ----------------epoch:0,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:0.001----------------\n",
      "06/21 06:30:55 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 06:31:13 PM |\t   40.0%:\t  W_train_loss:5.4241039\tV_train_syn_loss:3.0303794\tV_train_loss:4.7872901\t  V_star_val_loss:4.7713785\t  improvement:0.0043373\n",
      "06/21 06:31:13 PM |\t  tensor([1.1702, 1.1626, 1.0514, 1.0948], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:31:29 PM |\t  1e+02%:\t  W_train_loss:5.6851352\tV_train_syn_loss:2.3956587\tV_train_loss:5.0007577\t  V_star_val_loss:5.6840108\t  improvement:0.0001782\n",
      "06/21 06:31:29 PM |\t  tensor([1.3927, 1.1114, 1.4362, 1.2568], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:31:29 PM |\t  w_train_loss:33.327717304229736,improvement:0.013546466827392578\n",
      "06/21 06:31:29 PM |\t  \n",
      "\n",
      "  ----------------epoch:1,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:0.001----------------\n",
      "06/21 06:31:30 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 06:31:46 PM |\t   40.0%:\t  W_train_loss:6.2127593\tV_train_syn_loss:3.0449329\tV_train_loss:4.7873435\t  V_star_val_loss:4.7453225\t  improvement:0.0055283\n",
      "06/21 06:31:46 PM |\t  tensor([1.3795, 1.3706, 1.1400, 1.2427], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:32:03 PM |\t  1e+02%:\t  W_train_loss:6.2044500\tV_train_syn_loss:2.4307292\tV_train_loss:4.9864734\t  V_star_val_loss:5.5619270\t  improvement:-0.0002996\n",
      "06/21 06:32:03 PM |\t  tensor([1.4834, 1.2064, 1.4948, 1.4024], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:32:03 PM |\t  w_train_loss:37.251627922058105,improvement:0.01568603515625\n",
      "06/21 06:32:03 PM |\t  \n",
      "\n",
      "  ----------------epoch:2,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:0.00049----------------\n",
      "06/21 06:32:03 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 06:32:19 PM |\t   40.0%:\t  W_train_loss:6.5168386\tV_train_syn_loss:3.0581033\tV_train_loss:4.7876078\t  V_star_val_loss:4.7454123\t  improvement:0.0071502\n",
      "06/21 06:32:19 PM |\t  tensor([1.4524, 1.4481, 1.2073, 1.3302], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:32:36 PM |\t  1e+02%:\t  W_train_loss:6.3492044\tV_train_syn_loss:2.4078422\tV_train_loss:4.9793903\t  V_star_val_loss:5.5902144\t  improvement:0.0001178\n",
      "06/21 06:32:36 PM |\t  tensor([1.4939, 1.2529, 1.4986, 1.4438], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:32:36 PM |\t  w_train_loss:38.59812879562378,improvement:0.021803855895996094\n",
      "06/21 06:32:36 PM |\t  \n",
      "\n",
      "  ----------------epoch:3,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:0.0007----------------\n",
      "06/21 06:32:36 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 06:32:52 PM |\t   40.0%:\t  W_train_loss:6.6383120\tV_train_syn_loss:3.0548767\tV_train_loss:4.7872462\t  V_star_val_loss:4.7490884\t  improvement:0.0057117\n",
      "06/21 06:32:52 PM |\t  tensor([1.4729, 1.4697, 1.2494, 1.3706], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:33:09 PM |\t  1e+02%:\t  W_train_loss:6.4189769\tV_train_syn_loss:2.4033559\tV_train_loss:4.9776711\t  V_star_val_loss:5.5808380\t  improvement:-0.0000275\n",
      "06/21 06:33:09 PM |\t  tensor([1.4968, 1.2824, 1.4994, 1.4616], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:33:09 PM |\t  w_train_loss:39.17186689376831,improvement:0.017052650451660156\n",
      "06/21 06:33:09 PM |\t  \n",
      "\n",
      "  ----------------epoch:4,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:0.000343----------------\n",
      "06/21 06:33:09 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 06:33:26 PM |\t   40.0%:\t  W_train_loss:6.7066951\tV_train_syn_loss:2.9206940\tV_train_loss:4.7872763\t  V_star_val_loss:4.7852381\t  improvement:0.0054194\n",
      "06/21 06:33:26 PM |\t  tensor([1.4807, 1.4779, 1.2770, 1.3918], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:33:42 PM |\t  1e+02%:\t  W_train_loss:6.4471246\tV_train_syn_loss:2.4096483\tV_train_loss:5.0225588\t  V_star_val_loss:5.6639239\t  improvement:0.0003030\n",
      "06/21 06:33:42 PM |\t  tensor([1.4976, 1.2966, 1.4996, 1.4682], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:33:42 PM |\t  w_train_loss:39.461459159851074,improvement:0.017167091369628906\n",
      "06/21 06:33:42 PM |\t  \n",
      "\n",
      "  ----------------epoch:5,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:0.00049----------------\n",
      "06/21 06:33:43 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 06:33:59 PM |\t   40.0%:\t  W_train_loss:6.7474500\tV_train_syn_loss:2.9194648\tV_train_loss:4.7871215\t  V_star_val_loss:4.7842962\t  improvement:0.0054375\n",
      "06/21 06:33:59 PM |\t  tensor([1.4844, 1.4816, 1.2963, 1.4047], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:34:16 PM |\t  1e+02%:\t  W_train_loss:6.4691261\tV_train_syn_loss:2.4158233\tV_train_loss:5.0236130\t  V_star_val_loss:5.6648938\t  improvement:-0.0001243\n",
      "06/21 06:34:16 PM |\t  tensor([1.4981, 1.3080, 1.4997, 1.4727], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:34:16 PM |\t  w_train_loss:39.649728298187256,improvement:0.015939712524414062\n",
      "06/21 06:34:16 PM |\t  \n",
      "\n",
      "  ----------------epoch:6,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:0.00024009999999999998----------------\n",
      "06/21 06:34:16 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 06:34:32 PM |\t   40.0%:\t  W_train_loss:6.7817305\tV_train_syn_loss:2.9185596\tV_train_loss:4.7872310\t  V_star_val_loss:4.7834954\t  improvement:0.0054803\n",
      "06/21 06:34:32 PM |\t  tensor([1.4866, 1.4840, 1.3126, 1.4141], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:34:49 PM |\t  1e+02%:\t  W_train_loss:6.4853465\tV_train_syn_loss:2.4033369\tV_train_loss:5.0237532\t  V_star_val_loss:5.6650697\t  improvement:-0.0002357\n",
      "06/21 06:34:49 PM |\t  tensor([1.4984, 1.3166, 1.4997, 1.4754], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:34:49 PM |\t  w_train_loss:39.801230907440186,improvement:0.015733718872070312\n",
      "06/21 06:34:49 PM |\t  \n",
      "\n",
      "  ----------------epoch:7,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:0.000343----------------\n",
      "06/21 06:34:50 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 06:35:06 PM |\t   40.0%:\t  W_train_loss:6.8084909\tV_train_syn_loss:2.8351834\tV_train_loss:4.7920106\t  V_star_val_loss:4.7831473\t  improvement:0.0056561\n",
      "06/21 06:35:06 PM |\t  tensor([1.4880, 1.4854, 1.3257, 1.4206], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:35:22 PM |\t  1e+02%:\t  W_train_loss:6.4996675\tV_train_syn_loss:2.4073527\tV_train_loss:5.0249515\t  V_star_val_loss:5.7000111\t  improvement:-0.0000922\n",
      "06/21 06:35:22 PM |\t  tensor([1.4985, 1.3240, 1.4998, 1.4774], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:35:22 PM |\t  w_train_loss:39.92447519302368,improvement:0.01669168472290039\n",
      "06/21 06:35:22 PM |\t  \n",
      "\n",
      "  ----------------epoch:8,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:0.00016806999999999998----------------\n",
      "06/21 06:35:23 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 06:35:39 PM |\t   40.0%:\t  W_train_loss:6.8301962\tV_train_syn_loss:2.9178181\tV_train_loss:4.7918584\t  V_star_val_loss:4.7877997\t  improvement:0.0018832\n",
      "06/21 06:35:39 PM |\t  tensor([1.4889, 1.4863, 1.3358, 1.4254], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:35:55 PM |\t  1e+02%:\t  W_train_loss:6.5079989\tV_train_syn_loss:2.4034686\tV_train_loss:5.0327795\t  V_star_val_loss:5.6510941\t  improvement:-0.0001367\n",
      "06/21 06:35:55 PM |\t  tensor([1.4986, 1.3281, 1.4998, 1.4784], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:35:55 PM |\t  w_train_loss:40.01458549499512,improvement:0.0052394866943359375\n",
      "06/21 06:35:55 PM |\t  \n",
      "\n",
      "  ----------------epoch:9,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:0.00024009999999999998----------------\n",
      "06/21 06:35:56 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 06:36:12 PM |\t   40.0%:\t  W_train_loss:6.8433394\tV_train_syn_loss:2.8321778\tV_train_loss:4.7919189\t  V_star_val_loss:4.7824467\t  improvement:0.0049973\n",
      "06/21 06:36:12 PM |\t  tensor([1.4893, 1.4868, 1.3427, 1.4283], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:36:28 PM |\t  1e+02%:\t  W_train_loss:6.5143696\tV_train_syn_loss:2.4676747\tV_train_loss:5.0251683\t  V_star_val_loss:5.7241824\t  improvement:-0.0002117\n",
      "06/21 06:36:28 PM |\t  tensor([1.4987, 1.3317, 1.4998, 1.4791], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:36:28 PM |\t  w_train_loss:40.07312726974487,improvement:0.014356613159179688\n",
      "06/21 06:36:28 PM |\t  \n",
      "\n",
      "  ----------------epoch:10,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:0.00011764899999999998----------------\n",
      "06/21 06:36:29 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 06:36:45 PM |\t   40.0%:\t  W_train_loss:6.8556428\tV_train_syn_loss:2.8316702\tV_train_loss:4.7918599\t  V_star_val_loss:4.7827673\t  improvement:0.0053137\n",
      "06/21 06:36:45 PM |\t  tensor([1.4897, 1.4873, 1.3491, 1.4311], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:37:02 PM |\t  1e+02%:\t  W_train_loss:6.5208324\tV_train_syn_loss:2.4687980\tV_train_loss:5.0245973\t  V_star_val_loss:5.7238483\t  improvement:-0.0001516\n",
      "06/21 06:37:02 PM |\t  tensor([1.4987, 1.3353, 1.4998, 1.4796], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:37:02 PM |\t  w_train_loss:40.12942552566528,improvement:0.01548624038696289\n",
      "06/21 06:37:02 PM |\t  \n",
      "\n",
      "  ----------------epoch:11,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:0.00016806999999999998----------------\n",
      "06/21 06:37:02 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 06:37:18 PM |\t   40.0%:\t  W_train_loss:6.8655510\tV_train_syn_loss:2.8328319\tV_train_loss:4.7918709\t  V_star_val_loss:4.7820470\t  improvement:0.0054506\n",
      "06/21 06:37:18 PM |\t  tensor([1.4901, 1.4877, 1.3546, 1.4336], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:37:35 PM |\t  1e+02%:\t  W_train_loss:6.5270367\tV_train_syn_loss:2.4694946\tV_train_loss:5.0249437\t  V_star_val_loss:5.7313391\t  improvement:0.0000494\n",
      "06/21 06:37:35 PM |\t  tensor([1.4988, 1.3401, 1.4998, 1.4805], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:37:35 PM |\t  w_train_loss:40.17776298522949,improvement:0.016499996185302734\n",
      "06/21 06:37:35 PM |\t  \n",
      "\n",
      "  ----------------epoch:12,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:8.235429999999999e-05----------------\n",
      "06/21 06:37:35 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 06:37:51 PM |\t   40.0%:\t  W_train_loss:6.8792863\tV_train_syn_loss:2.7971580\tV_train_loss:4.7985064\t  V_star_val_loss:4.8041959\t  improvement:0.0083183\n",
      "06/21 06:37:51 PM |\t  tensor([1.4905, 1.4883, 1.3610, 1.4367], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:38:08 PM |\t  1e+02%:\t  W_train_loss:6.5337254\tV_train_syn_loss:2.4532358\tV_train_loss:5.0261537\t  V_star_val_loss:5.7572014\t  improvement:0.0011431\n",
      "06/21 06:38:08 PM |\t  tensor([1.4988, 1.3438, 1.4998, 1.4810], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:38:08 PM |\t  w_train_loss:40.23903512954712,improvement:0.02838420867919922\n",
      "06/21 06:38:08 PM |\t  \n",
      "\n",
      "  ----------------epoch:13,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:0.00011764899999999998----------------\n",
      "06/21 06:38:08 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 06:38:24 PM |\t   40.0%:\t  W_train_loss:6.8896583\tV_train_syn_loss:2.5721830\tV_train_loss:4.7981849\t  V_star_val_loss:4.8103911\t  improvement:-0.0262448\n",
      "06/21 06:38:24 PM |\t  tensor([1.4908, 1.4887, 1.3659, 1.4389], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:38:41 PM |\t  1e+02%:\t  W_train_loss:6.5416188\tV_train_syn_loss:2.3448836\tV_train_loss:5.0851997\t  V_star_val_loss:5.5853658\t  improvement:0.0002998\n",
      "06/21 06:38:41 PM |\t  tensor([1.4989, 1.3482, 1.4998, 1.4816], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:38:41 PM |\t  w_train_loss:40.29383134841919,improvement:-0.0778350830078125\n",
      "06/21 06:38:41 PM |\t  \n",
      "\n",
      "  ----------------epoch:14,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:5.764800999999999e-05----------------\n",
      "06/21 06:38:42 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 06:38:58 PM |\t   40.0%:\t  W_train_loss:6.8986766\tV_train_syn_loss:2.5722209\tV_train_loss:4.7983174\t  V_star_val_loss:4.8444935\t  improvement:0.0081561\n",
      "06/21 06:38:58 PM |\t  tensor([1.4911, 1.4890, 1.3701, 1.4408], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:39:14 PM |\t  1e+02%:\t  W_train_loss:6.5445960\tV_train_syn_loss:2.3454719\tV_train_loss:5.0633084\t  V_star_val_loss:5.5443840\t  improvement:-0.0115188\n",
      "06/21 06:39:14 PM |\t  tensor([1.4989, 1.3503, 1.4998, 1.4820], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:39:14 PM |\t  w_train_loss:40.32981777191162,improvement:-0.010087966918945312\n",
      "06/21 06:39:14 PM |\t  \n",
      "\n",
      "  ----------------epoch:15,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:8.235429999999999e-05----------------\n",
      "06/21 06:39:15 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 06:39:31 PM |\t   40.0%:\t  W_train_loss:6.9035298\tV_train_syn_loss:2.6041188\tV_train_loss:4.7915748\t  V_star_val_loss:4.8308139\t  improvement:0.0063787\n",
      "06/21 06:39:31 PM |\t  tensor([1.4912, 1.4891, 1.3724, 1.4418], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:39:47 PM |\t  1e+02%:\t  W_train_loss:6.5471182\tV_train_syn_loss:2.3551426\tV_train_loss:5.0357703\t  V_star_val_loss:5.5310764\t  improvement:0.0040104\n",
      "06/21 06:39:47 PM |\t  tensor([1.4989, 1.3515, 1.4998, 1.4822], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:39:47 PM |\t  w_train_loss:40.35194396972656,improvement:0.031167030334472656\n",
      "06/21 06:39:47 PM |\t  \n",
      "\n",
      "  ----------------epoch:16,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:4.035360699999999e-05----------------\n",
      "06/21 06:39:48 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 06:40:04 PM |\t   40.0%:\t  W_train_loss:6.9069578\tV_train_syn_loss:2.5719531\tV_train_loss:4.7984076\t  V_star_val_loss:4.8445512\t  improvement:0.0081665\n",
      "06/21 06:40:04 PM |\t  tensor([1.4913, 1.4892, 1.3740, 1.4424], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:40:20 PM |\t  1e+02%:\t  W_train_loss:6.5480073\tV_train_syn_loss:2.3489279\tV_train_loss:5.0620673\t  V_star_val_loss:5.5542272\t  improvement:0.0000146\n",
      "06/21 06:40:20 PM |\t  tensor([1.4989, 1.3519, 1.4998, 1.4823], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:40:20 PM |\t  w_train_loss:40.36489534378052,improvement:0.024543285369873047\n",
      "06/21 06:40:20 PM |\t  \n",
      "\n",
      "  ----------------epoch:17,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:5.764800999999999e-05----------------\n",
      "06/21 06:40:21 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 06:40:37 PM |\t   40.0%:\t  W_train_loss:6.9085339\tV_train_syn_loss:2.5719285\tV_train_loss:4.7986533\t  V_star_val_loss:4.8444826\t  improvement:0.0079921\n",
      "06/21 06:40:37 PM |\t  tensor([1.4913, 1.4893, 1.3748, 1.4427], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:40:54 PM |\t  1e+02%:\t  W_train_loss:6.5483190\tV_train_syn_loss:2.3512128\tV_train_loss:5.0621341\t  V_star_val_loss:5.5543987\t  improvement:-0.0000383\n",
      "06/21 06:40:54 PM |\t  tensor([1.4989, 1.3518, 1.4998, 1.4823], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:40:54 PM |\t  w_train_loss:40.370558738708496,improvement:0.023861408233642578\n",
      "06/21 06:40:54 PM |\t  \n",
      "\n",
      "  ----------------epoch:18,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:2.8247524899999994e-05----------------\n",
      "06/21 06:40:54 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 06:41:10 PM |\t   40.0%:\t  W_train_loss:6.9096222\tV_train_syn_loss:2.5718108\tV_train_loss:4.7986186\t  V_star_val_loss:4.8445668\t  improvement:0.0078492\n",
      "06/21 06:41:10 PM |\t  tensor([1.4913, 1.4892, 1.3755, 1.4428], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:41:27 PM |\t  1e+02%:\t  W_train_loss:6.5493056\tV_train_syn_loss:2.3493684\tV_train_loss:5.0628042\t  V_star_val_loss:5.5556211\t  improvement:0.0000099\n",
      "06/21 06:41:27 PM |\t  tensor([1.4989, 1.3519, 1.4998, 1.4823], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:41:27 PM |\t  w_train_loss:40.37678337097168,improvement:0.023577213287353516\n",
      "06/21 06:41:27 PM |\t  \n",
      "\n",
      "  ----------------epoch:19,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:4.035360699999999e-05----------------\n",
      "06/21 06:41:28 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 06:41:44 PM |\t   40.0%:\t  W_train_loss:6.9106431\tV_train_syn_loss:2.5718935\tV_train_loss:4.7987429\t  V_star_val_loss:4.8444304\t  improvement:0.0079905\n",
      "06/21 06:41:44 PM |\t  tensor([1.4913, 1.4892, 1.3761, 1.4430], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:42:01 PM |\t  1e+02%:\t  W_train_loss:6.5492409\tV_train_syn_loss:2.3479588\tV_train_loss:5.0615999\t  V_star_val_loss:5.5544222\t  improvement:-0.0000469\n",
      "06/21 06:42:01 PM |\t  tensor([1.4989, 1.3518, 1.4998, 1.4823], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:42:01 PM |\t  w_train_loss:40.37965202331543,improvement:0.023830890655517578\n",
      "06/21 06:42:01 PM |\t  \n",
      "\n",
      "  ----------------epoch:20,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:1.9773267429999995e-05----------------\n",
      "06/21 06:42:02 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 06:42:18 PM |\t   40.0%:\t  W_train_loss:6.9110832\tV_train_syn_loss:2.5715321\tV_train_loss:4.7984664\t  V_star_val_loss:4.8444068\t  improvement:0.0080709\n",
      "06/21 06:42:18 PM |\t  tensor([1.4913, 1.4892, 1.3763, 1.4431], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:42:34 PM |\t  1e+02%:\t  W_train_loss:6.5493285\tV_train_syn_loss:2.3451296\tV_train_loss:5.0618238\t  V_star_val_loss:5.5538850\t  improvement:-0.0001260\n",
      "06/21 06:42:34 PM |\t  tensor([1.4989, 1.3515, 1.4998, 1.4822], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:42:34 PM |\t  w_train_loss:40.381235122680664,improvement:0.023834705352783203\n",
      "06/21 06:42:34 PM |\t  \n",
      "\n",
      "  ----------------epoch:21,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:2.8247524899999994e-05----------------\n",
      "06/21 06:42:35 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 06:42:51 PM |\t   40.0%:\t  W_train_loss:6.9111520\tV_train_syn_loss:2.5712668\tV_train_loss:4.7986186\t  V_star_val_loss:4.8444484\t  improvement:0.0082122\n",
      "06/21 06:42:51 PM |\t  tensor([1.4913, 1.4892, 1.3765, 1.4431], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:43:07 PM |\t  1e+02%:\t  W_train_loss:6.5487814\tV_train_syn_loss:2.3456528\tV_train_loss:5.0610394\t  V_star_val_loss:5.5541019\t  improvement:0.0001133\n",
      "06/21 06:43:07 PM |\t  tensor([1.4989, 1.3513, 1.4998, 1.4822], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:43:07 PM |\t  w_train_loss:40.37980031967163,improvement:0.024976730346679688\n",
      "06/21 06:43:07 PM |\t  \n",
      "\n",
      "  ----------------epoch:22,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:1.3841287200999995e-05----------------\n",
      "06/21 06:43:08 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 06:43:24 PM |\t   40.0%:\t  W_train_loss:6.9115574\tV_train_syn_loss:2.6040487\tV_train_loss:4.7916554\t  V_star_val_loss:4.8298152\t  improvement:0.0054642\n",
      "06/21 06:43:24 PM |\t  tensor([1.4913, 1.4892, 1.3768, 1.4431], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:43:41 PM |\t  1e+02%:\t  W_train_loss:6.5492239\tV_train_syn_loss:2.3402953\tV_train_loss:5.0382455\t  V_star_val_loss:5.5349139\t  improvement:0.0008321\n",
      "06/21 06:43:41 PM |\t  tensor([1.4989, 1.3514, 1.4998, 1.4822], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:43:41 PM |\t  w_train_loss:40.382343769073486,improvement:0.01888895034790039\n",
      "06/21 06:43:41 PM |\t  \n",
      "\n",
      "  ----------------epoch:23,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:1.9773267429999995e-05----------------\n",
      "06/21 06:43:41 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 06:43:57 PM |\t   40.0%:\t  W_train_loss:6.9122922\tV_train_syn_loss:2.5714598\tV_train_loss:4.7986053\t  V_star_val_loss:4.8440878\t  improvement:0.0079517\n",
      "06/21 06:43:57 PM |\t  tensor([1.4913, 1.4892, 1.3772, 1.4433], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:44:14 PM |\t  1e+02%:\t  W_train_loss:6.5497053\tV_train_syn_loss:2.3464192\tV_train_loss:5.0617841\t  V_star_val_loss:5.5548547\t  improvement:-0.0001151\n",
      "06/21 06:44:14 PM |\t  tensor([1.4989, 1.3515, 1.4998, 1.4823], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:44:14 PM |\t  w_train_loss:40.38599252700806,improvement:0.023509979248046875\n",
      "06/21 06:44:14 PM |\t  \n",
      "\n",
      "  ----------------epoch:24,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:9.688901040699997e-06----------------\n",
      "06/21 06:44:14 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 06:44:30 PM |\t   40.0%:\t  W_train_loss:6.9127250\tV_train_syn_loss:2.6039732\tV_train_loss:4.7917388\t  V_star_val_loss:4.8296089\t  improvement:0.0054194\n",
      "06/21 06:44:30 PM |\t  tensor([1.4913, 1.4892, 1.3774, 1.4433], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:44:47 PM |\t  1e+02%:\t  W_train_loss:6.5499833\tV_train_syn_loss:2.3394981\tV_train_loss:5.0462144\t  V_star_val_loss:5.5409942\t  improvement:0.0004792\n",
      "06/21 06:44:47 PM |\t  tensor([1.4989, 1.3515, 1.4998, 1.4823], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:44:47 PM |\t  w_train_loss:40.38812494277954,improvement:0.017695903778076172\n",
      "06/21 06:44:47 PM |\t  \n",
      "\n",
      "  ----------------epoch:25,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:1.3841287200999995e-05----------------\n",
      "06/21 06:44:47 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 06:45:03 PM |\t   40.0%:\t  W_train_loss:6.9130565\tV_train_syn_loss:2.5772687\tV_train_loss:4.7915004\t  V_star_val_loss:4.8627745\t  improvement:0.0182395\n",
      "06/21 06:45:03 PM |\t  tensor([1.4913, 1.4892, 1.3776, 1.4434], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:45:20 PM |\t  1e+02%:\t  W_train_loss:6.5496141\tV_train_syn_loss:2.3591560\tV_train_loss:5.1114343\t  V_star_val_loss:5.6110285\t  improvement:-0.0001191\n",
      "06/21 06:45:20 PM |\t  tensor([1.4989, 1.3514, 1.4998, 1.4823], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:45:20 PM |\t  w_train_loss:40.38801193237305,improvement:0.05436134338378906\n",
      "06/21 06:45:20 PM |\t  \n",
      "\n",
      "  ----------------epoch:26,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:6.782230728489997e-06----------------\n",
      "06/21 06:45:20 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 06:45:36 PM |\t   40.0%:\t  W_train_loss:6.9133188\tV_train_syn_loss:2.6034580\tV_train_loss:4.7868183\t  V_star_val_loss:4.8439798\t  improvement:0.0096118\n",
      "06/21 06:45:36 PM |\t  tensor([1.4913, 1.4892, 1.3778, 1.4434], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:45:53 PM |\t  1e+02%:\t  W_train_loss:6.5505284\tV_train_syn_loss:2.3597502\tV_train_loss:5.0783676\t  V_star_val_loss:5.5850080\t  improvement:-0.0000916\n",
      "06/21 06:45:53 PM |\t  tensor([1.4989, 1.3513, 1.4998, 1.4823], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:45:53 PM |\t  w_train_loss:40.391541481018066,improvement:0.028560638427734375\n",
      "06/21 06:45:53 PM |\t  \n",
      "\n",
      "  ----------------epoch:27,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:9.688901040699997e-06----------------\n",
      "06/21 06:45:53 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 06:46:09 PM |\t   40.0%:\t  W_train_loss:6.9133264\tV_train_syn_loss:2.6039660\tV_train_loss:4.7868174\t  V_star_val_loss:4.8395263\t  improvement:0.0052722\n",
      "06/21 06:46:09 PM |\t  tensor([1.4913, 1.4892, 1.3779, 1.4434], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:46:26 PM |\t  1e+02%:\t  W_train_loss:6.5500409\tV_train_syn_loss:2.3593758\tV_train_loss:5.0752430\t  V_star_val_loss:5.5821760\t  improvement:0.0005817\n",
      "06/21 06:46:26 PM |\t  tensor([1.4989, 1.3512, 1.4998, 1.4822], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:46:26 PM |\t  w_train_loss:40.39010190963745,improvement:0.017561912536621094\n",
      "06/21 06:46:26 PM |\t  \n",
      "\n",
      "  ----------------epoch:28,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:4.747561509942998e-06----------------\n",
      "06/21 06:46:26 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 06:46:42 PM |\t   40.0%:\t  W_train_loss:6.9132106\tV_train_syn_loss:2.6043131\tV_train_loss:4.7917207\t  V_star_val_loss:4.8297734\t  improvement:0.0054173\n",
      "06/21 06:46:42 PM |\t  tensor([1.4913, 1.4891, 1.3780, 1.4434], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:46:59 PM |\t  1e+02%:\t  W_train_loss:6.5496702\tV_train_syn_loss:2.3385592\tV_train_loss:5.0374548\t  V_star_val_loss:5.5334150\t  improvement:0.0001135\n",
      "06/21 06:46:59 PM |\t  tensor([1.4989, 1.3511, 1.4998, 1.4822], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:46:59 PM |\t  w_train_loss:40.38864231109619,improvement:0.01659250259399414\n",
      "06/21 06:46:59 PM |\t  \n",
      "\n",
      "  ----------------epoch:29,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:6.782230728489997e-06----------------\n",
      "06/21 06:46:59 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 06:47:16 PM |\t   40.0%:\t  W_train_loss:6.9134711\tV_train_syn_loss:2.5770910\tV_train_loss:4.7914882\t  V_star_val_loss:4.8632228\t  improvement:0.0181332\n",
      "06/21 06:47:16 PM |\t  tensor([1.4913, 1.4891, 1.3780, 1.4434], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:47:32 PM |\t  1e+02%:\t  W_train_loss:6.5498724\tV_train_syn_loss:2.3564086\tV_train_loss:5.1128378\t  V_star_val_loss:5.6153119\t  improvement:0.0001882\n",
      "06/21 06:47:32 PM |\t  tensor([1.4989, 1.3511, 1.4998, 1.4822], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:47:32 PM |\t  w_train_loss:40.39003038406372,improvement:0.05496406555175781\n",
      "06/21 06:47:32 PM |\t  \n",
      "\n",
      "  ----------------epoch:30,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:3.323293056960098e-06----------------\n",
      "06/21 06:47:33 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 06:47:49 PM |\t   40.0%:\t  W_train_loss:6.9136532\tV_train_syn_loss:2.5773638\tV_train_loss:4.7916155\t  V_star_val_loss:4.8627648\t  improvement:0.0181718\n",
      "06/21 06:47:49 PM |\t  tensor([1.4913, 1.4891, 1.3781, 1.4434], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:48:05 PM |\t  1e+02%:\t  W_train_loss:6.5496562\tV_train_syn_loss:2.3581851\tV_train_loss:5.1120725\t  V_star_val_loss:5.6138261\t  improvement:-0.0000378\n",
      "06/21 06:48:05 PM |\t  tensor([1.4989, 1.3511, 1.4998, 1.4822], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:48:05 PM |\t  w_train_loss:40.389928340911865,improvement:0.05440187454223633\n",
      "06/21 06:48:05 PM |\t  \n",
      "\n",
      "  ----------------epoch:31,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:4.747561509942998e-06----------------\n",
      "06/21 06:48:06 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 06:48:22 PM |\t   40.0%:\t  W_train_loss:6.9137940\tV_train_syn_loss:2.5770905\tV_train_loss:4.7916910\t  V_star_val_loss:4.8526893\t  improvement:0.0080460\n",
      "06/21 06:48:22 PM |\t  tensor([1.4913, 1.4891, 1.3782, 1.4435], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:48:38 PM |\t  1e+02%:\t  W_train_loss:6.5497122\tV_train_syn_loss:2.3615963\tV_train_loss:5.1108176\t  V_star_val_loss:5.6116234\t  improvement:0.0000656\n",
      "06/21 06:48:38 PM |\t  tensor([1.4989, 1.3511, 1.4998, 1.4823], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:48:38 PM |\t  w_train_loss:40.39051866531372,improvement:0.02433490753173828\n",
      "06/21 06:48:38 PM |\t  \n",
      "\n",
      "  ----------------epoch:32,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:2.3263051398720685e-06----------------\n",
      "06/21 06:48:39 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 06:48:55 PM |\t   40.0%:\t  W_train_loss:6.9138904\tV_train_syn_loss:2.5709960\tV_train_loss:4.7987169\t  V_star_val_loss:4.8343533\t  improvement:-0.0019789\n",
      "06/21 06:48:55 PM |\t  tensor([1.4913, 1.4891, 1.3782, 1.4435], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:49:12 PM |\t  1e+02%:\t  W_train_loss:6.5496664\tV_train_syn_loss:2.3470265\tV_train_loss:5.0623339\t  V_star_val_loss:5.5554873\t  improvement:0.0116916\n",
      "06/21 06:49:12 PM |\t  tensor([1.4989, 1.3511, 1.4998, 1.4823], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:49:12 PM |\t  w_train_loss:40.39067029953003,improvement:0.02913808822631836\n",
      "06/21 06:49:12 PM |\t  \n",
      "\n",
      "  ----------------epoch:33,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:3.323293056960098e-06----------------\n",
      "06/21 06:49:12 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 06:49:28 PM |\t   40.0%:\t  W_train_loss:6.9138811\tV_train_syn_loss:2.6037308\tV_train_loss:4.7867721\t  V_star_val_loss:4.8394488\t  improvement:0.0053948\n",
      "06/21 06:49:28 PM |\t  tensor([1.4913, 1.4891, 1.3783, 1.4435], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:49:45 PM |\t  1e+02%:\t  W_train_loss:6.5499360\tV_train_syn_loss:2.3618188\tV_train_loss:5.0766362\t  V_star_val_loss:5.5832049\t  improvement:-0.0005352\n",
      "06/21 06:49:45 PM |\t  tensor([1.4989, 1.3511, 1.4998, 1.4823], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:49:45 PM |\t  w_train_loss:40.391451358795166,improvement:0.014578819274902344\n",
      "06/21 06:49:45 PM |\t  \n",
      "\n",
      "  ----------------epoch:34,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:1.6284135979104478e-06----------------\n",
      "06/21 06:49:45 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 06:50:01 PM |\t   40.0%:\t  W_train_loss:6.9139414\tV_train_syn_loss:2.6033949\tV_train_loss:4.7868439\t  V_star_val_loss:4.8398326\t  improvement:0.0053763\n",
      "06/21 06:50:01 PM |\t  tensor([1.4913, 1.4891, 1.3783, 1.4435], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:50:18 PM |\t  1e+02%:\t  W_train_loss:6.5497605\tV_train_syn_loss:2.3625728\tV_train_loss:5.0782423\t  V_star_val_loss:5.5850601\t  improvement:-0.0001478\n",
      "06/21 06:50:18 PM |\t  tensor([1.4989, 1.3510, 1.4998, 1.4823], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:50:18 PM |\t  w_train_loss:40.39110565185547,improvement:0.015685558319091797\n",
      "06/21 06:50:18 PM |\t  \n",
      "\n",
      "  ----------------epoch:35,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:2.3263051398720685e-06----------------\n",
      "06/21 06:50:18 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 06:50:34 PM |\t   40.0%:\t  W_train_loss:6.9138762\tV_train_syn_loss:2.6040814\tV_train_loss:4.7917794\t  V_star_val_loss:4.8255598\t  improvement:0.0010862\n",
      "06/21 06:50:34 PM |\t  tensor([1.4913, 1.4891, 1.3783, 1.4435], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:50:51 PM |\t  1e+02%:\t  W_train_loss:6.5496934\tV_train_syn_loss:2.3574491\tV_train_loss:5.0425255\t  V_star_val_loss:5.5231628\t  improvement:-0.0006380\n",
      "06/21 06:50:51 PM |\t  tensor([1.4989, 1.3510, 1.4998, 1.4823], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:50:51 PM |\t  w_train_loss:40.390708923339844,improvement:0.0013446807861328125\n",
      "06/21 06:50:51 PM |\t  \n",
      "\n",
      "  ----------------epoch:36,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:1.1398895185373134e-06----------------\n",
      "06/21 06:50:51 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 06:51:07 PM |\t   40.0%:\t  W_train_loss:6.9139355\tV_train_syn_loss:2.6039373\tV_train_loss:4.7868681\t  V_star_val_loss:4.8436631\t  improvement:0.0097241\n",
      "06/21 06:51:07 PM |\t  tensor([1.4913, 1.4891, 1.3783, 1.4435], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:51:24 PM |\t  1e+02%:\t  W_train_loss:6.5503664\tV_train_syn_loss:2.3626575\tV_train_loss:5.0816282\t  V_star_val_loss:5.5944120\t  improvement:0.0000612\n",
      "06/21 06:51:24 PM |\t  tensor([1.4989, 1.3510, 1.4998, 1.4823], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:51:24 PM |\t  w_train_loss:40.392905712127686,improvement:0.029356002807617188\n",
      "06/21 06:51:24 PM |\t  \n",
      "\n",
      "  ----------------epoch:37,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:1.6284135979104478e-06----------------\n",
      "06/21 06:51:24 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 06:51:40 PM |\t   40.0%:\t  W_train_loss:6.9139566\tV_train_syn_loss:2.6043345\tV_train_loss:4.7918669\t  V_star_val_loss:4.8292691\t  improvement:0.0055273\n",
      "06/21 06:51:40 PM |\t  tensor([1.4913, 1.4891, 1.3783, 1.4435], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:51:57 PM |\t  1e+02%:\t  W_train_loss:6.5503426\tV_train_syn_loss:2.3396043\tV_train_loss:5.0349402\t  V_star_val_loss:5.5313697\t  improvement:-0.0004307\n",
      "06/21 06:51:57 PM |\t  tensor([1.4989, 1.3510, 1.4998, 1.4823], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:51:57 PM |\t  w_train_loss:40.392897605895996,improvement:0.015289783477783203\n",
      "06/21 06:51:57 PM |\t  \n",
      "\n",
      "  ----------------epoch:38,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:7.979226629761193e-07----------------\n",
      "06/21 06:51:57 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 06:52:13 PM |\t   40.0%:\t  W_train_loss:6.9140015\tV_train_syn_loss:2.6038076\tV_train_loss:4.7916861\t  V_star_val_loss:4.8294559\t  improvement:0.0054415\n",
      "06/21 06:52:13 PM |\t  tensor([1.4913, 1.4891, 1.3784, 1.4435], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:52:30 PM |\t  1e+02%:\t  W_train_loss:6.5499198\tV_train_syn_loss:2.3406245\tV_train_loss:5.0412448\t  V_star_val_loss:5.5376940\t  improvement:0.0002012\n",
      "06/21 06:52:30 PM |\t  tensor([1.4989, 1.3510, 1.4998, 1.4823], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:52:30 PM |\t  w_train_loss:40.39176368713379,improvement:0.01692819595336914\n",
      "06/21 06:52:30 PM |\t  \n",
      "\n",
      "  ----------------epoch:39,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:1.1398895185373134e-06----------------\n",
      "06/21 06:52:31 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 06:52:46 PM |\t   40.0%:\t  W_train_loss:6.9140267\tV_train_syn_loss:2.6037073\tV_train_loss:4.7868388\t  V_star_val_loss:4.8439134\t  improvement:0.0095770\n",
      "06/21 06:52:46 PM |\t  tensor([1.4913, 1.4891, 1.3784, 1.4435], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:53:03 PM |\t  1e+02%:\t  W_train_loss:6.5499752\tV_train_syn_loss:2.3615153\tV_train_loss:5.0799349\t  V_star_val_loss:5.5914920\t  improvement:0.0003053\n",
      "06/21 06:53:03 PM |\t  tensor([1.4989, 1.3510, 1.4998, 1.4823], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:53:03 PM |\t  w_train_loss:40.392005920410156,improvement:0.029646873474121094\n",
      "06/21 06:53:03 PM |\t  \n",
      "\n",
      "  ----------------epoch:40,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:5.585458640832835e-07----------------\n",
      "06/21 06:53:03 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 06:53:19 PM |\t   40.0%:\t  W_train_loss:6.9140250\tV_train_syn_loss:2.5769332\tV_train_loss:4.7915896\t  V_star_val_loss:4.8528773\t  improvement:0.0080056\n",
      "06/21 06:53:19 PM |\t  tensor([1.4913, 1.4891, 1.3784, 1.4435], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:53:36 PM |\t  1e+02%:\t  W_train_loss:6.5492145\tV_train_syn_loss:2.3497422\tV_train_loss:5.1085773\t  V_star_val_loss:5.6082727\t  improvement:0.0000072\n",
      "06/21 06:53:36 PM |\t  tensor([1.4989, 1.3510, 1.4998, 1.4823], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:53:36 PM |\t  w_train_loss:40.389718532562256,improvement:0.024038314819335938\n",
      "06/21 06:53:36 PM |\t  \n",
      "\n",
      "  ----------------epoch:41,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:7.979226629761193e-07----------------\n",
      "06/21 06:53:36 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 06:53:52 PM |\t   40.0%:\t  W_train_loss:6.9140237\tV_train_syn_loss:2.6044498\tV_train_loss:4.7918676\t  V_star_val_loss:4.8293640\t  improvement:0.0054248\n",
      "06/21 06:53:52 PM |\t  tensor([1.4913, 1.4891, 1.3784, 1.4435], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:54:09 PM |\t  1e+02%:\t  W_train_loss:6.5497217\tV_train_syn_loss:2.3387933\tV_train_loss:5.0336043\t  V_star_val_loss:5.5271505\t  improvement:-0.0004066\n",
      "06/21 06:54:09 PM |\t  tensor([1.4989, 1.3510, 1.4998, 1.4823], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:54:09 PM |\t  w_train_loss:40.391236305236816,improvement:0.015054702758789062\n",
      "06/21 06:54:09 PM |\t  \n",
      "\n",
      "  ----------------epoch:42,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:3.9098210485829847e-07----------------\n",
      "06/21 06:54:09 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 06:54:25 PM |\t   40.0%:\t  W_train_loss:6.9141461\tV_train_syn_loss:2.6040956\tV_train_loss:4.7917670\t  V_star_val_loss:4.8298081\t  improvement:0.0053724\n",
      "06/21 06:54:25 PM |\t  tensor([1.4913, 1.4891, 1.3784, 1.4435], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:54:43 PM |\t  1e+02%:\t  W_train_loss:6.5497193\tV_train_syn_loss:2.3408336\tV_train_loss:5.0374459\t  V_star_val_loss:5.5364389\t  improvement:0.0012684\n",
      "06/21 06:54:43 PM |\t  tensor([1.4989, 1.3510, 1.4998, 1.4823], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:54:43 PM |\t  w_train_loss:40.39159631729126,improvement:0.019922256469726562\n",
      "06/21 06:54:43 PM |\t  \n",
      "\n",
      "  ----------------epoch:43,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:5.585458640832835e-07----------------\n",
      "06/21 06:54:43 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 06:54:59 PM |\t   40.0%:\t  W_train_loss:6.9141340\tV_train_syn_loss:2.6040581\tV_train_loss:4.7868646\t  V_star_val_loss:4.8397168\t  improvement:0.0056020\n",
      "06/21 06:54:59 PM |\t  tensor([1.4913, 1.4891, 1.3784, 1.4435], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:55:16 PM |\t  1e+02%:\t  W_train_loss:6.5499412\tV_train_syn_loss:2.3635308\tV_train_loss:5.0794433\t  V_star_val_loss:5.5898040\t  improvement:-0.0004603\n",
      "06/21 06:55:16 PM |\t  tensor([1.4989, 1.3510, 1.4998, 1.4823], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:55:16 PM |\t  w_train_loss:40.39222574234009,improvement:0.01542520523071289\n",
      "06/21 06:55:16 PM |\t  \n",
      "\n",
      "  ----------------epoch:44,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:2.736874734008089e-07----------------\n",
      "06/21 06:55:16 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 06:55:32 PM |\t   40.0%:\t  W_train_loss:6.9142173\tV_train_syn_loss:2.6034793\tV_train_loss:4.7868740\t  V_star_val_loss:4.8438136\t  improvement:0.0095741\n",
      "06/21 06:55:32 PM |\t  tensor([1.4913, 1.4891, 1.3785, 1.4435], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:55:49 PM |\t  1e+02%:\t  W_train_loss:6.5495090\tV_train_syn_loss:2.3616941\tV_train_loss:5.0754016\t  V_star_val_loss:5.5649600\t  improvement:-0.0009274\n",
      "06/21 06:55:49 PM |\t  tensor([1.4989, 1.3510, 1.4998, 1.4823], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:55:49 PM |\t  w_train_loss:40.39117908477783,improvement:0.02593994140625\n",
      "06/21 06:55:49 PM |\t  \n",
      "\n",
      "  ----------------epoch:45,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:3.9098210485829847e-07----------------\n",
      "06/21 06:55:50 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 06:56:05 PM |\t   40.0%:\t  W_train_loss:6.9142253\tV_train_syn_loss:2.6042577\tV_train_loss:4.7917916\t  V_star_val_loss:4.8252838\t  improvement:0.0009893\n",
      "06/21 06:56:06 PM |\t  tensor([1.4913, 1.4891, 1.3785, 1.4435], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:56:22 PM |\t  1e+02%:\t  W_train_loss:6.5495063\tV_train_syn_loss:2.3405687\tV_train_loss:5.0400918\t  V_star_val_loss:5.5318542\t  improvement:-0.0071068\n",
      "06/21 06:56:22 PM |\t  tensor([1.4989, 1.3510, 1.4998, 1.4823], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:56:22 PM |\t  w_train_loss:40.39119482040405,improvement:-0.018352508544921875\n",
      "06/21 06:56:22 PM |\t  \n",
      "\n",
      "  ----------------epoch:46,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:1.9158123138056623e-07----------------\n",
      "06/21 06:56:23 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 06:56:39 PM |\t   40.0%:\t  W_train_loss:6.9141839\tV_train_syn_loss:2.5714532\tV_train_loss:4.7986221\t  V_star_val_loss:4.8341656\t  improvement:-0.0018514\n",
      "06/21 06:56:39 PM |\t  tensor([1.4913, 1.4891, 1.3785, 1.4435], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:56:55 PM |\t  1e+02%:\t  W_train_loss:6.5497897\tV_train_syn_loss:2.3472627\tV_train_loss:5.0613300\t  V_star_val_loss:5.5548193\t  improvement:0.0000582\n",
      "06/21 06:56:55 PM |\t  tensor([1.4989, 1.3510, 1.4998, 1.4823], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:56:55 PM |\t  w_train_loss:40.391921043395996,improvement:-0.005379676818847656\n",
      "06/21 06:56:55 PM |\t  \n",
      "\n",
      "  ----------------epoch:47,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:2.736874734008089e-07----------------\n",
      "06/21 06:56:56 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 06:57:12 PM |\t   40.0%:\t  W_train_loss:6.9142731\tV_train_syn_loss:2.6042402\tV_train_loss:4.7918038\t  V_star_val_loss:4.8251987\t  improvement:0.0013970\n",
      "06/21 06:57:12 PM |\t  tensor([1.4913, 1.4891, 1.3785, 1.4435], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:57:29 PM |\t  1e+02%:\t  W_train_loss:6.5497225\tV_train_syn_loss:2.3397594\tV_train_loss:5.0310224\t  V_star_val_loss:5.5225994\t  improvement:0.0007610\n",
      "06/21 06:57:29 PM |\t  tensor([1.4989, 1.3510, 1.4998, 1.4823], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:57:29 PM |\t  w_train_loss:40.39198684692383,improvement:0.006474018096923828\n",
      "06/21 06:57:29 PM |\t  \n",
      "\n",
      "  ----------------epoch:48,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:1.3410686196639635e-07----------------\n",
      "06/21 06:57:29 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 06:57:45 PM |\t   40.0%:\t  W_train_loss:6.9142286\tV_train_syn_loss:2.6037243\tV_train_loss:4.7868409\t  V_star_val_loss:4.8396171\t  improvement:0.0053517\n",
      "06/21 06:57:45 PM |\t  tensor([1.4913, 1.4891, 1.3785, 1.4435], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:58:02 PM |\t  1e+02%:\t  W_train_loss:6.5501146\tV_train_syn_loss:2.3637002\tV_train_loss:5.0784308\t  V_star_val_loss:5.5877740\t  improvement:0.0001567\n",
      "06/21 06:58:02 PM |\t  tensor([1.4989, 1.3510, 1.4998, 1.4823], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:58:02 PM |\t  w_train_loss:40.39302968978882,improvement:0.0165252685546875\n",
      "06/21 06:58:02 PM |\t  \n",
      "\n",
      "  ----------------epoch:49,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:1.9158123138056623e-07----------------\n",
      "06/21 06:58:02 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 06:58:18 PM |\t   40.0%:\t  W_train_loss:6.9141812\tV_train_syn_loss:2.5709512\tV_train_loss:4.7986819\t  V_star_val_loss:4.8341970\t  improvement:-0.0019296\n",
      "06/21 06:58:18 PM |\t  tensor([1.4913, 1.4891, 1.3785, 1.4435], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:58:35 PM |\t  1e+02%:\t  W_train_loss:6.5497646\tV_train_syn_loss:2.3488786\tV_train_loss:5.0616067\t  V_star_val_loss:5.5556774\t  improvement:0.0001418\n",
      "06/21 06:58:35 PM |\t  tensor([1.4989, 1.3510, 1.4998, 1.4823], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:58:35 PM |\t  w_train_loss:40.39183759689331,improvement:-0.00536346435546875\n",
      "06/21 06:58:35 PM |\t  \n",
      "\n",
      "  ----------------epoch:50,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:9.387480337647744e-08----------------\n",
      "06/21 06:58:35 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 06:58:51 PM |\t   40.0%:\t  W_train_loss:6.9142737\tV_train_syn_loss:2.6039049\tV_train_loss:4.7917072\t  V_star_val_loss:4.8295005\t  improvement:0.0055485\n",
      "06/21 06:58:51 PM |\t  tensor([1.4913, 1.4891, 1.3785, 1.4435], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:59:08 PM |\t  1e+02%:\t  W_train_loss:6.5500104\tV_train_syn_loss:2.3413074\tV_train_loss:5.0375818\t  V_star_val_loss:5.5356007\t  improvement:-0.0003910\n",
      "06/21 06:59:08 PM |\t  tensor([1.4989, 1.3510, 1.4998, 1.4823], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:59:08 PM |\t  w_train_loss:40.39285230636597,improvement:0.015472412109375\n",
      "06/21 06:59:08 PM |\t  \n",
      "\n",
      "  ----------------epoch:51,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:1.3410686196639635e-07----------------\n",
      "06/21 06:59:08 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 06:59:24 PM |\t   40.0%:\t  W_train_loss:6.9143699\tV_train_syn_loss:2.6039544\tV_train_loss:4.7918142\t  V_star_val_loss:4.8250368\t  improvement:0.0010686\n",
      "06/21 06:59:24 PM |\t  tensor([1.4913, 1.4891, 1.3785, 1.4435], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:59:41 PM |\t  1e+02%:\t  W_train_loss:6.5497289\tV_train_syn_loss:2.3392566\tV_train_loss:5.0278225\t  V_star_val_loss:5.5120104\t  improvement:-0.0006488\n",
      "06/21 06:59:41 PM |\t  tensor([1.4989, 1.3510, 1.4998, 1.4823], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 06:59:41 PM |\t  w_train_loss:40.3922963142395,improvement:0.0012593269348144531\n",
      "06/21 06:59:41 PM |\t  \n",
      "\n",
      "  ----------------epoch:52,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:6.57123623635342e-08----------------\n",
      "06/21 06:59:41 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 06:59:58 PM |\t   40.0%:\t  W_train_loss:6.9142768\tV_train_syn_loss:2.5711662\tV_train_loss:4.7986320\t  V_star_val_loss:4.8443688\t  improvement:0.0080582\n",
      "06/21 06:59:58 PM |\t  tensor([1.4913, 1.4891, 1.3785, 1.4435], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 07:00:14 PM |\t  1e+02%:\t  W_train_loss:6.5494830\tV_train_syn_loss:2.3472722\tV_train_loss:5.0607659\t  V_star_val_loss:5.5425533\t  improvement:-0.0116490\n",
      "06/21 07:00:14 PM |\t  tensor([1.4989, 1.3510, 1.4998, 1.4823], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 07:00:14 PM |\t  w_train_loss:40.391279220581055,improvement:-0.010772228240966797\n",
      "06/21 07:00:14 PM |\t  \n",
      "\n",
      "  ----------------epoch:53,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:9.387480337647744e-08----------------\n",
      "06/21 07:00:15 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 07:00:31 PM |\t   40.0%:\t  W_train_loss:6.9141858\tV_train_syn_loss:2.5715115\tV_train_loss:4.7986881\t  V_star_val_loss:4.8441647\t  improvement:0.0079695\n",
      "06/21 07:00:31 PM |\t  tensor([1.4913, 1.4891, 1.3785, 1.4435], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 07:00:47 PM |\t  1e+02%:\t  W_train_loss:6.5499407\tV_train_syn_loss:2.3469290\tV_train_loss:5.0626121\t  V_star_val_loss:5.5558292\t  improvement:-0.0002367\n",
      "06/21 07:00:47 PM |\t  tensor([1.4989, 1.3510, 1.4998, 1.4823], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 07:00:47 PM |\t  w_train_loss:40.39237976074219,improvement:0.023198604583740234\n",
      "06/21 07:00:47 PM |\t  \n",
      "\n",
      "  ----------------epoch:54,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:4.5998653654473935e-08----------------\n",
      "06/21 07:00:48 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 07:01:04 PM |\t   40.0%:\t  W_train_loss:6.9143643\tV_train_syn_loss:2.5771976\tV_train_loss:4.7917183\t  V_star_val_loss:4.8526492\t  improvement:0.0079362\n",
      "06/21 07:01:04 PM |\t  tensor([1.4913, 1.4891, 1.3785, 1.4435], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 07:01:20 PM |\t  1e+02%:\t  W_train_loss:6.5495168\tV_train_syn_loss:2.3586255\tV_train_loss:5.1113369\t  V_star_val_loss:5.6131487\t  improvement:0.0018996\n",
      "06/21 07:01:20 PM |\t  tensor([1.4989, 1.3510, 1.4998, 1.4823], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 07:01:20 PM |\t  w_train_loss:40.39164352416992,improvement:0.029507160186767578\n",
      "06/21 07:01:20 PM |\t  \n",
      "\n",
      "  ----------------epoch:55,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:6.57123623635342e-08----------------\n",
      "06/21 07:01:21 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 07:01:37 PM |\t   40.0%:\t  W_train_loss:6.9143065\tV_train_syn_loss:2.6043005\tV_train_loss:4.7917663\t  V_star_val_loss:4.8253527\t  improvement:0.0012339\n",
      "06/21 07:01:37 PM |\t  tensor([1.4913, 1.4891, 1.3785, 1.4435], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 07:01:53 PM |\t  1e+02%:\t  W_train_loss:6.5500118\tV_train_syn_loss:2.3400340\tV_train_loss:5.0395533\t  V_star_val_loss:5.5392057\t  improvement:0.0004002\n",
      "06/21 07:01:53 PM |\t  tensor([1.4989, 1.3510, 1.4998, 1.4823], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 07:01:53 PM |\t  w_train_loss:40.39295482635498,improvement:0.004902362823486328\n",
      "06/21 07:01:53 PM |\t  \n",
      "\n",
      "  ----------------epoch:56,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:3.219905755813175e-08----------------\n",
      "06/21 07:01:54 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 07:02:10 PM |\t   40.0%:\t  W_train_loss:6.9144087\tV_train_syn_loss:2.6041058\tV_train_loss:4.7868107\t  V_star_val_loss:4.8397319\t  improvement:0.0054653\n",
      "06/21 07:02:10 PM |\t  tensor([1.4913, 1.4891, 1.3785, 1.4435], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 07:02:26 PM |\t  1e+02%:\t  W_train_loss:6.5494854\tV_train_syn_loss:2.3610078\tV_train_loss:5.0757170\t  V_star_val_loss:5.5743974\t  improvement:0.0005232\n",
      "06/21 07:02:26 PM |\t  tensor([1.4989, 1.3510, 1.4998, 1.4823], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 07:02:26 PM |\t  w_train_loss:40.391682147979736,improvement:0.01796579360961914\n",
      "06/21 07:02:26 PM |\t  \n",
      "\n",
      "  ----------------epoch:57,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:4.5998653654473935e-08----------------\n",
      "06/21 07:02:27 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 07:02:43 PM |\t   40.0%:\t  W_train_loss:6.9143043\tV_train_syn_loss:2.5772176\tV_train_loss:4.7916940\t  V_star_val_loss:4.8630158\t  improvement:0.0180456\n",
      "06/21 07:02:43 PM |\t  tensor([1.4913, 1.4891, 1.3785, 1.4435], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 07:03:00 PM |\t  1e+02%:\t  W_train_loss:6.5496505\tV_train_syn_loss:2.3569003\tV_train_loss:5.1119407\t  V_star_val_loss:5.6114130\t  improvement:-0.0000629\n",
      "06/21 07:03:00 PM |\t  tensor([1.4989, 1.3510, 1.4998, 1.4823], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 07:03:00 PM |\t  w_train_loss:40.39186429977417,improvement:0.05394792556762695\n",
      "06/21 07:03:00 PM |\t  \n",
      "\n",
      "  ----------------epoch:58,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:2.2539340290692225e-08----------------\n",
      "06/21 07:03:00 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 07:03:16 PM |\t   40.0%:\t  W_train_loss:6.9144305\tV_train_syn_loss:2.5773619\tV_train_loss:4.7915994\t  V_star_val_loss:4.8628043\t  improvement:0.0179469\n",
      "06/21 07:03:16 PM |\t  tensor([1.4913, 1.4891, 1.3785, 1.4435], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 07:03:33 PM |\t  1e+02%:\t  W_train_loss:6.5498662\tV_train_syn_loss:2.3586716\tV_train_loss:5.1117508\t  V_star_val_loss:5.6106987\t  improvement:0.0000585\n",
      "06/21 07:03:33 PM |\t  tensor([1.4989, 1.3510, 1.4998, 1.4823], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 07:03:33 PM |\t  w_train_loss:40.392889976501465,improvement:0.05401611328125\n",
      "06/21 07:03:33 PM |\t  \n",
      "\n",
      "  ----------------epoch:59,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:3.219905755813175e-08----------------\n",
      "06/21 07:03:33 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 07:03:49 PM |\t   40.0%:\t  W_train_loss:6.9142249\tV_train_syn_loss:2.6046156\tV_train_loss:4.7918703\t  V_star_val_loss:4.8296073\t  improvement:0.0051769\n",
      "06/21 07:03:49 PM |\t  tensor([1.4913, 1.4891, 1.3785, 1.4435], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 07:04:06 PM |\t  1e+02%:\t  W_train_loss:6.5501297\tV_train_syn_loss:2.3373452\tV_train_loss:5.0369603\t  V_star_val_loss:5.5338677\t  improvement:0.0003146\n",
      "06/21 07:04:06 PM |\t  tensor([1.4989, 1.3510, 1.4998, 1.4823], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 07:04:06 PM |\t  w_train_loss:40.39306402206421,improvement:0.016474246978759766\n",
      "06/21 07:04:06 PM |\t  \n",
      "\n",
      "  ----------------epoch:60,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:1.5777538203484557e-08----------------\n",
      "06/21 07:04:06 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 07:04:22 PM |\t   40.0%:\t  W_train_loss:6.9142536\tV_train_syn_loss:2.6040595\tV_train_loss:4.7868617\t  V_star_val_loss:4.8435737\t  improvement:0.0095930\n",
      "06/21 07:04:22 PM |\t  tensor([1.4913, 1.4891, 1.3785, 1.4435], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 07:04:39 PM |\t  1e+02%:\t  W_train_loss:6.5496028\tV_train_syn_loss:2.3634934\tV_train_loss:5.0773667\t  V_star_val_loss:5.5877000\t  improvement:0.0007000\n",
      "06/21 07:04:39 PM |\t  tensor([1.4989, 1.3510, 1.4998, 1.4823], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 07:04:39 PM |\t  w_train_loss:40.39156913757324,improvement:0.03087902069091797\n",
      "06/21 07:04:39 PM |\t  \n",
      "\n",
      "  ----------------epoch:61,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:2.2539340290692225e-08----------------\n",
      "06/21 07:04:39 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 07:04:55 PM |\t   40.0%:\t  W_train_loss:6.9143202\tV_train_syn_loss:2.5711616\tV_train_loss:4.7984964\t  V_star_val_loss:4.8441334\t  improvement:0.0077378\n",
      "06/21 07:04:55 PM |\t  tensor([1.4913, 1.4891, 1.3785, 1.4435], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 07:05:12 PM |\t  1e+02%:\t  W_train_loss:6.5497481\tV_train_syn_loss:2.3488182\tV_train_loss:5.0668534\t  V_star_val_loss:5.5636034\t  improvement:0.0000488\n",
      "06/21 07:05:12 PM |\t  tensor([1.4989, 1.3510, 1.4998, 1.4823], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 07:05:12 PM |\t  w_train_loss:40.39220476150513,improvement:0.02335977554321289\n",
      "06/21 07:05:12 PM |\t  \n",
      "\n",
      "  ----------------epoch:62,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:1.104427674243919e-08----------------\n",
      "06/21 07:05:12 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 07:05:28 PM |\t   40.0%:\t  W_train_loss:6.9141909\tV_train_syn_loss:2.5715932\tV_train_loss:4.7986450\t  V_star_val_loss:4.8443737\t  improvement:0.0081124\n",
      "06/21 07:05:28 PM |\t  tensor([1.4913, 1.4891, 1.3785, 1.4435], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 07:05:45 PM |\t  1e+02%:\t  W_train_loss:6.5499423\tV_train_syn_loss:2.3477709\tV_train_loss:5.0615204\t  V_star_val_loss:5.5547330\t  improvement:0.0000609\n",
      "06/21 07:05:45 PM |\t  tensor([1.4989, 1.3510, 1.4998, 1.4823], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 07:05:45 PM |\t  w_train_loss:40.39239978790283,improvement:0.024519920349121094\n",
      "06/21 07:05:45 PM |\t  \n",
      "\n",
      "  ----------------epoch:63,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:1.5777538203484557e-08----------------\n",
      "06/21 07:05:45 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 07:06:01 PM |\t   40.0%:\t  W_train_loss:6.9142656\tV_train_syn_loss:2.5715022\tV_train_loss:4.7986965\t  V_star_val_loss:4.8443235\t  improvement:0.0079498\n",
      "06/21 07:06:01 PM |\t  tensor([1.4913, 1.4891, 1.3785, 1.4435], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 07:06:18 PM |\t  1e+02%:\t  W_train_loss:6.5499018\tV_train_syn_loss:2.3456382\tV_train_loss:5.0620527\t  V_star_val_loss:5.5554533\t  improvement:0.0001666\n",
      "06/21 07:06:18 PM |\t  tensor([1.4989, 1.3510, 1.4998, 1.4823], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 07:06:18 PM |\t  w_train_loss:40.392502307891846,improvement:0.024349212646484375\n",
      "06/21 07:06:18 PM |\t  \n",
      "\n",
      "  ----------------epoch:64,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:7.730993719707432e-09----------------\n",
      "06/21 07:06:18 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 07:06:34 PM |\t   40.0%:\t  W_train_loss:6.9143141\tV_train_syn_loss:2.5711281\tV_train_loss:4.7985023\t  V_star_val_loss:4.8443386\t  improvement:0.0076842\n",
      "06/21 07:06:34 PM |\t  tensor([1.4913, 1.4891, 1.3785, 1.4435], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 07:06:51 PM |\t  1e+02%:\t  W_train_loss:6.5498268\tV_train_syn_loss:2.3486750\tV_train_loss:5.0686617\t  V_star_val_loss:5.5653143\t  improvement:0.0009101\n",
      "06/21 07:06:51 PM |\t  tensor([1.4989, 1.3510, 1.4998, 1.4823], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 07:06:51 PM |\t  w_train_loss:40.392422676086426,improvement:0.025783061981201172\n",
      "06/21 07:06:51 PM |\t  \n",
      "\n",
      "  ----------------epoch:65,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:1.104427674243919e-08----------------\n",
      "06/21 07:06:52 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 07:07:07 PM |\t   40.0%:\t  W_train_loss:6.9143004\tV_train_syn_loss:2.6042099\tV_train_loss:4.7918711\t  V_star_val_loss:4.8253245\t  improvement:0.0011020\n",
      "06/21 07:07:07 PM |\t  tensor([1.4913, 1.4891, 1.3785, 1.4435], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 07:07:24 PM |\t  1e+02%:\t  W_train_loss:6.5500625\tV_train_syn_loss:2.3371960\tV_train_loss:5.0323747\t  V_star_val_loss:5.5245625\t  improvement:-0.0002785\n",
      "06/21 07:07:24 PM |\t  tensor([1.4989, 1.3510, 1.4998, 1.4823], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 07:07:24 PM |\t  w_train_loss:40.393088817596436,improvement:0.0024704933166503906\n",
      "06/21 07:07:24 PM |\t  \n",
      "\n",
      "  ----------------epoch:66,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:5.411695603795202e-09----------------\n",
      "06/21 07:07:25 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 07:07:41 PM |\t   40.0%:\t  W_train_loss:6.9142138\tV_train_syn_loss:2.5709560\tV_train_loss:4.7987601\t  V_star_val_loss:4.8340311\t  improvement:-0.0020092\n",
      "06/21 07:07:41 PM |\t  tensor([1.4913, 1.4891, 1.3785, 1.4435], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 07:07:57 PM |\t  1e+02%:\t  W_train_loss:6.5499214\tV_train_syn_loss:2.3469201\tV_train_loss:5.0621357\t  V_star_val_loss:5.5552653\t  improvement:-0.0000461\n",
      "06/21 07:07:57 PM |\t  tensor([1.4989, 1.3510, 1.4998, 1.4823], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 07:07:57 PM |\t  w_train_loss:40.39240550994873,improvement:-0.006165981292724609\n",
      "06/21 07:07:57 PM |\t  \n",
      "\n",
      "  ----------------epoch:67,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:7.730993719707432e-09----------------\n",
      "06/21 07:07:58 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 07:08:14 PM |\t   40.0%:\t  W_train_loss:6.9142806\tV_train_syn_loss:2.5713807\tV_train_loss:4.7986832\t  V_star_val_loss:4.8443761\t  improvement:0.0082348\n",
      "06/21 07:08:14 PM |\t  tensor([1.4913, 1.4891, 1.3785, 1.4435], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 07:08:30 PM |\t  1e+02%:\t  W_train_loss:6.5494458\tV_train_syn_loss:2.3454785\tV_train_loss:5.0612343\t  V_star_val_loss:5.5541321\t  improvement:-0.0000455\n",
      "06/21 07:08:30 PM |\t  tensor([1.4989, 1.3510, 1.4998, 1.4823], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 07:08:30 PM |\t  w_train_loss:40.39117908477783,improvement:0.02456808090209961\n",
      "06/21 07:08:30 PM |\t  \n",
      "\n",
      "  ----------------epoch:68,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:3.788186922656641e-09----------------\n",
      "06/21 07:08:31 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 07:08:47 PM |\t   40.0%:\t  W_train_loss:6.9142577\tV_train_syn_loss:2.5772899\tV_train_loss:4.7916381\t  V_star_val_loss:4.8628743\t  improvement:0.0181438\n",
      "06/21 07:08:47 PM |\t  tensor([1.4913, 1.4891, 1.3785, 1.4435], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 07:09:03 PM |\t  1e+02%:\t  W_train_loss:6.5500847\tV_train_syn_loss:2.3586160\tV_train_loss:5.1110781\t  V_star_val_loss:5.6113140\t  improvement:0.0000968\n",
      "06/21 07:09:04 PM |\t  tensor([1.4989, 1.3510, 1.4998, 1.4823], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "06/21 07:09:04 PM |\t  w_train_loss:40.39302730560303,improvement:0.054721832275390625\n",
      "06/21 07:09:04 PM |\t  \n",
      "\n",
      "  ----------------epoch:69,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:5.411695603795202e-09----------------\n",
      "06/21 07:09:04 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/21 07:09:20 PM |\t   40.0%:\t  W_train_loss:6.9142003\tV_train_syn_loss:2.5774201\tV_train_loss:4.7916856\t  V_star_val_loss:4.8631810\t  improvement:0.0184026\n",
      "06/21 07:09:20 PM |\t  tensor([1.4913, 1.4891, 1.3785, 1.4435], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1860/4246411912.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"\\n\\n  ----------------epoch:{epoch},\\t\\tlr_w:{lr_w},\\t\\tlr_v:{lr_v},\\t\\tlr_A:{lr_A}----------------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mw_train_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimprovement\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mmy_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_v\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0marchitect\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_optimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv_optimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr_w\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr_v\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtot_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mscheduler_w\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1860/671100264.py\u001b[0m in \u001b[0;36mmy_train\u001b[1;34m(epoch, _dataloader, validdataloader, w_model, v_model, architect, A, w_optimizer, v_optimizer, lr_w, lr_v, tot_iter)\u001b[0m\n\u001b[0;32m     59\u001b[0m             \u001b[0mepsilon_w\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munrolled_w_lr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[0mepsilon_v\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munrolled_v_lr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m             v_star_val_loss = architect.step(input_w,  output_w, input_w_attn, output_w_attn, w_optimizer,\n\u001b[0m\u001b[0;32m     62\u001b[0m                                              \u001b[0minput_v\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_v_attn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_v\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_v_attn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_syn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_syn_attn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m                                              \u001b[0minput_A_v\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_A_v_attn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_A_v\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_A_v_attn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv_optimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mg:\\GitCode\\Self-teaching-for-machine-translation\\T5_newA\\architect.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, input_w, output_w, input_w_attn, output_w_attn, w_optimizer, input_v, input_v_attn, output_v, output_v_attn, input_syn, input_syn_attn, input_A_v, input_A_v_attn, output_A_v, output_A_v_attn, v_optimizer, lr_w, lr_v)\u001b[0m\n\u001b[0;32m    172\u001b[0m         \u001b[0munrolled_w_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         unrolled_v_model = self._compute_unrolled_v_model(\n\u001b[0m\u001b[0;32m    175\u001b[0m             input_v, input_v_attn, output_v, output_v_attn, input_syn, input_syn_attn, unrolled_w_model,  lr_v, v_optimizer)\n\u001b[0;32m    176\u001b[0m         \u001b[0munrolled_v_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mg:\\GitCode\\Self-teaching-for-machine-translation\\T5_newA\\architect.py\u001b[0m in \u001b[0;36m_compute_unrolled_v_model\u001b[1;34m(self, input_v, input_v_attn, output_v, output_v_attn, input_syn, input_syn_attn, unrolled_w_model, eta_v, v_optimizer)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;31m# DS loss on augmented dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         loss_aug = calc_loss_aug(\n\u001b[0m\u001b[0;32m    112\u001b[0m             input_syn, input_syn_attn, unrolled_w_model, self.v_model)\n\u001b[0;32m    113\u001b[0m         loss = my_loss2(input_v, input_v_attn, output_v,\n",
      "\u001b[1;32mg:\\GitCode\\Self-teaching-for-machine-translation\\T5_newA\\losses.py\u001b[0m in \u001b[0;36mcalc_loss_aug\u001b[1;34m(input_syn_ids, input_syn_attn, w_model, v_model)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcalc_loss_aug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_syn_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_syn_attn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[0mw_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mturnoff_dropout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m     \u001b[0moutput_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_syn_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_beams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[0matt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0moutput_ids\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[0mw_logits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_syn_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_syn_attn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_attn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0matt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogits\u001b[0m  \u001b[1;31m# TODO,forward_decoderinput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mg:\\GitCode\\Self-teaching-for-machine-translation\\T5_newA\\T5.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, input_ids, num_beams, max_length)\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_beams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m         \u001b[0moutput_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_beams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_beams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlength_penalty\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m0.6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrepetition_penalty\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cache\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m         \u001b[1;31m## sampling with top_p\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, typical_p, repetition_penalty, bad_words_ids, force_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, stopping_criteria, constraints, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, exponential_decay_length_penalty, **model_kwargs)\u001b[0m\n\u001b[0;32m   1252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1253\u001b[0m             \u001b[1;31m# 10. run greedy search\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1254\u001b[1;33m             return self.greedy_search(\n\u001b[0m\u001b[0;32m   1255\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogits_processor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\generation_utils.py\u001b[0m in \u001b[0;36mgreedy_search\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[0;32m   1636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1637\u001b[0m             \u001b[1;31m# forward pass to get next token\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1638\u001b[1;33m             outputs = self(\n\u001b[0m\u001b[0;32m   1639\u001b[0m                 \u001b[1;33m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1640\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1637\u001b[0m         \u001b[1;31m# Decode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1638\u001b[1;33m         decoder_outputs = self.decoder(\n\u001b[0m\u001b[0;32m   1639\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1640\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecoder_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1031\u001b[0m                 )\n\u001b[0;32m   1032\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1033\u001b[1;33m                 layer_outputs = layer_module(\n\u001b[0m\u001b[0;32m   1034\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1035\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[0;32m    692\u001b[0m                 \u001b[0mquery_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    693\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 694\u001b[1;33m             cross_attention_outputs = self.layer[1](\n\u001b[0m\u001b[0;32m    695\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    696\u001b[0m                 \u001b[0mkey_value_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoder_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, key_value_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, query_length, output_attentions)\u001b[0m\n\u001b[0;32m    617\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m         )\n\u001b[1;32m--> 619\u001b[1;33m         \u001b[0mlayer_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhidden_states\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    620\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# add attentions if we output them\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    621\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# if(args.valid_begin==1):\n",
    "#     my_test(valid_dataloader,model_w,-1) #before train\n",
    "#     my_test(valid_dataloader,model_v,-1)  \n",
    "\n",
    "tot_iter = [0]\n",
    "for epoch in range(args.epochs):\n",
    "    lr_w = scheduler_w.get_lr()[0]\n",
    "    lr_v = scheduler_v.get_lr()[0]\n",
    "    lr_A = architect.scheduler_A.get_lr()[0]\n",
    "\n",
    "    logging.info(f\"\\n\\n  ----------------epoch:{epoch},\\t\\tlr_w:{lr_w},\\t\\tlr_v:{lr_v},\\t\\tlr_A:{lr_A}----------------\")\n",
    "\n",
    "    w_train_loss,improvement =  my_train(epoch, train_dataloader, valid_dataloader, model_w, model_v,  architect, A, w_optimizer, v_optimizer, lr_w,lr_v,tot_iter)\n",
    "    \n",
    "    scheduler_w.step()\n",
    "    scheduler_v.step()\n",
    "    architect.scheduler_A.step()\n",
    "\n",
    "\n",
    "    logging.info(f\"w_train_loss:{w_train_loss},improvement:{improvement}\")\n",
    "    # wandb.log({'w_train_loss': w_train_loss, 'v_train_loss':v_train_loss})\n",
    "\n",
    "\n",
    "\n",
    "torch.save(model_v,'./model/'+now+'model_w.pt')\n",
    "torch.save(model_v,'./model/'+now+'model_v.pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./model\\\\input_w.pt', './model\\\\input_w_attn.pt', './model\\\\output_w.pt', './model\\\\output_w_attn.pt']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['translate English to German: The occupational profiles drawn up by the LOB in collaboration with industry are taken as a basis.',\n",
       " 'translate English to German: We need to tackle the reasons why women are more likely to have precarious jobs: the stereotypes, the unequal sharing of family and household tasks, and the undervaluation of female-dominated jobs.',\n",
       " 'translate English to German: They are a source of inexhaustible renewable energy.',\n",
       " 'translate English to German: Yes, it is. O&O UnErase 4 runs with all versions of Windows Vista, XP, 2000, 2003 and NT.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = load()\n",
    "d(l[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('python38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d33c3b0ef123e851f98887a8750ca7da758e4ff258891935cfe6ff9c0394387"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
