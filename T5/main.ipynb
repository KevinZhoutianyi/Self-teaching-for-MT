{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd() \n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from T5 import *\n",
    "from datasets import load_dataset,load_metric\n",
    "from transformers import T5Tokenizer\n",
    "import torch_optimizer as optim\n",
    "from transformers.optimization import Adafactor, AdafactorSchedule\n",
    "from MT_hyperparams import *\n",
    "import torch.backends.cudnn as cudnn\n",
    "from utils import *\n",
    "from attention_params import *\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, SubsetRandomSampler\n",
    "from torch.autograd import Variable\n",
    "from losses import *\n",
    "from architect import *\n",
    "import logging\n",
    "import sys\n",
    "import transformers\n",
    "import time\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(\"main\")\n",
    "\n",
    "\n",
    "parser.add_argument('--valid_num_points', type=int,             default = 100, help='validation data number')\n",
    "parser.add_argument('--train_num_points', type=int,             default = 1000, help='train data number')\n",
    "\n",
    "parser.add_argument('--batch_size', type=int,                   default=16,     help='Batch size')\n",
    "parser.add_argument('--train_w_num_points', type=int,           default=8,      help='train_w_num_points for each batch')\n",
    "parser.add_argument('--train_v_synthetic_num_points', type=int, default=4,      help='train_v_synthetic_num_points for each batch')\n",
    "parser.add_argument('--train_v_num_points', type=int,           default=2,      help='train_v_num_points for each batch')\n",
    "parser.add_argument('--train_A_num_points', type=int,           default=2,      help='train_A_num_points decay for each batch')\n",
    "\n",
    "\n",
    "parser.add_argument('--gpu', type=int,                          default=0,      help='gpu device id')\n",
    "parser.add_argument('--model_name', type=str,                   default='t5-small',      help='model_name')\n",
    "parser.add_argument('--exp_name', type=str,                     default='withlr large',      help='experiment name')\n",
    "parser.add_argument('--rep_num', type=int,                      default=25,      help='report times for 1 epoch')\n",
    "parser.add_argument('--test_num', type=int,                      default=4,      help='test times for 1 epoch')\n",
    "\n",
    "parser.add_argument('--epochs', type=int,                       default=50,     help='num of training epochs')\n",
    "parser.add_argument('--pre_epochs', type=int,                   default=0,      help='train model W for x epoch first')\n",
    "parser.add_argument('--grad_clip', type=float,                  default=1,      help='gradient clipping')\n",
    "parser.add_argument('--grad_acc_count', type=float,             default=64,      help='gradient accumulate steps')\n",
    "\n",
    "parser.add_argument('--w_lr', type=float,                       default=6e-4,   help='learning rate for w')\n",
    "parser.add_argument('--v_lr', type=float,                       default=6e-4,   help='learning rate for v')\n",
    "parser.add_argument('--A_lr', type=float,                       default=1e-4,   help='learning rate for A')\n",
    "parser.add_argument('--learning_rate_min', type=float,          default=1e-8,   help='learning_rate_min')\n",
    "parser.add_argument('--decay', type=float,                      default=1e-3,   help='weight decay')\n",
    "parser.add_argument('--momentum', type=float,                   default=0.7,    help='momentum')\n",
    "parser.add_argument('--smoothing', type=float,                   default=0.1,    help='labelsmoothing')\n",
    "\n",
    "\n",
    "parser.add_argument('--traindata_loss_ratio', type=float,       default=0.9,    help='human translated data ratio')\n",
    "parser.add_argument('--syndata_loss_ratio', type=float,         default=0.1,    help='augmented dataset ratio')\n",
    "\n",
    "parser.add_argument('--valid_begin', type=int,                  default=1,      help='whether valid before train')\n",
    "parser.add_argument('--train_A', type=int,                      default=0 ,     help='whether train A')\n",
    "\n",
    "\n",
    "\n",
    "args = parser.parse_args(args=[])#(args=['--batch_size', '8',  '--no_cuda'])#used in ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33monlydrinkwater\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    }
   ],
   "source": [
    "#https://wandb.ai/ check the running status online\n",
    "import wandb\n",
    "os.environ['WANDB_API_KEY']='a166474b1b7ad33a0549adaaec19a2f6d3f91d87'\n",
    "os.environ['WANDB_NAME']=args.exp_name\n",
    "wandb.init(project=\"500K\",config=args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/10 02:59:23 PM |\t  Reusing dataset wmt16 (C:\\Users\\kevin\\.cache\\huggingface\\datasets\\wmt16\\de-en\\1.0.0\\0d9fb3e814712c785176ad8cdb9f465fbe6479000ee6546725db30ad8a8b5f8a)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 33.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/10 02:59:23 PM |\t  Namespace(A_lr=0.0001, batch_size=20, decay=0.001, epochs=50, exp_name='withlr large', gpu=0, grad_acc_count=2, grad_clip=1, learning_rate_min=1e-08, model_name='t5-small', momentum=0.7, pre_epochs=0, rep_num=25, smoothing=0.1, syndata_loss_ratio=0.1, test_num=4, train_A=0, train_A_num_points=4, train_num_points=1000, train_v_num_points=4, train_v_synthetic_num_points=4, train_w_num_points=8, traindata_loss_ratio=0.9, v_lr=0.0006, valid_begin=1, valid_num_points=100, w_lr=0.0006)\n",
      "04/10 02:59:23 PM |\t  DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 4548885\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 2169\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 2999\n",
      "    })\n",
      "})\n",
      "04/10 02:59:23 PM |\t  {'translation': {'de': 'Ich bitte Sie, sich zu einer Schweigeminute zu erheben.', 'en': \"Please rise, then, for this minute' s silence.\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#logging file\n",
    "now = time.strftime(\"%Y-%m-%d-%H_%M_%S\",time.localtime(time.time())) \n",
    "\n",
    "log_format = '%(asctime)s |\\t  %(message)s'\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO,\n",
    "    format=log_format, datefmt='%m/%d %I:%M:%S %p')\n",
    "fh = logging.FileHandler(os.path.join(\"./log/\", now+'.txt'),'w',encoding = \"UTF-8\")\n",
    "fh.setFormatter(logging.Formatter(log_format))\n",
    "logging.getLogger().addHandler(fh)\n",
    "dataset = load_dataset('wmt16','de-en')\n",
    "\n",
    "logging.info(args)\n",
    "logging.info(dataset)\n",
    "logging.info(dataset['train'][5])\n",
    "\n",
    "writer = SummaryWriter('tensorboard')\n",
    "\n",
    "# Setting the seeds\n",
    "np.random.seed(seed_)\n",
    "torch.cuda.set_device(args.gpu)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cudnn.benchmark = True\n",
    "torch.manual_seed(seed_)\n",
    "cudnn.enabled=True\n",
    "torch.cuda.manual_seed(seed_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/10 02:59:25 PM |\t  modelsize:60.506624MB\n"
     ]
    }
   ],
   "source": [
    "modelname = args.model_name\n",
    "pretrained  =  T5ForConditionalGeneration.from_pretrained(modelname)\n",
    "logging.info(f'modelsize:{count_parameters_in_MB(pretrained)}MB')\n",
    "torch.save(pretrained,modelname+'.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/10 02:59:27 PM |\t  Loading cached shuffled indices for dataset at C:\\Users\\kevin\\.cache\\huggingface\\datasets\\wmt16\\de-en\\1.0.0\\0d9fb3e814712c785176ad8cdb9f465fbe6479000ee6546725db30ad8a8b5f8a\\cache-4574fe47268cd3fd.arrow\n",
      "04/10 02:59:27 PM |\t  Loading cached shuffled indices for dataset at C:\\Users\\kevin\\.cache\\huggingface\\datasets\\wmt16\\de-en\\1.0.0\\0d9fb3e814712c785176ad8cdb9f465fbe6479000ee6546725db30ad8a8b5f8a\\cache-bf1487bfb5cd2cad.arrow\n",
      "04/10 02:59:27 PM |\t  Loading cached shuffled indices for dataset at C:\\Users\\kevin\\.cache\\huggingface\\datasets\\wmt16\\de-en\\1.0.0\\0d9fb3e814712c785176ad8cdb9f465fbe6479000ee6546725db30ad8a8b5f8a\\cache-73316b6a255c34bc.arrow\n",
      "04/10 03:01:25 PM |\t  train len: 1000\n",
      "04/10 03:01:25 PM |\t  train_w_num_points_len: 400\n",
      "04/10 03:01:25 PM |\t  train_v_synthetic_num_points_len: 200\n",
      "04/10 03:01:25 PM |\t  train_v_num_points_len: 200\n",
      "04/10 03:01:25 PM |\t  train_A_num_points_len: 200\n",
      "04/10 03:01:26 PM |\t  valid len: 100\n",
      "04/10 03:01:26 PM |\t  test len: 2999\n",
      "04/10 03:01:26 PM |\t  {'de': 'Nur dann, wenn wir unsere Normen selber durchsetzen können, werden wir Märkte von morgen erobern können.', 'en': 'translate English to German: Only if we can develop our own standards will we be able to conquer the markets of the future.'}\n",
      "04/10 03:01:26 PM |\t  {'de': 'Zweifellos handelt es sich hier um zwei sehr wichtige Berichte.', 'en': 'translate English to German: There is no doubt that these are two very important reports.'}\n",
      "04/10 03:01:26 PM |\t  {'de': '\"Wir möchten die Familien über die Jahre kennenlernen und begleiten\".', 'en': 'translate English to German: \"We want to get to know the families and support them over the years.\"'}\n"
     ]
    }
   ],
   "source": [
    "# preprocess the data, make a dataloader\n",
    "import random\n",
    "tokenizer = T5Tokenizer.from_pretrained(modelname)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss( reduction='none')#teacher shouldn't have label smoothing, especially when student got same size.\n",
    "criterion_v = torch.nn.CrossEntropyLoss( reduction='none',label_smoothing=args.smoothing) #without LS, V may be too confident to that syn data, and LS do well for real data also.\n",
    "dataset = dataset.shuffle(seed=seed_)\n",
    "train = dataset['train']['translation'][:args.train_num_points]\n",
    "valid = dataset['train']['translation'][args.train_num_points:args.train_num_points+args.valid_num_points]#TODO:change dataset['validation']['translation'][:args.valid_num_points]\n",
    "test = dataset['test']['translation']#[L_t+L_v:L_t+L_v+L_test]\n",
    "def preprocess(dat):\n",
    "    for t in dat:\n",
    "        t['en'] = \"translate English to German: \" + t['en']  #needed for T5\n",
    "preprocess(train)\n",
    "preprocess(valid)\n",
    "preprocess(test)\n",
    "#TODO: Syn_input should be monolingual data, should try en-fo's en. cuz wmt may align\n",
    "num_batch = args.train_num_points//args.batch_size\n",
    "train = train[:args.batch_size*num_batch]\n",
    "logging.info(\"train len: %d\",len(train))\n",
    "\n",
    "'''\n",
    "each mini batch consist of : \n",
    "1. data to train W\n",
    "2. monolingual data to generate parallel data\n",
    "3. data to train V\n",
    "4. data to train A\n",
    "'''\n",
    "\n",
    "\n",
    "train_w_num_points_len = num_batch * args.train_w_num_points\n",
    "train_v_synthetic_num_points_len = num_batch * args.train_v_synthetic_num_points\n",
    "train_v_num_points_len = num_batch * args.train_v_num_points\n",
    "train_A_num_points_len = num_batch * args.train_A_num_points\n",
    "logging.info(\"train_w_num_points_len: %d\",train_w_num_points_len)\n",
    "logging.info(\"train_v_synthetic_num_points_len: %d\",train_v_synthetic_num_points_len)\n",
    "logging.info(\"train_v_num_points_len: %d\",train_v_num_points_len)\n",
    "logging.info(\"train_A_num_points_len: %d\",train_A_num_points_len)\n",
    "\n",
    "attn_idx_list = torch.arange(train_w_num_points_len).cuda()\n",
    "logging.info(\"valid len: %d\",len(valid))\n",
    "logging.info(\"test len: %d\" ,len(test))\n",
    "logging.info(train[2])\n",
    "logging.info(valid[2])\n",
    "logging.info(test[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get train data start\n",
      "get train data end\n",
      "04/10 03:01:26 PM |\t  train data get\n",
      "04/10 03:01:26 PM |\t  train data loader get\n",
      "04/10 03:01:26 PM |\t  valid data loader get\n",
      "04/10 03:01:27 PM |\t  test data loader get\n"
     ]
    }
   ],
   "source": [
    "target_language  = 'de'\n",
    "train_data = get_train_Dataset(train, tokenizer)# Create the DataLoader for our training set.\n",
    "logging.info('train data get')\n",
    "train_dataloader = DataLoader(train_data, sampler= SequentialSampler(train_data), \n",
    "                        batch_size=args.batch_size, pin_memory=True, num_workers=2)\n",
    "logging.info('train data loader get')\n",
    "valid_data = get_aux_dataset(valid, tokenizer)# Create the DataLoader for our training set.\n",
    "valid_dataloader = DataLoader(valid_data, sampler=RandomSampler(valid_data), \n",
    "                        batch_size=16, pin_memory=True, num_workers=2)\n",
    "logging.info('valid data loader get')\n",
    "test_data = get_aux_dataset(test, tokenizer)# Create the DataLoader for our training set.\n",
    "test_dataloader = DataLoader(test_data, sampler=SequentialSampler(test_data),\n",
    "                        batch_size=16, pin_memory=True, num_workers=2)#, sampler=RandomSampler(test_data)\n",
    "logging.info('test data loader get')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "A = attention_params(train_w_num_points_len)#half of train regarded as u\n",
    "A = A.cuda()\n",
    "\n",
    "\n",
    "\n",
    "# TODO: model loaded from saved model\n",
    "model_w = T5(criterion=criterion, tokenizer= tokenizer, args = args, name = 'model_w_in_main')\n",
    "model_w = model_w.cuda()\n",
    "w_optimizer = Adafactor(model_w.parameters(), lr = args.w_lr ,scale_parameter=False, relative_step=False , warmup_init=False,clip_threshold=1,beta1=0)\n",
    "scheduler_w  = torch.optim.lr_scheduler.StepLR(w_optimizer,step_size=10, gamma=0.9)\n",
    "\n",
    "\n",
    "\n",
    "model_v = T5(criterion=criterion_v, tokenizer= tokenizer, args = args, name = 'model_v_in_main')\n",
    "model_v = model_v.cuda()\n",
    "v_optimizer =Adafactor(model_v.parameters(), lr = args.v_lr ,scale_parameter=False, relative_step=False, warmup_init=False, clip_threshold=1,beta1=0)\n",
    "scheduler_v  = torch.optim.lr_scheduler.StepLR(v_optimizer,step_size=10, gamma=0.9)\n",
    "\n",
    "\n",
    "\n",
    "architect = Architect(model_w, model_v,  A, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def my_test(_dataloader,model,epoch):\n",
    "    \n",
    "    acc = 0\n",
    "    counter = 0\n",
    "    model.eval()\n",
    "    metric_sacrebleu =  load_metric('sacrebleu')\n",
    "    metric_bleu =  load_metric('bleu')\n",
    "\n",
    "    # for step, batch in enumerate(tqdm(_dataloader,desc =\"test for epoch\"+str(epoch))):\n",
    "    for step, batch in enumerate(_dataloader):\n",
    "        \n",
    "        test_dataloaderx = Variable(batch[0], requires_grad=False).to(device, non_blocking=False)\n",
    "        test_dataloaderx_attn = Variable(batch[1], requires_grad=False).to(device, non_blocking=False)\n",
    "        test_dataloadery = Variable(batch[2], requires_grad=False).to(device, non_blocking=False)\n",
    "        test_dataloadery_attn = Variable(batch[3], requires_grad=False).to(device, non_blocking=False)\n",
    "        ls = my_loss(test_dataloaderx,test_dataloaderx_attn,test_dataloadery,test_dataloadery_attn,model)\n",
    "        acc+= ls.item()\n",
    "        counter+= 1\n",
    "        pre = model.generate(test_dataloaderx)\n",
    "        x_decoded = tokenizer.batch_decode(test_dataloaderx,skip_special_tokens=True)\n",
    "        pred_decoded = tokenizer.batch_decode(pre,skip_special_tokens=True)\n",
    "        label_decoded =  tokenizer.batch_decode(test_dataloadery,skip_special_tokens=True)\n",
    "        \n",
    "        pred_str = [x  for x in pred_decoded]\n",
    "        label_str = [[x] for x in label_decoded]\n",
    "        pred_list = [x.split()  for x in pred_decoded]\n",
    "        label_list = [[x.split()] for x in label_decoded]\n",
    "        metric_sacrebleu.add_batch(predictions=pred_str, references=label_str)\n",
    "        metric_bleu.add_batch(predictions=pred_list, references=label_list)\n",
    "        if  step%100==0:\n",
    "            logging.info(f'x_decoded[:2]:{x_decoded[:2]}')\n",
    "            logging.info(f'pred_decoded[:2]:{pred_decoded[:2]}')\n",
    "            logging.info(f'label_decoded[:2]:{label_decoded[:2]}')\n",
    "            \n",
    "            \n",
    "    logging.info('computing score...') \n",
    "    sacrebleu_score = metric_sacrebleu.compute()\n",
    "    bleu_score = metric_bleu.compute()\n",
    "    logging.info('%s sacreBLEU : %f',model.name,sacrebleu_score['score'])#TODO:bleu may be wrong cuz max length\n",
    "    logging.info('%s BLEU : %f',model.name,bleu_score['bleu'])\n",
    "    logging.info('%s test loss : %f',model.name,acc/(counter))\n",
    "    writer.add_scalar(model.name+\"/test_loss\", acc/counter, global_step=epoch)\n",
    "    writer.add_scalar(model.name+\"/sacreBLEU\",sacrebleu_score['score'], global_step=epoch)\n",
    "    writer.add_scalar(model.name+\"/BLEU\",bleu_score['bleu'], global_step=epoch)\n",
    "    \n",
    "    wandb.log({'sacreBLEU'+model.name: sacrebleu_score['score']})\n",
    "    \n",
    "    wandb.log({'test_loss'+model.name: acc/counter})\n",
    "    del test_dataloaderx,acc,counter,test_dataloaderx_attn,sacrebleu_score,bleu_score,test_dataloadery,test_dataloadery_attn,ls,pre,x_decoded,pred_decoded,label_decoded,pred_str,label_str,pred_list,label_list\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    model.train()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_train(epoch, _dataloader, w_model, v_model, architect, A, w_optimizer, v_optimizer, lr_w, lr_v, ):\n",
    "    # print(torch.cuda.memory_allocated(device=device))\n",
    "       \n",
    "    objs_w = AvgrageMeter()\n",
    "    objs_v = AvgrageMeter()\n",
    "    v_trainloss_acc = 0\n",
    "    w_trainloss_acc = 0\n",
    "    wsize = args.train_w_num_points #now  train_x is [num of batch, datasize], so its seperate batch for the code below\n",
    "    synsize = args.train_v_synthetic_num_points\n",
    "    vsize = args.train_v_num_points \n",
    "    vtrainsize = vsize+synsize\n",
    "    vtrainsize_total = train_v_num_points_len+train_v_synthetic_num_points_len\n",
    "    Asize = args.train_A_num_points \n",
    "    grad_acc_count = args.grad_acc_count\n",
    "    loader_len = len(_dataloader)\n",
    "    split_size=[wsize,synsize,vsize,Asize]\n",
    "    for step, batch in enumerate(_dataloader) :\n",
    "        train_x = Variable(batch[0], requires_grad=False).to(device, non_blocking=True)\n",
    "        train_x_attn = Variable(batch[1], requires_grad=False).to(device, non_blocking=True)\n",
    "        train_y = Variable(batch[2], requires_grad=False).to(device, non_blocking=True)\n",
    "        train_y_attn = Variable(batch[3], requires_grad=False).to(device, non_blocking=True) \n",
    "        (input_w,input_syn,input_v,input_A_v) = torch.split(train_x,split_size)\n",
    "        (input_w_attn,input_syn_attn,input_v_attn,input_A_v_attn) = torch.split(train_x_attn,split_size)\n",
    "        (output_w,_,output_v,output_A_v) = torch.split(train_y,split_size)\n",
    "        (output_w_attn,_,output_v_attn,output_A_v_attn) = torch.split(train_y_attn,split_size)\n",
    "        attn_idx = attn_idx_list[wsize*step:(wsize*step+wsize)]\n",
    "       \n",
    "\n",
    "        if (epoch <= args.epochs) and (args.train_A == 1) and epoch >= args.pre_epochs:\n",
    "            architect.step(input_w,  output_w,input_w_attn, output_w_attn, w_optimizer, input_syn, input_syn_attn,input_A_v, input_A_v_attn, output_A_v, \n",
    "                output_A_v_attn, v_optimizer, attn_idx, lr_w, lr_v)\n",
    "        \n",
    "        \n",
    "        if  epoch <= args.epochs:\n",
    "            for p in w_model.parameters():\n",
    "                p.requires_grad = True\n",
    "                \n",
    "            loss_w = CTG_loss(input_w, input_w_attn, output_w, output_w_attn, attn_idx, A, w_model)\n",
    "            \n",
    "            w_trainloss_acc+=loss_w.item()\n",
    "            loss_w.backward()\n",
    "            objs_w.update(loss_w.item(), wsize)\n",
    "            if ((step + 1) % grad_acc_count == 0) or (step + 1 == loader_len): \n",
    "                # nn.utils.clip_grad_norm(w_model.parameters(), args.grad_clip)\n",
    "                w_optimizer.step()\n",
    "                w_optimizer.zero_grad()\n",
    "            for p in w_model.parameters():\n",
    "                    p.requires_grad = False\n",
    "\n",
    "        if epoch >= args.pre_epochs and epoch <= args.epochs:\n",
    "            \n",
    "            for p in v_model.parameters():\n",
    "                p.requires_grad = True\n",
    "            loss_aug = calc_loss_aug(input_syn, input_syn_attn, w_model, v_model)\n",
    "            loss = my_loss2(input_v,input_v_attn,output_v,output_v_attn,model_v)\n",
    "            v_loss =  (args.traindata_loss_ratio*loss+loss_aug*args.syndata_loss_ratio)/num_batch\n",
    "            v_trainloss_acc+=v_loss.item()\n",
    "            v_loss.backward()\n",
    "            objs_v.update(v_loss.item(), vtrainsize)\n",
    "            if ((step + 1) % grad_acc_count == 0) or (step + 1 == loader_len): \n",
    "                # nn.utils.clip_grad_norm(v_model.parameters(), args.grad_clip)\n",
    "                v_optimizer.step()  \n",
    "                v_optimizer.zero_grad() \n",
    "            for p in v_model.parameters():\n",
    "                    p.requires_grad = False\n",
    "        \n",
    "\n",
    "        progress = 100*(step)/(loader_len-1)\n",
    "        rep_fre = (loader_len//args.rep_num)\n",
    "        test_fre = (loader_len//args.test_num)\n",
    "\n",
    "        if((step)%test_fre == 0 and step!=0):\n",
    "            my_test(valid_dataloader,model_w,epoch)\n",
    "            my_test(valid_dataloader,model_v,epoch)\n",
    "        \n",
    "\n",
    "\n",
    "        if((step)%rep_fre == 0 or (step)==(loader_len-1)):\n",
    "            logging.info(f\"{progress:5.3}% \\t w_loss_avg:{objs_w.avg*train_w_num_points_len:^.7f}\\t v_loss_avg:{objs_v.avg*vtrainsize_total:^.7f}\")\n",
    "  \n",
    "    logging.info(str((\"Attention Weights A : \", A.alpha)))\n",
    "    \n",
    "    return w_trainloss_acc,v_trainloss_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "484058624\n",
      "04/10 03:01:39 PM |\t  x_decoded[:2]:['translate English to German: The worldwide Iguassu Falls are only a 20-minute drive away.', 'translate English to German: Soak up the central Madrid atmosphere from the sublime roof terrace both day and night; the Atico Stella apartment really knows how to steal the show in luxury vacation homes.']\n",
      "04/10 03:01:39 PM |\t  pred_decoded[:2]:['Die weltweiten Iguassu Falls sind nur 20 Fahrminuten entfernt.', 'Genießen Sie die zentrale Atmosphäre Madrids von der erhabenen Dachterrasse Tag und Nacht; das Atico Stella Apartment weiß wirklich, wie man die Show in luxuriösen Ferienhäusern stehlen kann.']\n",
      "04/10 03:01:39 PM |\t  label_decoded[:2]:['Die weltberühmten Iguaçu-Wasserfälle befinden sich nur 20 Fahrminuten entfernt.', 'Genießen Sie die Atmosphäre auf der schönen Dachterrasse bei Tag und bei Nacht. Das Atico Stella Apartment ist perfekt, um einen tollen Aufenthalt in Madrid zu verleben.']\n",
      "04/10 03:02:00 PM |\t  computing score...\n",
      "04/10 03:02:00 PM |\t  model_w_in_main sacreBLEU : 21.649276\n",
      "04/10 03:02:00 PM |\t  model_w_in_main BLEU : 0.174584\n",
      "04/10 03:02:00 PM |\t  model_w_in_main test loss : 1.569965\n",
      "484058624\n",
      "04/10 03:02:00 PM |\t  \n",
      "\n",
      "  ----------------epoch:0,\t\tlr_w:0.0006,\t\tlr_v:0.0006----------------\n",
      "484058624\n",
      "0\n",
      "2 484197888\n",
      "3 484197888\n",
      "4 730130432\n",
      "5 978527744\n",
      "04/10 03:02:03 PM |\t    0.0% \t w_loss_avg:1.3936968\t v_loss_avg:19.0046877\n",
      "978527744\n",
      "1\n",
      "2 978527744\n",
      "3 978527744\n",
      "step!zerograd\n",
      "4 1222310400\n",
      "5 1465142784\n",
      "1465142784\n",
      "2\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "04/10 03:02:05 PM |\t   4.08% \t w_loss_avg:1.7175377\t v_loss_avg:14.5678995\n",
      "1465142784\n",
      "3\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "step!zerograd\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "1465142784\n",
      "4\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "04/10 03:02:08 PM |\t   8.16% \t w_loss_avg:1.7825455\t v_loss_avg:15.8716874\n",
      "1465142784\n",
      "5\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "step!zerograd\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "1465142784\n",
      "6\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "04/10 03:02:10 PM |\t   12.2% \t w_loss_avg:1.7725960\t v_loss_avg:14.9162232\n",
      "1465142784\n",
      "7\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "step!zerograd\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "1465142784\n",
      "8\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "04/10 03:02:11 PM |\t   16.3% \t w_loss_avg:1.7177530\t v_loss_avg:14.2352923\n",
      "1465142784\n",
      "9\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "step!zerograd\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "1465142784\n",
      "10\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "04/10 03:02:14 PM |\t   20.4% \t w_loss_avg:1.6171455\t v_loss_avg:13.3018965\n",
      "1465142784\n",
      "11\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "step!zerograd\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "1465142784\n",
      "12\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "4 1465142784\n",
      "04/10 03:02:24 PM |\t  x_decoded[:2]:['translate English to German: Cappato Report (A5-0270)/2001)', 'translate English to German: But I would like to feel that the Minister was giving me some kind of response as to whether in his view the Council thinks this is an important priority.']\n",
      "04/10 03:02:24 PM |\t  pred_decoded[:2]:['Bericht Cappato (A5-0270)/2001)', 'Aber ich möchte den Eindruck haben, daß mir der Herr Minister eine gewisse Antwort gegeben hat, ob er der Ansicht ist, daß dies für den Rat eine wichtige Priorität ist.']\n",
      "04/10 03:02:24 PM |\t  label_decoded[:2]:['Bericht Cappato (A5-0270)/2001)', 'Ich kritisiere also keineswegs andere, statt vor der eigenen Tür zu kehren. Ich wäre jedoch dankbar, wenn der Minister mir erläutern könnte, ob er der Meinung ist, dass der Rat dies für eine wichtige Priorität hält.']\n",
      "04/10 03:02:45 PM |\t  computing score...\n",
      "04/10 03:02:45 PM |\t  model_w_in_main sacreBLEU : 21.298424\n",
      "04/10 03:02:45 PM |\t  model_w_in_main BLEU : 0.171488\n",
      "04/10 03:02:45 PM |\t  model_w_in_main test loss : 1.564822\n",
      "04/10 03:02:51 PM |\t  x_decoded[:2]:['translate English to German: All these concerns are brought together particularly in Amendment No 2 and the Commission is urged to respond positively and quickly.', 'translate English to German: This is the case with Iran.']\n",
      "04/10 03:02:51 PM |\t  pred_decoded[:2]:['All diese Bedenken werden insbesondere in nderungsantrag 2 zusammengefasst, und die Kommission wird aufgefordert, schnell und positiv zu reagieren.', 'Das gilt auch für den Iran.']\n",
      "04/10 03:02:51 PM |\t  label_decoded[:2]:['Alle diese Aspekte werden insbesondere im nderungsantrag Nr. 2 angesprochen, und die Kommission wird aufgefordert, schnell und positiv zu reagieren.', 'Dies trifft im Falle des Iran auch zu.']\n",
      "04/10 03:03:12 PM |\t  computing score...\n",
      "04/10 03:03:12 PM |\t  model_v_in_main sacreBLEU : 18.456294\n",
      "04/10 03:03:12 PM |\t  model_v_in_main BLEU : 0.146423\n",
      "04/10 03:03:12 PM |\t  model_v_in_main test loss : 7.062319\n",
      "5 1465142784\n",
      "04/10 03:03:12 PM |\t   24.5% \t w_loss_avg:1.6561192\t v_loss_avg:13.2180855\n",
      "1465142784\n",
      "13\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "step!zerograd\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "1465142784\n",
      "14\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "04/10 03:03:14 PM |\t   28.6% \t w_loss_avg:1.6492905\t v_loss_avg:12.9406479\n",
      "1465142784\n",
      "15\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "step!zerograd\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "1465142784\n",
      "16\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "04/10 03:03:17 PM |\t   32.7% \t w_loss_avg:1.6327372\t v_loss_avg:12.9458622\n",
      "1465142784\n",
      "17\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "step!zerograd\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "1465142784\n",
      "18\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "04/10 03:03:19 PM |\t   36.7% \t w_loss_avg:1.6771948\t v_loss_avg:12.4072980\n",
      "1465142784\n",
      "19\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "step!zerograd\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "1465142784\n",
      "20\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "04/10 03:03:22 PM |\t   40.8% \t w_loss_avg:1.6448813\t v_loss_avg:12.1354266\n",
      "1465142784\n",
      "21\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "step!zerograd\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "1465142784\n",
      "22\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "04/10 03:03:24 PM |\t   44.9% \t w_loss_avg:1.6707236\t v_loss_avg:11.8923322\n",
      "1465142784\n",
      "23\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "step!zerograd\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "1465142784\n",
      "24\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "4 1465142784\n",
      "04/10 03:03:34 PM |\t  x_decoded[:2]:['translate English to German: That is why we are able to say today, wherever we happen to be sitting or standing here in this Chamber, that if there is such a thing as political justice, right here in this European Parliament too, then this political justice has become reality with the election of Nicole Fontaine as President of the European Parliament.', 'translate English to German: Cappato Report (A5-0270)/2001)']\n",
      "04/10 03:03:34 PM |\t  pred_decoded[:2]:['Deshalb können wir heute sagen, wo immer wir hier in diesem Plenarsaal sitzen oder stehen, dass, wenn es so etwas wie politische Gerechtigkeit gibt, auch hier im Europäischen Parlament, diese politische Gerechtigkeit mit der Wahl von Nicole Fontaine zum Präsidenten des Europäischen Parlaments Wirklichkeit geworden ist.', 'Bericht Cappato (A5-0270)/2001)']\n",
      "04/10 03:03:34 PM |\t  label_decoded[:2]:['Deswegen können wir, wo immer wir hier im Haus stehen oder sitzen mögen, heute sagen: Wenn es politische Gerechtigkeit gibt, gerade auch hier in diesem Europäischen Parlament, dann ist diese politische Gerechtigkeit Wirklichkeit geworden mit der Wahl von Nicole Fontaine zur Präsidentin des Europäischen Parlaments!', 'Bericht Cappato (A5-0270)/2001)']\n",
      "04/10 03:03:55 PM |\t  computing score...\n",
      "04/10 03:03:55 PM |\t  model_w_in_main sacreBLEU : 22.732729\n",
      "04/10 03:03:55 PM |\t  model_w_in_main BLEU : 0.185454\n",
      "04/10 03:03:55 PM |\t  model_w_in_main test loss : 1.578347\n",
      "04/10 03:04:02 PM |\t  x_decoded[:2]:['translate English to German: We are not alone in highlighting these abuses: there have been loud protests from large parts of the Catholic Church, and both lay and Catholic voluntary associations and organisations.', 'translate English to German: Load the mini figure or the space vehicle.']\n",
      "04/10 03:04:02 PM |\t  pred_decoded[:2]:['Wir sind nicht alleine, wenn es darum geht, diesen Missbrauch hervorzuheben: es gab laute Proteste von großen Teilen der katholischen Kirche, sowohl von laien als auch von katholischen Freiwilligenverbänden und Organisationen.', 'Die Minifigur oder das Raumfahrzeug laden.']\n",
      "04/10 03:04:02 PM |\t  label_decoded[:2]:['Es sind nicht nur wir, die diese Übergriffe herausstellen: Es gab starke Proteste von breiten Kreisen der Katholischen Kirche sowie von weltlichen und katholischen Verbänden und ehrenamtlichen Organisationen.', 'Laden sie entweder die Figur oder den Raumgleiter wie üblich.']\n",
      "04/10 03:04:24 PM |\t  computing score...\n",
      "04/10 03:04:24 PM |\t  model_v_in_main sacreBLEU : 18.811849\n",
      "04/10 03:04:24 PM |\t  model_v_in_main BLEU : 0.150351\n",
      "04/10 03:04:24 PM |\t  model_v_in_main test loss : 6.775422\n",
      "5 1465142784\n",
      "04/10 03:04:24 PM |\t   49.0% \t w_loss_avg:1.6706258\t v_loss_avg:11.9231406\n",
      "1465142784\n",
      "25\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "step!zerograd\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "1465142784\n",
      "26\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "04/10 03:04:27 PM |\t   53.1% \t w_loss_avg:1.6657062\t v_loss_avg:11.6535257\n",
      "1465142784\n",
      "27\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "step!zerograd\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "1465142784\n",
      "28\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "04/10 03:04:29 PM |\t   57.1% \t w_loss_avg:1.6889328\t v_loss_avg:11.4875857\n",
      "1465142784\n",
      "29\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "step!zerograd\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "1465142784\n",
      "30\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "04/10 03:04:37 PM |\t   61.2% \t w_loss_avg:1.7244866\t v_loss_avg:11.2575111\n",
      "1465142784\n",
      "31\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "step!zerograd\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "1465142784\n",
      "32\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "04/10 03:04:40 PM |\t   65.3% \t w_loss_avg:1.7051202\t v_loss_avg:11.1881695\n",
      "1465142784\n",
      "33\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "step!zerograd\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "1465142784\n",
      "34\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "04/10 03:04:42 PM |\t   69.4% \t w_loss_avg:1.7108741\t v_loss_avg:11.1755314\n",
      "1465142784\n",
      "35\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "step!zerograd\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "1465142784\n",
      "36\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "4 1465142784\n",
      "04/10 03:04:52 PM |\t  x_decoded[:2]:['translate English to German: This study was based on a particularly small sample of children who consumed sweeteners.', 'translate English to German: All rooms have made up separate beds, a sink, mirror, closet, desk and a chair.']\n",
      "04/10 03:04:52 PM |\t  pred_decoded[:2]:['Diese Studie basierte auf einer besonders kleinen Probe von Kindern, die Süßungsmittel konsumierten.', 'Alle Zimmer sind mit separaten Betten, Waschbecken, Spiegel, Schrank, Schreibtisch und Stuhl ausgestattet.']\n",
      "04/10 03:04:52 PM |\t  label_decoded[:2]:['Die Studie stützte sich auf eine außerordentlich kleine Auswahl von Kindern, die Süßungsmittel verzehrten.', 'Aller Zimmer verfügen über separate Betten, ein Waschbecken, einen Spiegel, einen Wandschrank, einen Schreibtisch und einen Stuhl.']\n",
      "04/10 03:05:13 PM |\t  computing score...\n",
      "04/10 03:05:13 PM |\t  model_w_in_main sacreBLEU : 23.021354\n",
      "04/10 03:05:13 PM |\t  model_w_in_main BLEU : 0.191573\n",
      "04/10 03:05:13 PM |\t  model_w_in_main test loss : 1.615186\n",
      "04/10 03:05:20 PM |\t  x_decoded[:2]:['translate English to German: Take, for example, the frequently mentioned need for the new regulation of financial markets.', 'translate English to German: In practice the Canon PowerShot A620 is a pleasure to use.']\n",
      "04/10 03:05:20 PM |\t  pred_decoded[:2]:['Die häufig erwähnte Notwendigkeit der neuen Regulierung der Finanzmärkte.', 'the Canon PowerShot A620 is a pleasure to use.']\n",
      "04/10 03:05:20 PM |\t  label_decoded[:2]:['Nehmen wir alleine die oft beschworene Notwendigkeit der Neuregulierung der Finanzmärkte!', 'Die Benutzung der Canon PowerShot A620 hat uns in der Praxis rundherum gut gefallen.']\n",
      "04/10 03:05:41 PM |\t  computing score...\n",
      "04/10 03:05:41 PM |\t  model_v_in_main sacreBLEU : 19.851165\n",
      "04/10 03:05:41 PM |\t  model_v_in_main BLEU : 0.161373\n",
      "04/10 03:05:41 PM |\t  model_v_in_main test loss : 6.286617\n",
      "5 1465142784\n",
      "04/10 03:05:41 PM |\t   73.5% \t w_loss_avg:1.7182752\t v_loss_avg:11.0775002\n",
      "1465142784\n",
      "37\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "step!zerograd\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "1465142784\n",
      "38\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "04/10 03:05:44 PM |\t   77.6% \t w_loss_avg:1.7400935\t v_loss_avg:10.9613146\n",
      "1465142784\n",
      "39\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "step!zerograd\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "1465142784\n",
      "40\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "04/10 03:05:46 PM |\t   81.6% \t w_loss_avg:1.7266712\t v_loss_avg:10.8367880\n",
      "1465142784\n",
      "41\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "step!zerograd\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "1465142784\n",
      "42\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "04/10 03:05:48 PM |\t   85.7% \t w_loss_avg:1.7515968\t v_loss_avg:10.8048305\n",
      "1465142784\n",
      "43\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "step!zerograd\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "1465142784\n",
      "44\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "04/10 03:05:51 PM |\t   89.8% \t w_loss_avg:1.7549588\t v_loss_avg:10.8010427\n",
      "1465142784\n",
      "45\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "step!zerograd\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "1465142784\n",
      "46\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "04/10 03:05:53 PM |\t   93.9% \t w_loss_avg:1.7513285\t v_loss_avg:10.6309706\n",
      "1465142784\n",
      "47\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "step!zerograd\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "1465142784\n",
      "48\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "4 1465142784\n",
      "04/10 03:06:03 PM |\t  x_decoded[:2]:['translate English to German: I am also assuming that it will refrain from imposing any economic sanctions on Kosovo.', 'translate English to German: Let me reassure Mr Provan.']\n",
      "04/10 03:06:03 PM |\t  pred_decoded[:2]:['Ich gehe auch davon aus, daß es keine wirtschaftlichen Sanktionen gegen den Kosovo verhängen wird.', 'Lassen Sie mich Herrn Provan beruhigen.']\n",
      "04/10 03:06:03 PM |\t  label_decoded[:2]:['Des Weiteren gehe ich davon aus, dass sie keine Wirtschaftssanktionen gegen das Kosovo verhängen wird.', 'Ich kann Herrn Provan beruhigen.']\n",
      "04/10 03:06:25 PM |\t  computing score...\n",
      "04/10 03:06:25 PM |\t  model_w_in_main sacreBLEU : 21.655168\n",
      "04/10 03:06:25 PM |\t  model_w_in_main BLEU : 0.174606\n",
      "04/10 03:06:25 PM |\t  model_w_in_main test loss : 1.688302\n",
      "04/10 03:06:31 PM |\t  x_decoded[:2]:['translate English to German: An effective transport infrastructure could result in the distance being measured in time and not in kilometres, so that the people that work in urban areas could live in rural areas thus contributing to their economic development.', 'translate English to German: Only USD 3 billion a year is being spent globally in trying to halt the spread of AIDS.']\n",
      "04/10 03:06:31 PM |\t  pred_decoded[:2]:['Eine effektive Verkehrsinfrastruktur könnte dazu führen, dass die Entfernung zeitlich und nicht in Kilometern gemessen wird, sodass die Menschen, die in städtischen Gebieten arbeiten, in ländlichen Gebieten leben können, so dass sie ihre wirtschaftliche Entwicklung fördern.', 'nur 3 Milliarden USD pro Jahr werden weltweit ausgegeben, um die Ausbreitung von AIDS zu stoppen.']\n",
      "04/10 03:06:31 PM |\t  label_decoded[:2]:['Mit einer effizienten Verkehrsinfrastruktur ließen sich Entfernungen in Zeit anstatt in Kilometern messen. Menschen, die in Stadtgebieten arbeiten, könnten so auf dem Land leben und zu seiner wirtschaftlichen Entwicklung beitragen.', 'Derzeit werden weltweit lediglich drei Milliarden US-Dollar pro Jahr für Bemühungen ausgegeben, die Ausbreitung von Aids zum Stillstand zu bringen.']\n",
      "04/10 03:06:53 PM |\t  computing score...\n",
      "04/10 03:06:53 PM |\t  model_v_in_main sacreBLEU : 18.316221\n",
      "04/10 03:06:53 PM |\t  model_v_in_main BLEU : 0.146818\n",
      "04/10 03:06:53 PM |\t  model_v_in_main test loss : 6.289348\n",
      "5 1465142784\n",
      "04/10 03:06:53 PM |\t   98.0% \t w_loss_avg:1.7405162\t v_loss_avg:10.9819411\n",
      "1465142784\n",
      "49\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "step!zerograd\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "04/10 03:06:55 PM |\t  1e+02% \t w_loss_avg:1.7276946\t v_loss_avg:10.9336422\n",
      "04/10 03:06:55 PM |\t  ('Attention Weights A : ', Parameter containing:\n",
      "tensor([0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025], device='cuda:0', requires_grad=True))\n",
      "04/10 03:06:55 PM |\t  w_train_loss:1.727694634348154,v_train_loss:10.933642238378525\n",
      "04/10 03:07:03 PM |\t  x_decoded[:2]:['translate English to German: Fleeing Paris which was in the throes of a cholera epidemic, the young writer, who had travelled by stagecoach, finally reaches the foothills of the Dents du Midi.', 'translate English to German: Hospital units have restricted or almost no access to the status of their booked requests.']\n",
      "04/10 03:07:03 PM |\t  pred_decoded[:2]:['Der junge Schriftsteller, der mit Stagecoach gereist war, erreicht schließlich den Vorhang des Dents du Midi.', 'Krankenhauseinheiten haben eingeschränkt oder fast keinen Zugang zum Status ihrer gebuchten Anfragen.']\n",
      "04/10 03:07:03 PM |\t  label_decoded[:2]:['Der junge Schriftsteller ist auf der Flucht aus Paris, wo eine Choleraepidemie wütet, und landet nach einer Reise mit der Postkutsche am Fusse des Dents-du-Midi.', 'Ohne eine elektronische Auftragsverarbeitung fehlt die Datenbasis zur Qualitätssicherung und zur späteren Prozessoptimierung (z.B. Erkennen von Engpässen und deren Beseitigung).']\n",
      "04/10 03:07:24 PM |\t  computing score...\n",
      "04/10 03:07:24 PM |\t  model_w_in_main sacreBLEU : 21.513590\n",
      "04/10 03:07:24 PM |\t  model_w_in_main BLEU : 0.175632\n",
      "04/10 03:07:24 PM |\t  model_w_in_main test loss : 1.632205\n",
      "04/10 03:07:31 PM |\t  x_decoded[:2]:['translate English to German: If you are interested in a customised training session please consult us. We will be glad to submit you an offer.', 'translate English to German: With more then a third of the total population in Argentina it has the highest population of the country and the same goes for its dimensions.']\n",
      "04/10 03:07:31 PM |\t  pred_decoded[:2]:['Sollten Sie an einer kundenspezifischen Schulung interessiert sein, wenden Sie sich bitte an uns.', 'mit mehr als einem Drittel der Gesamtbevölkerung in Argentinien hat es die höchste Bevölkerung des Landes und dasselbe gilt für seine Dimensionen.']\n",
      "04/10 03:07:31 PM |\t  label_decoded[:2]:['Für diese erstellen wir Ihnen gerne ein Angebot nach Rücksprache.', 'Mit mehr als einem Drittel der Gesamtbevölkerung Argentiniens ist sie die bevölkerungsreichste Provinz des Landes sowie auch die flächenmäßig größte.']\n",
      "04/10 03:07:50 PM |\t  computing score...\n",
      "04/10 03:07:51 PM |\t  model_v_in_main sacreBLEU : 20.458347\n",
      "04/10 03:07:51 PM |\t  model_v_in_main BLEU : 0.165359\n",
      "04/10 03:07:51 PM |\t  model_v_in_main test loss : 6.503748\n",
      "04/10 03:07:51 PM |\t  \n",
      "\n",
      "  ----------------epoch:1,\t\tlr_w:0.0006,\t\tlr_v:0.0006----------------\n",
      "1465001472\n",
      "0\n",
      "2 1465140736\n",
      "3 1465140736\n",
      "4 1465141248\n",
      "5 1465142784\n",
      "04/10 03:07:54 PM |\t    0.0% \t w_loss_avg:1.1316109\t v_loss_avg:9.8591916\n",
      "1465142784\n",
      "1\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "step!zerograd\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "1465142784\n",
      "2\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "04/10 03:07:56 PM |\t   4.08% \t w_loss_avg:1.5110232\t v_loss_avg:8.6160031\n",
      "1465142784\n",
      "3\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "step!zerograd\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "1465142784\n",
      "4\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "04/10 03:07:58 PM |\t   8.16% \t w_loss_avg:1.5490762\t v_loss_avg:9.4171046\n",
      "1465142784\n",
      "5\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "step!zerograd\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "1465142784\n",
      "6\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "04/10 03:08:00 PM |\t   12.2% \t w_loss_avg:1.5212552\t v_loss_avg:9.3413394\n",
      "1465142784\n",
      "7\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "step!zerograd\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "1465142784\n",
      "8\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "04/10 03:08:02 PM |\t   16.3% \t w_loss_avg:1.4581553\t v_loss_avg:9.2855497\n",
      "1465142784\n",
      "9\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "step!zerograd\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "1465142784\n",
      "10\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "04/10 03:08:04 PM |\t   20.4% \t w_loss_avg:1.3600182\t v_loss_avg:8.9739485\n",
      "1465142784\n",
      "11\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "step!zerograd\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "1465142784\n",
      "12\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "4 1465142784\n",
      "04/10 03:08:13 PM |\t  x_decoded[:2]:[\"translate English to German: Save your helpers as much time as you can, they're busy people.\", 'translate English to German: Load the mini figure or the space vehicle.']\n",
      "04/10 03:08:13 PM |\t  pred_decoded[:2]:['Sparen Sie Ihre Helfer so viel Zeit wie möglich, sie sind beschäftigte Menschen.', 'Laden Sie die Minifigur oder das Raumfahrzeug.']\n",
      "04/10 03:08:13 PM |\t  label_decoded[:2]:['Sparen Sie soviel wie möglich Zeit der Helfer, diese sind meistens sehr beschäftigt.', 'Laden sie entweder die Figur oder den Raumgleiter wie üblich.']\n",
      "04/10 03:08:34 PM |\t  computing score...\n",
      "04/10 03:08:34 PM |\t  model_w_in_main sacreBLEU : 21.854155\n",
      "04/10 03:08:34 PM |\t  model_w_in_main BLEU : 0.178714\n",
      "04/10 03:08:34 PM |\t  model_w_in_main test loss : 1.662336\n",
      "04/10 03:08:41 PM |\t  x_decoded[:2]:['translate English to German: 9 And it came to pass that Alma did not know concerning them; but there were many a witnesses against them; yea, the people stood and testified of their iniquity in abundance.', 'translate English to German: When they left, we received a huge donation for which we are very grateful.']\n",
      "04/10 03:08:41 PM |\t  pred_decoded[:2]:['9 Und es begab sich: Alma wußte in Bezug auf sie nicht; aber es gab viele Zeugen gegen sie; ja, das Volk stand und zeugte von ihrem Übeltun im Überfluss.', 'Als sie verließen, haben wir eine riesige Spende erhalten, für die wir sehr dankbar sind.']\n",
      "04/10 03:08:41 PM |\t  label_decoded[:2]:['9 Und es begab sich: Alma wußte nichts in bezug auf sie; aber es gab viele Zeugen gegen sie; ja, das Volk stand auf und legte reichlich Zeugnis ab von ihrem Übeltun.', 'Als sie uns wieder verließen, erhielten wir eine riesige Spende, für die wir sehr dankbar sind!']\n",
      "04/10 03:09:02 PM |\t  computing score...\n",
      "04/10 03:09:02 PM |\t  model_v_in_main sacreBLEU : 21.088033\n",
      "04/10 03:09:02 PM |\t  model_v_in_main BLEU : 0.171658\n",
      "04/10 03:09:02 PM |\t  model_v_in_main test loss : 6.360535\n",
      "5 1465142784\n",
      "04/10 03:09:03 PM |\t   24.5% \t w_loss_avg:1.3918945\t v_loss_avg:9.2846835\n",
      "1465142784\n",
      "13\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "step!zerograd\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "1465142784\n",
      "14\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "04/10 03:09:04 PM |\t   28.6% \t w_loss_avg:1.3910725\t v_loss_avg:9.3179710\n",
      "1465142784\n",
      "15\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "step!zerograd\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "1465142784\n",
      "16\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "04/10 03:09:07 PM |\t   32.7% \t w_loss_avg:1.3672730\t v_loss_avg:9.5799522\n",
      "1465142784\n",
      "17\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "step!zerograd\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "1465142784\n",
      "18\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "04/10 03:09:09 PM |\t   36.7% \t w_loss_avg:1.4096193\t v_loss_avg:9.3096340\n",
      "1465142784\n",
      "19\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "step!zerograd\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "1465142784\n",
      "20\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "04/10 03:09:11 PM |\t   40.8% \t w_loss_avg:1.3805954\t v_loss_avg:9.2502320\n",
      "1465142784\n",
      "21\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "step!zerograd\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "1465142784\n",
      "22\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "04/10 03:09:14 PM |\t   44.9% \t w_loss_avg:1.4008298\t v_loss_avg:9.1830154\n",
      "1465142784\n",
      "23\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "step!zerograd\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "1465142784\n",
      "24\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "4 1465142784\n",
      "04/10 03:09:27 PM |\t  x_decoded[:2]:['translate English to German: And so, life for the elephants here in southern Thailand is much easier than in the logging camps of the north.', \"translate English to German: Save your helpers as much time as you can, they're busy people.\"]\n",
      "04/10 03:09:27 PM |\t  pred_decoded[:2]:['Und so ist das Leben für die Elefanten hier im Süden Thailands viel einfacher als in den Bergbaulagern im Norden.', 'Sparen Sie Ihre Helfer so viel Zeit wie möglich, sie sind beschäftigte Menschen.']\n",
      "04/10 03:09:27 PM |\t  label_decoded[:2]:['Haad Leela ist auch als Haad Seekantang bekannt und ist etwa 15 Gehminuten vom Stadtzentrum Haad Rin.', 'Sparen Sie soviel wie möglich Zeit der Helfer, diese sind meistens sehr beschäftigt.']\n",
      "04/10 03:09:47 PM |\t  computing score...\n",
      "04/10 03:09:47 PM |\t  model_w_in_main sacreBLEU : 22.203229\n",
      "04/10 03:09:47 PM |\t  model_w_in_main BLEU : 0.182920\n",
      "04/10 03:09:47 PM |\t  model_w_in_main test loss : 1.682011\n",
      "04/10 03:09:54 PM |\t  x_decoded[:2]:['translate English to German: So firstly, I should like to address Mrs de Palacio and secondly, Commissioner Schreyer.', 'translate English to German: The rapporteur stresses on a number of occasions in the report that the growing importance of the People’s Republic of China in world politics, together with its growing importance as a global economic superpower, bring greater international responsibilities.']\n",
      "04/10 03:09:54 PM |\t  pred_decoded[:2]:['Daher möchte ich mich erstens an Frau de Palacio und zweitens an Kommissarin Schreyer wenden.', 'Die Berichterstatterin unterstreicht in diesem Bericht mehrfach, dass die zunehmende Bedeutung der Volksrepublik China in der Weltpolitik, zusammen mit ihrer zunehmenden Bedeutung als globale Wirtschaftssupermacht, größere internationale Verantwortung mit sich bringt.']\n",
      "04/10 03:09:54 PM |\t  label_decoded[:2]:['Zunächst wende ich mich also an Frau de Palacio und anschließend an Frau Schreyer.', 'Mehrfach hebt der Berichterstatter im Bericht hervor, dass die wachsende Bedeutung der Volksrepublik China in der Weltpolitik im Verein mit ihrer zunehmenden Bedeutung als globale wirtschaftliche Supermacht größere internationale Verantwortlichkeiten mit sich bringt.']\n",
      "04/10 03:10:15 PM |\t  computing score...\n",
      "04/10 03:10:15 PM |\t  model_v_in_main sacreBLEU : 20.950871\n",
      "04/10 03:10:15 PM |\t  model_v_in_main BLEU : 0.172964\n",
      "04/10 03:10:15 PM |\t  model_v_in_main test loss : 6.538205\n",
      "5 1465142784\n",
      "04/10 03:10:15 PM |\t   49.0% \t w_loss_avg:1.4075504\t v_loss_avg:9.3467706\n",
      "1465142784\n",
      "25\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "step!zerograd\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "1465142784\n",
      "26\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "04/10 03:10:17 PM |\t   53.1% \t w_loss_avg:1.4034594\t v_loss_avg:9.2171845\n",
      "1465142784\n",
      "27\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "step!zerograd\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "1465142784\n",
      "28\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "04/10 03:10:19 PM |\t   57.1% \t w_loss_avg:1.4213677\t v_loss_avg:9.1717864\n",
      "1465142784\n",
      "29\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "step!zerograd\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "1465142784\n",
      "30\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "04/10 03:10:22 PM |\t   61.2% \t w_loss_avg:1.4533815\t v_loss_avg:9.0543666\n",
      "1465142784\n",
      "31\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "step!zerograd\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "1465142784\n",
      "32\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "04/10 03:10:23 PM |\t   65.3% \t w_loss_avg:1.4325746\t v_loss_avg:9.0705660\n",
      "1465142784\n",
      "33\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "step!zerograd\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "1465142784\n",
      "34\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "04/10 03:10:26 PM |\t   69.4% \t w_loss_avg:1.4406021\t v_loss_avg:9.1316502\n",
      "1465142784\n",
      "35\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "step!zerograd\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "1465142784\n",
      "36\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "4 1465142784\n",
      "04/10 03:10:36 PM |\t  x_decoded[:2]:['translate English to German: He claimed communism appeared to be the only reliable antidote to militarist fascism and spoke out against the remilitarization of the West and the division of Germany.', 'translate English to German: With more then a third of the total population in Argentina it has the highest population of the country and the same goes for its dimensions.']\n",
      "04/10 03:10:36 PM |\t  pred_decoded[:2]:['Er behauptete, der Kommunismus sei das einzige verlässliche Antidot gegen den Militarismus und sprach sich gegen die Remilitarisierung des Westens und die Teilung Deutschlands aus.', 'Mit mehr als einem Drittel der Gesamtbevölkerung in Argentinien hat es die höchste Bevölkerung des Landes, und dasselbe gilt für seine Dimensionen.']\n",
      "04/10 03:10:36 PM |\t  label_decoded[:2]:['Einen Tag später reiste er – während der Premiere von Das Leben des Galilei in New York – über Paris nach Zürich. Dort hielt er sich ein Jahr auf, da die Schweiz das einzige Land war, in das er noch einreisen durfte; die Einreise nach West- Deutschland wurde ihm untersagt.', 'Mit mehr als einem Drittel der Gesamtbevölkerung Argentiniens ist sie die bevölkerungsreichste Provinz des Landes sowie auch die flächenmäßig größte.']\n",
      "04/10 03:10:57 PM |\t  computing score...\n",
      "04/10 03:10:57 PM |\t  model_w_in_main sacreBLEU : 22.723219\n",
      "04/10 03:10:57 PM |\t  model_w_in_main BLEU : 0.187951\n",
      "04/10 03:10:57 PM |\t  model_w_in_main test loss : 1.607600\n",
      "04/10 03:11:03 PM |\t  x_decoded[:2]:['translate English to German: The worldwide Iguassu Falls are only a 20-minute drive away.', 'translate English to German: Another practical aspect of the introduction of the euro is the effective changeover from the relevant national coins and notes to the euro.']\n",
      "04/10 03:11:03 PM |\t  pred_decoded[:2]:['Die weltweiten Iguassu Falls sind nur 20 Fahrminuten entfernt.', 'Ein weiterer praktischer Aspekt der Einführung des Euro ist die effektive Umstellung von den entsprechenden nationalen Münzen und Banknoten auf den Euro.']\n",
      "04/10 03:11:03 PM |\t  label_decoded[:2]:['Die weltberühmten Iguaçu-Wasserfälle befinden sich nur 20 Fahrminuten entfernt.', 'Ein weiterer praktischer Aspekt der Einführung des Euro ist die effektive Umstellung der nationalen Münzen und Geldscheine in Euro.']\n",
      "04/10 03:11:26 PM |\t  computing score...\n",
      "04/10 03:11:26 PM |\t  model_v_in_main sacreBLEU : 21.774159\n",
      "04/10 03:11:26 PM |\t  model_v_in_main BLEU : 0.174727\n",
      "04/10 03:11:26 PM |\t  model_v_in_main test loss : 6.274886\n",
      "5 1465142784\n",
      "04/10 03:11:26 PM |\t   73.5% \t w_loss_avg:1.4469708\t v_loss_avg:9.1079959\n",
      "1465142784\n",
      "37\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "step!zerograd\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "1465142784\n",
      "38\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "04/10 03:11:29 PM |\t   77.6% \t w_loss_avg:1.4662130\t v_loss_avg:9.0644495\n",
      "1465142784\n",
      "39\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "step!zerograd\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "1465142784\n",
      "40\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "04/10 03:11:31 PM |\t   81.6% \t w_loss_avg:1.4557720\t v_loss_avg:9.0070117\n",
      "1465142784\n",
      "41\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "step!zerograd\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "1465142784\n",
      "42\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "04/10 03:11:33 PM |\t   85.7% \t w_loss_avg:1.4827026\t v_loss_avg:9.0298614\n",
      "1465142784\n",
      "43\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "step!zerograd\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "1465142784\n",
      "44\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "04/10 03:11:36 PM |\t   89.8% \t w_loss_avg:1.4857466\t v_loss_avg:9.0768042\n",
      "1465142784\n",
      "45\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "step!zerograd\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "1465142784\n",
      "46\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "04/10 03:11:38 PM |\t   93.9% \t w_loss_avg:1.4848725\t v_loss_avg:8.9655956\n",
      "1465142784\n",
      "47\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "step!zerograd\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "1465142784\n",
      "48\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "4 1465142784\n",
      "04/10 03:11:48 PM |\t  x_decoded[:2]:['translate English to German: The Haringvliet is a very good zander water with little commercial boat traffic.', 'translate English to German: Sunset Cove is a small Boutique Resort located on the scenic Chao Phao Beach.']\n",
      "04/10 03:11:48 PM |\t  pred_decoded[:2]:['Der Haringvliet ist ein sehr gutes Zanderwasser mit wenig kommerziellem Bootsverkehr.', 'Sunset Cove ist ein kleines Boutique-Resort am schönen Chao Phao Beach.']\n",
      "04/10 03:11:48 PM |\t  label_decoded[:2]:['Das Haringsvliet ist ein exellentes Zanderrevier mit nur sehr geringem Schiffsverkehr.', 'Sunset Cove ist ein kleines Boutique Resort am malerischen Chao Phao Beach.']\n",
      "04/10 03:12:09 PM |\t  computing score...\n",
      "04/10 03:12:09 PM |\t  model_w_in_main sacreBLEU : 22.181852\n",
      "04/10 03:12:09 PM |\t  model_w_in_main BLEU : 0.184587\n",
      "04/10 03:12:09 PM |\t  model_w_in_main test loss : 1.705531\n",
      "04/10 03:12:16 PM |\t  x_decoded[:2]:['translate English to German: Estonia, Poland, Slovenia, the Czech Republic, Hungary and Cyprus were the countries that had made the most progress.', 'translate English to German: Find yoga – anywhere you happen to be.']\n",
      "04/10 03:12:16 PM |\t  pred_decoded[:2]:['Estland, Polen, Slowenien, die Tschechische Republik, Ungarn und Zypern waren die Länder, die die meisten Fortschritte erzielt haben.', 'Finden Sie Yoga – wo immer Sie zufällig sind.']\n",
      "04/10 03:12:16 PM |\t  label_decoded[:2]:['Voraussetzung ist allerdings das Bekenntnis zu den Grundsätzen, die in den Kopenhagener Kriterien festgelegt sind.', 'Mit MINDBODY verfügt jeder über ein eigenes Konto.']\n",
      "04/10 03:12:38 PM |\t  computing score...\n",
      "04/10 03:12:38 PM |\t  model_v_in_main sacreBLEU : 21.285862\n",
      "04/10 03:12:38 PM |\t  model_v_in_main BLEU : 0.172758\n",
      "04/10 03:12:38 PM |\t  model_v_in_main test loss : 6.072472\n",
      "5 1465142784\n",
      "04/10 03:12:38 PM |\t   98.0% \t w_loss_avg:1.4770090\t v_loss_avg:9.3476409\n",
      "1465142784\n",
      "49\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "step!zerograd\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "04/10 03:12:40 PM |\t  1e+02% \t w_loss_avg:1.4653282\t v_loss_avg:9.3231119\n",
      "04/10 03:12:40 PM |\t  ('Attention Weights A : ', Parameter containing:\n",
      "tensor([0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
      "        0.0025, 0.0025, 0.0025, 0.0025], device='cuda:0', requires_grad=True))\n",
      "04/10 03:12:40 PM |\t  w_train_loss:1.4653282463550568,v_train_loss:9.323111928999424\n",
      "04/10 03:12:47 PM |\t  x_decoded[:2]:['translate English to German: So firstly, I should like to address Mrs de Palacio and secondly, Commissioner Schreyer.', 'translate English to German: As far as these substances too are concerned, we also want the Commission to accept the opinion of the Standing Veterinary Committee which was established by Article 1 of Decision 68/361/EEC and to make every effort to obtain further information in order to resolve this problem within a reasonable time.']\n",
      "04/10 03:12:47 PM |\t  pred_decoded[:2]:['Daher möchte ich erstens Frau de Palacio und zweitens Frau Kommissarin Schreyer ansprechen.', 'Wir möchten auch, daß die Kommission die Stellungnahme des Ständigen Veterinärausschusses akzeptiert, der in Artikel 1 des Beschlusses 68/361/EWG eingerichtet wurde, und daß sie sich bemüht, weitere Informationen zu erhalten, um dieses Problem innerhalb einer angemessenen Frist zu lösen.']\n",
      "04/10 03:12:47 PM |\t  label_decoded[:2]:['Zunächst wende ich mich also an Frau de Palacio und anschließend an Frau Schreyer.', 'Des Weiteren möchten wir, dass die Kommission zu diesen Stoffen ein Gutachten des gemäß Artikel 1 des Beschlusses 68/361/EWG eingerichteten ständigen Veterinärausschusses einholt und darum bemüht ist, sich zusätzliche Informationen zu beschaffen, um dieses Problem innerhalb vernünftiger Fristen zu lösen.']\n",
      "04/10 03:13:07 PM |\t  computing score...\n",
      "04/10 03:13:07 PM |\t  model_w_in_main sacreBLEU : 22.563959\n",
      "04/10 03:13:07 PM |\t  model_w_in_main BLEU : 0.187634\n",
      "04/10 03:13:07 PM |\t  model_w_in_main test loss : 1.624309\n",
      "04/10 03:13:14 PM |\t  x_decoded[:2]:['translate English to German: As far as these substances too are concerned, we also want the Commission to accept the opinion of the Standing Veterinary Committee which was established by Article 1 of Decision 68/361/EEC and to make every effort to obtain further information in order to resolve this problem within a reasonable time.', 'translate English to German: In our offer you can also find a vast collection of key boxes and jewellery boxes.']\n",
      "04/10 03:13:14 PM |\t  pred_decoded[:2]:['Was auch diese Stoffe betrifft, so möchten wir auch, dass die Kommission die Stellungnahme des Ständigen Veterinärausschusses akzeptiert, der gemäß Artikel 1 des Beschlusses 68/361/EWG eingerichtet wurde, und alle Anstrengungen unternehmen, um weitere Informationen zu erhalten, um dieses Problem innerhalb angemessener Zeit zu lösen.', 'In unserem Angebot finden Sie auch eine riesige Sammlung von Schlüsselboxen und Schmuckboxen.']\n",
      "04/10 03:13:14 PM |\t  label_decoded[:2]:['Des Weiteren möchten wir, dass die Kommission zu diesen Stoffen ein Gutachten des gemäß Artikel 1 des Beschlusses 68/361/EWG eingerichteten ständigen Veterinärausschusses einholt und darum bemüht ist, sich zusätzliche Informationen zu beschaffen, um dieses Problem innerhalb vernünftiger Fristen zu lösen.', 'In unserem Angebot finden Sie auch eine unfangreiche Kollektion von Schlüsselkästchen und Schmuckkästchen.']\n",
      "04/10 03:13:35 PM |\t  computing score...\n",
      "04/10 03:13:35 PM |\t  model_v_in_main sacreBLEU : 21.183640\n",
      "04/10 03:13:35 PM |\t  model_v_in_main BLEU : 0.172078\n",
      "04/10 03:13:35 PM |\t  model_v_in_main test loss : 6.043615\n",
      "04/10 03:13:36 PM |\t  \n",
      "\n",
      "  ----------------epoch:2,\t\tlr_w:0.0006,\t\tlr_v:0.0006----------------\n",
      "1465001472\n",
      "0\n",
      "2 1465140736\n",
      "3 1465140736\n",
      "4 1465141248\n",
      "5 1465142784\n",
      "04/10 03:13:39 PM |\t    0.0% \t w_loss_avg:0.9296464\t v_loss_avg:9.3588352\n",
      "1465142784\n",
      "1\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "step!zerograd\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "1465142784\n",
      "2\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "04/10 03:13:41 PM |\t   4.08% \t w_loss_avg:1.3778208\t v_loss_avg:8.1906291\n",
      "1465142784\n",
      "3\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "step!zerograd\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "1465142784\n",
      "4\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "04/10 03:13:43 PM |\t   8.16% \t w_loss_avg:1.3916994\t v_loss_avg:8.9815697\n",
      "1465142784\n",
      "5\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "step!zerograd\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "1465142784\n",
      "6\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "04/10 03:13:45 PM |\t   12.2% \t w_loss_avg:1.3577098\t v_loss_avg:8.9179669\n",
      "1465142784\n",
      "7\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "step!zerograd\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "1465142784\n",
      "8\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "04/10 03:13:47 PM |\t   16.3% \t w_loss_avg:1.2962371\t v_loss_avg:8.8681726\n",
      "1465142784\n",
      "9\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "step!zerograd\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "1465142784\n",
      "10\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "04/10 03:13:49 PM |\t   20.4% \t w_loss_avg:1.2078992\t v_loss_avg:8.5759070\n",
      "1465142784\n",
      "11\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "step!zerograd\n",
      "4 1465142784\n",
      "5 1465142784\n",
      "1465142784\n",
      "12\n",
      "2 1465142784\n",
      "3 1465142784\n",
      "4 1465142784\n",
      "04/10 03:14:07 PM |\t  x_decoded[:2]:['translate English to German: But design process didn’t finish at that stage.', 'translate English to German: Calls can also be taken over – even without configuration of working groups – simply using the Mac OS X Bonjour function.']\n",
      "04/10 03:14:07 PM |\t  pred_decoded[:2]:['Aber das Design-Prozess endete nicht zu diesem Zeitpunkt.', 'Auch Anrufe können – selbst ohne Konfiguration von Arbeitsgruppen – einfach über die Funktion Mac OS X Bonjour übernommen werden.']\n",
      "04/10 03:14:07 PM |\t  label_decoded[:2]:['Beflex baute das erste Muster in zwei Wochen, danach wurde innerhalb von drei Wochen das komplette Projekt abgewickelt.', 'Anrufe können auch herangeholt werden - und das alles ohne Konfiguration von Arbeitsgruppen, einfach per Bonjour-Automatik.']\n",
      "04/10 03:14:28 PM |\t  computing score...\n",
      "04/10 03:14:28 PM |\t  model_w_in_main sacreBLEU : 22.770453\n",
      "04/10 03:14:28 PM |\t  model_w_in_main BLEU : 0.189464\n",
      "04/10 03:14:28 PM |\t  model_w_in_main test loss : 1.609688\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_82720/2742564271.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"\\n\\n  ----------------epoch:{epoch},\\t\\tlr_w:{lr_w},\\t\\tlr_v:{lr_v}----------------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mw_train_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv_train_loss\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mmy_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_v\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0marchitect\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_optimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv_optimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr_w\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr_v\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mscheduler_w\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_82720/2833040793.py\u001b[0m in \u001b[0;36mmy_train\u001b[1;34m(epoch, _dataloader, w_model, v_model, architect, A, w_optimizer, v_optimizer, lr_w, lr_v)\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mtest_fre\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[0mmy_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_dataloader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_w\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m             \u001b[0mmy_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_dataloader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_v\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_82720/3123709118.py\u001b[0m in \u001b[0;36mmy_test\u001b[1;34m(_dataloader, model, epoch)\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0macc\u001b[0m\u001b[1;33m+=\u001b[0m \u001b[0mls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mcounter\u001b[0m\u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mpre\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_dataloaderx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0mx_decoded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_dataloaderx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mskip_special_tokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mpred_decoded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpre\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mskip_special_tokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mg:\\GitCode\\Self-teaching-for-machine-translation\\T5\\T5.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, input_ids, num_beams, max_length)\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_beams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m         \u001b[0moutput_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_beams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_beams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlength_penalty\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m0.6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrepetition_penalty\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[1;31m## sampling with top_p\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, typical_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, stopping_criteria, constraints, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[0;32m   1249\u001b[0m             )\n\u001b[0;32m   1250\u001b[0m             \u001b[1;31m# 12. run beam search\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1251\u001b[1;33m             return self.beam_search(\n\u001b[0m\u001b[0;32m   1252\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1253\u001b[0m                 \u001b[0mbeam_scorer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\generation_utils.py\u001b[0m in \u001b[0;36mbeam_search\u001b[1;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[0;32m   2033\u001b[0m             \u001b[0mmodel_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_inputs_for_generation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2034\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2035\u001b[1;33m             outputs = self(\n\u001b[0m\u001b[0;32m   2036\u001b[0m                 \u001b[1;33m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2037\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1634\u001b[0m         \u001b[1;31m# Decode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1635\u001b[1;33m         decoder_outputs = self.decoder(\n\u001b[0m\u001b[0;32m   1636\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1637\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecoder_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1028\u001b[0m                 )\n\u001b[0;32m   1029\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1030\u001b[1;33m                 layer_outputs = layer_module(\n\u001b[0m\u001b[0;32m   1031\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1032\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    716\u001b[0m         \u001b[1;31m# Apply Feed Forward layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 717\u001b[1;33m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    718\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m         \u001b[1;31m# clamp inf values to enable fp16 training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m         \u001b[0mforwarded_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    327\u001b[0m         \u001b[0mforwarded_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDenseReluDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforwarded_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhidden_states\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforwarded_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m         \u001b[0mvariance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 254\u001b[1;33m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhidden_states\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrsqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariance\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariance_epsilon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m         \u001b[1;31m# convert into half-precision if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if(args.valid_begin==1):\n",
    "    print(torch.cuda.memory_allocated(device=device))\n",
    "    my_test(valid_dataloader,model_w,-1) #before train\n",
    "    # my_test(valid_dataloader,model_v,-1)  \n",
    "    print(torch.cuda.memory_allocated(device=device))\n",
    "for epoch in range(args.epochs):\n",
    "    lr_w = scheduler_w.get_lr()[0]\n",
    "    lr_v = scheduler_v.get_lr()[0]\n",
    "\n",
    "    logging.info(f\"\\n\\n  ----------------epoch:{epoch},\\t\\tlr_w:{lr_w},\\t\\tlr_v:{lr_v}----------------\")\n",
    "\n",
    "    w_train_loss,v_train_loss =  my_train(epoch, train_dataloader, model_w, model_v,  architect, A, w_optimizer, v_optimizer, lr_w,lr_v)\n",
    "    \n",
    "    scheduler_w.step()\n",
    "    scheduler_v.step()\n",
    "\n",
    "    writer.add_scalar(\"MT/model_w_in_main/w_trainloss\", w_train_loss, global_step=epoch)\n",
    "    writer.add_scalar(\"MT/model_v_in_main/v_trainloss\", v_train_loss, global_step=epoch)\n",
    "\n",
    "    logging.info(f\"w_train_loss:{w_train_loss},v_train_loss:{v_train_loss}\")\n",
    "    wandb.log({'w_train_loss': w_train_loss, 'v_train_loss':v_train_loss})\n",
    "\n",
    "    \n",
    "    my_test(valid_dataloader,model_w,epoch) \n",
    "    my_test(valid_dataloader,model_v,epoch)  \n",
    "\n",
    "torch.save(model_v,'./model/'+now+'model_w.pt')\n",
    "torch.save(model_v,'./model/'+now+'model_v.pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "65768f95ed3f1ad80799466926a66640b39a99ef5d94bbece814e59aa067606e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('python38': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
