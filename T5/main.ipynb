{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd() \n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from T5 import *\n",
    "from datasets import load_dataset,load_metric\n",
    "from transformers import T5Tokenizer\n",
    "from MT_hyperparams import *\n",
    "import torch.backends.cudnn as cudnn\n",
    "from utils import *\n",
    "from attention_params import *\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, SubsetRandomSampler\n",
    "from torch.autograd import Variable\n",
    "from losses import *\n",
    "from architect import *\n",
    "import logging\n",
    "import sys\n",
    "import transformers\n",
    "import time\n",
    "import argparse\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(\"main\")\n",
    "# parser.add_argument('--seed_', type=int, default=2, help='seed')\n",
    "\n",
    "# parser.add_argument('--max_length', type=int, default = 256, help='max length')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "parser.add_argument('--valid_num_points', type=int,             default = 100 ,help='validation data number')\n",
    "parser.add_argument('--train_num_points', type=int,             default = 500 ,help='train data number')\n",
    "\n",
    "parser.add_argument('--batch_size', type=int,                   default=16,     help='Batch size')\n",
    "parser.add_argument('--train_w_num_points', type=int,           default=4,      help='train_w_num_points for each batch')\n",
    "parser.add_argument('--train_w_synthetic_num_points', type=int, default=4,      help='train_w_synthetic_num_points for each batch')\n",
    "parser.add_argument('--train_v_num_points', type=int,           default=4,      help='train_v_num_points for each batch')\n",
    "parser.add_argument('--train_A_num_points', type=int,           default=4,      help='train_A_num_points decay for each batch')#change to 1e-2 if needed\n",
    "\n",
    "\n",
    "parser.add_argument('--gpu', type=int,                          default=0,      help='gpu device id')\n",
    "parser.add_argument('--epochs', type=int,                       default=20,     help='num of training epochs')\n",
    "parser.add_argument('--pre_epochs', type=int,                   default=1,      help='train model W for x epoch first')\n",
    "parser.add_argument('--grad_clip', type=float,                  default=5,      help='gradient clipping')\n",
    "\n",
    "parser.add_argument('--w_lr', type=float,                       default=1e-3,   help='learning rate for w')\n",
    "parser.add_argument('--v_lr', type=float,                       default=1e-3,   help='learning rate for v')\n",
    "parser.add_argument('--A_lr', type=float,                       default=1e-4,   help='learning rate for A')\n",
    "parser.add_argument('--learning_rate_min', type=float,          default=0,      help='learning_rate_min')\n",
    "parser.add_argument('--decay', type=float,                      default=1e-3,   help='weight decay')\n",
    "parser.add_argument('--momentum', type=float,                   default=0.7,    help='momentum')\n",
    "\n",
    "\n",
    "parser.add_argument('--traindata_loss_ratio', type=float,       default=0.8,    help='human translated data ratio')\n",
    "parser.add_argument('--syndata_loss_ratio', type=float,         default=0.2,    help='augmented dataset ratio')\n",
    "\n",
    "parser.add_argument('--valid_begin', type=int,                  default=1,    help='whether valid before train')\n",
    "parser.add_argument('--train_A', type=int,                      default = 0 ,   help='whether train A')\n",
    "\n",
    "\n",
    "args = parser.parse_args(args=[])#(args=['--batch_size', '8',  '--no_cuda'])#used in ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/11 11:48:54 AM |\t  Reusing dataset wmt14 (C:\\Users\\kevin\\.cache\\huggingface\\datasets\\wmt14\\de-en\\1.0.0\\d239eaf0ff090d28da19b6bc9758e24634d84de0a1ef092f0b5c54e6f132d7e2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/11 11:48:55 AM |\t  Namespace(A_lr=0.0001, batch_size=16, decay=0.001, epochs=20, gpu=0, grad_clip=5, learning_rate_min=0, momentum=0.7, pre_epochs=1, syndata_loss_ratio=0.2, train_A=0, train_A_num_points=4, train_num_points=500, train_v_num_points=4, train_w_num_points=4, train_w_synthetic_num_points=4, traindata_loss_ratio=0.8, v_lr=0.001, valid_begin=1, valid_num_points=100, w_lr=0.001)\n",
      "03/11 11:48:55 AM |\t  DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 4508785\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 3000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 3003\n",
      "    })\n",
      "})\n",
      "03/11 11:48:55 AM |\t  {'translation': {'de': 'Ich bitte Sie, sich zu einer Schweigeminute zu erheben.', 'en': \"Please rise, then, for this minute' s silence.\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "now = time.strftime(\"%Y-%m-%d-%H_%M_%S\",time.localtime(time.time())) \n",
    "\n",
    "log_format = '%(asctime)s |\\t  %(message)s'\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO,\n",
    "    format=log_format, datefmt='%m/%d %I:%M:%S %p')\n",
    "fh = logging.FileHandler(os.path.join(\"./log/\", now+'.txt'),'w',encoding = \"UTF-8\")\n",
    "fh.setFormatter(logging.Formatter(log_format))\n",
    "logging.getLogger().addHandler(fh)\n",
    "dataset = load_dataset('wmt14','de-en')\n",
    "\n",
    "logging.info(args)\n",
    "logging.info(dataset)\n",
    "logging.info(dataset['train'][5])\n",
    "\n",
    "\n",
    "\n",
    "writer = SummaryWriter('tensorboard')\n",
    "\n",
    "# Setting the seeds\n",
    "np.random.seed(seed_)\n",
    "torch.cuda.set_device(args.gpu)\n",
    "cudnn.benchmark = True\n",
    "torch.manual_seed(seed_)\n",
    "cudnn.enabled=True\n",
    "torch.cuda.manual_seed(seed_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pretrained  =  T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
    "torch.save(pretrained,'T5BASE.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/11 11:49:41 AM |\t  train len: 496\n",
      "03/11 11:49:41 AM |\t  train_w_num_points_len: 124\n",
      "03/11 11:49:41 AM |\t  train_w_synthetic_num_points_len: 124\n",
      "03/11 11:49:41 AM |\t  train_v_num_points_len: 124\n",
      "03/11 11:49:41 AM |\t  train_A_num_points_len: 124\n",
      "03/11 11:49:41 AM |\t  valid len: 100\n",
      "03/11 11:49:41 AM |\t  test len: 3003\n",
      "03/11 11:49:41 AM |\t  {'de': 'Wie Sie feststellen konnten, ist der gefürchtete \"Millenium-Bug \" nicht eingetreten. Doch sind Bürger einiger unserer Mitgliedstaaten Opfer von schrecklichen Naturkatastrophen geworden.', 'en': \"translate English to German: Although, as you will have seen, the dreaded 'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\"}\n"
     ]
    }
   ],
   "source": [
    "# Load the tokenizer.\n",
    "import random\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss( reduction='none')#ignore_index = tokenizer.pad_token_id,\n",
    "# dataset = dataset.shuffle(seed=seed_)\n",
    "train = dataset['train']['translation'][:args.train_num_points]\n",
    "valid = dataset['validation']['translation'][:args.valid_num_points]\n",
    "test = dataset['test']['translation']#[L_t+L_v:L_t+L_v+L_test]\n",
    "def preprocess(dat):\n",
    "    for t in dat:\n",
    "        t['en'] = 'translate English to German: ' + t['en'] \n",
    "preprocess(train)\n",
    "preprocess(valid)\n",
    "preprocess(test)\n",
    "num_batch = args.train_num_points//args.batch_size\n",
    "train = train[:args.batch_size*num_batch]\n",
    "logging.info(\"train len: %d\",len(train))\n",
    "train_w_num_points_len = num_batch * args.train_w_num_points\n",
    "train_w_synthetic_num_points_len = num_batch * args.train_w_synthetic_num_points\n",
    "train_v_num_points_len = num_batch * args.train_v_num_points\n",
    "train_A_num_points_len = num_batch * args.train_A_num_points\n",
    "logging.info(\"train_w_num_points_len: %d\",train_w_num_points_len)\n",
    "logging.info(\"train_w_synthetic_num_points_len: %d\",train_w_synthetic_num_points_len)\n",
    "logging.info(\"train_v_num_points_len: %d\",train_v_num_points_len)\n",
    "logging.info(\"train_A_num_points_len: %d\",train_A_num_points_len)\n",
    "\n",
    "attn_idx_list = torch.arange(train_w_num_points_len).cuda()\n",
    "logging.info(\"valid len: %d\",len(valid))\n",
    "logging.info(\"test len: %d\" ,len(test))\n",
    "logging.info(train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_language  = 'de'\n",
    "train_data = get_train_Dataset(train, tokenizer)# Create the DataLoader for our training set.\n",
    "train_dataloader = DataLoader(train_data, sampler=SequentialSampler(train_data), \n",
    "                        batch_size=args.batch_size, pin_memory=True, num_workers=0)\n",
    "valid_data = get_aux_dataset(valid, tokenizer)# Create the DataLoader for our training set.\n",
    "valid_dataloader = DataLoader(valid_data, sampler=SequentialSampler(valid_data), \n",
    "                        batch_size=args.batch_size, pin_memory=True, num_workers=0)\n",
    "test_data = get_aux_dataset(test, tokenizer)# Create the DataLoader for our training set.\n",
    "test_dataloader = DataLoader(test_data, sampler=SequentialSampler(test_data),\n",
    "                        batch_size=args.batch_size, pin_memory=True, num_workers=0)#, sampler=RandomSampler(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "A = attention_params(train_w_num_points_len)#half of train regarded as u\n",
    "A = A.cuda()\n",
    "\n",
    "# TODO: model loaded from saved model\n",
    "model_w = T5(criterion=criterion, tokenizer= tokenizer, name = 'model_w_in_main')\n",
    "model_w = model_w.cuda()\n",
    "w_optimizer = torch.optim.SGD(model_w.parameters(),args.w_lr,momentum=args.momentum,weight_decay=args.decay)\n",
    "scheduler_w  = torch.optim.lr_scheduler.CosineAnnealingLR(w_optimizer, float(args.epochs), eta_min=args.learning_rate_min)\n",
    "\n",
    "\n",
    "\n",
    "model_v = T5(criterion=criterion, tokenizer= tokenizer, name = 'model_v_in_main')\n",
    "model_v = model_v.cuda()\n",
    "v_optimizer = torch.optim.SGD(model_v.parameters(),args.v_lr,momentum=args.momentum,weight_decay=args.decay)\n",
    "scheduler_v  = torch.optim.lr_scheduler.CosineAnnealingLR(v_optimizer, float(args.epochs), eta_min=args.learning_rate_min)\n",
    "\n",
    "\n",
    "\n",
    "architect = Architect(model_w, model_v,  A, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # x = ['im going to eat now ','it is my nameit is']\n",
    "# # for index,i in enumerate(x) :\n",
    "# #     x[index] = 'translate Enlgish to German:' + x[index]\n",
    "# # y= tokenize(x, tokenizer, max_length = max_length)\n",
    "# # input = y[0].cuda()\n",
    "# # output  = model_v.generate(input,max_length=max_length)\n",
    "# # tokenizer.batch_decode(output)\n",
    "\n",
    "\n",
    "# metric_bleu =  load_metric('sacrebleu')\n",
    "# predlist = ['Eine republikanische Strategie zur Bekämpfung der Wiederwahl Obamas','Die republikanischen Führer rechtfertigten ihre Politik mit der Notwendigkeit , Wahlbetrug zu bekämpfen .']\n",
    "# targetlist = ['Eine republikanische Strategie um der Wiederwahl von Obama entgegenzutreten','Die Führungskräfte der Republikaner rechtfertigen ihre Politik mit der Notwendigkeit , den Wahlbetrug zu bekämpfen']\n",
    "# predlist = ['Eine republikanische Strategie zur Bekämpfung der Wiederwahl Obamas', 'Die republikanischen Führer rechtfertigten ihre Politik mit der Notwendigkeit, Wahlbetrug zu bekämpfen.']\n",
    "# targetlist =['Eine republikanische Strategie, um der Wiederwahl von Obama entgegenzutreten', 'Die Führungskräfte der Republikaner rechtfertigen ihre Politik mit der Notwendigkeit, den Wahlbetrug zu bekämpfen.']\n",
    "# \n",
    "# predlist = [x.lower().translate( str.maketrans('', '', string.punctuation))  for x in predlist]\n",
    "# targetlist = [[x.lower().translate( str.maketrans('', '', string.punctuation))] for x in targetlist]\n",
    "# print(predlist)\n",
    "# print(targetlist)\n",
    "# metric_bleu.add_batch(predictions=predlist, references=targetlist)\n",
    "\n",
    "# sacrebleu_score = metric_bleu.compute()\n",
    "# print(sacrebleu_score)\n",
    "# from nltk.translate import bleu\n",
    "# from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "# def bleu(reference_captions, predicted_caption):\n",
    "#     return 100 * sentence_bleu(reference_captions, predicted_caption,\n",
    "#                                weights=(0.25, 0.25, 0.25,0.25), smoothing_function=SmoothingFunction().method1)\n",
    "# x = bleu(targetlist[1],predlist[1])+bleu(targetlist[0],predlist[0])\n",
    "# print(x/2)\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu,corpus_bleu\n",
    "def my_test(test_dataloader,model,epoch):\n",
    "    acc = 0\n",
    "    counter = 0\n",
    "    model.eval()\n",
    "    metric_sacrebleu =  load_metric('sacrebleu')\n",
    "    metric_bleu =  load_metric('bleu')\n",
    "    wsize = args.train_w_num_points\n",
    "    for step, batch in enumerate(test_dataloader):\n",
    "        \n",
    "        test_dataloaderx = Variable(batch[0], requires_grad=False).cuda()[:wsize]\n",
    "        n = test_dataloaderx.size(0)   \n",
    "        test_dataloaderx_attn = Variable(batch[1], requires_grad=False).cuda()[:wsize]\n",
    "        test_dataloadery = Variable(batch[2], requires_grad=False).cuda()[:wsize]\n",
    "        test_dataloadery_attn = Variable(batch[3], requires_grad=False).cuda()[:wsize]\n",
    "        ls = my_loss(test_dataloaderx,test_dataloaderx_attn,test_dataloadery,test_dataloadery_attn,model)\n",
    "        with torch.no_grad():\n",
    "            pre = model.generate(test_dataloaderx)\n",
    "            try:\n",
    "                x_decoded = tokenizer.batch_decode(test_dataloaderx,skip_special_tokens=True)\n",
    "                pred_decoded = tokenizer.batch_decode(pre,skip_special_tokens=True)\n",
    "                label_decoded =  tokenizer.batch_decode(test_dataloadery,skip_special_tokens=True)\n",
    "                \n",
    "                pred_str = [x.replace('.', '')  for x in pred_decoded]\n",
    "                label_str = [[x.replace('.', '')] for x in label_decoded]\n",
    "                pred_list = [x.replace('.', '').split()  for x in pred_decoded]\n",
    "                label_list = [[x.replace('.', '').split()] for x in label_decoded]\n",
    "                #pred_str = [x.translate( str.maketrans('', '', string.punctuation)) for x in pred_decoded] \n",
    "                # label_str = [[x.translate( str.maketrans('', '', string.punctuation))] for x in label_decoded]\n",
    "                # pred_list = [x.translate( str.maketrans('', '', string.punctuation)).split()  for x in pred_decoded]#TODO:improve\n",
    "                # label_list = [[x.translate( str.maketrans('', '', string.punctuation)).split()] for x in label_decoded]#TODO:improve\n",
    "                if  step%100==0:\n",
    "                    logging.info(f'x_decoded[:2]:{x_decoded[:2]}')\n",
    "                    logging.info(f'pred_decoded[:2]:{pred_decoded[:2]}')\n",
    "                    logging.info(f'label_decoded[:2]:{label_decoded[:2]}')\n",
    "                metric_sacrebleu.add_batch(predictions=pred_str, references=label_str)\n",
    "                metric_bleu.add_batch(predictions=pred_list, references=label_list)\n",
    "                \n",
    "               \n",
    "            except Exception as ex:\n",
    "                print(tokenizer.batch_decode(pre),[[x] for x in tokenizer.batch_decode(test_dataloadery)])\n",
    "                raise Exception(ex)\n",
    "        # logging.info(f\"loss:{ls}\")\n",
    "        \n",
    "        acc+= ls\n",
    "        counter+= 1\n",
    "    sacrebleu_score = metric_sacrebleu.compute()\n",
    "    bleu_score = metric_bleu.compute()\n",
    "    logging.info('%s sacreBLEU : %f',model.name,sacrebleu_score['score'])\n",
    "    logging.info('%s BLEU : %f',model.name,bleu_score['bleu'])\n",
    "    logging.info('%s test loss : %f',model.name,acc/(counter*n))\n",
    "    writer.add_scalar(\"MT/\"+model.name+\"/test_loss\", acc/counter, global_step=epoch)\n",
    "    writer.add_scalar(\"MT/\"+model.name+\"/sacreBLEU\",sacrebleu_score['score'], global_step=epoch)\n",
    "    writer.add_scalar(\"MT/\"+model.name+\"/BLEU\",bleu_score['bleu'], global_step=epoch)\n",
    "    model.train()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_train(epoch, train_dataloader, w_model, v_model, architect, A, w_optimizer, v_optimizer, lr_w, lr_v, ):\n",
    "    v_trainloss_acc = 0\n",
    "    w_trainloss_acc = 0\n",
    "    counter = 0\n",
    "    wsize = args.train_w_num_points #now  train_x is [num of batch, datasize], so its seperate batch for the code below\n",
    "    synsize = args.train_w_synthetic_num_points\n",
    "    vsize = args.train_v_num_points \n",
    "    Asize = args.train_A_num_points \n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        counter+=1\n",
    "        batch_loss_w, batch_loss_v = 0, 0\n",
    "        \n",
    "        train_x = Variable(batch[0], requires_grad=False).cuda()\n",
    "        train_x_attn = Variable(batch[1], requires_grad=False).cuda()\n",
    "        train_y = Variable(batch[2], requires_grad=False).cuda()\n",
    "        train_y_attn = Variable(batch[3], requires_grad=False).cuda() \n",
    "\n",
    "        input_w = train_x[:wsize]\n",
    "        input_w_attn = train_x_attn[:wsize]\n",
    "        output_w = train_y[:wsize]\n",
    "        output_w_attn = train_y_attn[:wsize]\n",
    "        attn_idx = attn_idx_list[args.train_w_num_points*step:(args.train_w_num_points*step+args.train_w_num_points)]\n",
    "           \n",
    "        input_syn = train_x[wsize:wsize+synsize]\n",
    "        input_syn_attn = train_x_attn[wsize:wsize+synsize]\n",
    "\n",
    "        input_v = train_x[wsize+synsize:wsize+synsize+vsize]\n",
    "        input_v_attn = train_x_attn[wsize+synsize:wsize+synsize+vsize]\n",
    "        output_v = train_y[wsize+synsize:wsize+synsize+vsize]\n",
    "        output_v_attn = train_y_attn[wsize+synsize:wsize+synsize+vsize]\n",
    "\n",
    "        input_A_v      = train_x[wsize+synsize+vsize:wsize+synsize+vsize+Asize]\n",
    "        input_A_v_attn = train_x_attn[wsize+synsize+vsize:wsize+synsize+vsize+Asize]\n",
    "        output_A_v      = train_y[wsize+synsize+vsize:wsize+synsize+vsize+Asize]\n",
    "        output_A_v_attn = train_y_attn[wsize+synsize+vsize:wsize+synsize+vsize+Asize]\n",
    "       \n",
    "\n",
    "        if (epoch <= args.epochs) and (args.train_A == 1):\n",
    "            architect.step(input_w,  output_w,input_w_attn, output_w_attn, w_optimizer, input_syn, input_syn_attn,input_A_v, input_A_v_attn, output_A_v, \n",
    "                output_A_v_attn, v_optimizer, attn_idx, lr_w, lr_v)\n",
    "\n",
    "        if epoch <= args.epochs:\n",
    "            \n",
    "            w_optimizer.zero_grad()\n",
    "            loss_w = CTG_loss(input_w, input_w_attn, output_w, output_w_attn, attn_idx, A, w_model)\n",
    "            batch_loss_w += loss_w.item()\n",
    "            loss_w.backward()\n",
    "            # nn.utils.clip_grad_norm(w_model.parameters(), args.grad_clip)\n",
    "            w_optimizer.step()\n",
    "            w_trainloss_acc+=loss_w.item()\n",
    "        if epoch >= args.pre_epochs and epoch <= args.epochs:\n",
    "            v_optimizer.zero_grad()\n",
    "            loss_aug = calc_loss_aug(input_syn, input_syn_attn, w_model, v_model)#,input_v,input_v_attn,output_v,output_v_attn)\n",
    "            loss = my_loss2(input_v,input_v_attn,output_v,output_v_attn,model_v)\n",
    "            \n",
    "            v_loss =  (args.syndata_loss_ratio*loss_aug+args.traindata_loss_ratio*loss)/num_batch\n",
    "            \n",
    "            batch_loss_v += v_loss.item()\n",
    "            v_loss.backward()\n",
    "            # nn.utils.clip_grad_norm(v_model.parameters(), args.grad_clip)\n",
    "            v_optimizer.step()     \n",
    "                \n",
    "            v_trainloss_acc+=v_loss.item()\n",
    "            \n",
    "        if(step*args.batch_size%5==0):\n",
    "            logging.info(f\"{step*args.batch_size*100/(args.train_num_points)}%\")\n",
    "    \n",
    "    logging.info(str((\"Attention Weights A : \", A.alpha)))\n",
    "    return w_trainloss_acc,v_trainloss_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/11 11:50:20 AM |\t  x_decoded[:2]:[\"translate English to German: These findings form the basis of the European programmes to protect the Barents Sea, and that is why I would ask you to examine a draft letter setting out the most important facts and to make Parliament's position, as expressed in the resolutions which it has adopted, clear as far as Russia is concerned.\", 'translate English to German: We know, and we have stated as much in very many resolutions indeed, including specifically during the last plenary part-session of last year, that this is not solely a legal case and that it is wrong for Alexander Nikitin to be accused of criminal activity and treason because of our involvement as the beneficiaries of his findings.']\n",
      "03/11 11:50:20 AM |\t  pred_decoded[:2]:['Diese Erkenntnisse bilden die Grundlage für die europäischen Programme zum Schutz der Barentssee, und deshalb möchte ich Sie bitten, einen Briefentwurf zu prüfen, in dem die bedeutendsten Fakten dargelegt werden und den Standpunkt des Parlaments, wie er in den von ihm angenommenen Entschließungen zum Ausdruck kommt, hinsichtlich Russland klar zu machen.', 'Wir wissen, und das haben wir in sehr vielen Entschließungen auch in der letzten Plenarsitzung im vergangenen Jahr gesagt, dass dies nicht nur ein Rechtsfall ist und dass es falsch ist, Alexander Nikitin wegen unserer Beteiligung als Nutznießer seiner Erkenntnisse des Verbrechens und Verrats beschuldigt zu werden.']\n",
      "03/11 11:50:20 AM |\t  label_decoded[:2]:['Diese Ergebnisse sind die Grundlage für die europäischen Programme zum Schutz der Barentsee, und deswegen bitte ich Sie, einen Briefentwurf, der Ihnen die wichtigsten Fakten schildert, zu prüfen und im Sinne der Beschlüsse des Parlaments in Rußland diese Position deutlich zu machen.', 'Wir wissen und wir haben es in wirklich sehr vielen Entschließungen festgestellt - gerade während der letzten Plenartagung des vergangenen Jahres-, daß dies nicht nur ein juristischer Fall ist und daß es falsch ist, Alexander Nikitin Kriminalität und Verrat vorzuwerfen, weil wir als Betroffene von seinen Ergebnissen einen Nutzen haben.']\n",
      "03/11 11:58:54 AM |\t  model_w_in_main sacreBLEU : 24.738548\n",
      "03/11 11:58:54 AM |\t  model_w_in_main BLEU : 0.215157\n",
      "03/11 11:58:54 AM |\t  model_w_in_main test loss : 3.365942\n",
      "03/11 11:59:22 AM |\t  x_decoded[:2]:['translate English to German: In particular, annexes cannot be adapted to take account of technical and industrial developments.', 'translate English to German: Furthermore, it has transpired that research in the ports in Belgium, Finland, but also in Japan has shown that 50% of containers with partially dangerous cargo are not delivered correctly for shipment.']\n",
      "03/11 11:59:22 AM |\t  pred_decoded[:2]:['Insbesondere können Anhänge nicht an die technischen und industriellen Entwicklungen angepasst werden.', 'Darüber hinaus hat sich gezeigt, dass Untersuchungen in den Häfen Belgiens, Finnlands, aber auch Japans gezeigt haben, daß 50 % der Container mit teilweise gefährlichen Ladungen nicht ordnungsgemäß zum Versand geliefert werden.']\n",
      "03/11 11:59:22 AM |\t  label_decoded[:2]:['Insbesondere können Anhänge nicht entsprechend der technischen und industriellen Entwicklung angepaßt werden.', 'Außerdem belegen Kontrollen in belgischen, finnischen wie auch in japanischen Häfen, daß 50 % der Container mit zum Teil gefährlicher Ladung nicht ordnungsgemäß angeliefert werden.']\n",
      "03/11 12:15:02 PM |\t  model_v_in_main sacreBLEU : 24.134325\n",
      "03/11 12:15:02 PM |\t  model_v_in_main BLEU : 0.206317\n",
      "03/11 12:15:02 PM |\t  model_v_in_main test loss : 3.230934\n",
      "03/11 12:15:02 PM |\t  \n",
      "\n",
      "  ----------------epoch:0,\t\tlr_w:0.001,\t\tlr_v:0.001----------------\n",
      "03/11 12:15:08 PM |\t  0.0%\n",
      "03/11 12:15:35 PM |\t  16.0%\n",
      "03/11 12:15:58 PM |\t  32.0%\n",
      "03/11 12:16:07 PM |\t  48.0%\n",
      "03/11 12:16:14 PM |\t  64.0%\n",
      "03/11 12:16:21 PM |\t  80.0%\n",
      "03/11 12:16:31 PM |\t  96.0%\n",
      "03/11 12:16:31 PM |\t  ('Attention Weights A : ', Parameter containing:\n",
      "tensor([0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "03/11 12:16:31 PM |\t  w_train_loss:8.944966077804565,v_train_loss:0\n",
      "03/11 12:16:47 PM |\t  x_decoded[:2]:['translate English to German: Relating to Wednesday:', 'translate English to German: We feel that it is important that the Commission takes account of the conclusions adopted by this Parliament, at least in spirit, because at this stage, it might seem as though what we are doing here is a useless exercise, and nothing but hot air.']\n",
      "03/11 12:16:47 PM |\t  pred_decoded[:2]:['Zum Mittwoch:', 'Wir halten es für wichtig, dass die Kommission die Schlussfolgerungen, die dieses Parlament angenommen hat, zumindest im Geiste berücksichtigt, denn im gegenwärtigen Stadium könnte man meinen, das, was wir hier tun, sei eine nutzlose Übung, nichts als heiße Luft.']\n",
      "03/11 12:16:47 PM |\t  label_decoded[:2]:['Zum Mittwoch:', 'Für uns ist es wichtig, daß die in diesem Parlament gebilligten Schlußfolgerungen von der Kommission, zumindest ihrem Wesen nach, berücksichtigt werden, denn bei dem nunmehr erreichten Stand könnte es so aussehen, als gäben wir uns hier einer unnütze, rein rhetorischen Tätigkeit hin.']\n",
      "03/11 12:25:33 PM |\t  model_w_in_main sacreBLEU : 29.943460\n",
      "03/11 12:25:33 PM |\t  model_w_in_main BLEU : 0.253680\n",
      "03/11 12:25:33 PM |\t  model_w_in_main test loss : 1.491668\n",
      "03/11 12:25:40 PM |\t  x_decoded[:2]:['translate English to German: The reason Mr Koch produced his sound report was because the work in the CEN and within the United Nations Economic Commission was proceeding none too expeditiously.', 'translate English to German: Thirdly, we broadly agree on the general guidelines provided they do not deviate from the comments we have made so far.']\n",
      "03/11 12:25:40 PM |\t  pred_decoded[:2]:['Herr Koch hat seinen fundierten Bericht vorgelegt, weil die Arbeit im CEN und innerhalb der Wirtschaftskommission der Vereinten Nationen nicht allzu schnell voranging.', 'Drittens stimmen wir den allgemeinen Leitlinien weitgehend zu, sofern sie nicht von unseren bisherigen Bemerkungen abweichen.']\n",
      "03/11 12:25:40 PM |\t  label_decoded[:2]:['Der Kollege Koch hat seinen guten Bericht gemacht, weil im CEN und auch im Rahmen der Wirtschaftskommission der Vereinten Nationen die Arbeit nicht so expeditiv gemacht wurde.', 'Drittens möchte ich anmerken, daß wir mit den Leitlinien im großen und ganzen einverstanden sind, soweit sie nicht von unseren Bemerkungen abweichen.']\n",
      "03/11 12:27:29 PM |\t  model_v_in_main sacreBLEU : 26.119524\n",
      "03/11 12:27:29 PM |\t  model_v_in_main BLEU : 0.230424\n",
      "03/11 12:27:29 PM |\t  model_v_in_main test loss : 3.181854\n",
      "03/11 12:27:33 PM |\t  \n",
      "\n",
      "  ----------------epoch:1,\t\tlr_w:0.000987726234834463,\t\tlr_v:0.000987726234834463----------------\n",
      "03/11 12:27:39 PM |\t  0.0%\n",
      "03/11 12:28:02 PM |\t  16.0%\n",
      "03/11 12:28:28 PM |\t  32.0%\n",
      "03/11 12:28:51 PM |\t  48.0%\n",
      "03/11 12:29:15 PM |\t  64.0%\n",
      "03/11 12:29:42 PM |\t  80.0%\n",
      "03/11 12:30:04 PM |\t  96.0%\n",
      "03/11 12:30:04 PM |\t  ('Attention Weights A : ', Parameter containing:\n",
      "tensor([0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "03/11 12:30:04 PM |\t  w_train_loss:4.196805834770203,v_train_loss:9.243749380111694\n",
      "03/11 12:30:12 PM |\t  x_decoded[:2]:[\"translate English to German: We see it as a very positive sign that, in her own conclusions, the rapporteur has taken account of our committee' s proposal that the Cohesion Fund countries should broaden the research infrastructure by locating universities and colleges in such a way that they would serve those who live in undeveloped regions better than now and make it easier for educated people to remain in their home districts.\", 'translate English to German: I know many have already done so, but she has indeed earned our praise for being particularly open and attentive to proposals from all sides, and I think it is this openness which has given her report the quality we see today.']\n",
      "03/11 12:30:12 PM |\t  pred_decoded[:2]:['Wir halten es für ein sehr positives Zeichen, daß die Berichterstatterin in ihren Schlußfolgerungen den Vorschlag unseres Ausschusse bezüglich der Ausweitung der Forschungsinfrastruktur in den Mitgliedstaaten des Kohäsionsfonds berücksichtigt hat, indem sie die Universitäten und Hochschulen so ansieht, damit sie den Menschen, die in nicht entwickelten Regionen leben, besser als heute dienen und den gebildeten Menschen erleichtern, in', 'Ich weiß, viele haben dies bereits getan, aber sie hat sich in der Tat Lob verdient, weil sie besonders offen und aufmerksam auf Vorschläge von allen Seiten reagiert, und ich denke, es ist diese Offenheit, die ihrem Bericht die Qualität verleiht, wie wir sie heute sehen.']\n",
      "03/11 12:30:12 PM |\t  label_decoded[:2]:['Zunächst möchte ich mich zum Forschungsaspekt äußern. Wir erachten es als sehr positiv, daß die Berichterstatterin den Vorschlag unseres Ausschusses in ihre Schlußfolgerungen aufgenommen hat, wonach in den Kohäsionsländern die wissenschaftliche Infrastruktur ausgedehnt werden muß, indem Hochschulen und Bildungseinrichtungen an solchen Orten geschaffen werden, an denen sie besser als bisher den Bewohnern unterentwickelter Regionen zur Verfügung stehen, und es Absolventen erleichtert wird, in ihren Heimatregionen zu verbleiben.', 'Viele haben das zwar schon getan, doch ich denke, sie hat es wirklich verdient, denn sie hat sich Anregungen der einen und anderen Seite gegenüber sehr offen und aufgeschlossen gezeigt, und ich meine, daß sich dies in der Qualität ihres Berichts niedergeschlagen hat.']\n",
      "03/11 12:32:00 PM |\t  model_w_in_main sacreBLEU : 28.689127\n",
      "03/11 12:32:00 PM |\t  model_w_in_main BLEU : 0.247028\n",
      "03/11 12:32:00 PM |\t  model_w_in_main test loss : 0.369057\n",
      "03/11 12:32:05 PM |\t  x_decoded[:2]:['translate English to German: I do not know whether this information is correct, but the PPE-DE Group would, in any case, be grateful if this item were removed because Parliament has addressed this issue several times already.', 'translate English to German: Yes, Mrs Schroedter, I shall be pleased to look into the facts of this case when I have received your letter.']\n",
      "03/11 12:32:05 PM |\t  pred_decoded[:2]:['Ich weiß nicht, ob diese Informationen richtig sind, aber die EVP-ED-Fraktion wäre auf jeden Fall dankbar, wenn dieser Punkt gestrichen würde, da das Parlament dieses Thema bereits mehrfach angesprochen hat.', 'Ja, Frau Schroedter, ich werde mich gerne mit dieser Angelegenheit befassen, sobald mir Ihr Schreiben vorliegt.']\n",
      "03/11 12:32:05 PM |\t  label_decoded[:2]:['Ich weiß nicht, ob diese Information richtig ist, aber wir als EVP-ED-Fraktion wären jedenfalls dankbar, wenn dieser Punkt abgesetzt würde, weil sich das Parlament nämlich schon mehrfach mit dieser Frage befaßt hat.', 'Frau Schroedter, ich bin gerne bereit, die damit zusammenhängenden Fakten zu prüfen, wenn mir Ihr Brief vorliegt.']\n",
      "03/11 12:33:53 PM |\t  model_v_in_main sacreBLEU : 27.026504\n",
      "03/11 12:33:53 PM |\t  model_v_in_main BLEU : 0.231284\n",
      "03/11 12:33:53 PM |\t  model_v_in_main test loss : 1.542519\n",
      "03/11 12:33:58 PM |\t  \n",
      "\n",
      "  ----------------epoch:2,\t\tlr_w:0.0009575498965391206,\t\tlr_v:0.0009575498965391206----------------\n",
      "03/11 12:34:02 PM |\t  0.0%\n",
      "03/11 12:34:26 PM |\t  16.0%\n",
      "03/11 12:34:52 PM |\t  32.0%\n",
      "03/11 12:35:15 PM |\t  48.0%\n",
      "03/11 12:35:41 PM |\t  64.0%\n",
      "03/11 12:36:10 PM |\t  80.0%\n",
      "03/11 12:36:39 PM |\t  96.0%\n",
      "03/11 12:36:39 PM |\t  ('Attention Weights A : ', Parameter containing:\n",
      "tensor([0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "03/11 12:36:39 PM |\t  w_train_loss:2.468206901103258,v_train_loss:5.12674306333065\n",
      "03/11 12:36:44 PM |\t  x_decoded[:2]:['translate English to German: As my fellow chairmen will recall, I even mentioned that it was not a matter of knowing whether one was for or against the Tobin tax, but of whether one dared to hear what the Commission and the Council thought of it.', 'translate English to German: That is precisely the time when you may, if you wish, raise this question, i.e. on Thursday prior to the start of the presentation of the report.']\n",
      "03/11 12:36:44 PM |\t  pred_decoded[:2]:['Wie sich meine Vorsitzenden erinnern werden, habe ich sogar darauf hingewiesen, dass es nicht darum ging, zu wissen, ob man für oder gegen die Tobin-Steuer ist, man wagte zu hören, was die Kommission und der Rat davon halten.', 'Dies ist genau der Zeitpunkt, an dem Sie, wenn Sie wollen, diese Frage stellen können, d. h. am Donnerstag vor Beginn der Vorlage des Berichts.']\n",
      "03/11 12:36:44 PM |\t  label_decoded[:2]:['Und ich hatte noch darauf hingewiesen, die anderen Präsidentenkollegen werden sich noch daran erinnern, daß es nicht darum geht, ob man für oder gegen die Tobin-Steuer ist, sondern darum, ob wir bereit sind, uns anzuhören, was die Kommission und der Rat davon halten.', 'Genau dann können Sie, wenn Sie wollen, diese Frage ansprechen, d. h. am Donnerstag zu Beginn der Aussprache über den Bericht.']\n",
      "03/11 12:38:53 PM |\t  model_w_in_main sacreBLEU : 22.420242\n",
      "03/11 12:38:53 PM |\t  model_w_in_main BLEU : 0.194717\n",
      "03/11 12:38:53 PM |\t  model_w_in_main test loss : 0.247544\n",
      "03/11 12:39:12 PM |\t  x_decoded[:2]:['translate English to German: The report looks at the issue of harmonising the examination requirements for safety advisors working in the areas of transportation of dangerous goods by road, rail and inland waterway.', 'translate English to German: It is not a lot to ask.']\n",
      "03/11 12:39:12 PM |\t  pred_decoded[:2]:['Der Bericht befasst sich mit der Frage der Harmonisierung der Prüfungsanforderungen für Sicherheitsberater, die im Bereich des Straßen-, Schienen- und Binnenschifffahrt gefährliche Güter transportieren.', 'Das ist nicht viel zu fordern.']\n",
      "03/11 12:39:12 PM |\t  label_decoded[:2]:['Der Bericht befaßt sich mit der Harmonisierung von Prüfungsanforderungen für Sicherheitsberater, die im Bereich der Beförderung gefährlicher Güter auf Straße, Schiene oder Binnenwasserstraße tätig sind.', 'Das ist nicht zuviel verlangt.']\n",
      "03/11 12:41:28 PM |\t  model_v_in_main sacreBLEU : 26.169216\n",
      "03/11 12:41:28 PM |\t  model_v_in_main BLEU : 0.223148\n",
      "03/11 12:41:28 PM |\t  model_v_in_main test loss : 0.630451\n",
      "03/11 12:41:32 PM |\t  \n",
      "\n",
      "  ----------------epoch:3,\t\tlr_w:0.0009164023811348203,\t\tlr_v:0.0009164023811348203----------------\n",
      "03/11 12:41:37 PM |\t  0.0%\n",
      "03/11 12:42:20 PM |\t  16.0%\n",
      "03/11 12:42:46 PM |\t  32.0%\n",
      "03/11 12:43:18 PM |\t  48.0%\n",
      "03/11 12:43:52 PM |\t  64.0%\n",
      "03/11 12:44:31 PM |\t  80.0%\n",
      "03/11 12:44:58 PM |\t  96.0%\n",
      "03/11 12:44:58 PM |\t  ('Attention Weights A : ', Parameter containing:\n",
      "tensor([0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "03/11 12:44:58 PM |\t  w_train_loss:1.9151086173951626,v_train_loss:3.2508125007152557\n",
      "03/11 12:45:03 PM |\t  x_decoded[:2]:['translate English to German: In so doing, it is supported by a committee of experts on the transport of dangerous goods under the regulatory procedure.', 'translate English to German: Whether or not this will encourage her to continue along the same path, I cannot say. Nevertheless, I would like to commend her on her work.']\n",
      "03/11 12:45:03 PM |\t  pred_decoded[:2]:['Dabei wird sie von einem Sachverständigenausschuss für den Transport gefährlicher Güter im Rahmen des Regelungsverfahrens unterstützt.', 'Ich kann nicht sagen, ob dies sie dazu ermutigen wird, denselben Weg weiterzugehen, aber ich möchte sie zu ihrer Arbeit beglückwünschen.']\n",
      "03/11 12:45:03 PM |\t  label_decoded[:2]:['Sie wird dabei von einem Expertenausschuß für Gefahrguttransporte nach dem Regelungsverfahren unterstützt.', 'Vielleicht wird sie dadurch ermutigt, in diese Richtung weiterzuarbeiten, auf jeden Fall möchte ich ihr aber meine Glückwünsche aussprechen.']\n",
      "03/11 12:47:13 PM |\t  model_w_in_main sacreBLEU : 26.228330\n",
      "03/11 12:47:13 PM |\t  model_w_in_main BLEU : 0.226588\n",
      "03/11 12:47:13 PM |\t  model_w_in_main test loss : 0.134066\n",
      "03/11 12:47:18 PM |\t  x_decoded[:2]:['translate English to German: In fact, all hell broke loose in some municipalities in my province.', 'translate English to German: If the Commissioner is unable to do so today then would she be prepared to inform the committee in writing of how matters stand and what stage negotiations between the CEN and the Economic Commission are at?']\n",
      "03/11 12:47:18 PM |\t  pred_decoded[:2]:['Tatsächlich ist in einigen Gemeinden meiner Provinz die Hölle losgelaufen.', 'Wenn die Kommissarin dies heute nicht tun kann, wäre sie dann bereit, den Ausschuß schriftlich darüber zu informieren, wie die Dinge stehen und in welchem Stadium sich die Verhandlungen zwischen dem CEN und der Wirtschaftskommission befinden?']\n",
      "03/11 12:47:18 PM |\t  label_decoded[:2]:['Es war in einzelnen Gemeinden in meinem Land wirklich die Hölle los.', 'Wenn die Frau Kommissarin das heute nicht machen kann, wäre sie dann bereit, dem Ausschuß schriftlich den Stand der Dinge und den Stand der Verhandlungen zwischen CEN und Wirtschaftskommission zu übermitteln?']\n",
      "03/11 12:49:31 PM |\t  model_v_in_main sacreBLEU : 24.873154\n",
      "03/11 12:49:31 PM |\t  model_v_in_main BLEU : 0.216962\n",
      "03/11 12:49:31 PM |\t  model_v_in_main test loss : 0.260807\n",
      "03/11 12:49:35 PM |\t  \n",
      "\n",
      "  ----------------epoch:4,\t\tlr_w:0.0008652911674490296,\t\tlr_v:0.0008652911674490296----------------\n",
      "03/11 12:49:39 PM |\t  0.0%\n",
      "03/11 12:50:05 PM |\t  16.0%\n",
      "03/11 12:50:34 PM |\t  32.0%\n",
      "03/11 12:51:02 PM |\t  48.0%\n",
      "03/11 12:51:28 PM |\t  64.0%\n",
      "03/11 12:51:57 PM |\t  80.0%\n",
      "03/11 12:52:34 PM |\t  96.0%\n",
      "03/11 12:52:34 PM |\t  ('Attention Weights A : ', Parameter containing:\n",
      "tensor([0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "03/11 12:52:34 PM |\t  w_train_loss:1.6399308666586876,v_train_loss:2.8264794647693634\n",
      "03/11 12:52:42 PM |\t  x_decoded[:2]:['translate English to German: This lack of infrastructure is also an obstacle to the establishment of companies and the creation of jobs.', 'translate English to German: There has therefore been enough time for the Commission to prepare its programme and for us to become familiar with it and explain it to our citizens.']\n",
      "03/11 12:52:42 PM |\t  pred_decoded[:2]:['Dieser Mangel an Infrastruktur ist auch ein Hindernis für die Gründung von Unternehmen und die Schaffung von Arbeitsplätzen.', 'Daher hat die Kommission genügend Zeit gehabt, um ihr Programm vorzubereiten und uns damit vertraut zu machen und es unseren Bürgerinnen und Bürgern zu erläutern.']\n",
      "03/11 12:52:42 PM |\t  label_decoded[:2]:['Diese fehlende Infrastruktur ist wiederum ein Hindernis für die Ansiedlung von Unternehmen und die Schaffung von Arbeitsplätzen.', 'Somit hatte die Kommission bereits genügend Zeit, ihr Programm zu erarbeiten, und wir, um es kennenlernen und den Bürgern erklären zu können.']\n",
      "03/11 12:54:49 PM |\t  model_w_in_main sacreBLEU : 26.744138\n",
      "03/11 12:54:49 PM |\t  model_w_in_main BLEU : 0.234133\n",
      "03/11 12:54:49 PM |\t  model_w_in_main test loss : 0.145076\n",
      "03/11 12:56:40 PM |\t  x_decoded[:2]:['translate English to German: The PPE-DE Group is requesting that this item be taken off the agenda.', \"translate English to German: Madam President, I should like to know if there will be a clear message going out from Parliament this week about our discontent over today's decision refusing to renew the arms embargo on Indonesia, considering that the vast majority in this Parliament have endorsed the arms embargo in Indonesia in the past?\"]\n",
      "03/11 12:56:40 PM |\t  pred_decoded[:2]:['Die PPE-DE-Fraktion beantragt, diesen Punkt von der Tagesordnung zu streichen.', 'Frau Präsidentin! Ich möchte wissen, ob das Parlament in dieser Woche eine klare Botschaft über unsere Unzufriedenheit über die heutige Entscheidung, das Waffenembargo gegen Indonesien zu verlängern, aussenden wird, wenn man bedenkt, dass die große Mehrheit dieses Parlaments in der Vergangenheit die Aufhebung des indonesischen Waffenenbarrierens unterstützt hat?']\n",
      "03/11 12:56:40 PM |\t  label_decoded[:2]:['Die PPE/DE-Fraktion beantragt, diesen Punkt von der Tagesordnung abzusetzen.', 'Frau Präsidentin, ich wüßte gern, ob das Parlament in dieser Woche ein deutliches Signal unserer Unzufriedenheit bezüglich der heutigen Entscheidung, mit der eine Verlängerung des Waffenembargos gegen Indonesien abgelehnt wird, aussenden wird, zumal sich die große Mehrheit in diesem Parlament in der Vergangenheit für das Waffenembargo gegen Indonesien ausgesprochen hat.']\n",
      "03/11 01:35:22 PM |\t  model_v_in_main sacreBLEU : 25.691838\n",
      "03/11 01:35:22 PM |\t  model_v_in_main BLEU : 0.217623\n",
      "03/11 01:35:22 PM |\t  model_v_in_main test loss : 0.189614\n",
      "03/11 01:35:27 PM |\t  \n",
      "\n",
      "  ----------------epoch:5,\t\tlr_w:0.000805468818544741,\t\tlr_v:0.000805468818544741----------------\n",
      "03/11 01:35:35 PM |\t  0.0%\n",
      "03/11 01:36:43 PM |\t  16.0%\n",
      "03/11 01:37:40 PM |\t  32.0%\n",
      "03/11 01:38:46 PM |\t  48.0%\n",
      "03/11 01:39:47 PM |\t  64.0%\n",
      "03/11 01:40:45 PM |\t  80.0%\n",
      "03/11 01:41:39 PM |\t  96.0%\n",
      "03/11 01:41:39 PM |\t  ('Attention Weights A : ', Parameter containing:\n",
      "tensor([0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "03/11 01:41:39 PM |\t  w_train_loss:1.6741792857646942,v_train_loss:2.652350302785635\n",
      "03/11 01:41:55 PM |\t  x_decoded[:2]:['translate English to German: The next item is the report (A5-0104/1999) by Mr Koch, on behalf of the Committee on Regional Policy, Transport and Tourism, on the proposal for a European Parliament and Council directive amending Directive 94/55/EC on the approximation of the laws of the Member States with regard to the transport of dangerous goods by road [COM(1999) 158 - C5-0004/1999 - 1999/0083(COD)].', 'translate English to German: Our amendments from the first reading have, I believe, been taken into account very satisfactorily.']\n",
      "03/11 01:41:55 PM |\t  pred_decoded[:2]:['Nach der Tagesordnung folgt der Bericht (A5-0104/1999) von Herrn Koch im Namen des Ausschusses für Regionalpolitik, Verkehr und Fremdenverkehr über den Vorschlag für eine Richtlinie des Europäischen Parlaments und des Rates zur nderung der Rechtsvorschrift 94/55/EG zur Angleichung des Rechts der Mitgliedstaaten im Hinblick auf die Beförderung gefährlicher Güter auf der Straße (KOM(1999) 158 - C5-0004/19', 'Meines Erachtens wurden unsere nderungsanträge aus der ersten Lesung sehr zufrieden stellend berücksichtigt.']\n",
      "03/11 01:41:55 PM |\t  label_decoded[:2]:['Nach der Tagesordnung folgt der Bericht (A5-0104/1999) von Herrn Koch im Namen des Ausschusses für Regionalpolitik, Verkehr und Fremdenverkehr für eine Richtlinie des Europäischen Parlament und des Rates (KOM(1999) 158 - C5-0004/1999 - 1999/0083(COD) ) zur nderung der Richtlinie 94/55/EG zur Angleichung der Rechtsvorschriften der Mitgliedstaaten für den Gefahrguttransport auf der Straße.', 'Unsere nderungsanträge aus der ersten Lesung halte ich für sehr zufriedenstellend berücksichtigt.']\n",
      "03/11 01:46:02 PM |\t  model_w_in_main sacreBLEU : 28.739157\n",
      "03/11 01:46:02 PM |\t  model_w_in_main BLEU : 0.253061\n",
      "03/11 01:46:02 PM |\t  model_w_in_main test loss : 0.110397\n",
      "03/11 01:46:17 PM |\t  x_decoded[:2]:['translate English to German: Agriculture only provides 5.5% of employment in the Union.', 'translate English to German: However, I would ask you, in accordance with the line which is now constantly followed by the European Parliament and by the whole of the European Community, to make representations, using the weight of your prestigious office and the institution you represent, to the President and to the Governor of Texas, Mr Bush, who has the power to order a stay of execution and to reprieve the condemned person.']\n",
      "03/11 01:46:17 PM |\t  pred_decoded[:2]:['Die Landwirtschaft stellt nur 5,5 % der Beschäftigung in der Union.', 'Ich möchte Sie jedoch bitten, in Übereinstimmung mit der Linie, die das Europäische Parlament und die gesamte Gemeinschaft jetzt ständig verfolgen, dem Präsidenten und dem Gouverneur von Texas, Herrn Bush, mit dem Gewicht Ihres renommierten Amtes und der von Ihnen vertretenen Institution, vorzutreten, der die Befugnis hat, einen Aufschub der Vollstreckung zu verlangen und den Verurteilten aufzuheben.']\n",
      "03/11 01:46:17 PM |\t  label_decoded[:2]:['Die Landwirtschaft stellt nur 5,5 % der Arbeitsplätze der Union.', 'Gemäß der vom Europäischen Parlament und von der gesamten Europäischen Union nunmehr ständig vertretenen Linie möchte ich Sie jedoch bitten, den ganzen Einfluß Ihres Amtes und der Institution, die Sie vertreten, bei dem Präsidentschaftskandidaten und Gouverneur von Texas, George W. Bush, der zur Aussetzung der Vollstreckung des Todesurteils und zur Begnadigung des Verurteilten befugt ist, geltend zu machen.']\n",
      "03/11 01:50:42 PM |\t  model_v_in_main sacreBLEU : 28.327534\n",
      "03/11 01:50:42 PM |\t  model_v_in_main BLEU : 0.246077\n",
      "03/11 01:50:42 PM |\t  model_v_in_main test loss : 0.132745\n",
      "03/11 01:50:47 PM |\t  \n",
      "\n",
      "  ----------------epoch:6,\t\tlr_w:0.0007384019661749497,\t\tlr_v:0.0007384019661749497----------------\n",
      "03/11 01:50:59 PM |\t  0.0%\n",
      "03/11 01:56:24 PM |\t  16.0%\n",
      "03/11 02:06:38 PM |\t  32.0%\n",
      "03/11 02:19:46 PM |\t  48.0%\n",
      "03/11 02:26:02 PM |\t  64.0%\n",
      "03/11 02:27:09 PM |\t  80.0%\n",
      "03/11 02:28:03 PM |\t  96.0%\n",
      "03/11 02:28:03 PM |\t  ('Attention Weights A : ', Parameter containing:\n",
      "tensor([0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "03/11 02:28:03 PM |\t  w_train_loss:1.6410199105739594,v_train_loss:2.4126345217227936\n",
      "03/11 02:28:21 PM |\t  x_decoded[:2]:['translate English to German: This is not in itself anything dreadful, but we should prioritise particularly the safety aspects for goods transported by road, rail and inland waterways and incorporate these, as part of the acquis communautaire, as soon as possible and present them to the acceding states.', \"translate English to German: That is why we would recommend - and it is my impression that the Commission is also open to this idea - that we hold the debate on the Commission's long-term programme up to the year 2005 in February - and I hope that the Commission will agree on a programme before then which it will propose to us - and that, at the same time, in February we also hold the debate on the Commission's legislative programme for the year 2000.\"]\n",
      "03/11 02:28:21 PM |\t  pred_decoded[:2]:['Das ist an sich nichts Schreckliches, aber wir sollten insbesondere die Sicherheitsaspekte für Güter, die auf der Straße, der Schiene und auf Binnenwasserstraßen befördert werden, in den gemeinschaftlichen Besitzstand einbeziehen und den Beitrittsländern so schnell wie möglich vorlegen.', 'Deshalb empfehlen wir - und ich habe den Eindruck, daß auch die Kommission dieser Idee aufgeschlossen gegenübersteht-, im Februar die Debatte über das langfristige Programm bis zum Jahr 2005 durchzuführen, und hoffentlich schließt sich die Europäische Union bis dahin auf ein Programm, das sie uns vorschlagen wird, ab und wir sollten außerdem während des Februars die Aussprache über die Gesetzgebungsprogramme für das Jahr 2000 durchführen.']\n",
      "03/11 02:28:21 PM |\t  label_decoded[:2]:['Obgleich ich das an sich nicht schlimm finde, sollten wir insbesondere den Sicherheitsaspekten des Gefahrguttransports auf Straße, Schiene und Binnenwasserstraßen Priorität einräumen, diesen Teil des Besitzstands so bald als möglich aufgreifen und den beitrittswilligen Staaten vorlegen.', 'Deswegen ist es unsere Empfehlung - und mein Eindruck ist, daß die Kommission auch aufgeschlossen ist für diesen Gedanken -, daß wir im Februar die Debatte über das langfristige Programm der Kommission bis zum Jahre 2005 führen - ich hoffe, die Kommission wird sich bis dahin auch auf ein Programm verständigen, das sie uns vorschlagen wird -, und daß wir gleichzeitig im Februar auch die Debatte über das Legislativprogramm der Kommission für das Jahr 2000 führen.']\n",
      "03/11 02:32:27 PM |\t  model_w_in_main sacreBLEU : 23.199322\n",
      "03/11 02:32:27 PM |\t  model_w_in_main BLEU : 0.197201\n",
      "03/11 02:32:27 PM |\t  model_w_in_main test loss : 0.136446\n",
      "03/11 02:32:32 PM |\t  x_decoded[:2]:['translate English to German: We have to remember that rural areas represent almost four fifths of the territory of the European Union.', 'translate English to German: There will be major problems with enforcing this rule at present, especially with smaller companies, as these cannot afford safety advisors.']\n",
      "03/11 02:32:32 PM |\t  pred_decoded[:2]:['Wir dürfen nicht vergessen, dass die ländlichen Gebiete fast vier Fünftel des Territoriums der Europäischen Union ausmachen.', 'Es wird derzeit große Probleme bei der Durchsetzung dieser Regelung geben, insbesondere bei kleineren Unternehmen, da diese sich keine Sicherheitsberater leisten können.']\n",
      "03/11 02:32:32 PM |\t  label_decoded[:2]:['Man muß sich vor Augen halten, daß der ländliche Raum nahezu vier Fünftel des Territoriums der Europäischen Union ausmacht.', 'Die Umsetzung ist gegenwärtig insbesondere in kleinen Betrieben mit Schwierigkeiten verbunden, denn sie können sich eine solche Stelle nicht leisten.']\n",
      "03/11 02:36:54 PM |\t  model_v_in_main sacreBLEU : 26.989820\n",
      "03/11 02:36:54 PM |\t  model_v_in_main BLEU : 0.233098\n",
      "03/11 02:36:54 PM |\t  model_v_in_main test loss : 0.161081\n",
      "03/11 02:36:58 PM |\t  \n",
      "\n",
      "  ----------------epoch:7,\t\tlr_w:0.0006657349821962692,\t\tlr_v:0.0006657349821962692----------------\n",
      "03/11 02:37:16 PM |\t  0.0%\n",
      "03/11 02:38:25 PM |\t  16.0%\n",
      "03/11 02:39:27 PM |\t  32.0%\n",
      "03/11 02:40:33 PM |\t  48.0%\n",
      "03/11 02:41:39 PM |\t  64.0%\n",
      "03/11 02:42:25 PM |\t  80.0%\n",
      "03/11 02:43:35 PM |\t  96.0%\n",
      "03/11 02:43:35 PM |\t  ('Attention Weights A : ', Parameter containing:\n",
      "tensor([0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "03/11 02:43:35 PM |\t  w_train_loss:1.6370752565562725,v_train_loss:2.3441611640155315\n",
      "03/11 02:43:50 PM |\t  x_decoded[:2]:['translate English to German: We shall pay particular attention to the wording of the Minutes, as we always do, of course.', 'translate English to German: The Commission, however, though bound to issue guidelines, does so only reluctantly and in a vague manner.']\n",
      "03/11 02:43:50 PM |\t  pred_decoded[:2]:['Wir werden der Formulierung des Protokolls besondere Aufmerksamkeit schenken, wie wir es selbstverständlich immer tun.', 'Die Kommission ist jedoch verpflichtet, Leitlinien zu erlassen, doch tut sie dies nur widerwillig und vage.']\n",
      "03/11 02:43:50 PM |\t  label_decoded[:2]:['Beim Abfassen des Protokolls werden wir mit großer Sorgfalt vorgehen. Das tun wir im übrigen immer.', 'Doch die Kommission, die die Aufgabe hat, Leitlinien vorzulegen, tut dies nur widerwillig und bleibt vage.']\n",
      "03/11 02:47:24 PM |\t  model_w_in_main sacreBLEU : 25.587220\n",
      "03/11 02:47:24 PM |\t  model_w_in_main BLEU : 0.225147\n",
      "03/11 02:47:24 PM |\t  model_w_in_main test loss : 0.130382\n",
      "03/11 02:47:29 PM |\t  x_decoded[:2]:['translate English to German: The consequences do not inspire hope.', 'translate English to German: I would also like to thank her for her willingness to enter into dialogue with the other political groups when compromise formulas have needed to be reached in the face of this avalanche of amendments - and perhaps there are more of them than we expected - but which genuinely reflect the importance of the report we are now discussing.']\n",
      "03/11 02:47:29 PM |\t  pred_decoded[:2]:['Die Folgen lassen keine Hoffnung wecken.', 'Ich möchte ihr auch für ihre Bereitschaft danken, mit den anderen Fraktionen in den Dialog zu treten, wenn angesichts dieser Lawine von nderungsanträgen - und vielleicht gibt es mehr, als wir erwartet haben, aber die wirklich die Bedeutung des Berichts widerspiegeln, den wir jetzt diskutieren.']\n",
      "03/11 02:47:29 PM |\t  label_decoded[:2]:['Die Folgen lassen nicht auf sich warten.', 'Außerdem möchte ich ihr für ihre Bereitschaft zum Dialog mit den übrigen Fraktionen bei der Suche nach Kompromißformeln angesichts dieser Lawine von nderungsanträgen danken; es waren vielleicht mehr als erwartet, aber sie tragen eigentlich der Bedeutung des hier behandelten Berichts Rechnung.']\n",
      "03/11 02:49:26 PM |\t  model_v_in_main sacreBLEU : 26.097385\n",
      "03/11 02:49:26 PM |\t  model_v_in_main BLEU : 0.220303\n",
      "03/11 02:49:26 PM |\t  model_v_in_main test loss : 0.113780\n",
      "03/11 02:49:29 PM |\t  \n",
      "\n",
      "  ----------------epoch:8,\t\tlr_w:0.0005892492048157691,\t\tlr_v:0.0005892492048157691----------------\n",
      "03/11 02:49:33 PM |\t  0.0%\n",
      "03/11 02:50:03 PM |\t  16.0%\n",
      "03/11 02:50:30 PM |\t  32.0%\n",
      "03/11 02:50:57 PM |\t  48.0%\n",
      "03/11 02:51:30 PM |\t  64.0%\n",
      "03/11 02:52:03 PM |\t  80.0%\n",
      "03/11 02:52:24 PM |\t  96.0%\n",
      "03/11 02:52:24 PM |\t  ('Attention Weights A : ', Parameter containing:\n",
      "tensor([0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081,\n",
      "        0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "03/11 02:52:24 PM |\t  w_train_loss:1.4640185423195362,v_train_loss:2.2693620808422565\n",
      "03/11 02:52:38 PM |\t  x_decoded[:2]:[\"translate English to German: We believe, however, that the Commission's strategic plan needs to be debated within a proper procedural framework, not only on the basis of an oral statement here in the European Parliament, but also on the basis of a document which is adopted in the Commission and which describes this programme over the five-year period.\", 'translate English to German: The rich areas were those where there were jobs in industry, but today those areas might have become a burden, and they may well be poor, meaning we also have to invest in new sectors of industry such as electronic production, as I might call it, and the production of services, because they are the industries of the future.']\n",
      "03/11 02:52:38 PM |\t  pred_decoded[:2]:['Wir sind jedoch der Auffassung, dass der strategische Plan der Kommission in einem ordentlichen Verfahrensrahmen diskutiert werden muss, nicht nur auf der Grundlage einer mündlichen Erklärung hier im Europäischen Parlament, sondern auch auf Grundlage eines Dokuments, das in der Richtlinie verabschiedet wird und in dem dieses Programm für den Fünfjahreszeitraum beschrieben wird.', 'Die reichen Gebiete waren diejenigen, in denen es Arbeitsplätze in der Industrie gab, aber heute könnten diese Bereiche zu einer Belastung geworden sein, und sie könnten durchaus arm sein. Das bedeutet, dass wir auch in neue Branchen wie die elektronische Produktion, wie ich sie nennen könnte, sowie die Produktion von Dienstleistungen investieren müssen, denn sie sind die Branchen der Zukunft.']\n",
      "03/11 02:52:38 PM |\t  label_decoded[:2]:['Aber wir sind auch der Meinung, daß wir eine Debatte über diese Strategie der Kommission in einem geordneten Verfahren führen müssen, nicht nur aufgrund einer mündlichen Erklärung hier im Europäischen Parlament, sondern auch aufgrund eines Dokumentes, das in der Kommission beschlossen ist und dieses Programm für fünf Jahre beschreibt.', 'Reich waren jene Regionen, in denen es Arbeitsplätze in der Industrie gab. Jetzt sind aus diesen Regionen teilweise Problemfälle und arme Gebiete geworden, wo auch in neue Branchen wie Elektronik und Dienstleistungen investiert werden muß, weil diese als zukunftsweisende Bereiche gelten.']\n",
      "03/11 02:54:40 PM |\t  model_w_in_main sacreBLEU : 26.427880\n",
      "03/11 02:54:40 PM |\t  model_w_in_main BLEU : 0.231426\n",
      "03/11 02:54:40 PM |\t  model_w_in_main test loss : 0.132061\n",
      "03/11 02:54:59 PM |\t  x_decoded[:2]:['translate English to German: Mr President, I support the main proposals of the report concerning the administration of the Structural Funds and the Cohesion Fund for the period 2000-2006 and the main recommendations of the report which include the following: there must always be an integrated approach to the spending of EU Structural and Cohesion Funds.', 'translate English to German: I do realise that this is only a small step towards increased transport safety, but I would ask you to endorse this report.']\n",
      "03/11 02:54:59 PM |\t  pred_decoded[:2]:['Herr Präsident, ich unterstütze die wichtigsten Vorschläge des Berichts über die Verwaltung der Strukturfonds und des Kohäsionsfond s für den Zeitraum 2000-2006 und die Hauptempfehlungen, zu denen folgende Empfehlungen zählen: Bei der Ausgaben der EU-Struktur- und der Europäischen Union muß stets ein integrierter Ansatz verfolgt werden.', 'Ich bin mir bewusst, dass dies nur ein kleiner Schritt hin zu mehr Verkehrssicherheit ist, aber ich bitte Sie, diesen Bericht zu unterstützen.']\n",
      "03/11 02:54:59 PM |\t  label_decoded[:2]:['Herr Präsident, ich unterstütze die wichtigsten Vorschläge des Berichts im Hinblick auf die Verwaltung der Strukturfonds und des Kohäsionsfonds für den Zeitraum 2000-2006 sowie die wichtigsten in dem Bericht enthaltenen Empfehlungen. Dazu zählt u. a., daß jederzeit ein einheitlicher Ansatz für die Verwendung der Mittel der EU-Strukturfonds und des Kohäsionsfonds bestehen muß.', 'Gleichwohl wissend, daß dies nur ein kleiner Schritt zu mehr Verkehrssicherheit ist, bitte ich Sie um die Zustimmung zu diesem Bericht.']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7912/3692329960.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mmy_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_w\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mmy_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_v\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_v\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'./model/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'model_v.pt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7912/3877741707.py\u001b[0m in \u001b[0;36mmy_test\u001b[1;34m(test_dataloader, model, epoch)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmy_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_dataloaderx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_dataloaderx_attn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_dataloadery\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_dataloadery_attn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[0mpre\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_dataloaderx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m                 \u001b[0mx_decoded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_dataloaderx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mskip_special_tokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mg:\\GitCode\\Self-teaching-for-machine-translation\\T5\\T5.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, input_ids, num_beams, max_length)\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[1;31m# print(\"start of : generate\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m         \u001b[0moutput_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_beams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_beams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mno_repeat_ngram_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrepetition_penalty\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, typical_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, stopping_criteria, constraints, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[0;32m   1249\u001b[0m             )\n\u001b[0;32m   1250\u001b[0m             \u001b[1;31m# 12. run beam search\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1251\u001b[1;33m             return self.beam_search(\n\u001b[0m\u001b[0;32m   1252\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1253\u001b[0m                 \u001b[0mbeam_scorer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\generation_utils.py\u001b[0m in \u001b[0;36mbeam_search\u001b[1;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[0;32m   2033\u001b[0m             \u001b[0mmodel_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_inputs_for_generation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2034\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2035\u001b[1;33m             outputs = self(\n\u001b[0m\u001b[0;32m   2036\u001b[0m                 \u001b[1;33m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2037\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1634\u001b[0m         \u001b[1;31m# Decode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1635\u001b[1;33m         decoder_outputs = self.decoder(\n\u001b[0m\u001b[0;32m   1636\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1637\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecoder_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1028\u001b[0m                 )\n\u001b[0;32m   1029\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1030\u001b[1;33m                 layer_outputs = layer_module(\n\u001b[0m\u001b[0;32m   1031\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1032\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[0;32m    663\u001b[0m             \u001b[0mself_attn_past_key_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcross_attn_past_key_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    664\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 665\u001b[1;33m         self_attention_outputs = self.layer[0](\n\u001b[0m\u001b[0;32m    666\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, output_attentions)\u001b[0m\n\u001b[0;32m    570\u001b[0m     ):\n\u001b[0;32m    571\u001b[0m         \u001b[0mnormed_hidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         attention_output = self.SelfAttention(\n\u001b[0m\u001b[0;32m    573\u001b[0m             \u001b[0mnormed_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m             \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions)\u001b[0m\n\u001b[0;32m    519\u001b[0m                     \u001b[0mposition_bias\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m                 \u001b[0mposition_bias\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_bias\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreal_seq_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;31m# if key and values are already calculated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py\u001b[0m in \u001b[0;36mcompute_bias\u001b[1;34m(self, query_length, key_length)\u001b[0m\n\u001b[0;32m    427\u001b[0m         )[None, :]\n\u001b[0;32m    428\u001b[0m         \u001b[0mrelative_position\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmemory_position\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mcontext_position\u001b[0m  \u001b[1;31m# shape (query_length, key_length)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m         relative_position_bucket = self._relative_position_bucket(\n\u001b[0m\u001b[0;32m    430\u001b[0m             \u001b[0mrelative_position\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# shape (query_length, key_length)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[0mbidirectional\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_decoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py\u001b[0m in \u001b[0;36m_relative_position_bucket\u001b[1;34m(relative_position, bidirectional, num_buckets, max_distance)\u001b[0m\n\u001b[0;32m    398\u001b[0m             \u001b[0mrelative_position\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrelative_position\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m             \u001b[0mrelative_position\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrelative_position\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrelative_position\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    401\u001b[0m         \u001b[1;31m# now relative_position is in the range [0, inf)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if(args.valid_begin==1):\n",
    "    my_test(train_dataloader,model_w,-1) #before train\n",
    "    my_test(train_dataloader,model_v,-1)  \n",
    "for epoch in range(args.epochs):\n",
    "\n",
    "    lr_w = scheduler_w.get_lr()[0]\n",
    "    lr_v = scheduler_v.get_lr()[0]\n",
    "\n",
    "    logging.info(f\"\\n\\n  ----------------epoch:{epoch},\\t\\tlr_w:{lr_w},\\t\\tlr_v:{lr_v}----------------\")\n",
    "\n",
    "    w_train_loss,v_train_loss =  my_train(epoch, train_dataloader, model_w, model_v,  architect, A, w_optimizer, v_optimizer, lr_w,lr_v)\n",
    "    \n",
    "    scheduler_w.step()\n",
    "    scheduler_v.step()\n",
    "\n",
    "    writer.add_scalar(\"MT/model_w_in_main/w_trainloss\", w_train_loss, global_step=epoch)\n",
    "    writer.add_scalar(\"MT/model_v_in_main/v_trainloss\", v_train_loss, global_step=epoch)\n",
    "\n",
    "    logging.info(f\"w_train_loss:{w_train_loss},v_train_loss:{v_train_loss}\")\n",
    "\n",
    "    \n",
    "    my_test(train_dataloader,model_w,epoch) \n",
    "    my_test(train_dataloader,model_v,epoch)  \n",
    "\n",
    "    torch.save(model_v,'./model/'+now+'model_v.pt')\n",
    "    torch.save(model_v,'./model/'+now+'model_w.pt')\n",
    "     \n",
    "   \n",
    "   \n",
    "        \n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "65768f95ed3f1ad80799466926a66640b39a99ef5d94bbece814e59aa067606e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('python38': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
