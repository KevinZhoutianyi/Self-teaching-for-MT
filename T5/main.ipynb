{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd() \n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from T5 import *\n",
    "from datasets import load_dataset,load_metric\n",
    "from transformers import T5Tokenizer\n",
    "import torch_optimizer as optim\n",
    "from transformers.optimization import Adafactor, AdafactorSchedule\n",
    "from MT_hyperparams import *\n",
    "import torch.backends.cudnn as cudnn\n",
    "from utils import *\n",
    "from attention_params import *\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, SubsetRandomSampler\n",
    "from torch.autograd import Variable\n",
    "from losses import *\n",
    "from architect import *\n",
    "import logging\n",
    "import sys\n",
    "import transformers\n",
    "import time\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(\"main\")\n",
    "\n",
    "\n",
    "parser.add_argument('--valid_num_points', type=int,             default = 100, help='validation data number')\n",
    "parser.add_argument('--train_num_points', type=int,             default = 1000, help='train data number')\n",
    "\n",
    "parser.add_argument('--batch_size', type=int,                   default=16,     help='Batch size')\n",
    "parser.add_argument('--train_w_num_points', type=int,           default=4,      help='train_w_num_points for each batch')\n",
    "parser.add_argument('--train_v_synthetic_num_points', type=int, default=4,      help='train_v_synthetic_num_points for each batch')\n",
    "parser.add_argument('--train_v_num_points', type=int,           default=4,      help='train_v_num_points for each batch')\n",
    "parser.add_argument('--train_A_num_points', type=int,           default=4,      help='train_A_num_points decay for each batch')\n",
    "\n",
    "\n",
    "parser.add_argument('--gpu', type=int,                          default=0,      help='gpu device id')\n",
    "parser.add_argument('--model_name', type=str,                   default='t5-small',      help='model_name')\n",
    "parser.add_argument('--exp_name', type=str,                     default='test',      help='experiment name')\n",
    "parser.add_argument('--rep_num', type=int,                      default=25,      help='report times for 1 epoch')\n",
    "parser.add_argument('--test_num', type=int,                      default=4,      help='test times for 1 epoch')\n",
    "\n",
    "parser.add_argument('--epochs', type=int,                       default=50,     help='num of training epochs')\n",
    "parser.add_argument('--pre_epochs', type=int,                   default=0,      help='train model W for x epoch first')\n",
    "parser.add_argument('--grad_clip', type=float,                  default=1,      help='gradient clipping')\n",
    "parser.add_argument('--grad_acc_count', type=float,             default=1,      help='gradient accumulate steps')\n",
    "\n",
    "parser.add_argument('--w_lr', type=float,                       default=6e-5,   help='learning rate for w')\n",
    "parser.add_argument('--v_lr', type=float,                       default=6e-5,   help='learning rate for v')\n",
    "parser.add_argument('--A_lr', type=float,                       default=1e-4,   help='learning rate for A')\n",
    "parser.add_argument('--learning_rate_min', type=float,          default=1e-8,   help='learning_rate_min')\n",
    "parser.add_argument('--decay', type=float,                      default=1e-3,   help='weight decay')\n",
    "parser.add_argument('--momentum', type=float,                   default=0.7,    help='momentum')\n",
    "parser.add_argument('--smoothing', type=float,                   default=0.1,    help='labelsmoothing')\n",
    "\n",
    "\n",
    "parser.add_argument('--traindata_loss_ratio', type=float,       default=0.9,    help='human translated data ratio')\n",
    "parser.add_argument('--syndata_loss_ratio', type=float,         default=0.1,    help='augmented dataset ratio')\n",
    "\n",
    "parser.add_argument('--valid_begin', type=int,                  default=1,      help='whether valid before train')\n",
    "parser.add_argument('--train_A', type=int,                      default=1 ,     help='whether train A')\n",
    "\n",
    "\n",
    "\n",
    "args = parser.parse_args(args=[])#(args=['--batch_size', '8',  '--no_cuda'])#used in ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33monlydrinkwater\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.14 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>g:\\GitCode\\Self-teaching-for-machine-translation\\T5\\wandb\\run-20220415_201536-23ewx44x</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/onlydrinkwater/smallT5/runs/23ewx44x\" target=\"_blank\">test</a></strong> to <a href=\"https://wandb.ai/onlydrinkwater/smallT5\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/onlydrinkwater/smallT5/runs/23ewx44x?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x28d1dd191f0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://wandb.ai/ check the running status online\n",
    "import wandb\n",
    "os.environ['WANDB_API_KEY']='a166474b1b7ad33a0549adaaec19a2f6d3f91d87'\n",
    "os.environ['WANDB_NAME']=args.exp_name\n",
    "wandb.init(project=\"smallT5\",config=args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/15 08:15:45 PM |\t  Reusing dataset wmt16 (C:\\Users\\kevin\\.cache\\huggingface\\datasets\\wmt16\\de-en\\1.0.0\\0d9fb3e814712c785176ad8cdb9f465fbe6479000ee6546725db30ad8a8b5f8a)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 12.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/15 08:15:45 PM |\t  Namespace(A_lr=0.0001, batch_size=16, decay=0.001, epochs=50, exp_name='test', gpu=0, grad_acc_count=64, grad_clip=1, learning_rate_min=1e-08, model_name='t5-small', momentum=0.7, pre_epochs=0, rep_num=25, smoothing=0.1, syndata_loss_ratio=0.1, test_num=4, train_A=1, train_A_num_points=4, train_num_points=1000, train_v_num_points=4, train_v_synthetic_num_points=4, train_w_num_points=4, traindata_loss_ratio=0.9, v_lr=6e-05, valid_begin=1, valid_num_points=100, w_lr=6e-05)\n",
      "04/15 08:15:45 PM |\t  DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 4548885\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 2169\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 2999\n",
      "    })\n",
      "})\n",
      "04/15 08:15:45 PM |\t  {'translation': {'de': 'Ich bitte Sie, sich zu einer Schweigeminute zu erheben.', 'en': \"Please rise, then, for this minute' s silence.\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#logging file\n",
    "now = time.strftime(\"%Y-%m-%d-%H_%M_%S\",time.localtime(time.time())) \n",
    "\n",
    "log_format = '%(asctime)s |\\t  %(message)s'\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO,\n",
    "    format=log_format, datefmt='%m/%d %I:%M:%S %p')\n",
    "fh = logging.FileHandler(os.path.join(\"./log/\", now+'.txt'),'w',encoding = \"UTF-8\")\n",
    "fh.setFormatter(logging.Formatter(log_format))\n",
    "logging.getLogger().addHandler(fh)\n",
    "dataset = load_dataset('wmt16','de-en')\n",
    "\n",
    "logging.info(args)\n",
    "logging.info(dataset)\n",
    "logging.info(dataset['train'][5])\n",
    "\n",
    "writer = SummaryWriter('tensorboard')\n",
    "\n",
    "# Setting the seeds\n",
    "np.random.seed(seed_)\n",
    "torch.cuda.set_device(args.gpu)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cudnn.benchmark = True\n",
    "torch.manual_seed(seed_)\n",
    "cudnn.enabled=True\n",
    "torch.cuda.manual_seed(seed_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/15 08:15:47 PM |\t  modelsize:60.506624MB\n"
     ]
    }
   ],
   "source": [
    "modelname = args.model_name\n",
    "pretrained  =  T5ForConditionalGeneration.from_pretrained(modelname)\n",
    "logging.info(f'modelsize:{count_parameters_in_MB(pretrained)}MB')\n",
    "torch.save(pretrained,modelname+'.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/15 08:15:49 PM |\t  Loading cached shuffled indices for dataset at C:\\Users\\kevin\\.cache\\huggingface\\datasets\\wmt16\\de-en\\1.0.0\\0d9fb3e814712c785176ad8cdb9f465fbe6479000ee6546725db30ad8a8b5f8a\\cache-4574fe47268cd3fd.arrow\n",
      "04/15 08:15:49 PM |\t  Loading cached shuffled indices for dataset at C:\\Users\\kevin\\.cache\\huggingface\\datasets\\wmt16\\de-en\\1.0.0\\0d9fb3e814712c785176ad8cdb9f465fbe6479000ee6546725db30ad8a8b5f8a\\cache-bf1487bfb5cd2cad.arrow\n",
      "04/15 08:15:49 PM |\t  Loading cached shuffled indices for dataset at C:\\Users\\kevin\\.cache\\huggingface\\datasets\\wmt16\\de-en\\1.0.0\\0d9fb3e814712c785176ad8cdb9f465fbe6479000ee6546725db30ad8a8b5f8a\\cache-73316b6a255c34bc.arrow\n",
      "04/15 08:18:33 PM |\t  train len: 992\n",
      "04/15 08:18:33 PM |\t  train_w_num_points_len: 248\n",
      "04/15 08:18:33 PM |\t  train_v_synthetic_num_points_len: 248\n",
      "04/15 08:18:33 PM |\t  train_v_num_points_len: 248\n",
      "04/15 08:18:33 PM |\t  train_A_num_points_len: 248\n",
      "04/15 08:18:33 PM |\t  valid len: 100\n",
      "04/15 08:18:33 PM |\t  test len: 2999\n",
      "04/15 08:18:33 PM |\t  {'de': 'Nur dann, wenn wir unsere Normen selber durchsetzen können, werden wir Märkte von morgen erobern können.', 'en': 'translate English to German: Only if we can develop our own standards will we be able to conquer the markets of the future.'}\n",
      "04/15 08:18:33 PM |\t  {'de': 'Zweifellos handelt es sich hier um zwei sehr wichtige Berichte.', 'en': 'translate English to German: There is no doubt that these are two very important reports.'}\n",
      "04/15 08:18:33 PM |\t  {'de': '\"Wir möchten die Familien über die Jahre kennenlernen und begleiten\".', 'en': 'translate English to German: \"We want to get to know the families and support them over the years.\"'}\n"
     ]
    }
   ],
   "source": [
    "# preprocess the data, make a dataloader\n",
    "import random\n",
    "tokenizer = T5Tokenizer.from_pretrained(modelname)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss( reduction='none')#teacher shouldn't have label smoothing, especially when student got same size.\n",
    "criterion_v = torch.nn.CrossEntropyLoss( reduction='none',label_smoothing=args.smoothing) #without LS, V may be too confident to that syn data, and LS do well for real data also.\n",
    "dataset = dataset.shuffle(seed=seed_)\n",
    "train = dataset['train']['translation'][:args.train_num_points]\n",
    "valid = dataset['train']['translation'][args.train_num_points:args.train_num_points+args.valid_num_points]#TODO:change dataset['validation']['translation'][:args.valid_num_points]\n",
    "test = dataset['test']['translation']#[L_t+L_v:L_t+L_v+L_test]\n",
    "def preprocess(dat):\n",
    "    for t in dat:\n",
    "        t['en'] = \"translate English to German: \" + t['en']  #needed for T5\n",
    "preprocess(train)\n",
    "preprocess(valid)\n",
    "preprocess(test)\n",
    "#TODO: Syn_input should be monolingual data, should try en-fo's en. cuz wmt may align\n",
    "num_batch = args.train_num_points//args.batch_size\n",
    "train = train[:args.batch_size*num_batch]\n",
    "logging.info(\"train len: %d\",len(train))\n",
    "\n",
    "'''\n",
    "each mini batch consist of : \n",
    "1. data to train W\n",
    "2. monolingual data to generate parallel data\n",
    "3. data to train V\n",
    "4. data to train A\n",
    "'''\n",
    "\n",
    "\n",
    "train_w_num_points_len = num_batch * args.train_w_num_points\n",
    "train_v_synthetic_num_points_len = num_batch * args.train_v_synthetic_num_points\n",
    "train_v_num_points_len = num_batch * args.train_v_num_points\n",
    "train_A_num_points_len = num_batch * args.train_A_num_points\n",
    "logging.info(\"train_w_num_points_len: %d\",train_w_num_points_len)\n",
    "logging.info(\"train_v_synthetic_num_points_len: %d\",train_v_synthetic_num_points_len)\n",
    "logging.info(\"train_v_num_points_len: %d\",train_v_num_points_len)\n",
    "logging.info(\"train_A_num_points_len: %d\",train_A_num_points_len)\n",
    "\n",
    "attn_idx_list = torch.arange(train_w_num_points_len).cuda()\n",
    "logging.info(\"valid len: %d\",len(valid))\n",
    "logging.info(\"test len: %d\" ,len(test))\n",
    "logging.info(train[2])\n",
    "logging.info(valid[2])\n",
    "logging.info(test[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get train data start\n",
      "get train data end\n",
      "04/15 08:18:33 PM |\t  train data get\n",
      "04/15 08:18:33 PM |\t  train data loader get\n",
      "04/15 08:18:33 PM |\t  valid data loader get\n",
      "04/15 08:18:34 PM |\t  test data loader get\n"
     ]
    }
   ],
   "source": [
    "target_language  = 'de'\n",
    "train_data = get_train_Dataset(train, tokenizer)# Create the DataLoader for our training set.\n",
    "logging.info('train data get')\n",
    "train_dataloader = DataLoader(train_data, sampler= SequentialSampler(train_data), \n",
    "                        batch_size=args.batch_size, pin_memory=True, num_workers=2)\n",
    "logging.info('train data loader get')\n",
    "valid_data = get_aux_dataset(valid, tokenizer)# Create the DataLoader for our training set.\n",
    "valid_dataloader = DataLoader(valid_data, sampler=RandomSampler(valid_data), \n",
    "                        batch_size=args.batch_size, pin_memory=True, num_workers=2)\n",
    "logging.info('valid data loader get')\n",
    "test_data = get_aux_dataset(test, tokenizer)# Create the DataLoader for our training set.\n",
    "test_dataloader = DataLoader(test_data, sampler=SequentialSampler(test_data),\n",
    "                        batch_size=args.batch_size, pin_memory=True, num_workers=2)#, sampler=RandomSampler(test_data)\n",
    "logging.info('test data loader get')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "A = attention_params(train_w_num_points_len)#half of train regarded as u\n",
    "A = A.cuda()\n",
    "\n",
    "\n",
    "\n",
    "# TODO: model loaded from saved model\n",
    "model_w = T5(criterion=criterion, tokenizer= tokenizer, args = args, name = 'model_w_in_main')\n",
    "model_w = model_w.cuda()\n",
    "w_optimizer = Adafactor(model_w.parameters(), lr = args.w_lr ,scale_parameter=False, relative_step=False , warmup_init=False,clip_threshold=1,beta1=0)\n",
    "scheduler_w  = torch.optim.lr_scheduler.StepLR(w_optimizer,step_size=10, gamma=0.9)\n",
    "\n",
    "\n",
    "\n",
    "model_v = T5(criterion=criterion_v, tokenizer= tokenizer, args = args, name = 'model_v_in_main')\n",
    "model_v = model_v.cuda()\n",
    "v_optimizer =Adafactor(model_v.parameters(), lr = args.v_lr ,scale_parameter=False, relative_step=False, warmup_init=False, clip_threshold=1,beta1=0)\n",
    "scheduler_v  = torch.optim.lr_scheduler.StepLR(v_optimizer,step_size=10, gamma=0.9)\n",
    "\n",
    "\n",
    "\n",
    "architect = Architect(model_w, model_v,  A, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def my_test(_dataloader,model,epoch):\n",
    "    # logging.info(f\"GPU mem before test:{getGPUMem(device)}%\")\n",
    "    acc = 0\n",
    "    counter = 0\n",
    "    model.eval()\n",
    "    metric_sacrebleu =  load_metric('sacrebleu')\n",
    "    metric_bleu =  load_metric('bleu')\n",
    "\n",
    "    # for step, batch in enumerate(tqdm(_dataloader,desc =\"test for epoch\"+str(epoch))):\n",
    "    for step, batch in enumerate(_dataloader):\n",
    "        \n",
    "        test_dataloaderx = Variable(batch[0], requires_grad=False).to(device, non_blocking=False)\n",
    "        test_dataloaderx_attn = Variable(batch[1], requires_grad=False).to(device, non_blocking=False)\n",
    "        test_dataloadery = Variable(batch[2], requires_grad=False).to(device, non_blocking=False)\n",
    "        test_dataloadery_attn = Variable(batch[3], requires_grad=False).to(device, non_blocking=False)\n",
    "        ls = my_loss(test_dataloaderx,test_dataloaderx_attn,test_dataloadery,test_dataloadery_attn,model)\n",
    "        acc+= ls.item()\n",
    "        counter+= 1\n",
    "        pre = model.generate(test_dataloaderx)\n",
    "        x_decoded = tokenizer.batch_decode(test_dataloaderx,skip_special_tokens=True)\n",
    "        pred_decoded = tokenizer.batch_decode(pre,skip_special_tokens=True)\n",
    "        label_decoded =  tokenizer.batch_decode(test_dataloadery,skip_special_tokens=True)\n",
    "        \n",
    "        pred_str = [x  for x in pred_decoded]\n",
    "        label_str = [[x] for x in label_decoded]\n",
    "        pred_list = [x.split()  for x in pred_decoded]\n",
    "        label_list = [[x.split()] for x in label_decoded]\n",
    "        metric_sacrebleu.add_batch(predictions=pred_str, references=label_str)\n",
    "        metric_bleu.add_batch(predictions=pred_list, references=label_list)\n",
    "        if  step%100==0:\n",
    "            logging.info(f'x_decoded[:2]:{x_decoded[:2]}')\n",
    "            logging.info(f'pred_decoded[:2]:{pred_decoded[:2]}')\n",
    "            logging.info(f'label_decoded[:2]:{label_decoded[:2]}')\n",
    "            \n",
    "            \n",
    "    logging.info('computing score...') \n",
    "    sacrebleu_score = metric_sacrebleu.compute()\n",
    "    bleu_score = metric_bleu.compute()\n",
    "    logging.info('%s sacreBLEU : %f',model.name,sacrebleu_score['score'])#TODO:bleu may be wrong cuz max length\n",
    "    logging.info('%s BLEU : %f',model.name,bleu_score['bleu'])\n",
    "    logging.info('%s test loss : %f',model.name,acc/(counter))\n",
    "    writer.add_scalar(model.name+\"/test_loss\", acc/counter, global_step=epoch)\n",
    "    writer.add_scalar(model.name+\"/sacreBLEU\",sacrebleu_score['score'], global_step=epoch)\n",
    "    writer.add_scalar(model.name+\"/BLEU\",bleu_score['bleu'], global_step=epoch)\n",
    "    \n",
    "    wandb.log({'sacreBLEU'+model.name: sacrebleu_score['score']})\n",
    "    \n",
    "    wandb.log({'test_loss'+model.name: acc/counter})\n",
    "    del test_dataloaderx,acc,counter,test_dataloaderx_attn,sacrebleu_score,bleu_score,test_dataloadery,test_dataloadery_attn,ls,pre,x_decoded,pred_decoded,label_decoded,pred_str,label_str,pred_list,label_list\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    model.train()\n",
    "    \n",
    "    \n",
    "    # logging.info(f\"GPU mem after test:{getGPUMem(device)}%\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_train(epoch, _dataloader, w_model, v_model, architect, A, w_optimizer, v_optimizer, lr_w, lr_v, ):\n",
    "    # print(torch.cuda.memory_allocated(device=device))\n",
    "       \n",
    "    objs_w = AvgrageMeter()\n",
    "    objs_v = AvgrageMeter()\n",
    "    v_trainloss_acc = 0\n",
    "    w_trainloss_acc = 0\n",
    "    wsize = args.train_w_num_points #now  train_x is [num of batch, datasize], so its seperate batch for the code below\n",
    "    synsize = args.train_v_synthetic_num_points\n",
    "    vsize = args.train_v_num_points \n",
    "    vtrainsize = vsize+synsize\n",
    "    vtrainsize_total = train_v_num_points_len+train_v_synthetic_num_points_len\n",
    "    Asize = args.train_A_num_points \n",
    "    grad_acc_count = args.grad_acc_count\n",
    "    loader_len = len(_dataloader)\n",
    "    split_size=[wsize,synsize,vsize,Asize]\n",
    "    logging.info(f\"split size:{split_size}\")\n",
    "    for step, batch in enumerate(_dataloader) :\n",
    "        # logging.info(f\"GPU mem :{getGPUMem(device)}%\")\n",
    "        train_x = Variable(batch[0], requires_grad=False).to(device, non_blocking=False)\n",
    "        train_x_attn = Variable(batch[1], requires_grad=False).to(device, non_blocking=False)\n",
    "        train_y = Variable(batch[2], requires_grad=False).to(device, non_blocking=False)\n",
    "        train_y_attn = Variable(batch[3], requires_grad=False).to(device, non_blocking=False) \n",
    "        (input_w,input_syn,input_v,input_A_v) = torch.split(train_x,split_size)\n",
    "        (input_w_attn,input_syn_attn,input_v_attn,input_A_v_attn) = torch.split(train_x_attn,split_size)\n",
    "        (output_w,_,output_v,output_A_v) = torch.split(train_y,split_size)\n",
    "        (output_w_attn,_,output_v_attn,output_A_v_attn) = torch.split(train_y_attn,split_size)\n",
    "        attn_idx = attn_idx_list[wsize*step:(wsize*step+wsize)]\n",
    "       \n",
    "\n",
    "        if (epoch <= args.epochs) and (args.train_A == 1) and epoch >= args.pre_epochs:\n",
    "            \n",
    "            for p in v_model.parameters():\n",
    "                p.requires_grad = True\n",
    "            for p in w_model.parameters():\n",
    "                p.requires_grad = True\n",
    "            architect.step(input_w,  output_w,input_w_attn, output_w_attn, w_optimizer, input_syn, input_syn_attn,input_A_v, input_A_v_attn, output_A_v, \n",
    "                output_A_v_attn, v_optimizer, attn_idx, lr_w, lr_v)\n",
    "            for p in v_model.parameters():\n",
    "                p.requires_grad = False\n",
    "            for p in w_model.parameters():\n",
    "                p.requires_grad = False\n",
    "        \n",
    "        if  epoch <= args.epochs:\n",
    "            for p in w_model.parameters():\n",
    "                p.requires_grad = True\n",
    "            loss_w = CTG_loss(input_w, input_w_attn, output_w, output_w_attn, attn_idx, A, w_model)\n",
    "            w_trainloss_acc+=loss_w.item()\n",
    "            loss_w.backward()\n",
    "            objs_w.update(loss_w.item(), wsize)\n",
    "            if ((step + 1) % grad_acc_count == 0) or (step + 1 == loader_len): \n",
    "                # nn.utils.clip_grad_norm(w_model.parameters(), args.grad_clip)\n",
    "                w_optimizer.step()\n",
    "                w_optimizer.zero_grad()\n",
    "            for p in w_model.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "        if epoch >= args.pre_epochs and epoch <= args.epochs:\n",
    "            \n",
    "            for p in v_model.parameters():\n",
    "                p.requires_grad = True\n",
    "            loss_aug = calc_loss_aug(input_syn, input_syn_attn, w_model, v_model)\n",
    "            loss = my_loss2(input_v,input_v_attn,output_v,output_v_attn,model_v)\n",
    "            v_loss =  (args.traindata_loss_ratio*loss+loss_aug*args.syndata_loss_ratio)/num_batch\n",
    "            v_trainloss_acc+=v_loss.item()\n",
    "            v_loss.backward()\n",
    "            objs_v.update(v_loss.item(), vtrainsize)\n",
    "            if ((step + 1) % grad_acc_count == 0) or (step + 1 == loader_len): \n",
    "                # nn.utils.clip_grad_norm(v_model.parameters(), args.grad_clip)\n",
    "                v_optimizer.step()  \n",
    "                v_optimizer.zero_grad() \n",
    "            for p in v_model.parameters():\n",
    "                p.requires_grad = False\n",
    "        \n",
    "\n",
    "        progress = 100*(step)/(loader_len-1)\n",
    "        rep_fre = (loader_len//args.rep_num)\n",
    "        test_fre = (loader_len//args.test_num)\n",
    "\n",
    "        if((step)%test_fre == 0 and step!=0):\n",
    "            my_test(valid_dataloader,model_w,epoch)\n",
    "            my_test(valid_dataloader,model_v,epoch)\n",
    "        \n",
    "        if((step)%rep_fre == 0 or (step)==(loader_len-1)):\n",
    "            logging.info(f\"{progress:5.3}% \\t w_loss_avg:{objs_w.avg*train_w_num_points_len:^.7f}\\t v_loss_avg:{objs_v.avg*vtrainsize_total:^.7f}\")\n",
    "            wandb.log({'train_loss_W_recent':objs_w.avg*train_w_num_points_len})\n",
    "            wandb.log({'train_loss_V_recent':objs_v.avg*vtrainsize_total})\n",
    "            \n",
    "            objs_v.reset()\n",
    "            objs_w.reset()\n",
    "  \n",
    "    logging.info(str((\"Attention Weights A : \", A.alpha)))\n",
    "    \n",
    "    return w_trainloss_acc,v_trainloss_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/15 08:18:47 PM |\t  x_decoded[:2]:['translate English to German: The worldwide Iguassu Falls are only a 20-minute drive away.', 'translate English to German: Soak up the central Madrid atmosphere from the sublime roof terrace both day and night; the Atico Stella apartment really knows how to steal the show in luxury vacation homes.']\n",
      "04/15 08:18:47 PM |\t  pred_decoded[:2]:['Die weltweiten Iguassu Falls sind nur 20 Fahrminuten entfernt.', 'Genießen Sie die zentrale Atmosphäre Madrids von der erhabenen Dachterrasse Tag und Nacht; das Atico Stella Apartment weiß wirklich, wie man die Show in luxuriösen Ferienhäusern stehlen kann.']\n",
      "04/15 08:18:47 PM |\t  label_decoded[:2]:['Die weltberühmten Iguaçu-Wasserfälle befinden sich nur 20 Fahrminuten entfernt.', 'Genießen Sie die Atmosphäre auf der schönen Dachterrasse bei Tag und bei Nacht. Das Atico Stella Apartment ist perfekt, um einen tollen Aufenthalt in Madrid zu verleben.']\n",
      "04/15 08:19:08 PM |\t  computing score...\n",
      "04/15 08:19:09 PM |\t  model_w_in_main sacreBLEU : 21.649276\n",
      "04/15 08:19:09 PM |\t  model_w_in_main BLEU : 0.174584\n",
      "04/15 08:19:09 PM |\t  model_w_in_main test loss : 1.569965\n",
      "04/15 08:19:09 PM |\t  \n",
      "\n",
      "  ----------------epoch:0,\t\tlr_w:6e-05,\t\tlr_v:6e-05----------------\n",
      "04/15 08:19:09 PM |\t  split size:[4, 4, 4, 4]\n",
      "04/15 08:19:16 PM |\t    0.0% \t w_loss_avg:1.6995889\t v_loss_avg:11.9800782\n",
      "04/15 08:19:26 PM |\t   3.28% \t w_loss_avg:1.8604957\t v_loss_avg:10.1113586\n",
      "04/15 08:19:34 PM |\t   6.56% \t w_loss_avg:2.3444059\t v_loss_avg:18.5725211\n",
      "04/15 08:19:43 PM |\t   9.84% \t w_loss_avg:2.1135774\t v_loss_avg:17.9114426\n",
      "04/15 08:19:51 PM |\t   13.1% \t w_loss_avg:1.4900929\t v_loss_avg:10.1649769\n",
      "04/15 08:19:59 PM |\t   16.4% \t w_loss_avg:1.3309950\t v_loss_avg:17.9069471\n",
      "04/15 08:20:08 PM |\t   19.7% \t w_loss_avg:1.1815690\t v_loss_avg:12.7955370\n",
      "04/15 08:20:22 PM |\t   23.0% \t w_loss_avg:2.6152832\t v_loss_avg:23.1529472\n",
      "04/15 08:20:35 PM |\t  x_decoded[:2]:['translate English to German: Cappato Report (A5-0270)/2001)', 'translate English to German: But I would like to feel that the Minister was giving me some kind of response as to whether in his view the Council thinks this is an important priority.']\n",
      "04/15 08:20:35 PM |\t  pred_decoded[:2]:['Bericht Cappato (A5-0270)/2001)', 'Ich möchte jedoch den Eindruck haben, daß mir der Herr Minister eine Art Antwort gegeben hat, ob er der Ansicht ist, daß dies eine wichtige Priorität ist.']\n",
      "04/15 08:20:35 PM |\t  label_decoded[:2]:['Bericht Cappato (A5-0270)/2001)', 'Ich kritisiere also keineswegs andere, statt vor der eigenen Tür zu kehren. Ich wäre jedoch dankbar, wenn der Minister mir erläutern könnte, ob er der Meinung ist, dass der Rat dies für eine wichtige Priorität hält.']\n",
      "04/15 08:20:56 PM |\t  computing score...\n",
      "04/15 08:20:56 PM |\t  model_w_in_main sacreBLEU : 21.649276\n",
      "04/15 08:20:56 PM |\t  model_w_in_main BLEU : 0.174584\n",
      "04/15 08:20:56 PM |\t  model_w_in_main test loss : 1.561806\n",
      "04/15 08:21:03 PM |\t  x_decoded[:2]:['translate English to German: All these concerns are brought together particularly in Amendment No 2 and the Commission is urged to respond positively and quickly.', 'translate English to German: This is the case with Iran.']\n",
      "04/15 08:21:03 PM |\t  pred_decoded[:2]:['All diese Bedenken werden insbesondere in nderungsantrag 2 zusammengefasst, und die Kommission wird aufgefordert, positiv und schnell zu reagieren.', 'Das ist bei dem Iran der Fall.']\n",
      "04/15 08:21:03 PM |\t  label_decoded[:2]:['Alle diese Aspekte werden insbesondere im nderungsantrag Nr. 2 angesprochen, und die Kommission wird aufgefordert, schnell und positiv zu reagieren.', 'Dies trifft im Falle des Iran auch zu.']\n",
      "04/15 08:21:24 PM |\t  computing score...\n",
      "04/15 08:21:24 PM |\t  model_v_in_main sacreBLEU : 21.649276\n",
      "04/15 08:21:24 PM |\t  model_v_in_main BLEU : 0.174584\n",
      "04/15 08:21:24 PM |\t  model_v_in_main test loss : 9.955382\n",
      "04/15 08:21:29 PM |\t   26.2% \t w_loss_avg:1.6300108\t v_loss_avg:15.3837058\n",
      "04/15 08:21:41 PM |\t   29.5% \t w_loss_avg:2.0478315\t v_loss_avg:11.3739632\n",
      "04/15 08:21:51 PM |\t   32.8% \t w_loss_avg:0.9011986\t v_loss_avg:17.6044326\n",
      "04/15 08:22:00 PM |\t   36.1% \t w_loss_avg:1.6264186\t v_loss_avg:14.4560440\n",
      "04/15 08:22:09 PM |\t   39.3% \t w_loss_avg:1.8561824\t v_loss_avg:13.4964413\n",
      "04/15 08:22:19 PM |\t   42.6% \t w_loss_avg:1.5070426\t v_loss_avg:11.1830344\n",
      "04/15 08:22:29 PM |\t   45.9% \t w_loss_avg:1.5665489\t v_loss_avg:13.0524044\n",
      "04/15 08:22:48 PM |\t  x_decoded[:2]:['translate English to German: That is why we are able to say today, wherever we happen to be sitting or standing here in this Chamber, that if there is such a thing as political justice, right here in this European Parliament too, then this political justice has become reality with the election of Nicole Fontaine as President of the European Parliament.', 'translate English to German: Cappato Report (A5-0270)/2001)']\n",
      "04/15 08:22:48 PM |\t  pred_decoded[:2]:['Deshalb können wir heute sagen, wo immer wir hier in diesem Saal sitzen oder stehen, dass, wenn es so etwas wie politische Gerechtigkeit gibt, auch hier in diesem Europäischen Parlament, diese politische Gerechtigkeit mit der Wahl von Nicole Fontaine zum Präsidenten des Europäischen Parlaments Wirklichkeit geworden ist.', 'Bericht Cappato (A5-0270)/2001)']\n",
      "04/15 08:22:48 PM |\t  label_decoded[:2]:['Deswegen können wir, wo immer wir hier im Haus stehen oder sitzen mögen, heute sagen: Wenn es politische Gerechtigkeit gibt, gerade auch hier in diesem Europäischen Parlament, dann ist diese politische Gerechtigkeit Wirklichkeit geworden mit der Wahl von Nicole Fontaine zur Präsidentin des Europäischen Parlaments!', 'Bericht Cappato (A5-0270)/2001)']\n",
      "04/15 08:23:09 PM |\t  computing score...\n",
      "04/15 08:23:09 PM |\t  model_w_in_main sacreBLEU : 21.649276\n",
      "04/15 08:23:09 PM |\t  model_w_in_main BLEU : 0.174584\n",
      "04/15 08:23:09 PM |\t  model_w_in_main test loss : 1.568481\n",
      "04/15 08:23:16 PM |\t  x_decoded[:2]:['translate English to German: We are not alone in highlighting these abuses: there have been loud protests from large parts of the Catholic Church, and both lay and Catholic voluntary associations and organisations.', 'translate English to German: Load the mini figure or the space vehicle.']\n",
      "04/15 08:23:16 PM |\t  pred_decoded[:2]:['Wir sind nicht allein, wenn wir diese Missstände hervorheben: es gab lautstarke Proteste in großen Teilen der katholischen Kirche, sowohl von Laien als auch von katholischen Freiwilligenverbänden und Organisationen.', 'Laden Sie die Minifigur oder das Raumfahrzeug.']\n",
      "04/15 08:23:16 PM |\t  label_decoded[:2]:['Es sind nicht nur wir, die diese Übergriffe herausstellen: Es gab starke Proteste von breiten Kreisen der Katholischen Kirche sowie von weltlichen und katholischen Verbänden und ehrenamtlichen Organisationen.', 'Laden sie entweder die Figur oder den Raumgleiter wie üblich.']\n",
      "04/15 08:23:38 PM |\t  computing score...\n",
      "04/15 08:23:38 PM |\t  model_v_in_main sacreBLEU : 21.649276\n",
      "04/15 08:23:38 PM |\t  model_v_in_main BLEU : 0.174584\n",
      "04/15 08:23:38 PM |\t  model_v_in_main test loss : 10.097752\n",
      "04/15 08:23:38 PM |\t   49.2% \t w_loss_avg:1.2648866\t v_loss_avg:13.6737573\n",
      "04/15 08:23:48 PM |\t   52.5% \t w_loss_avg:2.0008283\t v_loss_avg:10.2386400\n",
      "04/15 08:23:59 PM |\t   55.7% \t w_loss_avg:1.5687642\t v_loss_avg:11.4684850\n",
      "04/15 08:24:10 PM |\t   59.0% \t w_loss_avg:1.6732661\t v_loss_avg:9.3922407\n",
      "04/15 08:24:21 PM |\t   62.3% \t w_loss_avg:2.0487532\t v_loss_avg:11.9150214\n",
      "04/15 08:24:32 PM |\t   65.6% \t w_loss_avg:1.4739340\t v_loss_avg:13.4614792\n",
      "04/15 08:24:42 PM |\t   68.9% \t w_loss_avg:1.7017645\t v_loss_avg:12.9791451\n",
      "04/15 08:24:54 PM |\t   72.1% \t w_loss_avg:2.0684434\t v_loss_avg:14.3489377\n",
      "04/15 08:25:07 PM |\t  x_decoded[:2]:['translate English to German: This study was based on a particularly small sample of children who consumed sweeteners.', 'translate English to German: All rooms have made up separate beds, a sink, mirror, closet, desk and a chair.']\n",
      "04/15 08:25:07 PM |\t  pred_decoded[:2]:['Diese Studie basierte auf einer besonders kleinen Probe von Kindern, die Süßungsmittel verbrauchten.', 'Alle Zimmer sind mit separaten Betten, Waschbecken, Spiegel, Schrank, Schreibtisch und Stuhl ausgestattet.']\n",
      "04/15 08:25:07 PM |\t  label_decoded[:2]:['Die Studie stützte sich auf eine außerordentlich kleine Auswahl von Kindern, die Süßungsmittel verzehrten.', 'Aller Zimmer verfügen über separate Betten, ein Waschbecken, einen Spiegel, einen Wandschrank, einen Schreibtisch und einen Stuhl.']\n",
      "04/15 08:25:29 PM |\t  computing score...\n",
      "04/15 08:25:29 PM |\t  model_w_in_main sacreBLEU : 21.649276\n",
      "04/15 08:25:29 PM |\t  model_w_in_main BLEU : 0.174584\n",
      "04/15 08:25:29 PM |\t  model_w_in_main test loss : 1.598952\n",
      "04/15 08:25:36 PM |\t  x_decoded[:2]:['translate English to German: Take, for example, the frequently mentioned need for the new regulation of financial markets.', 'translate English to German: In practice the Canon PowerShot A620 is a pleasure to use.']\n",
      "04/15 08:25:36 PM |\t  pred_decoded[:2]:['Nehmen wir zum Beispiel die häufig erwähnte Notwendigkeit einer neuen Regulierung der Finanzmärkte.', 'In der Praxis ist die Canon PowerShot A620 ein Vergnügen.']\n",
      "04/15 08:25:36 PM |\t  label_decoded[:2]:['Nehmen wir alleine die oft beschworene Notwendigkeit der Neuregulierung der Finanzmärkte!', 'Die Benutzung der Canon PowerShot A620 hat uns in der Praxis rundherum gut gefallen.']\n",
      "04/15 08:25:57 PM |\t  computing score...\n",
      "04/15 08:25:58 PM |\t  model_v_in_main sacreBLEU : 21.649276\n",
      "04/15 08:25:58 PM |\t  model_v_in_main BLEU : 0.174584\n",
      "04/15 08:25:58 PM |\t  model_v_in_main test loss : 9.606490\n",
      "04/15 08:26:02 PM |\t   75.4% \t w_loss_avg:0.9930072\t v_loss_avg:12.3401725\n",
      "04/15 08:26:15 PM |\t   78.7% \t w_loss_avg:1.2963855\t v_loss_avg:12.5475569\n",
      "04/15 08:26:23 PM |\t   82.0% \t w_loss_avg:1.3173334\t v_loss_avg:11.6783407\n",
      "04/15 08:26:37 PM |\t   85.2% \t w_loss_avg:2.2475865\t v_loss_avg:18.5397994\n",
      "04/15 08:26:49 PM |\t   88.5% \t w_loss_avg:1.8123925\t v_loss_avg:13.9334757\n",
      "04/15 08:27:00 PM |\t   91.8% \t w_loss_avg:1.3396893\t v_loss_avg:13.5626086\n",
      "04/15 08:27:12 PM |\t   95.1% \t w_loss_avg:1.1297473\t v_loss_avg:15.1582944\n",
      "04/15 08:27:29 PM |\t  x_decoded[:2]:['translate English to German: I am also assuming that it will refrain from imposing any economic sanctions on Kosovo.', 'translate English to German: Let me reassure Mr Provan.']\n",
      "04/15 08:27:29 PM |\t  pred_decoded[:2]:['Ich gehe auch davon aus, daß es keine wirtschaftlichen Sanktionen gegen den Kosovo verhängen wird.', 'Lassen Sie mich Herrn Provan beruhigen.']\n",
      "04/15 08:27:29 PM |\t  label_decoded[:2]:['Des Weiteren gehe ich davon aus, dass sie keine Wirtschaftssanktionen gegen das Kosovo verhängen wird.', 'Ich kann Herrn Provan beruhigen.']\n",
      "04/15 08:27:50 PM |\t  computing score...\n",
      "04/15 08:27:51 PM |\t  model_w_in_main sacreBLEU : 21.649276\n",
      "04/15 08:27:51 PM |\t  model_w_in_main BLEU : 0.174584\n",
      "04/15 08:27:51 PM |\t  model_w_in_main test loss : 1.673287\n",
      "04/15 08:27:58 PM |\t  x_decoded[:2]:['translate English to German: An effective transport infrastructure could result in the distance being measured in time and not in kilometres, so that the people that work in urban areas could live in rural areas thus contributing to their economic development.', 'translate English to German: Only USD 3 billion a year is being spent globally in trying to halt the spread of AIDS.']\n",
      "04/15 08:27:58 PM |\t  pred_decoded[:2]:['Eine wirksame Verkehrsinfrastruktur könnte dazu führen, dass die Entfernung zeitlich und nicht in Kilometern gemessen wird, sodass die Menschen, die in städtischen Gebieten arbeiten, in ländlichen Gebieten leben können und damit zur wirtschaftlichen Entwicklung beitragen können.', 'Weltweit werden nur 3 Milliarden US-Dollar pro Jahr ausgegeben, um die Ausbreitung von AIDS zu stoppen.']\n",
      "04/15 08:27:58 PM |\t  label_decoded[:2]:['Mit einer effizienten Verkehrsinfrastruktur ließen sich Entfernungen in Zeit anstatt in Kilometern messen. Menschen, die in Stadtgebieten arbeiten, könnten so auf dem Land leben und zu seiner wirtschaftlichen Entwicklung beitragen.', 'Derzeit werden weltweit lediglich drei Milliarden US-Dollar pro Jahr für Bemühungen ausgegeben, die Ausbreitung von Aids zum Stillstand zu bringen.']\n",
      "04/15 08:28:20 PM |\t  computing score...\n",
      "04/15 08:28:20 PM |\t  model_v_in_main sacreBLEU : 21.649276\n",
      "04/15 08:28:20 PM |\t  model_v_in_main BLEU : 0.174584\n",
      "04/15 08:28:20 PM |\t  model_v_in_main test loss : 9.669197\n",
      "04/15 08:28:20 PM |\t   98.4% \t w_loss_avg:1.4983013\t v_loss_avg:19.6700288\n",
      "04/15 08:28:25 PM |\t  1e+02% \t w_loss_avg:1.9221631\t v_loss_avg:13.1616744\n",
      "04/15 08:28:25 PM |\t  ('Attention Weights A : ', Parameter containing:\n",
      "tensor([0.0043, 0.0043, 0.0047, 0.0040, 0.0037, 0.0038, 0.0042, 0.0038, 0.0046,\n",
      "        0.0040, 0.0043, 0.0039, 0.0050, 0.0043, 0.0039, 0.0046, 0.0050, 0.0044,\n",
      "        0.0051, 0.0050, 0.0039, 0.0044, 0.0044, 0.0044, 0.0047, 0.0045, 0.0050,\n",
      "        0.0049, 0.0042, 0.0047, 0.0042, 0.0045, 0.0037, 0.0043, 0.0037, 0.0043,\n",
      "        0.0046, 0.0037, 0.0051, 0.0049, 0.0037, 0.0037, 0.0038, 0.0044, 0.0037,\n",
      "        0.0045, 0.0040, 0.0039, 0.0045, 0.0045, 0.0038, 0.0038, 0.0046, 0.0038,\n",
      "        0.0039, 0.0038, 0.0044, 0.0039, 0.0037, 0.0036, 0.0040, 0.0038, 0.0040,\n",
      "        0.0047, 0.0047, 0.0038, 0.0046, 0.0047, 0.0047, 0.0040, 0.0038, 0.0038,\n",
      "        0.0047, 0.0039, 0.0047, 0.0038, 0.0039, 0.0044, 0.0042, 0.0041, 0.0047,\n",
      "        0.0051, 0.0052, 0.0046, 0.0049, 0.0048, 0.0050, 0.0039, 0.0052, 0.0046,\n",
      "        0.0052, 0.0045, 0.0039, 0.0041, 0.0048, 0.0051, 0.0038, 0.0052, 0.0038,\n",
      "        0.0049, 0.0051, 0.0043, 0.0052, 0.0040, 0.0049, 0.0040, 0.0047, 0.0052,\n",
      "        0.0038, 0.0049, 0.0040, 0.0038, 0.0049, 0.0038, 0.0038, 0.0038, 0.0050,\n",
      "        0.0041, 0.0053, 0.0047, 0.0042, 0.0039, 0.0049, 0.0051, 0.0046, 0.0049,\n",
      "        0.0050, 0.0052, 0.0050, 0.0038, 0.0050, 0.0048, 0.0046, 0.0050, 0.0049,\n",
      "        0.0049, 0.0040, 0.0051, 0.0052, 0.0050, 0.0048, 0.0036, 0.0048, 0.0050,\n",
      "        0.0051, 0.0051, 0.0048, 0.0051, 0.0036, 0.0035, 0.0035, 0.0048, 0.0050,\n",
      "        0.0039, 0.0051, 0.0047, 0.0053, 0.0052, 0.0053, 0.0045, 0.0050, 0.0036,\n",
      "        0.0049, 0.0049, 0.0036, 0.0049, 0.0050, 0.0038, 0.0052, 0.0040, 0.0051,\n",
      "        0.0038, 0.0035, 0.0049, 0.0035, 0.0035, 0.0035, 0.0049, 0.0035, 0.0036,\n",
      "        0.0052, 0.0049, 0.0045, 0.0050, 0.0051, 0.0037, 0.0052, 0.0038, 0.0050,\n",
      "        0.0037, 0.0051, 0.0036, 0.0046, 0.0051, 0.0052, 0.0038, 0.0037, 0.0054,\n",
      "        0.0053, 0.0053, 0.0052, 0.0051, 0.0037, 0.0038, 0.0054, 0.0052, 0.0052,\n",
      "        0.0042, 0.0052, 0.0036, 0.0036, 0.0051, 0.0046, 0.0042, 0.0042, 0.0053,\n",
      "        0.0039, 0.0039, 0.0039, 0.0039, 0.0056, 0.0042, 0.0056, 0.0056, 0.0057,\n",
      "        0.0042, 0.0042, 0.0042, 0.0056, 0.0044, 0.0055, 0.0045, 0.0043, 0.0043,\n",
      "        0.0057, 0.0057, 0.0057, 0.0044, 0.0052, 0.0057, 0.0052, 0.0045, 0.0057,\n",
      "        0.0057, 0.0054, 0.0047, 0.0054, 0.0054], device='cuda:0',\n",
      "       requires_grad=True))\n",
      "04/15 08:28:25 PM |\t  w_train_loss:1.6554068392142653,v_train_loss:14.020794063806534\n",
      "04/15 08:28:33 PM |\t  x_decoded[:2]:['translate English to German: Fleeing Paris which was in the throes of a cholera epidemic, the young writer, who had travelled by stagecoach, finally reaches the foothills of the Dents du Midi.', 'translate English to German: Hospital units have restricted or almost no access to the status of their booked requests.']\n",
      "04/15 08:28:33 PM |\t  pred_decoded[:2]:['Der junge Schriftsteller, der mit der Bühne reiste, erreicht schließlich die Vorgebirge des Dents du Midi.', 'Krankenhauseinheiten haben den Status ihrer gebuchten Anfragen eingeschränkt oder fast keinen Zugang.']\n",
      "04/15 08:28:33 PM |\t  label_decoded[:2]:['Der junge Schriftsteller ist auf der Flucht aus Paris, wo eine Choleraepidemie wütet, und landet nach einer Reise mit der Postkutsche am Fusse des Dents-du-Midi.', 'Ohne eine elektronische Auftragsverarbeitung fehlt die Datenbasis zur Qualitätssicherung und zur späteren Prozessoptimierung (z.B. Erkennen von Engpässen und deren Beseitigung).']\n",
      "04/15 08:28:54 PM |\t  computing score...\n",
      "04/15 08:28:54 PM |\t  model_w_in_main sacreBLEU : 21.544981\n",
      "04/15 08:28:54 PM |\t  model_w_in_main BLEU : 0.173394\n",
      "04/15 08:28:54 PM |\t  model_w_in_main test loss : 1.615868\n",
      "04/15 08:29:02 PM |\t  x_decoded[:2]:['translate English to German: If you are interested in a customised training session please consult us. We will be glad to submit you an offer.', 'translate English to German: With more then a third of the total population in Argentina it has the highest population of the country and the same goes for its dimensions.']\n",
      "04/15 08:29:02 PM |\t  pred_decoded[:2]:['Wenn Sie an einer kundenspezifischen Schulung interessiert sind, wenden Sie sich bitte an uns.', 'Mit mehr als einem Drittel der Gesamtbevölkerung in Argentinien hat es die höchste Bevölkerung des Landes und das Gleiche gilt für seine Dimensionen.']\n",
      "04/15 08:29:02 PM |\t  label_decoded[:2]:['Für diese erstellen wir Ihnen gerne ein Angebot nach Rücksprache.', 'Mit mehr als einem Drittel der Gesamtbevölkerung Argentiniens ist sie die bevölkerungsreichste Provinz des Landes sowie auch die flächenmäßig größte.']\n",
      "04/15 08:29:22 PM |\t  computing score...\n",
      "04/15 08:29:22 PM |\t  model_v_in_main sacreBLEU : 21.612228\n",
      "04/15 08:29:22 PM |\t  model_v_in_main BLEU : 0.174357\n",
      "04/15 08:29:22 PM |\t  model_v_in_main test loss : 10.184667\n",
      "04/15 08:29:22 PM |\t  \n",
      "\n",
      "  ----------------epoch:1,\t\tlr_w:6e-05,\t\tlr_v:6e-05----------------\n",
      "04/15 08:29:22 PM |\t  split size:[4, 4, 4, 4]\n",
      "04/15 08:29:29 PM |\t    0.0% \t w_loss_avg:1.5660044\t v_loss_avg:11.2711044\n",
      "04/15 08:29:39 PM |\t   3.28% \t w_loss_avg:1.7147597\t v_loss_avg:9.7147607\n",
      "04/15 08:29:47 PM |\t   6.56% \t w_loss_avg:2.1991463\t v_loss_avg:17.5578103\n",
      "04/15 08:29:55 PM |\t   9.84% \t w_loss_avg:2.0473625\t v_loss_avg:16.8315638\n",
      "04/15 08:30:04 PM |\t   13.1% \t w_loss_avg:1.4439755\t v_loss_avg:9.8602581\n",
      "04/15 08:30:13 PM |\t   16.4% \t w_loss_avg:1.2732432\t v_loss_avg:16.9988220\n",
      "04/15 08:30:21 PM |\t   19.7% \t w_loss_avg:1.1638356\t v_loss_avg:12.2891526\n",
      "04/15 08:30:35 PM |\t   23.0% \t w_loss_avg:2.6146977\t v_loss_avg:22.0075123\n",
      "04/15 08:30:47 PM |\t  x_decoded[:2]:[\"translate English to German: Save your helpers as much time as you can, they're busy people.\", 'translate English to German: Load the mini figure or the space vehicle.']\n",
      "04/15 08:30:47 PM |\t  pred_decoded[:2]:['Sparen Sie Ihre Helfer so viel Zeit wie möglich, sie sind beschäftigte Menschen.', 'Laden Sie die Minifigur oder das Raumfahrzeug.']\n",
      "04/15 08:30:47 PM |\t  label_decoded[:2]:['Sparen Sie soviel wie möglich Zeit der Helfer, diese sind meistens sehr beschäftigt.', 'Laden sie entweder die Figur oder den Raumgleiter wie üblich.']\n",
      "04/15 08:31:09 PM |\t  computing score...\n",
      "04/15 08:31:09 PM |\t  model_w_in_main sacreBLEU : 21.544981\n",
      "04/15 08:31:09 PM |\t  model_w_in_main BLEU : 0.173394\n",
      "04/15 08:31:09 PM |\t  model_w_in_main test loss : 1.633271\n",
      "04/15 08:31:17 PM |\t  x_decoded[:2]:['translate English to German: 9 And it came to pass that Alma did not know concerning them; but there were many a witnesses against them; yea, the people stood and testified of their iniquity in abundance.', 'translate English to German: When they left, we received a huge donation for which we are very grateful.']\n",
      "04/15 08:31:17 PM |\t  pred_decoded[:2]:['9 Und es begab sich: Alma wußte in Bezug auf sie nicht; aber es gab viele Zeugen gegen sie; ja, das Volk stand und bezeugte im Überfluss von seinem Übeltun.', 'Als sie verließen, haben wir eine riesige Spende erhalten, für die wir sehr dankbar sind.']\n",
      "04/15 08:31:17 PM |\t  label_decoded[:2]:['9 Und es begab sich: Alma wußte nichts in bezug auf sie; aber es gab viele Zeugen gegen sie; ja, das Volk stand auf und legte reichlich Zeugnis ab von ihrem Übeltun.', 'Als sie uns wieder verließen, erhielten wir eine riesige Spende, für die wir sehr dankbar sind!']\n",
      "04/15 08:31:38 PM |\t  computing score...\n",
      "04/15 08:31:38 PM |\t  model_v_in_main sacreBLEU : 21.597693\n",
      "04/15 08:31:38 PM |\t  model_v_in_main BLEU : 0.174297\n",
      "04/15 08:31:38 PM |\t  model_v_in_main test loss : 9.997454\n",
      "04/15 08:31:43 PM |\t   26.2% \t w_loss_avg:1.7709959\t v_loss_avg:15.0101238\n",
      "04/15 08:31:56 PM |\t   29.5% \t w_loss_avg:2.0028631\t v_loss_avg:11.4498884\n",
      "04/15 08:32:07 PM |\t   32.8% \t w_loss_avg:0.9514477\t v_loss_avg:17.5352965\n",
      "04/15 08:32:15 PM |\t   36.1% \t w_loss_avg:1.6137591\t v_loss_avg:14.1959796\n",
      "04/15 08:32:25 PM |\t   39.3% \t w_loss_avg:1.8839409\t v_loss_avg:13.4620723\n",
      "04/15 08:32:34 PM |\t   42.6% \t w_loss_avg:1.4136769\t v_loss_avg:11.3495069\n",
      "04/15 08:32:45 PM |\t   45.9% \t w_loss_avg:1.5709202\t v_loss_avg:13.1345653\n",
      "04/15 08:33:12 PM |\t  x_decoded[:2]:['translate English to German: And so, life for the elephants here in southern Thailand is much easier than in the logging camps of the north.', \"translate English to German: Save your helpers as much time as you can, they're busy people.\"]\n",
      "04/15 08:33:12 PM |\t  pred_decoded[:2]:['Und so ist das Leben für die Elefanten hier im Süden Thailands viel einfacher als in den Bergbaulagern im Norden.', 'Sparen Sie Ihre Helfer so viel Zeit wie möglich, sie sind beschäftigte Menschen.']\n",
      "04/15 08:33:12 PM |\t  label_decoded[:2]:['Haad Leela ist auch als Haad Seekantang bekannt und ist etwa 15 Gehminuten vom Stadtzentrum Haad Rin.', 'Sparen Sie soviel wie möglich Zeit der Helfer, diese sind meistens sehr beschäftigt.']\n",
      "04/15 08:33:32 PM |\t  computing score...\n",
      "04/15 08:33:32 PM |\t  model_w_in_main sacreBLEU : 21.545895\n",
      "04/15 08:33:32 PM |\t  model_w_in_main BLEU : 0.173403\n",
      "04/15 08:33:32 PM |\t  model_w_in_main test loss : 1.644408\n",
      "04/15 08:33:40 PM |\t  x_decoded[:2]:['translate English to German: So firstly, I should like to address Mrs de Palacio and secondly, Commissioner Schreyer.', 'translate English to German: The rapporteur stresses on a number of occasions in the report that the growing importance of the People’s Republic of China in world politics, together with its growing importance as a global economic superpower, bring greater international responsibilities.']\n",
      "04/15 08:33:40 PM |\t  pred_decoded[:2]:['Daher möchte ich erstens Frau de Palacio und zweitens Frau Kommissarin Schreyer ansprechen.', 'Der Berichterstatter betont in dem Bericht mehrfach, dass die wachsende Bedeutung der Volksrepublik China in der Weltpolitik sowie ihre wachsende Bedeutung als globale Wirtschaftssupermacht größere internationale Verantwortungen mit sich bringt.']\n",
      "04/15 08:33:40 PM |\t  label_decoded[:2]:['Zunächst wende ich mich also an Frau de Palacio und anschließend an Frau Schreyer.', 'Mehrfach hebt der Berichterstatter im Bericht hervor, dass die wachsende Bedeutung der Volksrepublik China in der Weltpolitik im Verein mit ihrer zunehmenden Bedeutung als globale wirtschaftliche Supermacht größere internationale Verantwortlichkeiten mit sich bringt.']\n",
      "04/15 08:34:02 PM |\t  computing score...\n",
      "04/15 08:34:02 PM |\t  model_v_in_main sacreBLEU : 21.597693\n",
      "04/15 08:34:02 PM |\t  model_v_in_main BLEU : 0.174297\n",
      "04/15 08:34:02 PM |\t  model_v_in_main test loss : 10.201458\n",
      "04/15 08:34:02 PM |\t   49.2% \t w_loss_avg:1.3045388\t v_loss_avg:13.7381184\n",
      "04/15 08:34:12 PM |\t   52.5% \t w_loss_avg:1.9770080\t v_loss_avg:10.2297537\n",
      "04/15 08:34:23 PM |\t   55.7% \t w_loss_avg:1.5979013\t v_loss_avg:11.4935132\n",
      "04/15 08:34:35 PM |\t   59.0% \t w_loss_avg:1.6537151\t v_loss_avg:9.4465223\n",
      "04/15 08:34:46 PM |\t   62.3% \t w_loss_avg:2.1578583\t v_loss_avg:11.8837668\n",
      "04/15 08:34:57 PM |\t   65.6% \t w_loss_avg:1.5124606\t v_loss_avg:13.4730946\n",
      "04/15 08:35:08 PM |\t   68.9% \t w_loss_avg:1.6892540\t v_loss_avg:12.9478771\n",
      "04/15 08:35:20 PM |\t   72.1% \t w_loss_avg:2.0791928\t v_loss_avg:14.4131884\n",
      "04/15 08:35:32 PM |\t  x_decoded[:2]:['translate English to German: He claimed communism appeared to be the only reliable antidote to militarist fascism and spoke out against the remilitarization of the West and the division of Germany.', 'translate English to German: With more then a third of the total population in Argentina it has the highest population of the country and the same goes for its dimensions.']\n",
      "04/15 08:35:32 PM |\t  pred_decoded[:2]:['Er behauptete, der Kommunismus sei das einzige verlässliche Antidot gegen den militaristischen Faschismus und sprach sich gegen die Remilitarisierung des Westens und die Teilung Deutschlands aus.', 'Mit mehr als einem Drittel der Gesamtbevölkerung in Argentinien hat es die höchste Bevölkerung des Landes und das Gleiche gilt für seine Dimensionen.']\n",
      "04/15 08:35:32 PM |\t  label_decoded[:2]:['Einen Tag später reiste er – während der Premiere von Das Leben des Galilei in New York – über Paris nach Zürich. Dort hielt er sich ein Jahr auf, da die Schweiz das einzige Land war, in das er noch einreisen durfte; die Einreise nach West- Deutschland wurde ihm untersagt.', 'Mit mehr als einem Drittel der Gesamtbevölkerung Argentiniens ist sie die bevölkerungsreichste Provinz des Landes sowie auch die flächenmäßig größte.']\n",
      "04/15 08:35:54 PM |\t  computing score...\n",
      "04/15 08:35:54 PM |\t  model_w_in_main sacreBLEU : 21.545895\n",
      "04/15 08:35:54 PM |\t  model_w_in_main BLEU : 0.173403\n",
      "04/15 08:35:54 PM |\t  model_w_in_main test loss : 1.550903\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_276856/2317287350.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"\\n\\n  ----------------epoch:{epoch},\\t\\tlr_w:{lr_w},\\t\\tlr_v:{lr_v}----------------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mw_train_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv_train_loss\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mmy_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_v\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0marchitect\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_optimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv_optimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr_w\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr_v\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mscheduler_w\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_276856/3980439228.py\u001b[0m in \u001b[0;36mmy_train\u001b[1;34m(epoch, _dataloader, w_model, v_model, architect, A, w_optimizer, v_optimizer, lr_w, lr_v)\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mtest_fre\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[0mmy_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_dataloader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_w\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m             \u001b[0mmy_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_dataloader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_v\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mrep_fre\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloader_len\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_276856/296739618.py\u001b[0m in \u001b[0;36mmy_test\u001b[1;34m(_dataloader, model, epoch)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mmetric_sacrebleu\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mload_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sacrebleu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mmetric_bleu\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mload_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bleu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m# for step, batch in enumerate(tqdm(_dataloader,desc =\"test for epoch\"+str(epoch))):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\datasets\\load.py\u001b[0m in \u001b[0;36mload_metric\u001b[1;34m(path, config_name, process_id, num_process, cache_dir, experiment_id, keep_in_memory, download_config, download_mode, revision, script_version, **metric_init_kwargs)\u001b[0m\n\u001b[0;32m   1336\u001b[0m         )\n\u001b[0;32m   1337\u001b[0m         \u001b[0mrevision\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscript_version\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1338\u001b[1;33m     metric_module = metric_module_factory(\n\u001b[0m\u001b[0;32m   1339\u001b[0m         \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdownload_config\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdownload_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdownload_mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1340\u001b[0m     ).module_path\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\datasets\\load.py\u001b[0m in \u001b[0;36mmetric_module_factory\u001b[1;34m(path, revision, download_config, download_mode, force_local_path, dynamic_modules_path, **download_kwargs)\u001b[0m\n\u001b[0;32m   1224\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mis_relative_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mforce_local_path\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1225\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1226\u001b[1;33m             return CanonicalMetricModuleFactory(\n\u001b[0m\u001b[0;32m   1227\u001b[0m                 \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1228\u001b[0m                 \u001b[0mrevision\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\datasets\\load.py\u001b[0m in \u001b[0;36mget_module\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    567\u001b[0m         \u001b[0mrevision\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrevision\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 569\u001b[1;33m             \u001b[0mlocal_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload_loading_script\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrevision\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    570\u001b[0m             \u001b[0mrevision\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrevision\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\datasets\\load.py\u001b[0m in \u001b[0;36mdownload_loading_script\u001b[1;34m(self, revision)\u001b[0m\n\u001b[0;32m    561\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdownload_loading_script\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m         \u001b[0mfile_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhf_github_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".py\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 563\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcached_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdownload_config\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mMetricModule\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\datasets\\utils\\file_utils.py\u001b[0m in \u001b[0;36mcached_path\u001b[1;34m(url_or_filename, download_config, **download_kwargs)\u001b[0m\n\u001b[0;32m    293\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mis_remote_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;31m# URL, so get it from the cache (downloading if necessary)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m         output_path = get_from_cache(\n\u001b[0m\u001b[0;32m    296\u001b[0m             \u001b[0murl_or_filename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[0mcache_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\datasets\\utils\\file_utils.py\u001b[0m in \u001b[0;36mget_from_cache\u001b[1;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, local_files_only, use_etag, max_retries, use_auth_token)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mconnected\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mftp_head\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             response = http_head(\n\u001b[0m\u001b[0;32m    551\u001b[0m                 \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m                 \u001b[0mallow_redirects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\datasets\\utils\\file_utils.py\u001b[0m in \u001b[0;36mhttp_head\u001b[1;34m(url, proxies, headers, cookies, allow_redirects, timeout, max_retries)\u001b[0m\n\u001b[0;32m    470\u001b[0m     \u001b[0mheaders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    471\u001b[0m     \u001b[0mheaders\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"user-agent\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_datasets_user_agent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_agent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"user-agent\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 472\u001b[1;33m     response = _request_with_retry(\n\u001b[0m\u001b[0;32m    473\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"HEAD\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m         \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\datasets\\utils\\file_utils.py\u001b[0m in \u001b[0;36m_request_with_retry\u001b[1;34m(method, url, max_retries, base_wait_time, max_wait_time, timeout, **params)\u001b[0m\n\u001b[0;32m    399\u001b[0m         \u001b[0mtries\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 401\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    402\u001b[0m             \u001b[0msuccess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConnectTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConnectionError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    540\u001b[0m         }\n\u001b[0;32m    541\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    653\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    654\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m                 resp = conn.urlopen(\n\u001b[0m\u001b[0;32m    440\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                     \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    697\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m             \u001b[1;31m# Make the request on the httplib connection object.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m             httplib_response = self._make_request(\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    380\u001b[0m         \u001b[1;31m# Trigger any extra validation we need to do.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m             \u001b[1;31m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1008\u001b[0m         \u001b[1;31m# Force connect early to allow us to validate the connection.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"sock\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1010\u001b[1;33m             \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1011\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1012\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_verified\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    356\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m         \u001b[1;31m# Add certificate verification\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 358\u001b[1;33m         \u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    359\u001b[0m         \u001b[0mhostname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m         \u001b[0mtls_in_tls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m             conn = connection.create_connection(\n\u001b[0m\u001b[0;32m    175\u001b[0m                 \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m             )\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\urllib3\\util\\connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     84\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0msource_address\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m             \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if(args.valid_begin==1):\n",
    "    my_test(valid_dataloader,model_w,-1) #before train\n",
    "    # my_test(valid_dataloader,model_v,-1)  \n",
    "for epoch in range(args.epochs):\n",
    "    lr_w = scheduler_w.get_lr()[0]\n",
    "    lr_v = scheduler_v.get_lr()[0]\n",
    "\n",
    "    logging.info(f\"\\n\\n  ----------------epoch:{epoch},\\t\\tlr_w:{lr_w},\\t\\tlr_v:{lr_v}----------------\")\n",
    "\n",
    "    w_train_loss,v_train_loss =  my_train(epoch, train_dataloader, model_w, model_v,  architect, A, w_optimizer, v_optimizer, lr_w,lr_v)\n",
    "    \n",
    "    scheduler_w.step()\n",
    "    scheduler_v.step()\n",
    "\n",
    "    writer.add_scalar(\"MT/model_w_in_main/w_trainloss\", w_train_loss, global_step=epoch)\n",
    "    writer.add_scalar(\"MT/model_v_in_main/v_trainloss\", v_train_loss, global_step=epoch)\n",
    "\n",
    "    logging.info(f\"w_train_loss:{w_train_loss},v_train_loss:{v_train_loss}\")\n",
    "    wandb.log({'w_train_loss': w_train_loss, 'v_train_loss':v_train_loss})\n",
    "\n",
    "    \n",
    "    my_test(valid_dataloader,model_w,epoch) \n",
    "    my_test(valid_dataloader,model_v,epoch)  \n",
    "\n",
    "torch.save(model_v,'./model/'+now+'model_w.pt')\n",
    "torch.save(model_v,'./model/'+now+'model_v.pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "65768f95ed3f1ad80799466926a66640b39a99ef5d94bbece814e59aa067606e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('python38': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
