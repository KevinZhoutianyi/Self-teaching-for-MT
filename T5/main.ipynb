{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd() \n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from T5 import *\n",
    "import torch\n",
    "from datasets import load_dataset,load_metric\n",
    "from transformers import T5Tokenizer\n",
    "import torch_optimizer as optim\n",
    "from transformers.optimization import Adafactor, AdafactorSchedule\n",
    "from MT_hyperparams import seed_,max_length,target_language\n",
    "import torch.backends.cudnn as cudnn\n",
    "from utils import *\n",
    "from attention_params import *\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, SubsetRandomSampler\n",
    "from torch.autograd import Variable\n",
    "from losses import *\n",
    "from architect import *\n",
    "import logging\n",
    "import sys\n",
    "import transformers\n",
    "import time\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(\"main\")\n",
    "\n",
    "\n",
    "parser.add_argument('--valid_num_points', type=int,             default = 200, help='validation data number')\n",
    "parser.add_argument('--train_num_points', type=int,             default = 200, help='train data number')\n",
    "\n",
    "parser.add_argument('--batch_size', type=int,                   default=16,     help='Batch size')\n",
    "parser.add_argument('--train_w_num_points', type=int,           default=4,      help='train_w_num_points for each batch')\n",
    "parser.add_argument('--train_v_synthetic_num_points', type=int, default=2,      help='train_v_synthetic_num_points for each batch')\n",
    "parser.add_argument('--train_v_num_points', type=int,           default=4,      help='train_v_num_points for each batch')\n",
    "parser.add_argument('--train_A_num_points', type=int,           default=6,      help='train_A_num_points decay for each batch')\n",
    "\n",
    "\n",
    "parser.add_argument('--gpu', type=int,                          default=0,      help='gpu device id')\n",
    "parser.add_argument('--model_name', type=str,                   default='t5-small',      help='model_name')\n",
    "parser.add_argument('--exp_name', type=str,                     default='T5spec',      help='experiment name')\n",
    "parser.add_argument('--rep_num', type=int,                      default=50,      help='report times for 1 epoch')\n",
    "parser.add_argument('--test_num', type=int,                     default=200,      help='test times for 1 epoch')\n",
    "\n",
    "parser.add_argument('--epochs', type=int,                       default=50,     help='num of training epochs')\n",
    "parser.add_argument('--pre_epochs', type=int,                   default=0,      help='train model W for x epoch first')\n",
    "parser.add_argument('--grad_clip', type=float,                  default=1,      help='gradient clipping')\n",
    "parser.add_argument('--grad_acc_count', type=float,             default=-1,      help='gradient accumulate steps')\n",
    "\n",
    "parser.add_argument('--w_lr', type=float,                       default=5e-4,   help='learning rate for w')\n",
    "# parser.add_argument('--unrolled_w_lr', type=float,              default=5e-4,   help='learning rate for w')\n",
    "parser.add_argument('--v_lr', type=float,                       default=5e-4,   help='learning rate for v')\n",
    "# parser.add_argument('--unrolled_v_lr', type=float,              default=5e-4,   help='learning rate for v')\n",
    "parser.add_argument('--A_lr', type=float,                       default=1e-3,   help='learning rate for A')\n",
    "parser.add_argument('--learning_rate_min', type=float,          default=1e-8,   help='learning_rate_min')\n",
    "parser.add_argument('--decay', type=float,                      default=1e-3,   help='weight decay')\n",
    "parser.add_argument('--momentum', type=float,                   default=0.9,    help='momentum')\n",
    "# parser.add_argument('--smoothing', type=float,                  default=0.1,    help='labelsmoothing')\n",
    "\n",
    "\n",
    "parser.add_argument('--traindata_loss_ratio', type=float,       default=0,    help='human translated data ratio')\n",
    "parser.add_argument('--syndata_loss_ratio', type=float,         default=1,    help='augmented dataset ratio')\n",
    "\n",
    "parser.add_argument('--valid_begin', type=int,                  default=1,      help='whether valid before train')\n",
    "parser.add_argument('--train_A', type=int,                      default=1 ,     help='whether train A')\n",
    "\n",
    "\n",
    "\n",
    "args = parser.parse_args(args=[])#(args=['--batch_size', '8',  '--no_cuda'])#used in ipynb\n",
    "args.test_num = args.test_num//args.batch_size * args.batch_size\n",
    "args.rep_num = args.rep_num//args.batch_size * args.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33monlydrinkwater\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.18 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.17"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>g:\\GitCode\\Self-teaching-for-machine-translation\\T5\\wandb\\run-20220609_153950-1sfndj0e</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/onlydrinkwater/Selftraining/runs/1sfndj0e\" target=\"_blank\">T5spec</a></strong> to <a href=\"https://wandb.ai/onlydrinkwater/Selftraining\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/onlydrinkwater/Selftraining/runs/1sfndj0e?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1c915f81520>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://wandb.ai/ check the running status online\n",
    "import wandb\n",
    "os.environ['WANDB_API_KEY']='a166474b1b7ad33a0549adaaec19a2f6d3f91d87'\n",
    "os.environ['WANDB_NAME']=args.exp_name\n",
    "wandb.init(project=\"Selftraining\",config=args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/09 03:39:58 PM |\t  Reusing dataset wmt14 (C:\\Users\\kevin\\.cache\\huggingface\\datasets\\wmt14\\de-en\\1.0.0\\d239eaf0ff090d28da19b6bc9758e24634d84de0a1ef092f0b5c54e6f132d7e2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 33.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/09 03:39:58 PM |\t  Namespace(A_lr=0.001, batch_size=16, decay=0.001, epochs=50, exp_name='T5spec', gpu=0, grad_acc_count=-1, grad_clip=1, learning_rate_min=1e-08, model_name='t5-small', momentum=0.9, pre_epochs=0, rep_num=48, syndata_loss_ratio=1, test_num=192, train_A=1, train_A_num_points=6, train_num_points=200, train_v_num_points=4, train_v_synthetic_num_points=2, train_w_num_points=4, traindata_loss_ratio=0, v_lr=0.0005, valid_begin=1, valid_num_points=200, w_lr=0.0005)\n",
      "06/09 03:39:58 PM |\t  DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 4508785\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 3000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 3003\n",
      "    })\n",
      "})\n",
      "06/09 03:39:58 PM |\t  {'translation': {'de': 'Ich bitte Sie, sich zu einer Schweigeminute zu erheben.', 'en': \"Please rise, then, for this minute' s silence.\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# logging file\n",
    "now = time.strftime(\"%Y-%m-%d-%H_%M_%S\", time.localtime(time.time()))\n",
    "\n",
    "log_format = '%(asctime)s |\\t  %(message)s'\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO,\n",
    "                    format=log_format, datefmt='%m/%d %I:%M:%S %p')\n",
    "fh = logging.FileHandler(os.path.join(\n",
    "    \"./log/\", now+'.txt'), 'w', encoding=\"UTF-8\")\n",
    "fh.setFormatter(logging.Formatter(log_format))\n",
    "logging.getLogger().addHandler(fh)\n",
    "dataset = load_dataset('wmt14', 'de-en')\n",
    "\n",
    "logging.info(args)\n",
    "logging.info(dataset)\n",
    "logging.info(dataset['train'][5])\n",
    "\n",
    "\n",
    "# Setting the seeds\n",
    "np.random.seed(seed_)\n",
    "torch.cuda.set_device(args.gpu)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cudnn.benchmark = True\n",
    "torch.manual_seed(seed_)\n",
    "cudnn.enabled = True\n",
    "torch.cuda.manual_seed(seed_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/09 03:40:00 PM |\t  modelsize:60.506624MB\n"
     ]
    }
   ],
   "source": [
    "modelname = args.model_name\n",
    "pretrained  =  T5ForConditionalGeneration.from_pretrained(modelname)\n",
    "pathname = modelname.replace('/','')\n",
    "logging.info(f'modelsize:{count_parameters_in_MB(pretrained)}MB')\n",
    "torch.save(pretrained,pathname+'.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t5-small\n",
      "06/09 03:40:02 PM |\t  Loading cached shuffled indices for dataset at C:\\Users\\kevin\\.cache\\huggingface\\datasets\\wmt14\\de-en\\1.0.0\\d239eaf0ff090d28da19b6bc9758e24634d84de0a1ef092f0b5c54e6f132d7e2\\cache-fcff064badad2159.arrow\n",
      "06/09 03:40:02 PM |\t  Loading cached shuffled indices for dataset at C:\\Users\\kevin\\.cache\\huggingface\\datasets\\wmt14\\de-en\\1.0.0\\d239eaf0ff090d28da19b6bc9758e24634d84de0a1ef092f0b5c54e6f132d7e2\\cache-ef861152e003e0c7.arrow\n",
      "06/09 03:40:02 PM |\t  Loading cached shuffled indices for dataset at C:\\Users\\kevin\\.cache\\huggingface\\datasets\\wmt14\\de-en\\1.0.0\\d239eaf0ff090d28da19b6bc9758e24634d84de0a1ef092f0b5c54e6f132d7e2\\cache-848b25adc701ab2b.arrow\n",
      "06/09 03:42:11 PM |\t  train len: 192\n",
      "06/09 03:42:11 PM |\t  train_w_num_points_len: 48\n",
      "06/09 03:42:11 PM |\t  train_v_synthetic_num_points_len: 24\n",
      "06/09 03:42:11 PM |\t  train_v_num_points_len: 48\n",
      "06/09 03:42:11 PM |\t  train_A_num_points_len: 72\n",
      "06/09 03:42:11 PM |\t  valid len: 200\n",
      "06/09 03:42:11 PM |\t  test len: 3003\n",
      "06/09 03:42:11 PM |\t  {'de': 'Dank unseres Personals und Geräteparks sind wir täglich rund um die Uhr in der Lage, uns allen erdenklichen Herausforderungen zu stellen.', 'en': 'translate English to German: Our staff and equipment stands ready to answer any challenges 24/7.'}\n",
      "06/09 03:42:11 PM |\t  {'de': 'Dank unseres Personals und Geräteparks sind wir täglich rund um die Uhr in der Lage, uns allen erdenklichen Herausforderungen zu stellen.', 'en': 'translate English to German: Our staff and equipment stands ready to answer any challenges 24/7.'}\n",
      "06/09 03:42:11 PM |\t  {'de': 'Die Gruppe – eine Mischung aus kamerunischen Ärzten und ausländischen Medizinstudenten – hat im letzten Jahr 700 kostenlose Operationen durchgeführt und weiß, dass sie mit ihrer Arbeit einen enormen Unterschied für die Menschen bewirkt, denen sie hilft.', 'en': 'translate English to German: The group -- a mix of Cameroonian doctors and foreign medical students -- has performed 700 free surgeries in the past year, and they know that their help can make a world of difference to those they help.'}\n"
     ]
    }
   ],
   "source": [
    "# preprocess the data, make a dataloader\n",
    "import random\n",
    "print(modelname)\n",
    "tokenizer = T5Tokenizer.from_pretrained(modelname)\n",
    "criterion = torch.nn.CrossEntropyLoss( reduction='none')#teacher shouldn't have label smoothing, especially when student got same size.\n",
    "criterion_v = torch.nn.CrossEntropyLoss( reduction='none')#,label_smoothing=args.smoothing) #without LS, V may be too confident to that syn data, and LS do well for real data also.\n",
    "dataset = dataset.shuffle(seed=seed_)\n",
    "train = dataset['train']['translation'][:args.train_num_points]\n",
    "valid = dataset['train']['translation'][:args.valid_num_points]#TODO:change dataset['validation']['translation'][:args.valid_num_points]args.train_num_points:args.train_num_points+args.valid_num_points\n",
    "test = dataset['test']['translation']#[L_t+L_v:L_t+L_v+L_test]\n",
    "def preprocess(dat):\n",
    "    for t in dat:\n",
    "        t['en'] = \"translate English to German: \" + t['en']  #needed for T5\n",
    "preprocess(train)\n",
    "preprocess(valid)\n",
    "preprocess(test)\n",
    "#TODO: Syn_input should be monolingual data, should try en-fo's en. cuz wmt may align\n",
    "num_batch = args.train_num_points//args.batch_size\n",
    "train = train[:args.batch_size*num_batch]\n",
    "logging.info(\"train len: %d\",len(train))\n",
    "\n",
    "'''\n",
    "each mini batch consist of : \n",
    "1. data to train W\n",
    "2. monolingual data to generate parallel data\n",
    "3. data to train V\n",
    "4. data to train A\n",
    "'''\n",
    "\n",
    "\n",
    "train_w_num_points_len = num_batch * args.train_w_num_points\n",
    "train_v_synthetic_num_points_len = num_batch * args.train_v_synthetic_num_points\n",
    "train_v_num_points_len = num_batch * args.train_v_num_points\n",
    "train_A_num_points_len = num_batch * args.train_A_num_points\n",
    "logging.info(\"train_w_num_points_len: %d\",train_w_num_points_len)\n",
    "logging.info(\"train_v_synthetic_num_points_len: %d\",train_v_synthetic_num_points_len)\n",
    "logging.info(\"train_v_num_points_len: %d\",train_v_num_points_len)\n",
    "logging.info(\"train_A_num_points_len: %d\",train_A_num_points_len)\n",
    "\n",
    "attn_idx_list = torch.arange(train_w_num_points_len).cuda()\n",
    "logging.info(\"valid len: %d\",len(valid))\n",
    "logging.info(\"test len: %d\" ,len(test))\n",
    "logging.info(train[2])\n",
    "logging.info(valid[2])\n",
    "logging.info(test[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get train data start\n",
      "get train data end\n",
      "06/09 03:42:12 PM |\t  train data get\n",
      "06/09 03:42:12 PM |\t  train data loader get\n",
      "06/09 03:42:12 PM |\t  valid data loader get\n",
      "06/09 03:42:13 PM |\t  test data loader get\n"
     ]
    }
   ],
   "source": [
    "target_language  = 'de'\n",
    "train_data = get_train_Dataset(train, tokenizer)# Create the DataLoader for our training set.\n",
    "logging.info('train data get')\n",
    "train_dataloader = DataLoader(train_data, sampler= SequentialSampler(train_data), \n",
    "                        batch_size=args.batch_size, pin_memory=False, num_workers=0)\n",
    "logging.info('train data loader get')\n",
    "valid_data = get_aux_dataset(valid, tokenizer)# Create the DataLoader for our training set.\n",
    "valid_dataloader = DataLoader(valid_data, sampler=SequentialSampler(valid_data), \n",
    "                        batch_size=args.batch_size, pin_memory=False, num_workers=0)\n",
    "logging.info('valid data loader get')\n",
    "test_data = get_aux_dataset(test, tokenizer)# Create the DataLoader for our training set.\n",
    "test_dataloader = DataLoader(test_data, sampler=SequentialSampler(test_data),\n",
    "                        batch_size=args.batch_size, pin_memory=False, num_workers=0)#, sampler=RandomSampler(test_data)\n",
    "logging.info('test data loader get')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "A = attention_params(train_w_num_points_len)#half of train regarded as u\n",
    "A = A.cuda()\n",
    "\n",
    "\n",
    "\n",
    "# TODO: model loaded from saved model\n",
    "model_w = T5(criterion=criterion, tokenizer= tokenizer, args = args, name = 'model_w_in_main')\n",
    "model_w = model_w.cuda()\n",
    "w_optimizer = torch.optim.Adam(model_w.parameters(),  lr= args.w_lr ,  betas=(0, args.momentum)  )\n",
    "# w_optimizer = Adafactor(model_w.parameters(), lr = args.w_lr ,scale_parameter=False, relative_step=False , warmup_init=False,clip_threshold=1,beta1=0,eps=( 1e-30,0.001))\n",
    "scheduler_w  = torch.optim.lr_scheduler.StepLR(w_optimizer,step_size=10, gamma=0.9)\n",
    "\n",
    "\n",
    "\n",
    "model_v = T5(criterion=criterion_v, tokenizer= tokenizer, args = args, name = 'model_v_in_main')\n",
    "model_v = model_v.cuda()\n",
    "v_optimizer = torch.optim.Adam(model_v.parameters(),  lr= args.v_lr ,  betas=(0, args.momentum)  )\n",
    "# v_optimizer =Adafactor(model_v.parameters(), lr = args.v_lr ,scale_parameter=False, relative_step=False , warmup_init=False,clip_threshold=1,beta1=0,eps=( 1e-30,0.001))\n",
    "scheduler_v  = torch.optim.lr_scheduler.StepLR(v_optimizer,step_size=10, gamma=0.9)\n",
    "\n",
    "\n",
    "\n",
    "architect = Architect(model_w, model_v,  A, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def my_test(_dataloader,model,epoch):\n",
    "    # logging.info(f\"GPU mem before test:{getGPUMem(device)}%\")\n",
    "    acc = 0\n",
    "    counter = 0\n",
    "    model.eval()\n",
    "    metric_sacrebleu =  load_metric('sacrebleu')\n",
    "    # metric_bleu =  load_metric('bleu')\n",
    "    \n",
    "    for step, batch in enumerate(_dataloader):\n",
    "        \n",
    "        test_dataloaderx = Variable(batch[0], requires_grad=False).to(device, non_blocking=False)\n",
    "        test_dataloaderx_attn = Variable(batch[1], requires_grad=False).to(device, non_blocking=False)\n",
    "        test_dataloadery = Variable(batch[2], requires_grad=False).to(device, non_blocking=False)\n",
    "        test_dataloadery_attn = Variable(batch[3], requires_grad=False).to(device, non_blocking=False)\n",
    "        ls = my_loss(test_dataloaderx,test_dataloaderx_attn,test_dataloadery,test_dataloadery_attn,model)\n",
    "        acc+= ls.item()\n",
    "        counter+= 1\n",
    "        pre = model.generate(test_dataloaderx)\n",
    "        x_decoded = tokenizer.batch_decode(test_dataloaderx,skip_special_tokens=True)\n",
    "        pred_decoded = tokenizer.batch_decode(pre,skip_special_tokens=True)\n",
    "        label_decoded =  tokenizer.batch_decode(test_dataloadery,skip_special_tokens=True)\n",
    "        \n",
    "        pred_str = [x  for x in pred_decoded]\n",
    "        label_str = [[x] for x in label_decoded]\n",
    "        # pred_list = [x.split()  for x in pred_decoded]\n",
    "        # label_list = [[x.split()] for x in label_decoded]\n",
    "        metric_sacrebleu.add_batch(predictions=pred_str, references=label_str)\n",
    "        # metric_bleu.add_batch(predictions=pred_list, references=label_list)\n",
    "        if  step==0:\n",
    "            logging.info(f'x_decoded[:2]:{x_decoded[:2]}')\n",
    "            logging.info(f'pred_decoded[:2]:{pred_decoded[:2]}')\n",
    "            logging.info(f'label_decoded[:2]:{label_decoded[:2]}')\n",
    "            \n",
    "            \n",
    "    logging.info('computing score...') \n",
    "    sacrebleu_score = metric_sacrebleu.compute()\n",
    "    # bleu_score = metric_bleu.compute()\n",
    "    logging.info('%s sacreBLEU : %f',model.name,sacrebleu_score['score'])#TODO:bleu may be wrong cuz max length\n",
    "    # logging.info('%s BLEU : %f',model.name,bleu_score['bleu'])\n",
    "    logging.info('%s test loss : %f',model.name,acc/(counter))\n",
    "    wandb.log({'sacreBLEU'+model.name: sacrebleu_score['score']})\n",
    "    wandb.log({'test_loss'+model.name: acc/counter})\n",
    "    # del test_dataloaderx,acc,counter,test_dataloaderx_attn,sacrebleu_score,bleu_score,test_dataloadery,test_dataloadery_attn,ls,pre,x_decoded,pred_decoded,label_decoded,pred_str,label_str,pred_list,label_list\n",
    "    # gc.collect()\n",
    "    # torch.cuda.empty_cache()\n",
    "    model.train()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_train(epoch, _dataloader, validdataloader, w_model, v_model, architect, A, w_optimizer, v_optimizer, lr_w, lr_v, tot_iter):\n",
    "\n",
    "    objs_w = AvgrageMeter()\n",
    "    objs_v_syn = AvgrageMeter()\n",
    "    objs_v_train = AvgrageMeter()\n",
    "    objs_v_star_val = AvgrageMeter()\n",
    "    v_trainloss_acc = 0\n",
    "    w_trainloss_acc = 0\n",
    "    # now  train_x is [num of batch, datasize], so its seperate batch for the code below\n",
    "    wsize = args.train_w_num_points\n",
    "    synsize = args.train_v_synthetic_num_points\n",
    "    vsize = args.train_v_num_points\n",
    "    vtrainsize = vsize+synsize\n",
    "    vtrainsize_total = train_v_num_points_len+train_v_synthetic_num_points_len\n",
    "    Asize = args.train_A_num_points\n",
    "    loader_len = len(_dataloader)\n",
    "    split_size = [wsize, synsize, vsize, Asize]\n",
    "    bs = args.batch_size\n",
    "\n",
    "    logging.info(f\"split size:{split_size}\")\n",
    "    for step, batch in enumerate(_dataloader):\n",
    "        tot_iter[0] += bs\n",
    "        # logging.info(f\"GPU mem :{getGPUMem(device)}%\")\n",
    "        train_x = Variable(batch[0], requires_grad=False).to(\n",
    "            device, non_blocking=False)\n",
    "        train_x_attn = Variable(batch[1], requires_grad=False).to(\n",
    "            device, non_blocking=False)\n",
    "        train_y = Variable(batch[2], requires_grad=False).to(\n",
    "            device, non_blocking=False)\n",
    "        train_y_attn = Variable(batch[3], requires_grad=False).to(\n",
    "            device, non_blocking=False)\n",
    "        (input_w, input_syn, input_v, input_A_v) = torch.split(train_x, split_size)\n",
    "        (input_w_attn, input_syn_attn, input_v_attn,\n",
    "         input_A_v_attn) = torch.split(train_x_attn, split_size)\n",
    "        (output_w, _, output_v, output_A_v) = torch.split(train_y, split_size)\n",
    "        (output_w_attn, _, output_v_attn, output_A_v_attn) = torch.split(\n",
    "            train_y_attn, split_size)\n",
    "        attn_idx = attn_idx_list[wsize*step:(wsize*step+wsize)]\n",
    "\n",
    "        if (args.train_A == 1):\n",
    "            v_star_val_loss = architect.step(input_w,  output_w, input_w_attn, output_w_attn, w_optimizer,\n",
    "                                             input_v, input_v_attn, output_v, output_v_attn, input_syn, input_syn_attn,\n",
    "                                             input_A_v, input_A_v_attn, output_A_v, output_A_v_attn, v_optimizer,\n",
    "                                             attn_idx, lr_w, lr_v)\n",
    "            objs_v_star_val.update(v_star_val_loss, Asize)\n",
    "\n",
    "        w_optimizer.zero_grad()\n",
    "        loss_w = CTG_loss(input_w, input_w_attn, output_w,\n",
    "                          output_w_attn, attn_idx, A, w_model)\n",
    "        w_trainloss_acc += loss_w.item()\n",
    "        loss_w.backward()\n",
    "        objs_w.update(loss_w.item(), wsize)\n",
    "        # if ((step + 1) % grad_acc_count == 0) or (step + 1 == loader_len):\n",
    "        # nn.utils.clip_grad_norm(w_model.parameters(), args.grad_clip)\n",
    "        w_optimizer.step()\n",
    "\n",
    "        v_optimizer.zero_grad()\n",
    "        loss_aug = calc_loss_aug(input_syn, input_syn_attn, w_model, v_model)\n",
    "        loss = my_loss2(input_v, input_v_attn, output_v,\n",
    "                        output_v_attn, v_model)\n",
    "        v_loss = (args.traindata_loss_ratio*loss +\n",
    "                  loss_aug*args.syndata_loss_ratio)\n",
    "        v_trainloss_acc += v_loss.item()\n",
    "        v_loss.backward()\n",
    "        objs_v_syn.update(loss_aug.item(), synsize)\n",
    "        objs_v_train.update(loss.item(), vsize)\n",
    "        # if ((step + 1) % grad_acc_count == 0) or (step + 1 == loader_len):\n",
    "        # nn.utils.clip_grad_norm(v_model.parameters(), args.grad_clip)\n",
    "        v_optimizer.step()\n",
    "\n",
    "        progress = 100*(step)/(loader_len-1)\n",
    "\n",
    "        if(tot_iter[0] % args.test_num == 0 and tot_iter[0] != 0):\n",
    "            my_test(validdataloader, model_w, epoch)\n",
    "            my_test(validdataloader, model_v, epoch)\n",
    "\n",
    "        if(tot_iter[0] % args.rep_num == 0 and tot_iter[0] != 0):\n",
    "            logging.info(f\"{progress:5.3}%:\\t  W_train_loss:{objs_w.avg:^.7f}\\tV_train_syn_loss:{objs_v_syn.avg:^.7f}\\tV_train_loss:{objs_v_train.avg:^.7f}\\t  V_star_val_loss:{objs_v_star_val.avg:^.7f}\")\n",
    "            wandb.log({'W_train_loss': objs_w.avg})\n",
    "            wandb.log({'V_train_syn_loss': objs_v_syn.avg})\n",
    "            wandb.log({'V_train_loss': objs_v_train.avg})\n",
    "            wandb.log({'V_star_val_loss': objs_v_star_val.avg})\n",
    "            objs_v_syn.reset()\n",
    "            objs_v_train.reset()\n",
    "            objs_w.reset()\n",
    "            objs_v_star_val.reset()\n",
    "\n",
    "    logging.info(str((\"Attention Weights A : \", A.alpha)))\n",
    "\n",
    "    return w_trainloss_acc, v_trainloss_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/09 03:42:14 PM |\t  \n",
      "\n",
      "  ----------------epoch:0,\t\tlr_w:0.0005,\t\tlr_v:0.0005----------------\n",
      "06/09 03:42:14 PM |\t  split size:[4, 2, 4, 6]\n",
      "06/09 03:42:29 PM |\t   18.2%:\t  W_train_loss:1.0369498\tV_train_syn_loss:8.4202727\tV_train_loss:1.2597007\t  V_star_val_loss:1.0899185\n",
      "06/09 03:42:41 PM |\t   45.5%:\t  W_train_loss:1.0720870\tV_train_syn_loss:5.5090639\tV_train_loss:0.9796694\t  V_star_val_loss:1.2047672\n",
      "06/09 03:42:51 PM |\t   72.7%:\t  W_train_loss:1.0754684\tV_train_syn_loss:4.3627803\tV_train_loss:1.6543841\t  V_star_val_loss:1.4507847\n",
      "06/09 03:43:06 PM |\t  x_decoded[:2]:[\"translate English to German: On these pages you will find the wanted or missing notices that are issued at public prosecutor or examining magistrate's request.\", 'translate English to German: Dimczewski usually depicts young women, which have regular facial features, smooth and sleek cheeks and long hair - wavy, bushy and wriggling.']\n",
      "06/09 03:43:06 PM |\t  pred_decoded[:2]:['Auf diesen Seiten finden Sie die gesuchten oder fehlenden Hinweise, die auf Anfrage des Staatsanwalts oder Untersuchungsrichter erteilt werden.', 'Dimczewski zeigt in der Regel junge Frauen, die reguläre Gesichtsmerkmale haben, glatte und schlanke Wangen und lange Haare - wuchtig, braun und wriggling.']\n",
      "06/09 03:43:06 PM |\t  label_decoded[:2]:['In diesem Rubrik finden Sie Fahndungsmeldungen, die auf Anfrage eines Staatsanwalts oder Untersuchungsrichter verbreitet werden.', 'Dimczewski bevorzugt junge Frauen mit regelmässigen Gesichtszügen zum Modellsitzen. Frauen mitglatten rosigen Wangen und langen welligen Haaren.']\n",
      "06/09 03:43:35 PM |\t  computing score...\n",
      "06/09 03:43:35 PM |\t  model_w_in_main sacreBLEU : 31.590506\n",
      "06/09 03:43:35 PM |\t  model_w_in_main test loss : 1.195069\n",
      "06/09 03:43:38 PM |\t  x_decoded[:2]:[\"translate English to German: On these pages you will find the wanted or missing notices that are issued at public prosecutor or examining magistrate's request.\", 'translate English to German: Dimczewski usually depicts young women, which have regular facial features, smooth and sleek cheeks and long hair - wavy, bushy and wriggling.']\n",
      "06/09 03:43:38 PM |\t  pred_decoded[:2]:['Auf diesen Seiten finden Sie die gesuchten oder fehlenden Hinweise, die auf Antrag des Staatsanwalts oder des Untersuchungsrichters erteilt werden.', 'Dimczewski zeigt in der Regel junge Frauen, die regelmäßige Gesichtsmerkmale haben, glatte und schmale Wangen und lange Haar Haare - wunde, blühende Haare.']\n",
      "06/09 03:43:38 PM |\t  label_decoded[:2]:['In diesem Rubrik finden Sie Fahndungsmeldungen, die auf Anfrage eines Staatsanwalts oder Untersuchungsrichter verbreitet werden.', 'Dimczewski bevorzugt junge Frauen mit regelmässigen Gesichtszügen zum Modellsitzen. Frauen mitglatten rosigen Wangen und langen welligen Haaren.']\n",
      "06/09 03:44:07 PM |\t  computing score...\n",
      "06/09 03:44:07 PM |\t  model_v_in_main sacreBLEU : 26.371748\n",
      "06/09 03:44:07 PM |\t  model_v_in_main test loss : 1.405368\n",
      "06/09 03:44:07 PM |\t  1e+02%:\t  W_train_loss:1.0172417\tV_train_syn_loss:3.4302638\tV_train_loss:1.4220522\t  V_star_val_loss:1.3651314\n",
      "06/09 03:44:07 PM |\t  ('Attention Weights A : ', Parameter containing:\n",
      "tensor([0.9990, 1.0010, 1.0010, 1.0010, 0.9986, 1.0014, 0.9987, 1.0014, 1.0016,\n",
      "        0.9984, 0.9984, 1.0016, 0.9982, 1.0018, 1.0018, 1.0017, 0.9980, 0.9980,\n",
      "        1.0019, 1.0020, 1.0021, 0.9979, 0.9991, 0.9983, 0.9978, 0.9978, 1.0022,\n",
      "        1.0022, 0.9980, 0.9976, 1.0023, 1.0024, 1.0024, 0.9975, 0.9976, 1.0024,\n",
      "        1.0025, 1.0025, 1.0025, 0.9975, 1.0026, 0.9996, 1.0025, 0.9975, 1.0026,\n",
      "        1.0026, 1.0026, 1.0024], device='cuda:0', requires_grad=True))\n",
      "06/09 03:44:07 PM |\t  w_train_loss:12.605240762233734,v_train_loss:65.16714191436768\n",
      "06/09 03:44:07 PM |\t  \n",
      "\n",
      "  ----------------epoch:1,\t\tlr_w:0.0005,\t\tlr_v:0.0005----------------\n",
      "06/09 03:44:07 PM |\t  split size:[4, 2, 4, 6]\n",
      "06/09 03:44:20 PM |\t   18.2%:\t  W_train_loss:0.8630189\tV_train_syn_loss:3.6266994\tV_train_loss:1.8880672\t  V_star_val_loss:1.1899381\n",
      "06/09 03:44:33 PM |\t   45.5%:\t  W_train_loss:0.7898180\tV_train_syn_loss:3.3928897\tV_train_loss:1.4418272\t  V_star_val_loss:1.3597906\n",
      "06/09 03:44:44 PM |\t   72.7%:\t  W_train_loss:0.7787189\tV_train_syn_loss:3.0241899\tV_train_loss:2.4678656\t  V_star_val_loss:1.6895535\n",
      "06/09 03:44:58 PM |\t  x_decoded[:2]:[\"translate English to German: On these pages you will find the wanted or missing notices that are issued at public prosecutor or examining magistrate's request.\", 'translate English to German: Dimczewski usually depicts young women, which have regular facial features, smooth and sleek cheeks and long hair - wavy, bushy and wriggling.']\n",
      "06/09 03:44:58 PM |\t  pred_decoded[:2]:['Auf diesen Seiten finden Sie die gesuchten oder fehlenden Hinweise, die auf Anfrage eines Staatsanwalts oder Untersuchungsrichter ausgestellt werden.', 'Dimczewski zeigt in der Regel junge Frauen, die regelmäßige Gesichtsmerkmale haben, glatte und schlanke Wangen und lange Haare - wunden, braun und wriggling.']\n",
      "06/09 03:44:58 PM |\t  label_decoded[:2]:['In diesem Rubrik finden Sie Fahndungsmeldungen, die auf Anfrage eines Staatsanwalts oder Untersuchungsrichter verbreitet werden.', 'Dimczewski bevorzugt junge Frauen mit regelmässigen Gesichtszügen zum Modellsitzen. Frauen mitglatten rosigen Wangen und langen welligen Haaren.']\n",
      "06/09 03:45:27 PM |\t  computing score...\n",
      "06/09 03:45:27 PM |\t  model_w_in_main sacreBLEU : 34.044367\n",
      "06/09 03:45:27 PM |\t  model_w_in_main test loss : 1.181051\n",
      "06/09 03:45:30 PM |\t  x_decoded[:2]:[\"translate English to German: On these pages you will find the wanted or missing notices that are issued at public prosecutor or examining magistrate's request.\", 'translate English to German: Dimczewski usually depicts young women, which have regular facial features, smooth and sleek cheeks and long hair - wavy, bushy and wriggling.']\n",
      "06/09 03:45:30 PM |\t  pred_decoded[:2]:['Auf diesen Seiten finden Sie die gesuchtenen oder fehlenden Hinweishinweishinweishinweishinweishinweishinweishinweishinweishinweishinweishinweishinweishinweishinweishinweishinweishinweishinweishinweishinweishinweishinweishinweishinweishinweishinweishinweishinweishinweishinweishinweishinweishinweishinweishinweishinweishinweishinweishinweishinweishinweishinweishinweishinweishinweishinweishinweishinweishinweis', 'Dimczewski zeigt in der Regel junge Frauen, die regelmäßige Gesichts Gesichts Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht']\n",
      "06/09 03:45:30 PM |\t  label_decoded[:2]:['In diesem Rubrik finden Sie Fahndungsmeldungen, die auf Anfrage eines Staatsanwalts oder Untersuchungsrichter verbreitet werden.', 'Dimczewski bevorzugt junge Frauen mit regelmässigen Gesichtszügen zum Modellsitzen. Frauen mitglatten rosigen Wangen und langen welligen Haaren.']\n",
      "06/09 03:46:01 PM |\t  computing score...\n",
      "06/09 03:46:01 PM |\t  model_v_in_main sacreBLEU : 17.265420\n",
      "06/09 03:46:01 PM |\t  model_v_in_main test loss : 1.746028\n",
      "06/09 03:46:01 PM |\t  1e+02%:\t  W_train_loss:0.8028621\tV_train_syn_loss:2.3180995\tV_train_loss:2.1893827\t  V_star_val_loss:1.6642908\n",
      "06/09 03:46:01 PM |\t  ('Attention Weights A : ', Parameter containing:\n",
      "tensor([1.0017, 0.9983, 1.0037, 1.0037, 1.0014, 1.0041, 1.0015, 0.9986, 0.9988,\n",
      "        0.9956, 0.9956, 0.9988, 1.0010, 1.0047, 0.9990, 0.9989, 0.9951, 1.0009,\n",
      "        0.9990, 0.9991, 1.0050, 0.9950, 0.9962, 0.9954, 1.0007, 1.0007, 1.0052,\n",
      "        0.9993, 1.0010, 1.0006, 0.9993, 1.0053, 1.0054, 1.0005, 0.9946, 0.9995,\n",
      "        0.9995, 0.9995, 1.0055, 1.0005, 1.0056, 0.9966, 1.0055, 1.0005, 1.0027,\n",
      "        1.0056, 1.0057, 1.0055], device='cuda:0', requires_grad=True))\n",
      "06/09 03:46:01 PM |\t  w_train_loss:9.70325380563736,v_train_loss:37.0856351852417\n",
      "06/09 03:46:01 PM |\t  \n",
      "\n",
      "  ----------------epoch:2,\t\tlr_w:0.0005,\t\tlr_v:0.0005----------------\n",
      "06/09 03:46:01 PM |\t  split size:[4, 2, 4, 6]\n",
      "06/09 03:46:11 PM |\t   18.2%:\t  W_train_loss:0.6721844\tV_train_syn_loss:2.5348002\tV_train_loss:2.4314371\t  V_star_val_loss:1.5716392\n",
      "06/09 03:46:24 PM |\t   45.5%:\t  W_train_loss:0.5842244\tV_train_syn_loss:2.3628004\tV_train_loss:2.1204527\t  V_star_val_loss:1.8515115\n",
      "06/09 03:46:36 PM |\t   72.7%:\t  W_train_loss:0.5747746\tV_train_syn_loss:1.8415359\tV_train_loss:3.5353266\t  V_star_val_loss:2.7600176\n",
      "06/09 03:46:50 PM |\t  x_decoded[:2]:[\"translate English to German: On these pages you will find the wanted or missing notices that are issued at public prosecutor or examining magistrate's request.\", 'translate English to German: Dimczewski usually depicts young women, which have regular facial features, smooth and sleek cheeks and long hair - wavy, bushy and wriggling.']\n",
      "06/09 03:46:50 PM |\t  pred_decoded[:2]:['Auf diesen Seiten finden Sie Benachrichtigungen, die auf Anfrage eines Staatsanwalts oder Untersuchungsrichter veröffentlicht werden.', 'Dimczewski zeigt in der Regel junge Frauen mit regulären Gesichtszügen, glatte und schmale Wangen und langen Haaren - wuchtig, brasilianisch und wriggling.']\n",
      "06/09 03:46:50 PM |\t  label_decoded[:2]:['In diesem Rubrik finden Sie Fahndungsmeldungen, die auf Anfrage eines Staatsanwalts oder Untersuchungsrichter verbreitet werden.', 'Dimczewski bevorzugt junge Frauen mit regelmässigen Gesichtszügen zum Modellsitzen. Frauen mitglatten rosigen Wangen und langen welligen Haaren.']\n",
      "06/09 03:47:18 PM |\t  computing score...\n",
      "06/09 03:47:18 PM |\t  model_w_in_main sacreBLEU : 36.349624\n",
      "06/09 03:47:18 PM |\t  model_w_in_main test loss : 1.188587\n",
      "06/09 03:47:21 PM |\t  x_decoded[:2]:[\"translate English to German: On these pages you will find the wanted or missing notices that are issued at public prosecutor or examining magistrate's request.\", 'translate English to German: Dimczewski usually depicts young women, which have regular facial features, smooth and sleek cheeks and long hair - wavy, bushy and wriggling.']\n",
      "06/09 03:47:21 PM |\t  pred_decoded[:2]:['Auf diesen Seiten finden Sie die gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht', 'Dimczewski zeigt in der Regel junge junge Frauen Frauen, die regelmäßig regelmäßigee Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht Gesicht']\n",
      "06/09 03:47:21 PM |\t  label_decoded[:2]:['In diesem Rubrik finden Sie Fahndungsmeldungen, die auf Anfrage eines Staatsanwalts oder Untersuchungsrichter verbreitet werden.', 'Dimczewski bevorzugt junge Frauen mit regelmässigen Gesichtszügen zum Modellsitzen. Frauen mitglatten rosigen Wangen und langen welligen Haaren.']\n",
      "06/09 03:47:53 PM |\t  computing score...\n",
      "06/09 03:47:54 PM |\t  model_v_in_main sacreBLEU : 7.193861\n",
      "06/09 03:47:54 PM |\t  model_v_in_main test loss : 3.194504\n",
      "06/09 03:47:54 PM |\t  1e+02%:\t  W_train_loss:0.5912187\tV_train_syn_loss:1.4773872\tV_train_loss:3.6731145\t  V_star_val_loss:2.7233574\n",
      "06/09 03:47:54 PM |\t  ('Attention Weights A : ', Parameter containing:\n",
      "tensor([1.0048, 0.9953, 1.0066, 1.0011, 0.9993, 1.0011, 1.0040, 0.9955, 1.0019,\n",
      "        0.9986, 0.9925, 1.0018, 1.0041, 1.0062, 0.9999, 1.0020, 0.9982, 1.0039,\n",
      "        0.9985, 0.9960, 1.0081, 0.9944, 0.9932, 0.9984, 1.0033, 0.9977, 1.0083,\n",
      "        1.0024, 0.9979, 0.9975, 0.9963, 1.0033, 1.0085, 1.0035, 0.9915, 0.9968,\n",
      "        1.0004, 0.9965, 1.0086, 1.0036, 1.0025, 0.9998, 1.0081, 0.9974, 0.9996,\n",
      "        1.0087, 1.0088, 1.0024], device='cuda:0', requires_grad=True))\n",
      "06/09 03:47:54 PM |\t  w_train_loss:7.267206475138664,v_train_loss:24.64957106113434\n",
      "06/09 03:47:54 PM |\t  \n",
      "\n",
      "  ----------------epoch:3,\t\tlr_w:0.0005,\t\tlr_v:0.0005----------------\n",
      "06/09 03:47:54 PM |\t  split size:[4, 2, 4, 6]\n",
      "06/09 03:48:05 PM |\t   18.2%:\t  W_train_loss:0.5038769\tV_train_syn_loss:1.6425876\tV_train_loss:4.1026955\t  V_star_val_loss:2.8357801\n",
      "06/09 03:48:18 PM |\t   45.5%:\t  W_train_loss:0.4851128\tV_train_syn_loss:1.3343004\tV_train_loss:3.3827470\t  V_star_val_loss:3.2332164\n",
      "06/09 03:48:28 PM |\t   72.7%:\t  W_train_loss:0.4748402\tV_train_syn_loss:1.2375052\tV_train_loss:4.5994954\t  V_star_val_loss:3.9976225\n",
      "06/09 03:48:43 PM |\t  x_decoded[:2]:[\"translate English to German: On these pages you will find the wanted or missing notices that are issued at public prosecutor or examining magistrate's request.\", 'translate English to German: Dimczewski usually depicts young women, which have regular facial features, smooth and sleek cheeks and long hair - wavy, bushy and wriggling.']\n",
      "06/09 03:48:43 PM |\t  pred_decoded[:2]:['Auf diesen Seiten finden Sie Benachrichtigungen, die auf Anfrage eines Staatsanwalts oder Untersuchungsrichter veröffentlicht werden.', 'Dimczewski zeigt in der Regel junge Frauen mit regulären Gesichtszügen, glatte Wangen und langen Haaren.']\n",
      "06/09 03:48:43 PM |\t  label_decoded[:2]:['In diesem Rubrik finden Sie Fahndungsmeldungen, die auf Anfrage eines Staatsanwalts oder Untersuchungsrichter verbreitet werden.', 'Dimczewski bevorzugt junge Frauen mit regelmässigen Gesichtszügen zum Modellsitzen. Frauen mitglatten rosigen Wangen und langen welligen Haaren.']\n",
      "06/09 03:49:11 PM |\t  computing score...\n",
      "06/09 03:49:11 PM |\t  model_w_in_main sacreBLEU : 37.867149\n",
      "06/09 03:49:11 PM |\t  model_w_in_main test loss : 1.218958\n",
      "06/09 03:49:14 PM |\t  x_decoded[:2]:[\"translate English to German: On these pages you will find the wanted or missing notices that are issued at public prosecutor or examining magistrate's request.\", 'translate English to German: Dimczewski usually depicts young women, which have regular facial features, smooth and sleek cheeks and long hair - wavy, bushy and wriggling.']\n",
      "06/09 03:49:14 PM |\t  pred_decoded[:2]:['Auf diesen Seiten Seiten finden Sie die gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht gesucht', 'Dimczewski zeigt normalerweise junge junge Frauen Frauen, die mit regelmäßig regelmäßig regelmäßigenenenenenenenenenenenenenenenenenenenenenenenenenenenenenenenenenenenenenenenenenenenenen']\n",
      "06/09 03:49:14 PM |\t  label_decoded[:2]:['In diesem Rubrik finden Sie Fahndungsmeldungen, die auf Anfrage eines Staatsanwalts oder Untersuchungsrichter verbreitet werden.', 'Dimczewski bevorzugt junge Frauen mit regelmässigen Gesichtszügen zum Modellsitzen. Frauen mitglatten rosigen Wangen und langen welligen Haaren.']\n",
      "06/09 03:49:47 PM |\t  computing score...\n",
      "06/09 03:49:47 PM |\t  model_v_in_main sacreBLEU : 5.912037\n",
      "06/09 03:49:47 PM |\t  model_v_in_main test loss : 3.662003\n",
      "06/09 03:49:47 PM |\t  1e+02%:\t  W_train_loss:0.4632268\tV_train_syn_loss:1.0089122\tV_train_loss:4.6556875\t  V_star_val_loss:3.7461535\n",
      "06/09 03:49:47 PM |\t  ('Attention Weights A : ', Parameter containing:\n",
      "tensor([1.0018, 0.9928, 1.0035, 0.9980, 1.0024, 1.0042, 1.0071, 0.9942, 0.9990,\n",
      "        1.0017, 0.9957, 1.0007, 1.0069, 1.0094, 1.0030, 1.0049, 1.0011, 1.0008,\n",
      "        0.9953, 0.9930, 1.0050, 0.9913, 0.9960, 0.9953, 1.0065, 0.9945, 1.0051,\n",
      "        0.9994, 0.9948, 1.0006, 0.9993, 1.0002, 1.0056, 1.0004, 0.9887, 0.9937,\n",
      "        0.9972, 0.9933, 1.0105, 1.0062, 0.9994, 0.9967, 1.0110, 0.9943, 0.9986,\n",
      "        1.0117, 1.0117, 0.9994], device='cuda:0', requires_grad=True))\n",
      "06/09 03:49:47 PM |\t  w_train_loss:5.781170219182968,v_train_loss:15.66991639137268\n",
      "06/09 03:49:47 PM |\t  \n",
      "\n",
      "  ----------------epoch:4,\t\tlr_w:0.0005,\t\tlr_v:0.0005----------------\n",
      "06/09 03:49:47 PM |\t  split size:[4, 2, 4, 6]\n",
      "06/09 03:50:00 PM |\t   18.2%:\t  W_train_loss:0.3981849\tV_train_syn_loss:1.0259184\tV_train_loss:4.4452451\t  V_star_val_loss:3.9046485\n",
      "06/09 03:50:13 PM |\t   45.5%:\t  W_train_loss:0.3786631\tV_train_syn_loss:0.9400042\tV_train_loss:4.0568530\t  V_star_val_loss:4.4957763\n",
      "06/09 03:50:24 PM |\t   72.7%:\t  W_train_loss:0.3187636\tV_train_syn_loss:0.7943562\tV_train_loss:5.4149068\t  V_star_val_loss:5.7707901\n",
      "06/09 03:50:37 PM |\t  x_decoded[:2]:[\"translate English to German: On these pages you will find the wanted or missing notices that are issued at public prosecutor or examining magistrate's request.\", 'translate English to German: Dimczewski usually depicts young women, which have regular facial features, smooth and sleek cheeks and long hair - wavy, bushy and wriggling.']\n",
      "06/09 03:50:37 PM |\t  pred_decoded[:2]:['In diesem Rubrik finden Sie Fahndungsmeldungen, die auf Anfrage eines Staatsanwalts oder Untersuchungsrichter verbreitet werden.', 'Dimczewski zeigt in der Regel junge Frauen mit regelmässigen Gesichtszügen, glatte und schmale Wangen und langen Haaren - wavy, bushy and wriggling.']\n",
      "06/09 03:50:37 PM |\t  label_decoded[:2]:['In diesem Rubrik finden Sie Fahndungsmeldungen, die auf Anfrage eines Staatsanwalts oder Untersuchungsrichter verbreitet werden.', 'Dimczewski bevorzugt junge Frauen mit regelmässigen Gesichtszügen zum Modellsitzen. Frauen mitglatten rosigen Wangen und langen welligen Haaren.']\n",
      "06/09 03:51:06 PM |\t  computing score...\n",
      "06/09 03:51:06 PM |\t  model_w_in_main sacreBLEU : 38.919441\n",
      "06/09 03:51:06 PM |\t  model_w_in_main test loss : 1.236857\n",
      "06/09 03:51:09 PM |\t  x_decoded[:2]:[\"translate English to German: On these pages you will find the wanted or missing notices that are issued at public prosecutor or examining magistrate's request.\", 'translate English to German: Dimczewski usually depicts young women, which have regular facial features, smooth and sleek cheeks and long hair - wavy, bushy and wriggling.']\n",
      "06/09 03:51:09 PM |\t  pred_decoded[:2]:['Auf diesen Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten', 'Dimczewski zeigt gewöhnlich gewöhnlich junge junge Fraueninneninneninneninneninneninneninneninneninneninneninneninneninneninneninneninneninneninneninneninneninneninneninneninneninneninneninneninneninneninneninneninneninneninneninneninneninneninneninneninneninneninneninneninneninneninneninneninneninneninneninneninnen']\n",
      "06/09 03:51:09 PM |\t  label_decoded[:2]:['In diesem Rubrik finden Sie Fahndungsmeldungen, die auf Anfrage eines Staatsanwalts oder Untersuchungsrichter verbreitet werden.', 'Dimczewski bevorzugt junge Frauen mit regelmässigen Gesichtszügen zum Modellsitzen. Frauen mitglatten rosigen Wangen und langen welligen Haaren.']\n",
      "06/09 03:51:42 PM |\t  computing score...\n",
      "06/09 03:51:42 PM |\t  model_v_in_main sacreBLEU : 1.778306\n",
      "06/09 03:51:42 PM |\t  model_v_in_main test loss : 6.243442\n",
      "06/09 03:51:42 PM |\t  1e+02%:\t  W_train_loss:0.4048179\tV_train_syn_loss:0.5971859\tV_train_loss:6.2160942\t  V_star_val_loss:5.6651580\n",
      "06/09 03:51:42 PM |\t  ('Attention Weights A : ', Parameter containing:\n",
      "tensor([1.0047, 0.9960, 1.0005, 0.9976, 0.9993, 1.0069, 1.0102, 0.9911, 0.9961,\n",
      "        1.0021, 0.9986, 1.0039, 1.0099, 1.0124, 0.9999, 1.0019, 0.9980, 0.9978,\n",
      "        0.9982, 0.9960, 1.0070, 0.9932, 0.9948, 0.9969, 1.0096, 0.9926, 1.0043,\n",
      "        0.9984, 0.9979, 0.9976, 1.0012, 1.0027, 1.0079, 1.0029, 0.9857, 0.9959,\n",
      "        0.9941, 0.9903, 1.0075, 1.0092, 1.0025, 0.9945, 1.0142, 0.9968, 1.0007,\n",
      "        1.0127, 1.0149, 1.0009], device='cuda:0', requires_grad=True))\n",
      "06/09 03:51:42 PM |\t  w_train_loss:4.501288615167141,v_train_loss:10.072394371032715\n",
      "06/09 03:51:42 PM |\t  \n",
      "\n",
      "  ----------------epoch:5,\t\tlr_w:0.0005,\t\tlr_v:0.0005----------------\n",
      "06/09 03:51:42 PM |\t  split size:[4, 2, 4, 6]\n",
      "06/09 03:51:54 PM |\t   18.2%:\t  W_train_loss:0.3143596\tV_train_syn_loss:0.7175395\tV_train_loss:5.9765875\t  V_star_val_loss:5.7841803\n",
      "06/09 03:52:07 PM |\t   45.5%:\t  W_train_loss:0.3172708\tV_train_syn_loss:0.6437831\tV_train_loss:5.8037837\t  V_star_val_loss:6.4699009\n",
      "06/09 03:52:18 PM |\t   72.7%:\t  W_train_loss:0.2760022\tV_train_syn_loss:0.5340571\tV_train_loss:6.7927980\t  V_star_val_loss:7.2433756\n",
      "06/09 03:52:33 PM |\t  x_decoded[:2]:[\"translate English to German: On these pages you will find the wanted or missing notices that are issued at public prosecutor or examining magistrate's request.\", 'translate English to German: Dimczewski usually depicts young women, which have regular facial features, smooth and sleek cheeks and long hair - wavy, bushy and wriggling.']\n",
      "06/09 03:52:33 PM |\t  pred_decoded[:2]:['In diesem Rubrik finden Sie Fahndungsmeldungen, die auf Anfrage eines Staatsanwalts oder Untersuchungsrichter verbreitet werden.', 'Dimczewski zeigt in der Regel junge Frauen mit regelmässigen Gesichtszügen, glatten Wangen und langen, braunen Haaren.']\n",
      "06/09 03:52:33 PM |\t  label_decoded[:2]:['In diesem Rubrik finden Sie Fahndungsmeldungen, die auf Anfrage eines Staatsanwalts oder Untersuchungsrichter verbreitet werden.', 'Dimczewski bevorzugt junge Frauen mit regelmässigen Gesichtszügen zum Modellsitzen. Frauen mitglatten rosigen Wangen und langen welligen Haaren.']\n",
      "06/09 03:53:01 PM |\t  computing score...\n",
      "06/09 03:53:01 PM |\t  model_w_in_main sacreBLEU : 40.053918\n",
      "06/09 03:53:01 PM |\t  model_w_in_main test loss : 1.260966\n",
      "06/09 03:53:04 PM |\t  x_decoded[:2]:[\"translate English to German: On these pages you will find the wanted or missing notices that are issued at public prosecutor or examining magistrate's request.\", 'translate English to German: Dimczewski usually depicts young women, which have regular facial features, smooth and sleek cheeks and long hair - wavy, bushy and wriggling.']\n",
      "06/09 03:53:04 PM |\t  pred_decoded[:2]:['Auf diesen Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten', 'Dimczewski zeigt normal normalerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweise']\n",
      "06/09 03:53:04 PM |\t  label_decoded[:2]:['In diesem Rubrik finden Sie Fahndungsmeldungen, die auf Anfrage eines Staatsanwalts oder Untersuchungsrichter verbreitet werden.', 'Dimczewski bevorzugt junge Frauen mit regelmässigen Gesichtszügen zum Modellsitzen. Frauen mitglatten rosigen Wangen und langen welligen Haaren.']\n",
      "06/09 03:53:37 PM |\t  computing score...\n",
      "06/09 03:53:37 PM |\t  model_v_in_main sacreBLEU : 1.033487\n",
      "06/09 03:53:37 PM |\t  model_v_in_main test loss : 7.162534\n",
      "06/09 03:53:37 PM |\t  1e+02%:\t  W_train_loss:0.3023181\tV_train_syn_loss:0.4727857\tV_train_loss:6.8724217\t  V_star_val_loss:6.9698782\n",
      "06/09 03:53:37 PM |\t  ('Attention Weights A : ', Parameter containing:\n",
      "tensor([1.0015, 0.9991, 1.0037, 1.0007, 1.0023, 1.0040, 1.0084, 0.9938, 0.9935,\n",
      "        1.0051, 0.9960, 1.0010, 1.0110, 1.0142, 0.9968, 1.0018, 1.0000, 0.9961,\n",
      "        1.0010, 0.9985, 1.0042, 0.9901, 0.9951, 0.9944, 1.0073, 0.9898, 1.0011,\n",
      "        0.9955, 0.9995, 0.9949, 0.9997, 1.0020, 1.0063, 0.9998, 0.9877, 0.9990,\n",
      "        0.9913, 0.9877, 1.0067, 1.0116, 1.0021, 0.9913, 1.0111, 0.9995, 0.9991,\n",
      "        1.0159, 1.0129, 1.0035], device='cuda:0', requires_grad=True))\n",
      "06/09 03:53:37 PM |\t  w_train_loss:3.6298521384596825,v_train_loss:7.104496240615845\n",
      "06/09 03:53:37 PM |\t  \n",
      "\n",
      "  ----------------epoch:6,\t\tlr_w:0.0005,\t\tlr_v:0.0005----------------\n",
      "06/09 03:53:37 PM |\t  split size:[4, 2, 4, 6]\n",
      "06/09 03:53:48 PM |\t   18.2%:\t  W_train_loss:0.2513547\tV_train_syn_loss:0.5723075\tV_train_loss:7.7163973\t  V_star_val_loss:7.0969906\n",
      "06/09 03:54:01 PM |\t   45.5%:\t  W_train_loss:0.2527072\tV_train_syn_loss:0.5094898\tV_train_loss:6.6990326\t  V_star_val_loss:7.8083820\n",
      "06/09 03:54:12 PM |\t   72.7%:\t  W_train_loss:0.2156680\tV_train_syn_loss:0.4062675\tV_train_loss:7.2099614\t  V_star_val_loss:7.8263982\n",
      "06/09 03:54:26 PM |\t  x_decoded[:2]:[\"translate English to German: On these pages you will find the wanted or missing notices that are issued at public prosecutor or examining magistrate's request.\", 'translate English to German: Dimczewski usually depicts young women, which have regular facial features, smooth and sleek cheeks and long hair - wavy, bushy and wriggling.']\n",
      "06/09 03:54:26 PM |\t  pred_decoded[:2]:['In diesem Rubrik finden Sie Fahndungsmeldungen, die auf Anfrage eines Staatsanwalts oder Untersuchungsrichter verbreitet werden.', 'Dimczewski zeigt in der Regel junge Frauen mit regelmässigen Gesichtszügen, glatten und rosigen Wangen und langen, braunen und wrigglingigen Haaren.']\n",
      "06/09 03:54:26 PM |\t  label_decoded[:2]:['In diesem Rubrik finden Sie Fahndungsmeldungen, die auf Anfrage eines Staatsanwalts oder Untersuchungsrichter verbreitet werden.', 'Dimczewski bevorzugt junge Frauen mit regelmässigen Gesichtszügen zum Modellsitzen. Frauen mitglatten rosigen Wangen und langen welligen Haaren.']\n",
      "06/09 03:54:54 PM |\t  computing score...\n",
      "06/09 03:54:55 PM |\t  model_w_in_main sacreBLEU : 40.918626\n",
      "06/09 03:54:55 PM |\t  model_w_in_main test loss : 1.323220\n",
      "06/09 03:54:58 PM |\t  x_decoded[:2]:[\"translate English to German: On these pages you will find the wanted or missing notices that are issued at public prosecutor or examining magistrate's request.\", 'translate English to German: Dimczewski usually depicts young women, which have regular facial features, smooth and sleek cheeks and long hair - wavy, bushy and wriggling.']\n",
      "06/09 03:54:58 PM |\t  pred_decoded[:2]:['Auf diesendiesen Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten Seiten', 'Dimczewski zeigt normal normalerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweiseerweise']\n",
      "06/09 03:54:58 PM |\t  label_decoded[:2]:['In diesem Rubrik finden Sie Fahndungsmeldungen, die auf Anfrage eines Staatsanwalts oder Untersuchungsrichter verbreitet werden.', 'Dimczewski bevorzugt junge Frauen mit regelmässigen Gesichtszügen zum Modellsitzen. Frauen mitglatten rosigen Wangen und langen welligen Haaren.']\n",
      "06/09 03:55:31 PM |\t  computing score...\n",
      "06/09 03:55:31 PM |\t  model_v_in_main sacreBLEU : 0.985356\n",
      "06/09 03:55:31 PM |\t  model_v_in_main test loss : 8.492051\n",
      "06/09 03:55:31 PM |\t  1e+02%:\t  W_train_loss:0.2502258\tV_train_syn_loss:0.3537297\tV_train_loss:7.6754789\t  V_star_val_loss:8.5352723\n",
      "06/09 03:55:31 PM |\t  ('Attention Weights A : ', Parameter containing:\n",
      "tensor([1.0012, 0.9980, 1.0025, 0.9997, 1.0045, 1.0023, 1.0112, 0.9941, 0.9966,\n",
      "        1.0046, 0.9930, 0.9986, 1.0131, 1.0172, 0.9989, 0.9992, 1.0022, 0.9987,\n",
      "        1.0039, 1.0001, 1.0050, 0.9918, 0.9981, 0.9913, 1.0045, 0.9929, 0.9999,\n",
      "        0.9936, 0.9964, 0.9979, 1.0004, 1.0051, 1.0031, 1.0010, 0.9851, 1.0005,\n",
      "        0.9916, 0.9846, 1.0036, 1.0147, 1.0047, 0.9919, 1.0142, 0.9964, 1.0022,\n",
      "        1.0166, 1.0118, 1.0003], device='cuda:0', requires_grad=True))\n",
      "06/09 03:55:31 PM |\t  w_train_loss:2.909866914153099,v_train_loss:5.525383502244949\n",
      "06/09 03:55:31 PM |\t  \n",
      "\n",
      "  ----------------epoch:7,\t\tlr_w:0.0005,\t\tlr_v:0.0005----------------\n",
      "06/09 03:55:31 PM |\t  split size:[4, 2, 4, 6]\n",
      "06/09 03:55:42 PM |\t   18.2%:\t  W_train_loss:0.1928213\tV_train_syn_loss:0.5537447\tV_train_loss:7.8656089\t  V_star_val_loss:8.0923537\n",
      "06/09 03:55:55 PM |\t   45.5%:\t  W_train_loss:0.2160754\tV_train_syn_loss:0.3211255\tV_train_loss:7.5832384\t  V_star_val_loss:8.5279361\n",
      "06/09 03:56:06 PM |\t   72.7%:\t  W_train_loss:0.1817174\tV_train_syn_loss:0.2423459\tV_train_loss:8.6879695\t  V_star_val_loss:10.1062956\n",
      "06/09 03:56:19 PM |\t  x_decoded[:2]:[\"translate English to German: On these pages you will find the wanted or missing notices that are issued at public prosecutor or examining magistrate's request.\", 'translate English to German: Dimczewski usually depicts young women, which have regular facial features, smooth and sleek cheeks and long hair - wavy, bushy and wriggling.']\n",
      "06/09 03:56:19 PM |\t  pred_decoded[:2]:['In diesem Rubrik finden Sie Fahndungsmeldungen, die auf Anfrage eines Staatsanwalts oder Untersuchungsrichter verbreitet werden.', 'Dimczewski zieht in der Regel junge Frauen mit regelmässigen Gesichtszügen, glatten und rosigen Wangen und langen, braunen und wrigglingigen Haaren.']\n",
      "06/09 03:56:19 PM |\t  label_decoded[:2]:['In diesem Rubrik finden Sie Fahndungsmeldungen, die auf Anfrage eines Staatsanwalts oder Untersuchungsrichter verbreitet werden.', 'Dimczewski bevorzugt junge Frauen mit regelmässigen Gesichtszügen zum Modellsitzen. Frauen mitglatten rosigen Wangen und langen welligen Haaren.']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_165904/4252205212.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"\\n\\n  ----------------epoch:{epoch},\\t\\tlr_w:{lr_w},\\t\\tlr_v:{lr_v}----------------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mw_train_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv_train_loss\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mmy_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_v\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0marchitect\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_optimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv_optimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr_w\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr_v\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtot_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mscheduler_w\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_165904/196390784.py\u001b[0m in \u001b[0;36mmy_train\u001b[1;34m(epoch, _dataloader, validdataloader, w_model, v_model, architect, A, w_optimizer, v_optimizer, lr_w, lr_v, tot_iter)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtot_iter\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_num\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtot_iter\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[0mmy_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvaliddataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m             \u001b[0mmy_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvaliddataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_v\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_165904/2485994566.py\u001b[0m in \u001b[0;36mmy_test\u001b[1;34m(_dataloader, model, epoch)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0macc\u001b[0m\u001b[1;33m+=\u001b[0m \u001b[0mls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mcounter\u001b[0m\u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mpre\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_dataloaderx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0mx_decoded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_dataloaderx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mskip_special_tokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mpred_decoded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpre\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mskip_special_tokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mg:\\GitCode\\Self-teaching-for-machine-translation\\T5\\T5.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, input_ids, num_beams, max_length)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;31m## sampling with top_p\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m         \u001b[1;31m# output_ids = self.model.generate( input_ids = input_ids, num_beams = 1, max_length = max_length, top_p = 0.95, top_k = 50, no_repeat_ngram_size = 2, repetition_penalty = 1.2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput_ids\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, typical_p, repetition_penalty, bad_words_ids, force_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, stopping_criteria, constraints, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, exponential_decay_length_penalty, **model_kwargs)\u001b[0m\n\u001b[0;32m   1313\u001b[0m             )\n\u001b[0;32m   1314\u001b[0m             \u001b[1;31m# 12. run beam search\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1315\u001b[1;33m             return self.beam_search(\n\u001b[0m\u001b[0;32m   1316\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1317\u001b[0m                 \u001b[0mbeam_scorer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\generation_utils.py\u001b[0m in \u001b[0;36mbeam_search\u001b[1;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[0;32m   2156\u001b[0m             \u001b[0mmodel_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_inputs_for_generation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2158\u001b[1;33m             outputs = self(\n\u001b[0m\u001b[0;32m   2159\u001b[0m                 \u001b[1;33m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2160\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1637\u001b[0m         \u001b[1;31m# Decode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1638\u001b[1;33m         decoder_outputs = self.decoder(\n\u001b[0m\u001b[0;32m   1639\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1640\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecoder_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1031\u001b[0m                 )\n\u001b[0;32m   1032\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1033\u001b[1;33m                 layer_outputs = layer_module(\n\u001b[0m\u001b[0;32m   1034\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1035\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[0;32m    718\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m         \u001b[1;31m# Apply Feed Forward layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 720\u001b[1;33m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    721\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    722\u001b[0m         \u001b[1;31m# clamp inf values to enable fp16 training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 327\u001b[1;33m         \u001b[0mforwarded_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    328\u001b[0m         \u001b[0mforwarded_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDenseReluDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforwarded_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhidden_states\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforwarded_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[0mvariance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhidden_states\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrsqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariance\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariance_epsilon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m         \u001b[1;31m# convert into half-precision if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# if(args.valid_begin==1):\n",
    "#     my_test(valid_dataloader,model_w,-1) #before train\n",
    "    # my_test(valid_dataloader,model_v,-1)  \n",
    "\n",
    "tot_iter = [0]\n",
    "for epoch in range(args.epochs):\n",
    "    lr_w = scheduler_w.get_lr()[0]\n",
    "    lr_v = scheduler_v.get_lr()[0]\n",
    "\n",
    "    logging.info(f\"\\n\\n  ----------------epoch:{epoch},\\t\\tlr_w:{lr_w},\\t\\tlr_v:{lr_v}----------------\")\n",
    "\n",
    "    w_train_loss,v_train_loss =  my_train(epoch, train_dataloader, valid_dataloader, model_w, model_v,  architect, A, w_optimizer, v_optimizer, lr_w,lr_v,tot_iter)\n",
    "    \n",
    "    scheduler_w.step()\n",
    "    scheduler_v.step()\n",
    "\n",
    "\n",
    "    logging.info(f\"w_train_loss:{w_train_loss},v_train_loss:{v_train_loss}\")\n",
    "    # wandb.log({'w_train_loss': w_train_loss, 'v_train_loss':v_train_loss})\n",
    "\n",
    "\n",
    "\n",
    "torch.save(model_v,'./model/'+now+'model_w.pt')\n",
    "torch.save(model_v,'./model/'+now+'model_v.pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.1+cu113'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2d33c3b0ef123e851f98887a8750ca7da758e4ff258891935cfe6ff9c0394387"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('python38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
