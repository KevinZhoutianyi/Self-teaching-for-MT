{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd() \n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from T5 import *\n",
    "from datasets import load_dataset,load_metric\n",
    "from transformers import T5Tokenizer\n",
    "from MT_hyperparams import *\n",
    "import torch.backends.cudnn as cudnn\n",
    "from utils import *\n",
    "from attention_params import *\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, SubsetRandomSampler\n",
    "from torch.autograd import Variable\n",
    "from losses import *\n",
    "from architect import *\n",
    "import logging\n",
    "import sys\n",
    "import transformers\n",
    "import time\n",
    "import argparse\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(\"main\")\n",
    "\n",
    "\n",
    "parser.add_argument('--valid_num_points', type=int,             default = 2000, help='validation data number')\n",
    "parser.add_argument('--train_num_points', type=int,             default = 100, help='train data number')\n",
    "\n",
    "parser.add_argument('--batch_size', type=int,                   default=16,     help='Batch size')\n",
    "parser.add_argument('--train_w_num_points', type=int,           default=4,      help='train_w_num_points for each batch')\n",
    "parser.add_argument('--train_w_synthetic_num_points', type=int, default=4,      help='train_w_synthetic_num_points for each batch')\n",
    "parser.add_argument('--train_v_num_points', type=int,           default=4,      help='train_v_num_points for each batch')\n",
    "parser.add_argument('--train_A_num_points', type=int,           default=4,      help='train_A_num_points decay for each batch')\n",
    "\n",
    "\n",
    "parser.add_argument('--gpu', type=int,                          default=0,      help='gpu device id')\n",
    "parser.add_argument('--epochs', type=int,                       default=50,     help='num of training epochs')\n",
    "parser.add_argument('--pre_epochs', type=int,                   default=3,      help='train model W for x epoch first')\n",
    "parser.add_argument('--grad_clip', type=float,                  default=5,      help='gradient clipping')\n",
    "\n",
    "parser.add_argument('--w_lr', type=float,                       default=5e-5,   help='learning rate for w')\n",
    "parser.add_argument('--v_lr', type=float,                       default=5e-5,   help='learning rate for v')\n",
    "parser.add_argument('--A_lr', type=float,                       default=1e-4,   help='learning rate for A')\n",
    "parser.add_argument('--learning_rate_min', type=float,          default=1e-5,   help='learning_rate_min')\n",
    "parser.add_argument('--decay', type=float,                      default=1e-3,   help='weight decay')\n",
    "parser.add_argument('--momentum', type=float,                   default=0.7,    help='momentum')\n",
    "\n",
    "\n",
    "parser.add_argument('--traindata_loss_ratio', type=float,       default=0.5,    help='human translated data ratio')\n",
    "parser.add_argument('--syndata_loss_ratio', type=float,         default=0.5,    help='augmented dataset ratio')\n",
    "\n",
    "parser.add_argument('--valid_begin', type=int,                  default=1,      help='whether valid before train')\n",
    "parser.add_argument('--train_A', type=int,                      default=1 ,     help='whether train A')\n",
    "\n",
    "\n",
    "args = parser.parse_args(args=[])#(args=['--batch_size', '8',  '--no_cuda'])#used in ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/20 06:31:37 PM |\t  Reusing dataset wmt14 (C:\\Users\\kevin\\.cache\\huggingface\\datasets\\wmt14\\de-en\\1.0.0\\d239eaf0ff090d28da19b6bc9758e24634d84de0a1ef092f0b5c54e6f132d7e2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 35.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/20 06:31:38 PM |\t  Namespace(A_lr=0.0001, batch_size=8, decay=0.001, epochs=50, gpu=0, grad_clip=5, learning_rate_min=1e-05, momentum=0.7, pre_epochs=0, syndata_loss_ratio=0.5, train_A=1, train_A_num_points=2, train_num_points=100, train_v_num_points=2, train_w_num_points=2, train_w_synthetic_num_points=2, traindata_loss_ratio=0.5, v_lr=5e-05, valid_begin=1, valid_num_points=200, w_lr=5e-05)\n",
      "03/20 06:31:38 PM |\t  DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 4508785\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 3000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 3003\n",
      "    })\n",
      "})\n",
      "03/20 06:31:38 PM |\t  {'translation': {'de': 'Ich bitte Sie, sich zu einer Schweigeminute zu erheben.', 'en': \"Please rise, then, for this minute' s silence.\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "now = time.strftime(\"%Y-%m-%d-%H_%M_%S\",time.localtime(time.time())) \n",
    "\n",
    "log_format = '%(asctime)s |\\t  %(message)s'\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO,\n",
    "    format=log_format, datefmt='%m/%d %I:%M:%S %p')\n",
    "fh = logging.FileHandler(os.path.join(\"./log/\", now+'.txt'),'w',encoding = \"UTF-8\")\n",
    "fh.setFormatter(logging.Formatter(log_format))\n",
    "logging.getLogger().addHandler(fh)\n",
    "dataset = load_dataset('wmt14','de-en')\n",
    "\n",
    "logging.info(args)\n",
    "logging.info(dataset)\n",
    "logging.info(dataset['train'][5])\n",
    "\n",
    "\n",
    "\n",
    "writer = SummaryWriter('tensorboard')\n",
    "\n",
    "# Setting the seeds\n",
    "np.random.seed(seed_)\n",
    "torch.cuda.set_device(args.gpu)\n",
    "cudnn.benchmark = True\n",
    "torch.manual_seed(seed_)\n",
    "cudnn.enabled=True\n",
    "torch.cuda.manual_seed(seed_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pretrained  =  T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "torch.save(pretrained,'T5BASE.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/20 06:32:09 PM |\t  train len: 96\n",
      "03/20 06:32:09 PM |\t  train_w_num_points_len: 24\n",
      "03/20 06:32:09 PM |\t  train_w_synthetic_num_points_len: 24\n",
      "03/20 06:32:09 PM |\t  train_v_num_points_len: 24\n",
      "03/20 06:32:09 PM |\t  train_A_num_points_len: 24\n",
      "03/20 06:32:09 PM |\t  valid len: 200\n",
      "03/20 06:32:09 PM |\t  test len: 3003\n",
      "03/20 06:32:09 PM |\t  {'de': 'Wie Sie feststellen konnten, ist der gefürchtete \"Millenium-Bug \" nicht eingetreten. Doch sind Bürger einiger unserer Mitgliedstaaten Opfer von schrecklichen Naturkatastrophen geworden.', 'en': \"translate English to German: Although, as you will have seen, the dreaded 'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\"}\n"
     ]
    }
   ],
   "source": [
    "# Load the tokenizer.\n",
    "import random\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss( reduction='none')#,ignore_index = tokenizer.pad_token_id)#\n",
    "# dataset = dataset.shuffle(seed=seed_)\n",
    "train = dataset['train']['translation'][:args.train_num_points]\n",
    "valid = dataset['validation']['translation'][:args.valid_num_points]\n",
    "test = dataset['test']['translation']#[L_t+L_v:L_t+L_v+L_test]\n",
    "def preprocess(dat):\n",
    "    for t in dat:\n",
    "        t['en'] = 'translate English to German: ' + t['en'] \n",
    "preprocess(train)\n",
    "preprocess(valid)\n",
    "preprocess(test)\n",
    "num_batch = args.train_num_points//args.batch_size\n",
    "train = train[:args.batch_size*num_batch]\n",
    "logging.info(\"train len: %d\",len(train))\n",
    "train_w_num_points_len = num_batch * args.train_w_num_points\n",
    "train_w_synthetic_num_points_len = num_batch * args.train_w_synthetic_num_points\n",
    "train_v_num_points_len = num_batch * args.train_v_num_points\n",
    "train_A_num_points_len = num_batch * args.train_A_num_points\n",
    "logging.info(\"train_w_num_points_len: %d\",train_w_num_points_len)\n",
    "logging.info(\"train_w_synthetic_num_points_len: %d\",train_w_synthetic_num_points_len)\n",
    "logging.info(\"train_v_num_points_len: %d\",train_v_num_points_len)\n",
    "logging.info(\"train_A_num_points_len: %d\",train_A_num_points_len)\n",
    "\n",
    "attn_idx_list = torch.arange(train_w_num_points_len).cuda()\n",
    "logging.info(\"valid len: %d\",len(valid))\n",
    "logging.info(\"test len: %d\" ,len(test))\n",
    "logging.info(train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_language  = 'de'\n",
    "train_data = get_train_Dataset(train, tokenizer)# Create the DataLoader for our training set.\n",
    "train_dataloader = DataLoader(train_data, sampler=SequentialSampler(train_data), \n",
    "                        batch_size=args.batch_size, pin_memory=True, num_workers=0)\n",
    "valid_data = get_aux_dataset(valid, tokenizer)# Create the DataLoader for our training set.\n",
    "valid_dataloader = DataLoader(valid_data, sampler=SequentialSampler(valid_data), \n",
    "                        batch_size=args.batch_size, pin_memory=True, num_workers=0)\n",
    "test_data = get_aux_dataset(test, tokenizer)# Create the DataLoader for our training set.\n",
    "test_dataloader = DataLoader(test_data, sampler=SequentialSampler(test_data),\n",
    "                        batch_size=args.batch_size, pin_memory=True, num_workers=0)#, sampler=RandomSampler(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "A = attention_params(train_w_num_points_len)#half of train regarded as u\n",
    "A = A.cuda()\n",
    "\n",
    "# TODO: model loaded from saved model\n",
    "model_w = T5(criterion=criterion, tokenizer= tokenizer, name = 'model_w_in_main')\n",
    "model_w = model_w.cuda()\n",
    "w_optimizer = torch.optim.Adam(model_w.parameters(),args.w_lr)#,momentum=args.momentum,weight_decay=args.decay)\n",
    "scheduler_w  = torch.optim.lr_scheduler.StepLR(w_optimizer,step_size=30, gamma=0.5)\n",
    "# scheduler_w  = torch.optim.lr_scheduler.CosineAnnealingLR(w_optimizer, float(args.epochs), eta_min=args.learning_rate_min)\n",
    "\n",
    "\n",
    "\n",
    "model_v = T5(criterion=criterion, tokenizer= tokenizer, name = 'model_v_in_main')\n",
    "model_v = model_v.cuda()\n",
    "v_optimizer = torch.optim.Adam(model_v.parameters(),args.v_lr)#,momentum=args.momentum,weight_decay=args.decay)\n",
    "scheduler_v  = torch.optim.lr_scheduler.StepLR(v_optimizer,step_size=30, gamma=0.5)\n",
    "# scheduler_v  = torch.optim.lr_scheduler.CosineAnnealingLR(v_optimizer, float(args.epochs), eta_min=args.learning_rate_min)\n",
    "\n",
    "\n",
    "\n",
    "architect = Architect(model_w, model_v,  A, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # x = ['im going to eat now ','it is my nameit is']\n",
    "# # for index,i in enumerate(x) :\n",
    "# #     x[index] = 'translate Enlgish to German:' + x[index]\n",
    "# # y= tokenize(x, tokenizer, max_length = max_length)\n",
    "# # input = y[0].cuda()\n",
    "# # output  = model_v.generate(input,max_length=max_length)\n",
    "# # tokenizer.batch_decode(output)\n",
    "\n",
    "\n",
    "# metric_bleu =  load_metric('sacrebleu')\n",
    "# predlist = ['Eine republikanische Strategie zur Bekämpfung der Wiederwahl Obamas','Die republikanischen Führer rechtfertigten ihre Politik mit der Notwendigkeit , Wahlbetrug zu bekämpfen .']\n",
    "# targetlist = ['Eine republikanische Strategie um der Wiederwahl von Obama entgegenzutreten','Die Führungskräfte der Republikaner rechtfertigen ihre Politik mit der Notwendigkeit , den Wahlbetrug zu bekämpfen']\n",
    "# predlist = ['Eine republikanische Strategie zur Bekämpfung der Wiederwahl Obamas', 'Die republikanischen Führer rechtfertigten ihre Politik mit der Notwendigkeit, Wahlbetrug zu bekämpfen.']\n",
    "# targetlist =['Eine republikanische Strategie, um der Wiederwahl von Obama entgegenzutreten', 'Die Führungskräfte der Republikaner rechtfertigen ihre Politik mit der Notwendigkeit, den Wahlbetrug zu bekämpfen.']\n",
    "# \n",
    "# predlist = [x.lower().translate( str.maketrans('', '', string.punctuation))  for x in predlist]\n",
    "# targetlist = [[x.lower().translate( str.maketrans('', '', string.punctuation))] for x in targetlist]\n",
    "# print(predlist)\n",
    "# print(targetlist)\n",
    "# metric_bleu.add_batch(predictions=predlist, references=targetlist)\n",
    "\n",
    "# sacrebleu_score = metric_bleu.compute()\n",
    "# print(sacrebleu_score)\n",
    "# from nltk.translate import bleu\n",
    "# from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "# def bleu(reference_captions, predicted_caption):\n",
    "#     return 100 * sentence_bleu(reference_captions, predicted_caption,\n",
    "#                                weights=(0.25, 0.25, 0.25,0.25), smoothing_function=SmoothingFunction().method1)\n",
    "# x = bleu(targetlist[1],predlist[1])+bleu(targetlist[0],predlist[0])\n",
    "# print(x/2)\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu,corpus_bleu\n",
    "def my_test(_dataloader,model,epoch):\n",
    "    acc = 0\n",
    "    counter = 0\n",
    "    model.eval()\n",
    "    metric_sacrebleu =  load_metric('sacrebleu')\n",
    "    metric_bleu =  load_metric('bleu')\n",
    "\n",
    "    for step, batch in enumerate(_dataloader):\n",
    "        test_dataloaderx = Variable(batch[0], requires_grad=False).cuda()\n",
    "        test_dataloaderx_attn = Variable(batch[1], requires_grad=False).cuda()\n",
    "        test_dataloadery = Variable(batch[2], requires_grad=False).cuda()\n",
    "        test_dataloadery_attn = Variable(batch[3], requires_grad=False).cuda()\n",
    "        with torch.no_grad():\n",
    "            ls = my_loss(test_dataloaderx,test_dataloaderx_attn,test_dataloadery,test_dataloadery_attn,model)\n",
    "            acc+= ls\n",
    "            counter+= 1\n",
    "            pre = model.generate(test_dataloaderx)\n",
    "            # print('pre',pre)\n",
    "            try:\n",
    "                x_decoded = tokenizer.batch_decode(test_dataloaderx,skip_special_tokens=True)\n",
    "                pred_decoded = tokenizer.batch_decode(pre,skip_special_tokens=True)\n",
    "                label_decoded =  tokenizer.batch_decode(test_dataloadery,skip_special_tokens=True)\n",
    "                \n",
    "                pred_str = [x.replace('.', '')  for x in pred_decoded]\n",
    "                label_str = [[x.replace('.', '')] for x in label_decoded]\n",
    "                pred_list = [x.replace('.', '').split()  for x in pred_decoded]\n",
    "                label_list = [[x.replace('.', '').split()] for x in label_decoded]\n",
    "                #pred_str = [x.translate( str.maketrans('', '', string.punctuation)) for x in pred_decoded] \n",
    "                # label_str = [[x.translate( str.maketrans('', '', string.punctuation))] for x in label_decoded]\n",
    "                # pred_list = [x.translate( str.maketrans('', '', string.punctuation)).split()  for x in pred_decoded]#TODO:improve\n",
    "                # label_list = [[x.translate( str.maketrans('', '', string.punctuation)).split()] for x in label_decoded]#TODO:improve\n",
    "                if  step%100==0:\n",
    "                    logging.info(f'x_decoded[:2]:{x_decoded[:2]}')\n",
    "                    logging.info(f'pred_decoded[:2]:{pred_decoded[:2]}')\n",
    "                    logging.info(f'label_decoded[:2]:{label_decoded[:2]}')\n",
    "                metric_sacrebleu.add_batch(predictions=pred_str, references=label_str)\n",
    "                metric_bleu.add_batch(predictions=pred_list, references=label_list)\n",
    "                \n",
    "               \n",
    "            except Exception as ex:\n",
    "                print(tokenizer.batch_decode(pre),[[x] for x in tokenizer.batch_decode(test_dataloadery)])\n",
    "                raise Exception(ex)\n",
    "        # logging.info(f\"loss:{ls}\")\n",
    "    sacrebleu_score = metric_sacrebleu.compute()\n",
    "    bleu_score = metric_bleu.compute()\n",
    "    logging.info('%s sacreBLEU : %f',model.name,sacrebleu_score['score'])\n",
    "    logging.info('%s BLEU : %f',model.name,bleu_score['bleu'])\n",
    "    logging.info('%s test loss : %f',model.name,acc/(counter))\n",
    "    writer.add_scalar(model.name+\"/test_loss\", acc/counter, global_step=epoch)\n",
    "    writer.add_scalar(model.name+\"/sacreBLEU\",sacrebleu_score['score'], global_step=epoch)\n",
    "    writer.add_scalar(model.name+\"/BLEU\",bleu_score['bleu'], global_step=epoch)\n",
    "    model.train()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_train(epoch, _dataloader, w_model, v_model, architect, A, w_optimizer, v_optimizer, lr_w, lr_v, ):\n",
    "    \n",
    "    v_trainloss_acc = 0\n",
    "    w_trainloss_acc = 0\n",
    "    counter = 0\n",
    "    wsize = args.train_w_num_points #now  train_x is [num of batch, datasize], so its seperate batch for the code below\n",
    "    synsize = args.train_w_synthetic_num_points\n",
    "    vsize = args.train_v_num_points \n",
    "    Asize = args.train_A_num_points \n",
    "    for step, batch in enumerate(_dataloader):\n",
    "        counter+=1\n",
    "        batch_loss_w, batch_loss_v = 0, 0\n",
    "        \n",
    "        train_x = Variable(batch[0], requires_grad=False).cuda()\n",
    "        train_x_attn = Variable(batch[1], requires_grad=False).cuda()\n",
    "        train_y = Variable(batch[2], requires_grad=False).cuda()\n",
    "        train_y_attn = Variable(batch[3], requires_grad=False).cuda() \n",
    "\n",
    "        input_w = train_x[:wsize]\n",
    "        \n",
    "        input_w_attn = train_x_attn[:wsize]\n",
    "        output_w = train_y[:wsize]\n",
    "        output_w_attn = train_y_attn[:wsize]\n",
    "        attn_idx = attn_idx_list[args.train_w_num_points*step:(args.train_w_num_points*step+args.train_w_num_points)]\n",
    "           \n",
    "        input_syn = train_x[wsize:wsize+synsize]\n",
    "        input_syn_attn = train_x_attn[wsize:wsize+synsize]\n",
    "\n",
    "        input_v = train_x[wsize+synsize:wsize+synsize+vsize]\n",
    "        input_v_attn = train_x_attn[wsize+synsize:wsize+synsize+vsize]\n",
    "        output_v = train_y[wsize+synsize:wsize+synsize+vsize]\n",
    "        output_v_attn = train_y_attn[wsize+synsize:wsize+synsize+vsize]\n",
    "\n",
    "        input_A_v      = train_x[wsize+synsize+vsize:wsize+synsize+vsize+Asize]\n",
    "        input_A_v_attn = train_x_attn[wsize+synsize+vsize:wsize+synsize+vsize+Asize]\n",
    "        output_A_v      = train_y[wsize+synsize+vsize:wsize+synsize+vsize+Asize]\n",
    "        output_A_v_attn = train_y_attn[wsize+synsize+vsize:wsize+synsize+vsize+Asize]\n",
    "       \n",
    "\n",
    "        if (epoch <= args.epochs) and (args.train_A == 1):\n",
    "            architect.step(input_w,  output_w,input_w_attn, output_w_attn, w_optimizer, input_syn, input_syn_attn,input_A_v, input_A_v_attn, output_A_v, \n",
    "                output_A_v_attn, v_optimizer, attn_idx, lr_w, lr_v)\n",
    "        \n",
    "        if  epoch <= args.epochs and epoch <= args.epochs:\n",
    "            \n",
    "            w_optimizer.zero_grad()\n",
    "            loss_w = CTG_loss(input_w, input_w_attn, output_w, output_w_attn, attn_idx, A, w_model)\n",
    "            batch_loss_w += loss_w.item()\n",
    "            w_trainloss_acc+=loss_w.item()\n",
    "            loss_w.backward()\n",
    "            # nn.utils.clip_grad_norm(w_model.parameters(), args.grad_clip)\n",
    "            w_optimizer.step()\n",
    "        if epoch >= args.pre_epochs and epoch <= args.epochs:\n",
    "            v_optimizer.zero_grad()\n",
    "            loss_aug = calc_loss_aug(input_syn, input_syn_attn, w_model, v_model)#,input_v,input_v_attn,output_v,output_v_attn)\n",
    "            loss = my_loss2(input_v,input_v_attn,output_v,output_v_attn,model_v)\n",
    "            \n",
    "            v_loss =  (args.syndata_loss_ratio*loss_aug+args.traindata_loss_ratio*loss)/num_batch\n",
    "            \n",
    "            batch_loss_v += v_loss.item()\n",
    "            v_trainloss_acc+=v_loss.item()\n",
    "            v_loss.backward()\n",
    "            # nn.utils.clip_grad_norm(v_model.parameters(), args.grad_clip)\n",
    "            v_optimizer.step()     \n",
    "                \n",
    "            \n",
    "        if(step*args.batch_size%5==0):\n",
    "            logging.info(f\"{step*args.batch_size*100/(args.train_num_points)}%\")\n",
    "    logging.info(str((\"Attention Weights A : \", A.alpha)))\n",
    "    \n",
    "    return w_trainloss_acc,v_trainloss_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/20 06:32:16 PM |\t  x_decoded[:2]:[\"translate English to German: Although, as you will have seen, the dreaded'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\", 'translate English to German: You have requested a debate on this subject in the course of the next few days, during this part-session.']\n",
      "03/20 06:32:16 PM |\t  pred_decoded[:2]:['Obwohl, wie Sie gesehen haben, der gefürchtete \"Millennium-Fehler\" nicht zustande gekommen ist, erlitten die Menschen in einigen Ländern immer noch eine Reihe von Naturkatastrophen, die wirklich schrecklich waren.', 'Sie haben in den nächsten Tagen, in dieser Sitzung, eine Aussprache zu diesem Thema beantragt.']\n",
      "03/20 06:32:16 PM |\t  label_decoded[:2]:['Wie Sie feststellen konnten, ist der gefürchtete \"Millenium-Bug \" nicht eingetreten. Doch sind Bürger einiger unserer Mitgliedstaaten Opfer von schrecklichen Naturkatastrophen geworden.', 'Im Parlament besteht der Wunsch nach einer Aussprache im Verlauf dieser Sitzungsperiode in den nächsten Tagen.']\n",
      "03/20 06:32:32 PM |\t  model_w_in_main sacreBLEU : 19.735388\n",
      "03/20 06:32:32 PM |\t  model_w_in_main BLEU : 0.162411\n",
      "03/20 06:32:32 PM |\t  model_w_in_main test loss : 0.496536\n",
      "03/20 06:32:34 PM |\t  x_decoded[:2]:[\"translate English to German: Although, as you will have seen, the dreaded'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\", 'translate English to German: You have requested a debate on this subject in the course of the next few days, during this part-session.']\n",
      "03/20 06:32:34 PM |\t  pred_decoded[:2]:['Obwohl, wie Sie gesehen haben, der gefürchtete \"Millennium-Fehler\" nicht zustande gekommen ist, erlitten die Menschen in einigen Ländern immer noch eine Reihe von Naturkatastrophen, die wirklich schrecklich waren.', 'Sie haben in den nächsten Tagen, in dieser Sitzung, eine Aussprache zu diesem Thema beantragt.']\n",
      "03/20 06:32:34 PM |\t  label_decoded[:2]:['Wie Sie feststellen konnten, ist der gefürchtete \"Millenium-Bug \" nicht eingetreten. Doch sind Bürger einiger unserer Mitgliedstaaten Opfer von schrecklichen Naturkatastrophen geworden.', 'Im Parlament besteht der Wunsch nach einer Aussprache im Verlauf dieser Sitzungsperiode in den nächsten Tagen.']\n",
      "03/20 06:32:50 PM |\t  model_v_in_main sacreBLEU : 19.735388\n",
      "03/20 06:32:50 PM |\t  model_v_in_main BLEU : 0.162411\n",
      "03/20 06:32:50 PM |\t  model_v_in_main test loss : 0.496536\n",
      "03/20 06:32:50 PM |\t  \n",
      "\n",
      "  ----------------epoch:0,\t\tlr_w:5e-05,\t\tlr_v:5e-05----------------\n",
      "03/20 06:32:58 PM |\t  0.0%\n",
      "03/20 06:33:36 PM |\t  40.0%\n",
      "03/20 06:34:17 PM |\t  80.0%\n",
      "03/20 06:34:21 PM |\t  ('Attention Weights A : ', Parameter containing:\n",
      "tensor([0.0418, 0.0417, 0.0413, 0.0415, 0.0413, 0.0416, 0.0416, 0.0415, 0.0413,\n",
      "        0.0413, 0.0415, 0.0416, 0.0417, 0.0413, 0.0417, 0.0416, 0.0419, 0.0414,\n",
      "        0.0417, 0.0414, 0.0416, 0.0421, 0.0416, 0.0416], device='cuda:0',\n",
      "       requires_grad=True))\n",
      "03/20 06:34:21 PM |\t  w_train_loss:0.47920547565445304,v_train_loss:0.12227024254389107\n",
      "03/20 06:34:24 PM |\t  x_decoded[:2]:[\"translate English to German: Although, as you will have seen, the dreaded'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\", 'translate English to German: You have requested a debate on this subject in the course of the next few days, during this part-session.']\n",
      "03/20 06:34:24 PM |\t  pred_decoded[:2]:['Obwohl, wie Sie gesehen haben, der gefürchtete \"Millennium-Fehler\" nicht zustande gekommen ist, erlitten die Menschen in einigen Ländern immer noch eine Reihe von Naturkatastrophen, die wirklich schrecklich waren.', 'Sie haben in den nächsten Tagen, in dieser Sitzung, eine Aussprache zu diesem Thema beantragt.']\n",
      "03/20 06:34:24 PM |\t  label_decoded[:2]:['Wie Sie feststellen konnten, ist der gefürchtete \"Millenium-Bug \" nicht eingetreten. Doch sind Bürger einiger unserer Mitgliedstaaten Opfer von schrecklichen Naturkatastrophen geworden.', 'Im Parlament besteht der Wunsch nach einer Aussprache im Verlauf dieser Sitzungsperiode in den nächsten Tagen.']\n",
      "03/20 06:34:41 PM |\t  model_w_in_main sacreBLEU : 19.579981\n",
      "03/20 06:34:41 PM |\t  model_w_in_main BLEU : 0.161558\n",
      "03/20 06:34:41 PM |\t  model_w_in_main test loss : 0.479616\n",
      "03/20 06:34:43 PM |\t  x_decoded[:2]:[\"translate English to German: Although, as you will have seen, the dreaded'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\", 'translate English to German: You have requested a debate on this subject in the course of the next few days, during this part-session.']\n",
      "03/20 06:34:43 PM |\t  pred_decoded[:2]:['Obwohl, wie Sie gesehen haben, der gefürchtete \"Millennium-Fehler\" nicht zustande gekommen ist, erlitten die Menschen in einigen Ländern immer noch eine Reihe von Naturkatastrophen, die wirklich schrecklich waren.', 'Sie haben in den nächsten Tagen, in dieser Sitzung, eine Aussprache zu diesem Thema beantragt.']\n",
      "03/20 06:34:43 PM |\t  label_decoded[:2]:['Wie Sie feststellen konnten, ist der gefürchtete \"Millenium-Bug \" nicht eingetreten. Doch sind Bürger einiger unserer Mitgliedstaaten Opfer von schrecklichen Naturkatastrophen geworden.', 'Im Parlament besteht der Wunsch nach einer Aussprache im Verlauf dieser Sitzungsperiode in den nächsten Tagen.']\n",
      "03/20 06:34:59 PM |\t  model_v_in_main sacreBLEU : 20.157911\n",
      "03/20 06:34:59 PM |\t  model_v_in_main BLEU : 0.164109\n",
      "03/20 06:34:59 PM |\t  model_v_in_main test loss : 0.496553\n",
      "03/20 06:34:59 PM |\t  \n",
      "\n",
      "  ----------------epoch:1,\t\tlr_w:5e-05,\t\tlr_v:5e-05----------------\n",
      "03/20 06:35:08 PM |\t  0.0%\n",
      "03/20 06:35:46 PM |\t  40.0%\n",
      "03/20 06:36:26 PM |\t  80.0%\n",
      "03/20 06:36:29 PM |\t  ('Attention Weights A : ', Parameter containing:\n",
      "tensor([0.0420, 0.0416, 0.0413, 0.0412, 0.0414, 0.0417, 0.0418, 0.0417, 0.0418,\n",
      "        0.0413, 0.0417, 0.0419, 0.0419, 0.0414, 0.0420, 0.0417, 0.0421, 0.0416,\n",
      "        0.0417, 0.0418, 0.0417, 0.0419, 0.0418, 0.0418], device='cuda:0',\n",
      "       requires_grad=True))\n",
      "03/20 06:36:29 PM |\t  w_train_loss:0.41423492413014174,v_train_loss:0.11357149970717728\n",
      "03/20 06:36:32 PM |\t  x_decoded[:2]:[\"translate English to German: Although, as you will have seen, the dreaded'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\", 'translate English to German: You have requested a debate on this subject in the course of the next few days, during this part-session.']\n",
      "03/20 06:36:32 PM |\t  pred_decoded[:2]:['Obwohl, wie Sie gesehen haben, der gefürchtete \"Millennium-Fehler\" nicht zustande gekommen ist, erlitten die Menschen in einigen Ländern immer noch eine Reihe von Naturkatastrophen, die wirklich schrecklich waren.', 'Sie haben in den nächsten Tagen, in dieser Sitzung, eine Aussprache zu diesem Thema beantragt.']\n",
      "03/20 06:36:32 PM |\t  label_decoded[:2]:['Wie Sie feststellen konnten, ist der gefürchtete \"Millenium-Bug \" nicht eingetreten. Doch sind Bürger einiger unserer Mitgliedstaaten Opfer von schrecklichen Naturkatastrophen geworden.', 'Im Parlament besteht der Wunsch nach einer Aussprache im Verlauf dieser Sitzungsperiode in den nächsten Tagen.']\n",
      "03/20 06:36:48 PM |\t  model_w_in_main sacreBLEU : 20.653460\n",
      "03/20 06:36:48 PM |\t  model_w_in_main BLEU : 0.172352\n",
      "03/20 06:36:48 PM |\t  model_w_in_main test loss : 0.433959\n",
      "03/20 06:36:51 PM |\t  x_decoded[:2]:[\"translate English to German: Although, as you will have seen, the dreaded'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\", 'translate English to German: You have requested a debate on this subject in the course of the next few days, during this part-session.']\n",
      "03/20 06:36:51 PM |\t  pred_decoded[:2]:['Obwohl, wie Sie gesehen haben, der gefürchtete \"Millennium-Fehler\" nicht zustande gekommen ist, erlitten die Menschen in einigen Ländern immer noch eine Reihe von Naturkatastrophen, die wirklich schrecklich waren.', 'Sie haben in den nächsten Tagen, während dieser Sitzung, eine Aussprache zu diesem Thema beantragt.']\n",
      "03/20 06:36:51 PM |\t  label_decoded[:2]:['Wie Sie feststellen konnten, ist der gefürchtete \"Millenium-Bug \" nicht eingetreten. Doch sind Bürger einiger unserer Mitgliedstaaten Opfer von schrecklichen Naturkatastrophen geworden.', 'Im Parlament besteht der Wunsch nach einer Aussprache im Verlauf dieser Sitzungsperiode in den nächsten Tagen.']\n",
      "03/20 06:37:07 PM |\t  model_v_in_main sacreBLEU : 21.315310\n",
      "03/20 06:37:07 PM |\t  model_v_in_main BLEU : 0.176924\n",
      "03/20 06:37:07 PM |\t  model_v_in_main test loss : 0.499863\n",
      "03/20 06:37:07 PM |\t  \n",
      "\n",
      "  ----------------epoch:2,\t\tlr_w:5e-05,\t\tlr_v:5e-05----------------\n",
      "03/20 06:37:14 PM |\t  0.0%\n",
      "03/20 06:37:51 PM |\t  40.0%\n",
      "03/20 06:38:31 PM |\t  80.0%\n",
      "03/20 06:38:35 PM |\t  ('Attention Weights A : ', Parameter containing:\n",
      "tensor([0.0421, 0.0417, 0.0416, 0.0414, 0.0415, 0.0418, 0.0419, 0.0417, 0.0416,\n",
      "        0.0413, 0.0418, 0.0420, 0.0419, 0.0414, 0.0421, 0.0418, 0.0420, 0.0417,\n",
      "        0.0420, 0.0418, 0.0420, 0.0418, 0.0418, 0.0418], device='cuda:0',\n",
      "       requires_grad=True))\n",
      "03/20 06:38:35 PM |\t  w_train_loss:0.4023441728204489,v_train_loss:0.11087448615580797\n",
      "03/20 06:38:39 PM |\t  x_decoded[:2]:[\"translate English to German: Although, as you will have seen, the dreaded'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\", 'translate English to German: You have requested a debate on this subject in the course of the next few days, during this part-session.']\n",
      "03/20 06:38:39 PM |\t  pred_decoded[:2]:['Obwohl, wie Sie gesehen haben, der gefürchtete \"Millennium-Fehler\" nicht zustande kam, erlitten die Menschen in einigen Ländern noch immer eine Reihe von Naturkatastrophen, die wirklich schrecklich waren.', 'Sie haben in den nächsten Tagen, in dieser Sitzung, eine Aussprache zu diesem Thema beantragt.']\n",
      "03/20 06:38:39 PM |\t  label_decoded[:2]:['Wie Sie feststellen konnten, ist der gefürchtete \"Millenium-Bug \" nicht eingetreten. Doch sind Bürger einiger unserer Mitgliedstaaten Opfer von schrecklichen Naturkatastrophen geworden.', 'Im Parlament besteht der Wunsch nach einer Aussprache im Verlauf dieser Sitzungsperiode in den nächsten Tagen.']\n",
      "03/20 06:38:55 PM |\t  model_w_in_main sacreBLEU : 20.977830\n",
      "03/20 06:38:55 PM |\t  model_w_in_main BLEU : 0.174650\n",
      "03/20 06:38:55 PM |\t  model_w_in_main test loss : 0.416046\n",
      "03/20 06:38:58 PM |\t  x_decoded[:2]:[\"translate English to German: Although, as you will have seen, the dreaded'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\", 'translate English to German: You have requested a debate on this subject in the course of the next few days, during this part-session.']\n",
      "03/20 06:38:58 PM |\t  pred_decoded[:2]:['Obwohl, wie Sie gesehen haben, der gefürchtete \"Millennium-Fehler\" nicht zustande gekommen ist, erlitten die Menschen in einigen Ländern immer noch eine Reihe von Naturkatastrophen, die wirklich schrecklich waren.', 'Sie haben in den nächsten Tagen, während dieser Sitzung, eine Aussprache zu diesem Thema beantragt.']\n",
      "03/20 06:38:58 PM |\t  label_decoded[:2]:['Wie Sie feststellen konnten, ist der gefürchtete \"Millenium-Bug \" nicht eingetreten. Doch sind Bürger einiger unserer Mitgliedstaaten Opfer von schrecklichen Naturkatastrophen geworden.', 'Im Parlament besteht der Wunsch nach einer Aussprache im Verlauf dieser Sitzungsperiode in den nächsten Tagen.']\n",
      "03/20 06:39:13 PM |\t  model_v_in_main sacreBLEU : 21.165852\n",
      "03/20 06:39:13 PM |\t  model_v_in_main BLEU : 0.172175\n",
      "03/20 06:39:13 PM |\t  model_v_in_main test loss : 0.501937\n",
      "03/20 06:39:13 PM |\t  \n",
      "\n",
      "  ----------------epoch:3,\t\tlr_w:5e-05,\t\tlr_v:5e-05----------------\n",
      "03/20 06:39:22 PM |\t  0.0%\n",
      "03/20 06:39:58 PM |\t  40.0%\n",
      "03/20 06:40:40 PM |\t  80.0%\n",
      "03/20 06:40:44 PM |\t  ('Attention Weights A : ', Parameter containing:\n",
      "tensor([0.0419, 0.0416, 0.0417, 0.0414, 0.0413, 0.0416, 0.0417, 0.0415, 0.0413,\n",
      "        0.0411, 0.0415, 0.0418, 0.0417, 0.0414, 0.0419, 0.0416, 0.0416, 0.0416,\n",
      "        0.0418, 0.0418, 0.0423, 0.0419, 0.0416, 0.0417], device='cuda:0',\n",
      "       requires_grad=True))\n",
      "03/20 06:40:44 PM |\t  w_train_loss:0.3530792114324868,v_train_loss:0.10015519359149039\n",
      "03/20 06:40:47 PM |\t  x_decoded[:2]:[\"translate English to German: Although, as you will have seen, the dreaded'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\", 'translate English to German: You have requested a debate on this subject in the course of the next few days, during this part-session.']\n",
      "03/20 06:40:47 PM |\t  pred_decoded[:2]:['Obwohl, wie Sie gesehen haben, der gefürchtete \"Millennium-Fehler\" nicht zustande kam, erlitten die Menschen in einigen Ländern noch immer eine Reihe von Naturkatastrophen, die wirklich schrecklich waren.', 'Sie haben in den nächsten Tagen, in dieser Sitzung, eine Aussprache zu diesem Thema beantragt.']\n",
      "03/20 06:40:47 PM |\t  label_decoded[:2]:['Wie Sie feststellen konnten, ist der gefürchtete \"Millenium-Bug \" nicht eingetreten. Doch sind Bürger einiger unserer Mitgliedstaaten Opfer von schrecklichen Naturkatastrophen geworden.', 'Im Parlament besteht der Wunsch nach einer Aussprache im Verlauf dieser Sitzungsperiode in den nächsten Tagen.']\n",
      "03/20 06:41:03 PM |\t  model_w_in_main sacreBLEU : 19.848744\n",
      "03/20 06:41:03 PM |\t  model_w_in_main BLEU : 0.162201\n",
      "03/20 06:41:03 PM |\t  model_w_in_main test loss : 0.403587\n",
      "03/20 06:41:06 PM |\t  x_decoded[:2]:[\"translate English to German: Although, as you will have seen, the dreaded'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\", 'translate English to German: You have requested a debate on this subject in the course of the next few days, during this part-session.']\n",
      "03/20 06:41:06 PM |\t  pred_decoded[:2]:['Obwohl, wie Sie gesehen haben, der gefürchtete \"Millennium-Fehler\" nicht zustande gekommen ist, erlitten die Menschen in einigen Ländern immer noch eine Reihe von Naturkatastrophen, die wirklich schrecklich waren.', 'Sie haben in den nächsten Tagen, während dieser Sitzung, eine Aussprache zu diesem Thema beantragt.']\n",
      "03/20 06:41:06 PM |\t  label_decoded[:2]:['Wie Sie feststellen konnten, ist der gefürchtete \"Millenium-Bug \" nicht eingetreten. Doch sind Bürger einiger unserer Mitgliedstaaten Opfer von schrecklichen Naturkatastrophen geworden.', 'Im Parlament besteht der Wunsch nach einer Aussprache im Verlauf dieser Sitzungsperiode in den nächsten Tagen.']\n",
      "03/20 06:41:22 PM |\t  model_v_in_main sacreBLEU : 20.816003\n",
      "03/20 06:41:22 PM |\t  model_v_in_main BLEU : 0.169707\n",
      "03/20 06:41:22 PM |\t  model_v_in_main test loss : 0.505180\n",
      "03/20 06:41:22 PM |\t  \n",
      "\n",
      "  ----------------epoch:4,\t\tlr_w:5e-05,\t\tlr_v:5e-05----------------\n",
      "03/20 06:41:30 PM |\t  0.0%\n",
      "03/20 06:42:08 PM |\t  40.0%\n",
      "03/20 06:42:50 PM |\t  80.0%\n",
      "03/20 06:42:54 PM |\t  ('Attention Weights A : ', Parameter containing:\n",
      "tensor([0.0417, 0.0416, 0.0416, 0.0411, 0.0412, 0.0415, 0.0416, 0.0414, 0.0412,\n",
      "        0.0409, 0.0413, 0.0416, 0.0417, 0.0414, 0.0418, 0.0417, 0.0416, 0.0417,\n",
      "        0.0417, 0.0414, 0.0420, 0.0421, 0.0416, 0.0416], device='cuda:0',\n",
      "       requires_grad=True))\n",
      "03/20 06:42:54 PM |\t  w_train_loss:0.3452456588856876,v_train_loss:0.09554526361171156\n",
      "03/20 06:42:57 PM |\t  x_decoded[:2]:[\"translate English to German: Although, as you will have seen, the dreaded'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\", 'translate English to German: You have requested a debate on this subject in the course of the next few days, during this part-session.']\n",
      "03/20 06:42:57 PM |\t  pred_decoded[:2]:['Obwohl, wie Sie gesehen haben, der gefürchtete \"Millennium-Fehler\" nicht zustande kam, erlitten die Menschen in einigen Ländern immer noch eine Reihe von Naturkatastrophen, die wirklich schrecklich waren.', 'Sie haben in den nächsten Tagen, in dieser Sitzung, eine Aussprache zu diesem Thema beantragt.']\n",
      "03/20 06:42:57 PM |\t  label_decoded[:2]:['Wie Sie feststellen konnten, ist der gefürchtete \"Millenium-Bug \" nicht eingetreten. Doch sind Bürger einiger unserer Mitgliedstaaten Opfer von schrecklichen Naturkatastrophen geworden.', 'Im Parlament besteht der Wunsch nach einer Aussprache im Verlauf dieser Sitzungsperiode in den nächsten Tagen.']\n",
      "03/20 06:43:13 PM |\t  model_w_in_main sacreBLEU : 20.117257\n",
      "03/20 06:43:13 PM |\t  model_w_in_main BLEU : 0.165721\n",
      "03/20 06:43:13 PM |\t  model_w_in_main test loss : 0.395002\n",
      "03/20 06:43:16 PM |\t  x_decoded[:2]:[\"translate English to German: Although, as you will have seen, the dreaded'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\", 'translate English to German: You have requested a debate on this subject in the course of the next few days, during this part-session.']\n",
      "03/20 06:43:16 PM |\t  pred_decoded[:2]:['Obwohl, wie Sie gesehen haben, der gefürchtete \"Millennium-Fehler\" nicht zustande gekommen ist, erlitten die Menschen in einigen Ländern immer noch eine Reihe von Naturkatastrophen, die wirklich schrecklich waren.', 'Sie haben in den nächsten Tagen, in dieser Sitzung, eine Aussprache zu diesem Thema beantragt.']\n",
      "03/20 06:43:16 PM |\t  label_decoded[:2]:['Wie Sie feststellen konnten, ist der gefürchtete \"Millenium-Bug \" nicht eingetreten. Doch sind Bürger einiger unserer Mitgliedstaaten Opfer von schrecklichen Naturkatastrophen geworden.', 'Im Parlament besteht der Wunsch nach einer Aussprache im Verlauf dieser Sitzungsperiode in den nächsten Tagen.']\n",
      "03/20 06:43:32 PM |\t  model_v_in_main sacreBLEU : 20.880708\n",
      "03/20 06:43:32 PM |\t  model_v_in_main BLEU : 0.168260\n",
      "03/20 06:43:32 PM |\t  model_v_in_main test loss : 0.508341\n",
      "03/20 06:43:32 PM |\t  \n",
      "\n",
      "  ----------------epoch:5,\t\tlr_w:5e-05,\t\tlr_v:5e-05----------------\n",
      "03/20 06:43:40 PM |\t  0.0%\n",
      "03/20 06:44:17 PM |\t  40.0%\n",
      "03/20 06:44:58 PM |\t  80.0%\n",
      "03/20 06:45:02 PM |\t  ('Attention Weights A : ', Parameter containing:\n",
      "tensor([0.0417, 0.0417, 0.0417, 0.0409, 0.0412, 0.0414, 0.0416, 0.0414, 0.0411,\n",
      "        0.0411, 0.0413, 0.0417, 0.0417, 0.0412, 0.0419, 0.0417, 0.0416, 0.0417,\n",
      "        0.0418, 0.0414, 0.0414, 0.0422, 0.0416, 0.0416], device='cuda:0',\n",
      "       requires_grad=True))\n",
      "03/20 06:45:02 PM |\t  w_train_loss:0.3301439434289932,v_train_loss:0.09012485854327679\n",
      "03/20 06:45:05 PM |\t  x_decoded[:2]:[\"translate English to German: Although, as you will have seen, the dreaded'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\", 'translate English to German: You have requested a debate on this subject in the course of the next few days, during this part-session.']\n",
      "03/20 06:45:05 PM |\t  pred_decoded[:2]:['Obwohl, wie Sie gesehen haben, der gefürchtete \"Millennium-Fehler\" nicht zustande kam, erlitten die Menschen in einigen Ländern immer noch eine Reihe von Naturkatastrophen, die wirklich schrecklich waren.', 'Sie haben in den nächsten Tagen, in dieser Sitzung, eine Aussprache zu diesem Thema beantragt.']\n",
      "03/20 06:45:05 PM |\t  label_decoded[:2]:['Wie Sie feststellen konnten, ist der gefürchtete \"Millenium-Bug \" nicht eingetreten. Doch sind Bürger einiger unserer Mitgliedstaaten Opfer von schrecklichen Naturkatastrophen geworden.', 'Im Parlament besteht der Wunsch nach einer Aussprache im Verlauf dieser Sitzungsperiode in den nächsten Tagen.']\n",
      "03/20 06:45:21 PM |\t  model_w_in_main sacreBLEU : 20.025703\n",
      "03/20 06:45:21 PM |\t  model_w_in_main BLEU : 0.164328\n",
      "03/20 06:45:21 PM |\t  model_w_in_main test loss : 0.390604\n",
      "03/20 06:45:24 PM |\t  x_decoded[:2]:[\"translate English to German: Although, as you will have seen, the dreaded'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\", 'translate English to German: You have requested a debate on this subject in the course of the next few days, during this part-session.']\n",
      "03/20 06:45:24 PM |\t  pred_decoded[:2]:['Obwohl, wie Sie gesehen haben, der gefürchtete \"Millennium-Fehler\" nicht zustande gekommen ist, erlitten die Menschen in einigen Ländern immer noch eine Reihe von Naturkatastrophen, die wirklich schrecklich waren.', 'Sie haben in den nächsten Tagen, in dieser Sitzung, eine Aussprache zu diesem Thema beantragt.']\n",
      "03/20 06:45:24 PM |\t  label_decoded[:2]:['Wie Sie feststellen konnten, ist der gefürchtete \"Millenium-Bug \" nicht eingetreten. Doch sind Bürger einiger unserer Mitgliedstaaten Opfer von schrecklichen Naturkatastrophen geworden.', 'Im Parlament besteht der Wunsch nach einer Aussprache im Verlauf dieser Sitzungsperiode in den nächsten Tagen.']\n",
      "03/20 06:45:40 PM |\t  model_v_in_main sacreBLEU : 20.696681\n",
      "03/20 06:45:40 PM |\t  model_v_in_main BLEU : 0.164359\n",
      "03/20 06:45:40 PM |\t  model_v_in_main test loss : 0.510877\n",
      "03/20 06:45:40 PM |\t  \n",
      "\n",
      "  ----------------epoch:6,\t\tlr_w:5e-05,\t\tlr_v:5e-05----------------\n",
      "03/20 06:45:48 PM |\t  0.0%\n",
      "03/20 06:46:24 PM |\t  40.0%\n",
      "03/20 06:47:06 PM |\t  80.0%\n",
      "03/20 06:47:10 PM |\t  ('Attention Weights A : ', Parameter containing:\n",
      "tensor([0.0419, 0.0415, 0.0415, 0.0405, 0.0409, 0.0417, 0.0417, 0.0416, 0.0411,\n",
      "        0.0411, 0.0414, 0.0417, 0.0418, 0.0414, 0.0420, 0.0420, 0.0418, 0.0418,\n",
      "        0.0421, 0.0418, 0.0412, 0.0422, 0.0417, 0.0417], device='cuda:0',\n",
      "       requires_grad=True))\n",
      "03/20 06:47:10 PM |\t  w_train_loss:0.3116975072771311,v_train_loss:0.08476075099315494\n",
      "03/20 06:47:13 PM |\t  x_decoded[:2]:[\"translate English to German: Although, as you will have seen, the dreaded'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\", 'translate English to German: You have requested a debate on this subject in the course of the next few days, during this part-session.']\n",
      "03/20 06:47:13 PM |\t  pred_decoded[:2]:['Obwohl, wie Sie gesehen haben, der gefürchtete \"Millennium-Fehler\" nicht zustande kam, erlitten die Menschen in einigen Ländern immer noch eine Reihe von Naturkatastrophen, die wirklich schrecklich waren.', 'Sie haben in den nächsten Tagen, in dieser Sitzung, eine Aussprache zu diesem Thema beantragt.']\n",
      "03/20 06:47:13 PM |\t  label_decoded[:2]:['Wie Sie feststellen konnten, ist der gefürchtete \"Millenium-Bug \" nicht eingetreten. Doch sind Bürger einiger unserer Mitgliedstaaten Opfer von schrecklichen Naturkatastrophen geworden.', 'Im Parlament besteht der Wunsch nach einer Aussprache im Verlauf dieser Sitzungsperiode in den nächsten Tagen.']\n",
      "03/20 06:47:29 PM |\t  model_w_in_main sacreBLEU : 20.039004\n",
      "03/20 06:47:29 PM |\t  model_w_in_main BLEU : 0.164467\n",
      "03/20 06:47:29 PM |\t  model_w_in_main test loss : 0.388662\n",
      "03/20 06:47:32 PM |\t  x_decoded[:2]:[\"translate English to German: Although, as you will have seen, the dreaded'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\", 'translate English to German: You have requested a debate on this subject in the course of the next few days, during this part-session.']\n",
      "03/20 06:47:32 PM |\t  pred_decoded[:2]:['Obwohl der gefürchtete \"Millennium-Fehler\" nicht zustande gekommen ist, haben die Menschen in einigen Ländern noch immer eine Reihe von Naturkatastrophen erlitten, die wirklich schrecklich waren.', 'Sie haben in den nächsten Tagen, in dieser Sitzung, eine Aussprache zu diesem Thema beantragt.']\n",
      "03/20 06:47:32 PM |\t  label_decoded[:2]:['Wie Sie feststellen konnten, ist der gefürchtete \"Millenium-Bug \" nicht eingetreten. Doch sind Bürger einiger unserer Mitgliedstaaten Opfer von schrecklichen Naturkatastrophen geworden.', 'Im Parlament besteht der Wunsch nach einer Aussprache im Verlauf dieser Sitzungsperiode in den nächsten Tagen.']\n",
      "03/20 06:47:48 PM |\t  model_v_in_main sacreBLEU : 20.971834\n",
      "03/20 06:47:48 PM |\t  model_v_in_main BLEU : 0.169739\n",
      "03/20 06:47:48 PM |\t  model_v_in_main test loss : 0.515529\n",
      "03/20 06:47:48 PM |\t  \n",
      "\n",
      "  ----------------epoch:7,\t\tlr_w:5e-05,\t\tlr_v:5e-05----------------\n",
      "03/20 06:47:56 PM |\t  0.0%\n",
      "03/20 06:48:33 PM |\t  40.0%\n",
      "03/20 06:49:14 PM |\t  80.0%\n",
      "03/20 06:49:19 PM |\t  ('Attention Weights A : ', Parameter containing:\n",
      "tensor([0.0419, 0.0415, 0.0416, 0.0404, 0.0410, 0.0415, 0.0419, 0.0417, 0.0414,\n",
      "        0.0416, 0.0415, 0.0418, 0.0421, 0.0416, 0.0421, 0.0419, 0.0416, 0.0419,\n",
      "        0.0421, 0.0420, 0.0409, 0.0422, 0.0418, 0.0418], device='cuda:0',\n",
      "       requires_grad=True))\n",
      "03/20 06:49:19 PM |\t  w_train_loss:0.2990888571366668,v_train_loss:0.07754818606190383\n",
      "03/20 06:49:21 PM |\t  x_decoded[:2]:[\"translate English to German: Although, as you will have seen, the dreaded'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\", 'translate English to German: You have requested a debate on this subject in the course of the next few days, during this part-session.']\n",
      "03/20 06:49:21 PM |\t  pred_decoded[:2]:['Obwohl, wie Sie gesehen haben, der gefürchtete \"Millennium-Fehler\" nicht zustande kam, erlitten die Menschen in einigen Ländern immer noch eine Reihe von Naturkatastrophen, die wirklich schrecklich waren.', 'Sie haben in den nächsten Tagen, in dieser Sitzung, eine Aussprache zu diesem Thema beantragt.']\n",
      "03/20 06:49:21 PM |\t  label_decoded[:2]:['Wie Sie feststellen konnten, ist der gefürchtete \"Millenium-Bug \" nicht eingetreten. Doch sind Bürger einiger unserer Mitgliedstaaten Opfer von schrecklichen Naturkatastrophen geworden.', 'Im Parlament besteht der Wunsch nach einer Aussprache im Verlauf dieser Sitzungsperiode in den nächsten Tagen.']\n",
      "03/20 06:49:38 PM |\t  model_w_in_main sacreBLEU : 19.379088\n",
      "03/20 06:49:38 PM |\t  model_w_in_main BLEU : 0.154808\n",
      "03/20 06:49:38 PM |\t  model_w_in_main test loss : 0.387804\n",
      "03/20 06:49:41 PM |\t  x_decoded[:2]:[\"translate English to German: Although, as you will have seen, the dreaded'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\", 'translate English to German: You have requested a debate on this subject in the course of the next few days, during this part-session.']\n",
      "03/20 06:49:41 PM |\t  pred_decoded[:2]:['Obwohl der gefürchtete \"Millennium-Fehler\" nicht zustande gekommen ist, haben die Menschen in einigen Ländern noch immer eine Reihe von Naturkatastrophen erlitten, die wirklich schrecklich waren.', 'Sie haben in den nächsten Tagen während dieser Sitzung eine Aussprache zu diesem Thema beantragt.']\n",
      "03/20 06:49:41 PM |\t  label_decoded[:2]:['Wie Sie feststellen konnten, ist der gefürchtete \"Millenium-Bug \" nicht eingetreten. Doch sind Bürger einiger unserer Mitgliedstaaten Opfer von schrecklichen Naturkatastrophen geworden.', 'Im Parlament besteht der Wunsch nach einer Aussprache im Verlauf dieser Sitzungsperiode in den nächsten Tagen.']\n",
      "03/20 06:49:57 PM |\t  model_v_in_main sacreBLEU : 21.660461\n",
      "03/20 06:49:57 PM |\t  model_v_in_main BLEU : 0.179535\n",
      "03/20 06:49:57 PM |\t  model_v_in_main test loss : 0.520239\n",
      "03/20 06:49:57 PM |\t  \n",
      "\n",
      "  ----------------epoch:8,\t\tlr_w:5e-05,\t\tlr_v:5e-05----------------\n",
      "03/20 06:50:06 PM |\t  0.0%\n",
      "03/20 06:50:42 PM |\t  40.0%\n",
      "03/20 06:51:22 PM |\t  80.0%\n",
      "03/20 06:51:26 PM |\t  ('Attention Weights A : ', Parameter containing:\n",
      "tensor([0.0421, 0.0418, 0.0415, 0.0403, 0.0412, 0.0416, 0.0421, 0.0419, 0.0417,\n",
      "        0.0417, 0.0417, 0.0420, 0.0423, 0.0418, 0.0422, 0.0420, 0.0414, 0.0419,\n",
      "        0.0424, 0.0422, 0.0405, 0.0421, 0.0421, 0.0421], device='cuda:0',\n",
      "       requires_grad=True))\n",
      "03/20 06:51:26 PM |\t  w_train_loss:0.296169969253242,v_train_loss:0.0778271536109969\n",
      "03/20 06:51:29 PM |\t  x_decoded[:2]:[\"translate English to German: Although, as you will have seen, the dreaded'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\", 'translate English to German: You have requested a debate on this subject in the course of the next few days, during this part-session.']\n",
      "03/20 06:51:29 PM |\t  pred_decoded[:2]:['Obwohl, wie Sie gesehen haben, der gefürchtete \"Millennium-Fehler\" nicht zustande kam, erlitten die Menschen in einigen Ländern immer noch eine Reihe von Naturkatastrophen, die wirklich schrecklich waren.', 'Sie haben in den nächsten Tagen, in dieser Sitzung, eine Aussprache zu diesem Thema beantragt.']\n",
      "03/20 06:51:29 PM |\t  label_decoded[:2]:['Wie Sie feststellen konnten, ist der gefürchtete \"Millenium-Bug \" nicht eingetreten. Doch sind Bürger einiger unserer Mitgliedstaaten Opfer von schrecklichen Naturkatastrophen geworden.', 'Im Parlament besteht der Wunsch nach einer Aussprache im Verlauf dieser Sitzungsperiode in den nächsten Tagen.']\n",
      "03/20 06:51:45 PM |\t  model_w_in_main sacreBLEU : 19.410029\n",
      "03/20 06:51:45 PM |\t  model_w_in_main BLEU : 0.155129\n",
      "03/20 06:51:45 PM |\t  model_w_in_main test loss : 0.387036\n",
      "03/20 06:51:48 PM |\t  x_decoded[:2]:[\"translate English to German: Although, as you will have seen, the dreaded'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\", 'translate English to German: You have requested a debate on this subject in the course of the next few days, during this part-session.']\n",
      "03/20 06:51:48 PM |\t  pred_decoded[:2]:['Obwohl der gefürchtete \"Millennium-Fehler\" nicht zustande gekommen ist, haben die Menschen in einigen Ländern noch immer eine Reihe von Naturkatastrophen erlitten, die wirklich schrecklich waren.', 'Sie haben in den nächsten Tagen während dieser Sitzung eine Aussprache zu diesem Thema beantragt.']\n",
      "03/20 06:51:48 PM |\t  label_decoded[:2]:['Wie Sie feststellen konnten, ist der gefürchtete \"Millenium-Bug \" nicht eingetreten. Doch sind Bürger einiger unserer Mitgliedstaaten Opfer von schrecklichen Naturkatastrophen geworden.', 'Im Parlament besteht der Wunsch nach einer Aussprache im Verlauf dieser Sitzungsperiode in den nächsten Tagen.']\n",
      "03/20 06:52:04 PM |\t  model_v_in_main sacreBLEU : 21.471351\n",
      "03/20 06:52:04 PM |\t  model_v_in_main BLEU : 0.177480\n",
      "03/20 06:52:04 PM |\t  model_v_in_main test loss : 0.525051\n",
      "03/20 06:52:04 PM |\t  \n",
      "\n",
      "  ----------------epoch:9,\t\tlr_w:5e-05,\t\tlr_v:5e-05----------------\n",
      "03/20 06:52:12 PM |\t  0.0%\n",
      "03/20 06:52:49 PM |\t  40.0%\n",
      "03/20 06:53:30 PM |\t  80.0%\n",
      "03/20 06:53:34 PM |\t  ('Attention Weights A : ', Parameter containing:\n",
      "tensor([0.0420, 0.0416, 0.0414, 0.0400, 0.0412, 0.0415, 0.0420, 0.0418, 0.0415,\n",
      "        0.0417, 0.0417, 0.0417, 0.0422, 0.0418, 0.0422, 0.0420, 0.0417, 0.0416,\n",
      "        0.0421, 0.0419, 0.0404, 0.0423, 0.0419, 0.0419], device='cuda:0',\n",
      "       requires_grad=True))\n",
      "03/20 06:53:34 PM |\t  w_train_loss:0.2748149139806628,v_train_loss:0.07785267836879939\n",
      "03/20 06:53:36 PM |\t  x_decoded[:2]:[\"translate English to German: Although, as you will have seen, the dreaded'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\", 'translate English to German: You have requested a debate on this subject in the course of the next few days, during this part-session.']\n",
      "03/20 06:53:36 PM |\t  pred_decoded[:2]:['Obwohl der gefürchtete \"Millennium-Fehler\" nicht zustande gekommen ist, haben die Menschen in einigen Ländern noch immer eine Reihe von Naturkatastrophen erlitten, die wirklich schrecklich waren.', 'Sie haben in den nächsten Tagen, in dieser Sitzung, eine Aussprache zu diesem Thema beantragt.']\n",
      "03/20 06:53:36 PM |\t  label_decoded[:2]:['Wie Sie feststellen konnten, ist der gefürchtete \"Millenium-Bug \" nicht eingetreten. Doch sind Bürger einiger unserer Mitgliedstaaten Opfer von schrecklichen Naturkatastrophen geworden.', 'Im Parlament besteht der Wunsch nach einer Aussprache im Verlauf dieser Sitzungsperiode in den nächsten Tagen.']\n",
      "03/20 06:53:52 PM |\t  model_w_in_main sacreBLEU : 20.288208\n",
      "03/20 06:53:52 PM |\t  model_w_in_main BLEU : 0.161699\n",
      "03/20 06:53:52 PM |\t  model_w_in_main test loss : 0.386225\n",
      "03/20 06:53:55 PM |\t  x_decoded[:2]:[\"translate English to German: Although, as you will have seen, the dreaded'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\", 'translate English to German: You have requested a debate on this subject in the course of the next few days, during this part-session.']\n",
      "03/20 06:53:55 PM |\t  pred_decoded[:2]:['Obwohl der gefürchtete \"Millennium-Fehler\" nicht zustande gekommen ist, haben die Menschen in einigen Ländern noch immer eine Reihe von Naturkatastrophen erlitten, die wirklich schrecklich waren.', 'Sie haben in den nächsten Tagen während dieser Sitzung eine Aussprache zu diesem Thema beantragt.']\n",
      "03/20 06:53:55 PM |\t  label_decoded[:2]:['Wie Sie feststellen konnten, ist der gefürchtete \"Millenium-Bug \" nicht eingetreten. Doch sind Bürger einiger unserer Mitgliedstaaten Opfer von schrecklichen Naturkatastrophen geworden.', 'Im Parlament besteht der Wunsch nach einer Aussprache im Verlauf dieser Sitzungsperiode in den nächsten Tagen.']\n",
      "03/20 06:54:12 PM |\t  model_v_in_main sacreBLEU : 21.471351\n",
      "03/20 06:54:12 PM |\t  model_v_in_main BLEU : 0.177480\n",
      "03/20 06:54:12 PM |\t  model_v_in_main test loss : 0.526987\n",
      "03/20 06:54:12 PM |\t  \n",
      "\n",
      "  ----------------epoch:10,\t\tlr_w:5e-05,\t\tlr_v:5e-05----------------\n",
      "03/20 06:54:20 PM |\t  0.0%\n",
      "03/20 06:54:57 PM |\t  40.0%\n",
      "03/20 06:55:38 PM |\t  80.0%\n",
      "03/20 06:55:42 PM |\t  ('Attention Weights A : ', Parameter containing:\n",
      "tensor([0.0419, 0.0417, 0.0412, 0.0396, 0.0412, 0.0413, 0.0418, 0.0416, 0.0414,\n",
      "        0.0419, 0.0415, 0.0415, 0.0421, 0.0416, 0.0420, 0.0419, 0.0416, 0.0416,\n",
      "        0.0419, 0.0415, 0.0406, 0.0425, 0.0418, 0.0417], device='cuda:0',\n",
      "       requires_grad=True))\n",
      "03/20 06:55:42 PM |\t  w_train_loss:0.2600657595321536,v_train_loss:0.06958964269142598\n",
      "03/20 06:55:45 PM |\t  x_decoded[:2]:[\"translate English to German: Although, as you will have seen, the dreaded'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\", 'translate English to German: You have requested a debate on this subject in the course of the next few days, during this part-session.']\n",
      "03/20 06:55:45 PM |\t  pred_decoded[:2]:['Obwohl der gefürchtete \"Millennium-Fehler\" nicht zustande gekommen ist, haben die Menschen in einigen Ländern noch immer eine Reihe von Naturkatastrophen erlitten, die wirklich schrecklich waren.', 'Sie haben in den nächsten Tagen, in dieser Sitzung, eine Aussprache zu diesem Thema beantragt.']\n",
      "03/20 06:55:45 PM |\t  label_decoded[:2]:['Wie Sie feststellen konnten, ist der gefürchtete \"Millenium-Bug \" nicht eingetreten. Doch sind Bürger einiger unserer Mitgliedstaaten Opfer von schrecklichen Naturkatastrophen geworden.', 'Im Parlament besteht der Wunsch nach einer Aussprache im Verlauf dieser Sitzungsperiode in den nächsten Tagen.']\n",
      "03/20 06:56:01 PM |\t  model_w_in_main sacreBLEU : 20.165442\n",
      "03/20 06:56:01 PM |\t  model_w_in_main BLEU : 0.162935\n",
      "03/20 06:56:01 PM |\t  model_w_in_main test loss : 0.386062\n",
      "03/20 06:56:04 PM |\t  x_decoded[:2]:[\"translate English to German: Although, as you will have seen, the dreaded'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\", 'translate English to German: You have requested a debate on this subject in the course of the next few days, during this part-session.']\n",
      "03/20 06:56:04 PM |\t  pred_decoded[:2]:['Obwohl der gefürchtete \"Millennium-Fehler\" nicht zustande gekommen ist, haben die Menschen in einigen Ländern noch immer eine Reihe von Naturkatastrophen erlitten, die wirklich schrecklich waren.', 'Sie haben in den nächsten Tagen, in dieser Sitzung, um eine Aussprache zu diesem Thema gebeten.']\n",
      "03/20 06:56:04 PM |\t  label_decoded[:2]:['Wie Sie feststellen konnten, ist der gefürchtete \"Millenium-Bug \" nicht eingetreten. Doch sind Bürger einiger unserer Mitgliedstaaten Opfer von schrecklichen Naturkatastrophen geworden.', 'Im Parlament besteht der Wunsch nach einer Aussprache im Verlauf dieser Sitzungsperiode in den nächsten Tagen.']\n",
      "03/20 06:56:21 PM |\t  model_v_in_main sacreBLEU : 21.038801\n",
      "03/20 06:56:21 PM |\t  model_v_in_main BLEU : 0.170680\n",
      "03/20 06:56:21 PM |\t  model_v_in_main test loss : 0.531032\n",
      "03/20 06:56:21 PM |\t  \n",
      "\n",
      "  ----------------epoch:11,\t\tlr_w:5e-05,\t\tlr_v:5e-05----------------\n",
      "03/20 06:56:28 PM |\t  0.0%\n",
      "03/20 06:57:05 PM |\t  40.0%\n",
      "03/20 06:57:46 PM |\t  80.0%\n",
      "03/20 06:57:50 PM |\t  ('Attention Weights A : ', Parameter containing:\n",
      "tensor([0.0419, 0.0418, 0.0413, 0.0390, 0.0412, 0.0413, 0.0418, 0.0417, 0.0413,\n",
      "        0.0419, 0.0417, 0.0416, 0.0423, 0.0417, 0.0420, 0.0420, 0.0418, 0.0419,\n",
      "        0.0419, 0.0410, 0.0408, 0.0425, 0.0418, 0.0418], device='cuda:0',\n",
      "       requires_grad=True))\n",
      "03/20 06:57:50 PM |\t  w_train_loss:0.25534276431426406,v_train_loss:0.06812759966123849\n",
      "03/20 06:57:53 PM |\t  x_decoded[:2]:[\"translate English to German: Although, as you will have seen, the dreaded'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\", 'translate English to German: You have requested a debate on this subject in the course of the next few days, during this part-session.']\n",
      "03/20 06:57:53 PM |\t  pred_decoded[:2]:['Obwohl, wie Sie gesehen haben, der gefürchtete \"Millennium-Fehler\" nicht zustande gekommen ist, haben die Menschen in einigen Ländern immer noch eine Reihe von Naturkatastrophen erlitten, die wirklich schrecklich waren.', 'Sie haben in den nächsten Tagen, in dieser Sitzung, eine Aussprache zu diesem Thema beantragt.']\n",
      "03/20 06:57:53 PM |\t  label_decoded[:2]:['Wie Sie feststellen konnten, ist der gefürchtete \"Millenium-Bug \" nicht eingetreten. Doch sind Bürger einiger unserer Mitgliedstaaten Opfer von schrecklichen Naturkatastrophen geworden.', 'Im Parlament besteht der Wunsch nach einer Aussprache im Verlauf dieser Sitzungsperiode in den nächsten Tagen.']\n",
      "03/20 06:58:09 PM |\t  model_w_in_main sacreBLEU : 20.140970\n",
      "03/20 06:58:09 PM |\t  model_w_in_main BLEU : 0.162522\n",
      "03/20 06:58:09 PM |\t  model_w_in_main test loss : 0.386126\n",
      "03/20 06:58:12 PM |\t  x_decoded[:2]:[\"translate English to German: Although, as you will have seen, the dreaded'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\", 'translate English to German: You have requested a debate on this subject in the course of the next few days, during this part-session.']\n",
      "03/20 06:58:12 PM |\t  pred_decoded[:2]:['Obwohl der gefürchtete \"Millennium-Fehler\" nicht zustande gekommen ist, haben die Menschen in einigen Ländern noch immer eine Reihe von Naturkatastrophen erlitten, die wirklich schrecklich waren.', 'Sie haben in den nächsten Tagen, in dieser Sitzung, um eine Aussprache zu diesem Thema gebeten.']\n",
      "03/20 06:58:12 PM |\t  label_decoded[:2]:['Wie Sie feststellen konnten, ist der gefürchtete \"Millenium-Bug \" nicht eingetreten. Doch sind Bürger einiger unserer Mitgliedstaaten Opfer von schrecklichen Naturkatastrophen geworden.', 'Im Parlament besteht der Wunsch nach einer Aussprache im Verlauf dieser Sitzungsperiode in den nächsten Tagen.']\n",
      "03/20 06:58:29 PM |\t  model_v_in_main sacreBLEU : 20.774337\n",
      "03/20 06:58:29 PM |\t  model_v_in_main BLEU : 0.167637\n",
      "03/20 06:58:29 PM |\t  model_v_in_main test loss : 0.535490\n",
      "03/20 06:58:29 PM |\t  \n",
      "\n",
      "  ----------------epoch:12,\t\tlr_w:5e-05,\t\tlr_v:5e-05----------------\n",
      "03/20 06:58:37 PM |\t  0.0%\n",
      "03/20 06:59:15 PM |\t  40.0%\n",
      "03/20 06:59:56 PM |\t  80.0%\n",
      "03/20 07:00:00 PM |\t  ('Attention Weights A : ', Parameter containing:\n",
      "tensor([0.0422, 0.0417, 0.0412, 0.0392, 0.0414, 0.0414, 0.0421, 0.0419, 0.0411,\n",
      "        0.0418, 0.0419, 0.0417, 0.0425, 0.0420, 0.0422, 0.0422, 0.0418, 0.0419,\n",
      "        0.0420, 0.0408, 0.0409, 0.0424, 0.0421, 0.0420], device='cuda:0',\n",
      "       requires_grad=True))\n",
      "03/20 07:00:00 PM |\t  w_train_loss:0.2417028807103634,v_train_loss:0.06690146762412041\n",
      "03/20 07:00:03 PM |\t  x_decoded[:2]:[\"translate English to German: Although, as you will have seen, the dreaded'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\", 'translate English to German: You have requested a debate on this subject in the course of the next few days, during this part-session.']\n",
      "03/20 07:00:03 PM |\t  pred_decoded[:2]:['Obwohl, wie Sie sicher gesehen haben, der gefürchtete \"Millennium-Fehler\" nicht zustande kam, erlitten die Menschen in einigen Ländern immer noch eine Reihe von Naturkatastrophen, die wirklich schrecklich waren.', 'Sie haben in den nächsten Tagen, in dieser Sitzung, eine Aussprache zu diesem Thema beantragt.']\n",
      "03/20 07:00:03 PM |\t  label_decoded[:2]:['Wie Sie feststellen konnten, ist der gefürchtete \"Millenium-Bug \" nicht eingetreten. Doch sind Bürger einiger unserer Mitgliedstaaten Opfer von schrecklichen Naturkatastrophen geworden.', 'Im Parlament besteht der Wunsch nach einer Aussprache im Verlauf dieser Sitzungsperiode in den nächsten Tagen.']\n",
      "03/20 07:00:19 PM |\t  model_w_in_main sacreBLEU : 20.481700\n",
      "03/20 07:00:19 PM |\t  model_w_in_main BLEU : 0.166351\n",
      "03/20 07:00:19 PM |\t  model_w_in_main test loss : 0.385798\n",
      "03/20 07:00:22 PM |\t  x_decoded[:2]:[\"translate English to German: Although, as you will have seen, the dreaded'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\", 'translate English to German: You have requested a debate on this subject in the course of the next few days, during this part-session.']\n",
      "03/20 07:00:22 PM |\t  pred_decoded[:2]:['Obwohl, wie Sie gesehen haben, der gefürchtete \"Millennium-Fehler\" nicht zustande gekommen ist, erlitten die Menschen in einigen Ländern immer noch eine Reihe von Naturkatastrophen, die wirklich schrecklich waren.', 'Sie haben in den nächsten Tagen, in dieser Sitzung, um eine Aussprache zu diesem Thema gebeten.']\n",
      "03/20 07:00:22 PM |\t  label_decoded[:2]:['Wie Sie feststellen konnten, ist der gefürchtete \"Millenium-Bug \" nicht eingetreten. Doch sind Bürger einiger unserer Mitgliedstaaten Opfer von schrecklichen Naturkatastrophen geworden.', 'Im Parlament besteht der Wunsch nach einer Aussprache im Verlauf dieser Sitzungsperiode in den nächsten Tagen.']\n",
      "03/20 07:00:39 PM |\t  model_v_in_main sacreBLEU : 20.792428\n",
      "03/20 07:00:39 PM |\t  model_v_in_main BLEU : 0.167669\n",
      "03/20 07:00:39 PM |\t  model_v_in_main test loss : 0.541550\n",
      "03/20 07:00:39 PM |\t  \n",
      "\n",
      "  ----------------epoch:13,\t\tlr_w:5e-05,\t\tlr_v:5e-05----------------\n",
      "03/20 07:00:47 PM |\t  0.0%\n",
      "03/20 07:01:23 PM |\t  40.0%\n",
      "03/20 07:02:04 PM |\t  80.0%\n",
      "03/20 07:02:08 PM |\t  ('Attention Weights A : ', Parameter containing:\n",
      "tensor([0.0420, 0.0415, 0.0410, 0.0390, 0.0412, 0.0412, 0.0419, 0.0417, 0.0408,\n",
      "        0.0417, 0.0417, 0.0415, 0.0424, 0.0420, 0.0421, 0.0420, 0.0414, 0.0417,\n",
      "        0.0419, 0.0406, 0.0411, 0.0425, 0.0420, 0.0418], device='cuda:0',\n",
      "       requires_grad=True))\n",
      "03/20 07:02:08 PM |\t  w_train_loss:0.23948972369544208,v_train_loss:0.06060432340018451\n",
      "03/20 07:02:11 PM |\t  x_decoded[:2]:[\"translate English to German: Although, as you will have seen, the dreaded'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\", 'translate English to German: You have requested a debate on this subject in the course of the next few days, during this part-session.']\n",
      "03/20 07:02:11 PM |\t  pred_decoded[:2]:['Obwohl, wie Sie sicher gesehen haben, der gefürchtete \"Millennium-Fehler\" nicht zustande kam, erlitten die Menschen in einigen Ländern immer noch eine Reihe von Naturkatastrophen, die wirklich schrecklich waren.', 'Sie haben in den nächsten Tagen, in dieser Sitzung, eine Aussprache zu diesem Thema beantragt.']\n",
      "03/20 07:02:11 PM |\t  label_decoded[:2]:['Wie Sie feststellen konnten, ist der gefürchtete \"Millenium-Bug \" nicht eingetreten. Doch sind Bürger einiger unserer Mitgliedstaaten Opfer von schrecklichen Naturkatastrophen geworden.', 'Im Parlament besteht der Wunsch nach einer Aussprache im Verlauf dieser Sitzungsperiode in den nächsten Tagen.']\n",
      "03/20 07:02:27 PM |\t  model_w_in_main sacreBLEU : 20.253636\n",
      "03/20 07:02:27 PM |\t  model_w_in_main BLEU : 0.163914\n",
      "03/20 07:02:27 PM |\t  model_w_in_main test loss : 0.385638\n",
      "03/20 07:02:30 PM |\t  x_decoded[:2]:[\"translate English to German: Although, as you will have seen, the dreaded'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\", 'translate English to German: You have requested a debate on this subject in the course of the next few days, during this part-session.']\n",
      "03/20 07:02:30 PM |\t  pred_decoded[:2]:['Obwohl, wie Sie gesehen haben, der gefürchtete \"Millennium-Fehler\" nicht zustande gekommen ist, erlitten die Menschen in einigen Ländern nach wie vor eine Reihe von Naturkatastrophen, die wirklich schrecklich waren.', 'Sie haben in den nächsten Tagen, in dieser Sitzung, um eine Aussprache zu diesem Thema gebeten.']\n",
      "03/20 07:02:30 PM |\t  label_decoded[:2]:['Wie Sie feststellen konnten, ist der gefürchtete \"Millenium-Bug \" nicht eingetreten. Doch sind Bürger einiger unserer Mitgliedstaaten Opfer von schrecklichen Naturkatastrophen geworden.', 'Im Parlament besteht der Wunsch nach einer Aussprache im Verlauf dieser Sitzungsperiode in den nächsten Tagen.']\n",
      "03/20 07:02:46 PM |\t  model_v_in_main sacreBLEU : 21.212668\n",
      "03/20 07:02:46 PM |\t  model_v_in_main BLEU : 0.172057\n",
      "03/20 07:02:46 PM |\t  model_v_in_main test loss : 0.547183\n",
      "03/20 07:02:46 PM |\t  \n",
      "\n",
      "  ----------------epoch:14,\t\tlr_w:5e-05,\t\tlr_v:5e-05----------------\n",
      "03/20 07:02:55 PM |\t  0.0%\n",
      "03/20 07:03:32 PM |\t  40.0%\n",
      "03/20 07:04:12 PM |\t  80.0%\n",
      "03/20 07:04:16 PM |\t  ('Attention Weights A : ', Parameter containing:\n",
      "tensor([0.0422, 0.0411, 0.0410, 0.0389, 0.0416, 0.0413, 0.0420, 0.0418, 0.0408,\n",
      "        0.0422, 0.0420, 0.0417, 0.0425, 0.0420, 0.0422, 0.0419, 0.0416, 0.0420,\n",
      "        0.0420, 0.0407, 0.0408, 0.0425, 0.0421, 0.0419], device='cuda:0',\n",
      "       requires_grad=True))\n",
      "03/20 07:04:16 PM |\t  w_train_loss:0.22986137587577105,v_train_loss:0.06068236380815506\n",
      "03/20 07:04:19 PM |\t  x_decoded[:2]:[\"translate English to German: Although, as you will have seen, the dreaded'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\", 'translate English to German: You have requested a debate on this subject in the course of the next few days, during this part-session.']\n",
      "03/20 07:04:19 PM |\t  pred_decoded[:2]:['Obwohl, wie Sie sicher gesehen haben, der gefürchtete \"Millennium-Fehler\" nicht zustande kam, erlitten die Menschen in einigen Ländern immer noch eine Reihe von Naturkatastrophen, die wirklich schrecklich waren.', 'Sie haben in den nächsten Tagen, in dieser Sitzung, eine Aussprache zu diesem Thema beantragt.']\n",
      "03/20 07:04:19 PM |\t  label_decoded[:2]:['Wie Sie feststellen konnten, ist der gefürchtete \"Millenium-Bug \" nicht eingetreten. Doch sind Bürger einiger unserer Mitgliedstaaten Opfer von schrecklichen Naturkatastrophen geworden.', 'Im Parlament besteht der Wunsch nach einer Aussprache im Verlauf dieser Sitzungsperiode in den nächsten Tagen.']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10280/757767886.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mmy_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_w\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[0mmy_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_v\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10280/371678548.py\u001b[0m in \u001b[0;36mmy_test\u001b[1;34m(_dataloader, model, epoch)\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0macc\u001b[0m\u001b[1;33m+=\u001b[0m \u001b[0mls\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0mcounter\u001b[0m\u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m             \u001b[0mpre\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_dataloaderx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m             \u001b[1;31m# print('pre',pre)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mg:\\GitCode\\Self-teaching-for-machine-translation\\T5\\T5.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, input_ids, num_beams, max_length)\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;31m# print(\"start of : generate\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m         \u001b[0moutput_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_beams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_beams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mno_repeat_ngram_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrepetition_penalty\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, typical_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, stopping_criteria, constraints, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[0;32m   1249\u001b[0m             )\n\u001b[0;32m   1250\u001b[0m             \u001b[1;31m# 12. run beam search\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1251\u001b[1;33m             return self.beam_search(\n\u001b[0m\u001b[0;32m   1252\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1253\u001b[0m                 \u001b[0mbeam_scorer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\generation_utils.py\u001b[0m in \u001b[0;36mbeam_search\u001b[1;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[0;32m   2098\u001b[0m             \u001b[0mbeam_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbeam_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"next_beam_indices\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2099\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2100\u001b[1;33m             \u001b[0minput_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbeam_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeam_next_tokens\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2102\u001b[0m             model_kwargs = self._update_model_kwargs_for_generation(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if(args.valid_begin==1):\n",
    "    my_test(valid_dataloader,model_w,-1) #before train\n",
    "    my_test(valid_dataloader,model_v,-1)  \n",
    "for epoch in range(args.epochs):\n",
    "    lr_w = scheduler_w.get_lr()[0]\n",
    "    lr_v = scheduler_v.get_lr()[0]\n",
    "\n",
    "    logging.info(f\"\\n\\n  ----------------epoch:{epoch},\\t\\tlr_w:{lr_w},\\t\\tlr_v:{lr_v}----------------\")\n",
    "\n",
    "    w_train_loss,v_train_loss =  my_train(epoch, train_dataloader, model_w, model_v,  architect, A, w_optimizer, v_optimizer, lr_w,lr_v)\n",
    "    \n",
    "    scheduler_w.step()\n",
    "    scheduler_v.step()\n",
    "\n",
    "    writer.add_scalar(\"MT/model_w_in_main/w_trainloss\", w_train_loss, global_step=epoch)\n",
    "    writer.add_scalar(\"MT/model_v_in_main/v_trainloss\", v_train_loss, global_step=epoch)\n",
    "\n",
    "    logging.info(f\"w_train_loss:{w_train_loss},v_train_loss:{v_train_loss}\")\n",
    "\n",
    "    \n",
    "    my_test(valid_dataloader,model_w,epoch) \n",
    "    my_test(valid_dataloader,model_v,epoch)  \n",
    "\n",
    "torch.save(model_v,'./model/'+now+'model_v.pt')\n",
    "torch.save(model_v,'./model/'+now+'model_w.pt')\n",
    "     \n",
    "   \n",
    "   \n",
    "        \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]])\n",
      "tensor([[-2.4861, -2.4251],\n",
      "        [ 1.1426,  0.0629],\n",
      "        [-0.9223,  0.6709]], requires_grad=True)\n",
      "tensor([0.7241, 1.3721, 1.7782], grad_fn=<NegBackward0>)\n",
      "tensor(1.3721, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "input = torch.randn(3, 2, requires_grad=True)\n",
    "target = torch.tensor([0, 1, 0])\n",
    "\n",
    "\n",
    "\n",
    "# class probabilities\n",
    "criterion = nn.CrossEntropyLoss(reduction='none')\n",
    "target = torch.nn.functional.one_hot(target).float()\n",
    "print(target)\n",
    "print(input)\n",
    "loss = criterion(input, target)\n",
    "print(loss)\n",
    "loss = loss[target[:, 0] != 1].mean()\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "65768f95ed3f1ad80799466926a66640b39a99ef5d94bbece814e59aa067606e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('python38': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
