{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd() \n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from T5 import *\n",
    "import torch\n",
    "from datasets import load_dataset,load_metric\n",
    "from transformers import T5Tokenizer,AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import torch_optimizer as optim\n",
    "from transformers.optimization import Adafactor, AdafactorSchedule\n",
    "from MT_hyperparams import seed_,max_length,target_language\n",
    "import torch.backends.cudnn as cudnn\n",
    "from utils import *\n",
    "from attention_params import *\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, SubsetRandomSampler\n",
    "from torch.autograd import Variable\n",
    "from losses import *\n",
    "from architect import *\n",
    "import logging\n",
    "import sys\n",
    "import transformers\n",
    "import time\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(\"main\")\n",
    "\n",
    "\n",
    "parser.add_argument('--valid_num_points', type=int,             default = 100, help='validation data number')\n",
    "parser.add_argument('--train_num_points', type=int,             default = 200, help='train data number')\n",
    "\n",
    "parser.add_argument('--batch_size', type=int,                   default=32,     help='Batch size')\n",
    "parser.add_argument('--train_w_num_points', type=int,           default=32,      help='train_w_num_points for each batch')\n",
    "parser.add_argument('--train_v_synthetic_num_points', type=int, default=0,      help='train_v_synthetic_num_points for each batch')\n",
    "parser.add_argument('--train_v_num_points', type=int,           default=0,      help='train_v_num_points for each batch')\n",
    "parser.add_argument('--train_A_num_points', type=int,           default=0,      help='train_A_num_points decay for each batch')\n",
    "\n",
    "parser.add_argument('--gpu', type=int,                          default=0,      help='gpu device id')\n",
    "parser.add_argument('--num_workers', type=int,                  default=0,      help='num_workers')\n",
    "parser.add_argument('--model_name_teacher', type=str,           default='google/t5-small-lm-adapt',      help='model_name')\n",
    "parser.add_argument('--model_name_student', type=str,           default='google/t5-small-lm-adapt',      help='model_name')\n",
    "parser.add_argument('--exp_name', type=str,                     default='T5spec',      help='experiment name')\n",
    "parser.add_argument('--rep_num', type=int,                      default=50,      help='report times for 1 epoch')\n",
    "parser.add_argument('--test_num', type=int,                     default=2000,      help='test times for 1 epoch')\n",
    "\n",
    "parser.add_argument('--epochs', type=int,                       default=500,     help='num of training epochs')\n",
    "parser.add_argument('--pre_epochs', type=int,                   default=0,      help='train model W for x epoch first')\n",
    "parser.add_argument('--grad_clip', type=float,                  default=1,      help='gradient clipping')\n",
    "parser.add_argument('--grad_acc_count', type=float,             default=-1,      help='gradient accumulate steps')\n",
    "\n",
    "parser.add_argument('--w_lr', type=float,                       default=1e-3,   help='learning rate for w')\n",
    "parser.add_argument('--unrolled_w_lr', type=float,              default=0,   help='learning rate for w')\n",
    "parser.add_argument('--v_lr', type=float,                       default=0,   help='learning rate for v')\n",
    "parser.add_argument('--unrolled_v_lr', type=float,              default=0,   help='learning rate for v')\n",
    "parser.add_argument('--A_lr', type=float,                       default=0,   help='learning rate for A')\n",
    "parser.add_argument('--learning_rate_min', type=float,          default=1e-8,   help='learning_rate_min')\n",
    "parser.add_argument('--decay', type=float,                      default=1e-3,   help='weight decay')\n",
    "parser.add_argument('--beta1', type=float,                      default=0.9,    help='momentum')\n",
    "parser.add_argument('--beta2', type=float,                      default=0.98,    help='momentum')\n",
    "parser.add_argument('--warm', type=float,                       default=10,    help='warmup step')\n",
    "parser.add_argument('--num_step_lr', type=float,                default=5,    help='warmup step')\n",
    "# parser.add_argument('--smoothing', type=float,                  default=0.1,    help='labelsmoothing')\n",
    "\n",
    "\n",
    "parser.add_argument('--traindata_loss_ratio', type=float,       default=0,    help='human translated data ratio')\n",
    "parser.add_argument('--syndata_loss_ratio', type=float,         default=1,    help='augmented dataset ratio')\n",
    "\n",
    "parser.add_argument('--valid_begin', type=int,                  default=1,      help='whether valid before train')\n",
    "parser.add_argument('--train_A', type=int,                      default=1 ,     help='whether train A')\n",
    "\n",
    "\n",
    "\n",
    "args = parser.parse_args(args=[])#(args=['--batch_size', '8',  '--no_cuda'])#used in ipynb\n",
    "args.test_num = args.test_num//args.batch_size * args.batch_size\n",
    "args.rep_num = args.rep_num//args.batch_size * args.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33monlydrinkwater\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.18 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.17"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>g:\\GitCode\\Self-teaching-for-machine-translation\\T5_scratch\\wandb\\run-20220613_201838-mvxledmf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/onlydrinkwater/Selftraining/runs/mvxledmf\" target=\"_blank\">T5spec</a></strong> to <a href=\"https://wandb.ai/onlydrinkwater/Selftraining\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/onlydrinkwater/Selftraining/runs/mvxledmf?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1c3a2ccb580>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://wandb.ai/ check the running status online\n",
    "import wandb\n",
    "os.environ['WANDB_API_KEY']='a166474b1b7ad33a0549adaaec19a2f6d3f91d87'\n",
    "os.environ['WANDB_NAME']=args.exp_name\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "wandb.init(project=\"Selftraining\",config=args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/13 08:18:47 PM |\t  Reusing dataset wmt14 (C:\\Users\\kevin\\.cache\\huggingface\\datasets\\wmt14\\de-en\\1.0.0\\d239eaf0ff090d28da19b6bc9758e24634d84de0a1ef092f0b5c54e6f132d7e2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 31.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/13 08:18:47 PM |\t  Namespace(A_lr=0, batch_size=32, beta1=0.9, beta2=0.98, decay=0.001, epochs=500, exp_name='T5spec', gpu=0, grad_acc_count=-1, grad_clip=1, learning_rate_min=1e-08, model_name_student='google/t5-small-lm-adapt', model_name_teacher='google/t5-small-lm-adapt', num_step_lr=5, num_workers=0, pre_epochs=0, rep_num=32, syndata_loss_ratio=1, test_num=1984, train_A=1, train_A_num_points=0, train_num_points=200, train_v_num_points=0, train_v_synthetic_num_points=0, train_w_num_points=32, traindata_loss_ratio=0, unrolled_v_lr=0, unrolled_w_lr=0, v_lr=0, valid_begin=1, valid_num_points=100, w_lr=0.001, warm=10)\n",
      "06/13 08:18:47 PM |\t  DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 4508785\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 3000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 3003\n",
      "    })\n",
      "})\n",
      "06/13 08:18:47 PM |\t  {'translation': {'de': 'Ich bitte Sie, sich zu einer Schweigeminute zu erheben.', 'en': \"Please rise, then, for this minute' s silence.\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# logging file\n",
    "now = time.strftime(\"%Y-%m-%d-%H_%M_%S\", time.localtime(time.time()))\n",
    "\n",
    "log_format = '%(asctime)s |\\t  %(message)s'\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO,\n",
    "                    format=log_format, datefmt='%m/%d %I:%M:%S %p')\n",
    "fh = logging.FileHandler(os.path.join(\n",
    "    \"./log/\", now+'.txt'), 'w', encoding=\"UTF-8\")\n",
    "fh.setFormatter(logging.Formatter(log_format))\n",
    "logging.getLogger().addHandler(fh)\n",
    "dataset = load_dataset('wmt14', 'de-en')\n",
    "\n",
    "logging.info(args)\n",
    "logging.info(dataset)\n",
    "logging.info(dataset['train'][5])\n",
    "\n",
    "\n",
    "# Setting the seeds\n",
    "np.random.seed(seed_)\n",
    "torch.cuda.set_device(args.gpu)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cudnn.benchmark = True\n",
    "torch.manual_seed(seed_)\n",
    "cudnn.enabled = True\n",
    "torch.cuda.manual_seed(seed_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/13 08:18:49 PM |\t  modelsize:76.961152MB\n",
      "06/13 08:18:50 PM |\t  modelsize:76.961152MB\n"
     ]
    }
   ],
   "source": [
    "modelname = args.model_name_teacher\n",
    "pretrained  =  AutoModelForSeq2SeqLM.from_pretrained(modelname)\n",
    "pathname = modelname.replace('/','')\n",
    "logging.info(f'modelsize:{count_parameters_in_MB(pretrained)}MB')\n",
    "torch.save(pretrained,pathname+'.pt')\n",
    "\n",
    "modelname = args.model_name_student\n",
    "pretrained  =  AutoModelForSeq2SeqLM.from_pretrained(modelname)\n",
    "pathname = modelname.replace('/','')\n",
    "logging.info(f'modelsize:{count_parameters_in_MB(pretrained)}MB')\n",
    "torch.save(pretrained,pathname+'.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/13 08:19:47 PM |\t  train len: 192\n",
      "06/13 08:19:47 PM |\t  train_w_num_points_len: 192\n",
      "06/13 08:19:47 PM |\t  train_v_synthetic_num_points_len: 0\n",
      "06/13 08:19:47 PM |\t  train_v_num_points_len: 0\n",
      "06/13 08:19:47 PM |\t  train_A_num_points_len: 0\n",
      "06/13 08:19:48 PM |\t  valid len: 100\n",
      "06/13 08:19:48 PM |\t  test len: 3003\n",
      "06/13 08:19:48 PM |\t  {'de': 'Wie Sie feststellen konnten, ist der gefürchtete \"Millenium-Bug \" nicht eingetreten. Doch sind Bürger einiger unserer Mitgliedstaaten Opfer von schrecklichen Naturkatastrophen geworden.', 'en': \"translate English to German: Although, as you will have seen, the dreaded 'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\"}\n",
      "06/13 08:19:48 PM |\t  {'de': 'Wie Sie feststellen konnten, ist der gefürchtete \"Millenium-Bug \" nicht eingetreten. Doch sind Bürger einiger unserer Mitgliedstaaten Opfer von schrecklichen Naturkatastrophen geworden.', 'en': \"translate English to German: Although, as you will have seen, the dreaded 'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\"}\n",
      "06/13 08:19:48 PM |\t  {'de': 'Zwei Anlagen so nah beieinander: Absicht oder Schildbürgerstreich?', 'en': 'Two sets of lights so close to one another: intentional or just a silly error?'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# preprocess the data, make a dataloader\n",
    "import random\n",
    "modelname = args.model_name_teacher\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelname)\n",
    "criterion = torch.nn.CrossEntropyLoss( reduction='none')#teacher shouldn't have label smoothing, especially when student got same size.\n",
    "criterion_v = torch.nn.CrossEntropyLoss( reduction='none')#,label_smoothing=args.smoothing) #without LS, V may be too confident to that syn data, and LS do well for real data also.\n",
    "# dataset = dataset.shuffle(seed=seed_)\n",
    "train = dataset['train']['translation'][:args.train_num_points]\n",
    "valid = dataset['train']['translation'][:args.valid_num_points]#TODO:change dataset['validation']['translation'][:args.valid_num_points]args.train_num_points:args.train_num_points+args.valid_num_points\n",
    "test = dataset['test']['translation']#[L_t+L_v:L_t+L_v+L_test]\n",
    "\n",
    "def preprocess(dat):\n",
    "    for t in dat:\n",
    "        t['en'] = \"translate English to German: \" + t['en']  #needed for T5\n",
    "preprocess(train)\n",
    "preprocess(valid)\n",
    "# preprocess(test)#TODO:\n",
    "#TODO: Syn_input should be monolingual data, should try en-fo's en. cuz wmt may align\n",
    "num_batch = args.train_num_points//args.batch_size\n",
    "train = train[:args.batch_size*num_batch]\n",
    "logging.info(\"train len: %d\",len(train))\n",
    "\n",
    "'''\n",
    "each mini batch consist of : \n",
    "1. data to train W\n",
    "2. monolingual data to generate parallel data\n",
    "3. data to train V\n",
    "4. data to train A\n",
    "'''\n",
    "train_w_num_points_len = num_batch * args.train_w_num_points\n",
    "train_v_synthetic_num_points_len = num_batch * args.train_v_synthetic_num_points\n",
    "train_v_num_points_len = num_batch * args.train_v_num_points\n",
    "train_A_num_points_len = num_batch * args.train_A_num_points\n",
    "logging.info(\"train_w_num_points_len: %d\",train_w_num_points_len)\n",
    "logging.info(\"train_v_synthetic_num_points_len: %d\",train_v_synthetic_num_points_len)\n",
    "logging.info(\"train_v_num_points_len: %d\",train_v_num_points_len)\n",
    "logging.info(\"train_A_num_points_len: %d\",train_A_num_points_len)\n",
    "\n",
    "attn_idx_list = torch.arange(train_w_num_points_len).cuda()\n",
    "logging.info(\"valid len: %d\",len(valid))\n",
    "logging.info(\"test len: %d\" ,len(test))\n",
    "logging.info(train[2])\n",
    "logging.info(valid[2])\n",
    "logging.info(test[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get train data start\n",
      "get train data end\n",
      "06/13 08:19:48 PM |\t  train data get\n",
      "06/13 08:19:48 PM |\t  train data loader get\n",
      "06/13 08:19:48 PM |\t  valid data loader get\n",
      "06/13 08:19:48 PM |\t  test data loader get\n"
     ]
    }
   ],
   "source": [
    "target_language  = 'de'\n",
    "train_data = get_train_Dataset(train, tokenizer)# Create the DataLoader for our training set.\n",
    "logging.info('train data get')\n",
    "train_dataloader = DataLoader(train_data, sampler= SequentialSampler(train_data), \n",
    "                        batch_size=args.batch_size, pin_memory=args.num_workers>0, num_workers=args.num_workers)\n",
    "logging.info('train data loader get')\n",
    "valid_data = get_aux_dataset(valid, tokenizer)# Create the DataLoader for our training set.\n",
    "valid_dataloader = DataLoader(valid_data, sampler=SequentialSampler(valid_data), \n",
    "                        batch_size=args.batch_size, pin_memory=args.num_workers>0, num_workers=args.num_workers)\n",
    "logging.info('valid data loader get')\n",
    "test_data = get_aux_dataset(test, tokenizer)# Create the DataLoader for our training set.\n",
    "test_dataloader = DataLoader(test_data, sampler=SequentialSampler(test_data),\n",
    "                        batch_size=args.batch_size, pin_memory=args.num_workers>0, num_workers=args.num_workers)#, sampler=RandomSampler(test_data)\n",
    "logging.info('test data loader get')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "A = attention_params(train_w_num_points_len)#half of train regarded as u\n",
    "A = A.cuda()\n",
    "\n",
    "\n",
    "\n",
    "# TODO: model loaded from saved model\n",
    "model_w = T5(criterion=criterion, tokenizer= tokenizer, args = args, name = 'model_w_in_main')\n",
    "model_w = model_w.cuda()\n",
    "w_optimizer = torch.optim.Adam(model_w.parameters(),  lr= args.w_lr ,  betas=(args.beta1, args.beta2) ,eps=1e-9 )\n",
    "# w_optimizer = Adafactor(model_w.parameters(), lr = args.w_lr ,scale_parameter=False, relative_step=False , warmup_init=False,clip_threshold=1,beta1=0,eps=( 1e-30,0.001))\n",
    "scheduler_w  =   StepLR(w_optimizer, step_size=args.num_step_lr, gamma=0.9)\n",
    "# scheduler_w  = Scheduler(w_optimizer,dim_embed=512, warmup_steps=args.warm, initlr = args.w_lr)\n",
    "\n",
    "\n",
    "\n",
    "model_v = T5(criterion=criterion_v, tokenizer= tokenizer, args = args, name = 'model_v_in_main')\n",
    "model_v = model_v.cuda()\n",
    "v_optimizer = torch.optim.Adam(model_v.parameters(),  lr= args.v_lr ,  betas=(args.beta1,args.beta2) ,eps=1e-9  )\n",
    "# v_optimizer =Adafactor(model_v.parameters(), lr = args.v_lr ,scale_parameter=False, relative_step=False , warmup_init=False,clip_threshold=1,beta1=0,eps=( 1e-30,0.001))\n",
    "scheduler_v  = Scheduler(v_optimizer,dim_embed=512, warmup_steps=args.warm, initlr = args.v_lr)\n",
    "\n",
    "\n",
    "architect = Architect(model_w, model_v,  A, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def my_test(_dataloader,model,epoch):\n",
    "    # logging.info(f\"GPU mem before test:{getGPUMem(device)}%\")\n",
    "    acc = 0\n",
    "    counter = 0\n",
    "    model.eval()\n",
    "    metric_sacrebleu =  load_metric('sacrebleu')\n",
    "    # metric_bleu =  load_metric('bleu')\n",
    "    \n",
    "    for step, batch in enumerate(_dataloader):\n",
    "        \n",
    "        test_dataloaderx = Variable(batch[0], requires_grad=False).to(device, non_blocking=False)[:args.train_w_num_points]\n",
    "        test_dataloaderx_attn = Variable(batch[1], requires_grad=False).to(device, non_blocking=False)[:args.train_w_num_points]\n",
    "        test_dataloadery = Variable(batch[2], requires_grad=False).to(device, non_blocking=False)[:args.train_w_num_points]\n",
    "        test_dataloadery_attn = Variable(batch[3], requires_grad=False).to(device, non_blocking=False)[:args.train_w_num_points]\n",
    "        ls = my_loss(test_dataloaderx,test_dataloaderx_attn,test_dataloadery,test_dataloadery_attn,model)\n",
    "        acc+= ls.item()\n",
    "        counter+= 1\n",
    "        pre = model.generate(test_dataloaderx)\n",
    "        x_decoded = tokenizer.batch_decode(test_dataloaderx,skip_special_tokens=True)\n",
    "        pred_decoded = tokenizer.batch_decode(pre,skip_special_tokens=True)\n",
    "        label_decoded =  tokenizer.batch_decode(test_dataloadery,skip_special_tokens=True)\n",
    "        \n",
    "        pred_str = [x  for x in pred_decoded]\n",
    "        label_str = [[x] for x in label_decoded]\n",
    "        # pred_list = [x.split()  for x in pred_decoded]\n",
    "        # label_list = [[x.split()] for x in label_decoded]\n",
    "        metric_sacrebleu.add_batch(predictions=pred_str, references=label_str)\n",
    "        # metric_bleu.add_batch(predictions=pred_list, references=label_list)\n",
    "        if  step==0:\n",
    "            logging.info(f'x_decoded[:2]:{x_decoded[:2]}')\n",
    "            logging.info(f'pred_decoded[:2]:{pred_decoded[:2]}')\n",
    "            logging.info(f'label_decoded[:2]:{label_decoded[:2]}')\n",
    "            \n",
    "            \n",
    "    logging.info('computing score...') \n",
    "    sacrebleu_score = metric_sacrebleu.compute()\n",
    "    # bleu_score = metric_bleu.compute()\n",
    "    logging.info('%s sacreBLEU : %f',model.name,sacrebleu_score['score'])#TODO:bleu may be wrong cuz max length\n",
    "    # logging.info('%s BLEU : %f',model.name,bleu_score['bleu'])\n",
    "    logging.info('%s test loss : %f',model.name,acc/(counter))\n",
    "    wandb.log({'sacreBLEU'+model.name: sacrebleu_score['score']})\n",
    "    wandb.log({'test_loss'+model.name: acc/counter})\n",
    "    # del test_dataloaderx,acc,counter,test_dataloaderx_attn,sacrebleu_score,bleu_score,test_dataloadery,test_dataloadery_attn,ls,pre,x_decoded,pred_decoded,label_decoded,pred_str,label_str,pred_list,label_list\n",
    "    # gc.collect()\n",
    "    # torch.cuda.empty_cache()\n",
    "    model.train()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_train(epoch, _dataloader, validdataloader, w_model, v_model, architect, A, w_optimizer, v_optimizer, lr_w, lr_v, tot_iter):\n",
    "\n",
    "    objs_w = AvgrageMeter()\n",
    "    objs_v_syn = AvgrageMeter()\n",
    "    objs_v_train = AvgrageMeter()\n",
    "    objs_v_star_val = AvgrageMeter()\n",
    "    objs_v_val = AvgrageMeter()\n",
    "    v_trainloss_acc = 0\n",
    "    w_trainloss_acc = 0\n",
    "    # now  train_x is [num of batch, datasize], so its seperate batch for the code below\n",
    "    wsize = args.train_w_num_points\n",
    "    synsize = args.train_v_synthetic_num_points\n",
    "    vsize = args.train_v_num_points\n",
    "    vtrainsize = vsize+synsize\n",
    "    vtrainsize_total = train_v_num_points_len+train_v_synthetic_num_points_len\n",
    "    Asize = args.train_A_num_points\n",
    "    loader_len = len(_dataloader)\n",
    "    split_size = [wsize, synsize, vsize, Asize]\n",
    "    bs = args.batch_size\n",
    "\n",
    "    logging.info(f\"split size:{split_size}\")\n",
    "    for step, batch in enumerate(_dataloader):\n",
    "        tot_iter[0] += bs\n",
    "        \n",
    "        w_model.eval()#!train\n",
    "        v_model.eval()\n",
    "\n",
    "        # logging.info(f\"GPU mem :{getGPUMem(device)}%\")\n",
    "        train_x = Variable(batch[0], requires_grad=False).to(\n",
    "            device, non_blocking=False)\n",
    "        train_x_attn = Variable(batch[1], requires_grad=False).to(\n",
    "            device, non_blocking=False)\n",
    "        train_y = Variable(batch[2], requires_grad=False).to(\n",
    "            device, non_blocking=False)\n",
    "        train_y_attn = Variable(batch[3], requires_grad=False).to(\n",
    "            device, non_blocking=False)\n",
    "        (input_w, input_syn, input_v, input_A_v) = torch.split(train_x, split_size)\n",
    "        (input_w_attn, input_syn_attn, input_v_attn,\n",
    "         input_A_v_attn) = torch.split(train_x_attn, split_size)\n",
    "        (output_w, _, output_v, output_A_v) = torch.split(train_y, split_size)\n",
    "        (output_w_attn, _, output_v_attn, output_A_v_attn) = torch.split(\n",
    "            train_y_attn, split_size)\n",
    "        attn_idx = attn_idx_list[wsize*step:(wsize*step+wsize)]\n",
    "        # with torch.no_grad():\n",
    "        #     print('out_old_loss',my_loss2(input_A_v, input_A_v_attn,  output_A_v, output_A_v_attn,v_model))\n",
    "\n",
    "        # if (args.train_A == 1):\n",
    "        #     epsilon_w = args.unrolled_w_lr\n",
    "        #     epsilon_v  = args.unrolled_v_lr\n",
    "        #     v_star_val_loss = architect.step(input_w,  output_w, input_w_attn, output_w_attn, w_optimizer,\n",
    "        #                                      input_v, input_v_attn, output_v, output_v_attn, input_syn, input_syn_attn,\n",
    "        #                                      input_A_v, input_A_v_attn, output_A_v, output_A_v_attn, v_optimizer,\n",
    "        #                                      attn_idx, lr_w, lr_v)\n",
    "        #     objs_v_star_val.update(v_star_val_loss, Asize)\n",
    "\n",
    "        w_model.train()\n",
    "        w_optimizer.zero_grad()\n",
    "   \n",
    "        loss_w = CTG_loss(input_w, input_w_attn, output_w,\n",
    "                          output_w_attn, attn_idx, A, w_model)\n",
    "        w_trainloss_acc += loss_w.item()\n",
    "        loss_w.backward()\n",
    "        objs_w.update(loss_w.item(), wsize)\n",
    "        w_optimizer.step()\n",
    "        # assert False\n",
    "\n",
    "\n",
    "        # v_optimizer.zero_grad()\n",
    "        # loss_aug = calc_loss_aug(input_syn, input_syn_attn, w_model, v_model)\n",
    "        # loss = my_loss2(input_v, input_v_attn, output_v,\n",
    "        #                 output_v_attn, v_model)\n",
    "        # v_loss = (args.traindata_loss_ratio*loss +\n",
    "        #           loss_aug*args.syndata_loss_ratio)\n",
    "        # v_trainloss_acc += v_loss.item()\n",
    "        # v_loss.backward()\n",
    "        # objs_v_syn.update(loss_aug.item(), synsize)\n",
    "        # objs_v_train.update(loss.item(), vsize)\n",
    "        # v_optimizer.step()\n",
    "\n",
    "        # with torch.no_grad():\n",
    "        #     valloss = my_loss2(input_A_v, input_A_v_attn,  output_A_v, output_A_v_attn,v_model)\n",
    "        #     objs_v_val.update(valloss.item(), Asize)\n",
    "\n",
    "        progress = 100*(step)/(loader_len-1)\n",
    "        if(tot_iter[0] % args.test_num == 0 and tot_iter[0] != 0):\n",
    "            my_test(_dataloader, model_w, epoch)\n",
    "            my_test(_dataloader, model_v, epoch)\n",
    "            logging.info(str((\"Attention Weights A : \", A.ReLU(A.alpha))))\n",
    "            torch.save(model_v,'./model/'+'model_w.pt')#+now+\n",
    "            torch.save(model_v,'./model/'+'model_v.pt')\n",
    "\n",
    "        if(tot_iter[0] % args.rep_num == 0 and tot_iter[0] != 0):\n",
    "            logging.info(f\"{progress:5.3}%:\\t  W_train_loss:{objs_w.avg:^.7f}\\tV_train_syn_loss:{objs_v_syn.avg:^.7f}\\tV_train_loss:{objs_v_train.avg:^.7f}\\t  V_star_val_loss:{objs_v_star_val.avg:^.7f}\\t  V_val_loss:{objs_v_val.avg:^.7f}\")\n",
    "            wandb.log({'W_train_loss': objs_w.avg})\n",
    "            wandb.log({'V_train_syn_loss': objs_v_syn.avg})\n",
    "            wandb.log({'V_train_loss': objs_v_train.avg})\n",
    "            wandb.log({'V_star_val_loss': objs_v_star_val.avg})\n",
    "            wandb.log({'V_val_loss': objs_v_val.avg})\n",
    "            objs_v_syn.reset()\n",
    "            objs_v_train.reset()\n",
    "            objs_w.reset()\n",
    "            objs_v_star_val.reset()\n",
    "            objs_v_val.reset()\n",
    "\n",
    "    return w_trainloss_acc, v_trainloss_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/13 08:19:49 PM |\t  \n",
      "\n",
      "  ----------------epoch:0,\t\tlr_w:0.001,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:19:49 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:19:55 PM |\t    0.0%:\t  W_train_loss:5.6472673\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:19:56 PM |\t   20.0%:\t  W_train_loss:5.1471167\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:19:56 PM |\t   40.0%:\t  W_train_loss:5.4087157\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:19:56 PM |\t   60.0%:\t  W_train_loss:4.7139463\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:19:56 PM |\t   80.0%:\t  W_train_loss:4.6053076\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:19:56 PM |\t  1e+02%:\t  W_train_loss:5.1571846\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:19:56 PM |\t  w_train_loss:30.679538249969482,v_train_loss:0\n",
      "06/13 08:19:56 PM |\t  \n",
      "\n",
      "  ----------------epoch:1,\t\tlr_w:0.001,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:19:56 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:19:57 PM |\t    0.0%:\t  W_train_loss:4.3585873\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:19:57 PM |\t   20.0%:\t  W_train_loss:4.2823768\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:19:57 PM |\t   40.0%:\t  W_train_loss:4.5400219\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:19:57 PM |\t   60.0%:\t  W_train_loss:3.9482572\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:19:58 PM |\t   80.0%:\t  W_train_loss:3.9469473\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:19:58 PM |\t  1e+02%:\t  W_train_loss:4.6911736\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:19:58 PM |\t  w_train_loss:25.767364025115967,v_train_loss:0\n",
      "06/13 08:19:58 PM |\t  \n",
      "\n",
      "  ----------------epoch:2,\t\tlr_w:0.001,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:19:58 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:19:58 PM |\t    0.0%:\t  W_train_loss:3.7785091\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:19:58 PM |\t   20.0%:\t  W_train_loss:3.8252583\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:19:58 PM |\t   40.0%:\t  W_train_loss:3.9914937\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:19:59 PM |\t   60.0%:\t  W_train_loss:3.3952625\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:19:59 PM |\t   80.0%:\t  W_train_loss:3.4192133\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:19:59 PM |\t  1e+02%:\t  W_train_loss:4.2660093\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:19:59 PM |\t  w_train_loss:22.675746202468872,v_train_loss:0\n",
      "06/13 08:19:59 PM |\t  \n",
      "\n",
      "  ----------------epoch:3,\t\tlr_w:0.001,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:19:59 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:19:59 PM |\t    0.0%:\t  W_train_loss:3.3859079\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:00 PM |\t   20.0%:\t  W_train_loss:3.4680221\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:00 PM |\t   40.0%:\t  W_train_loss:3.5053902\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:00 PM |\t   60.0%:\t  W_train_loss:3.0193653\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:00 PM |\t   80.0%:\t  W_train_loss:3.0203211\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:01 PM |\t  1e+02%:\t  W_train_loss:3.8590899\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:01 PM |\t  w_train_loss:20.25809645652771,v_train_loss:0\n",
      "06/13 08:20:01 PM |\t  \n",
      "\n",
      "  ----------------epoch:4,\t\tlr_w:0.001,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:20:01 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:20:01 PM |\t    0.0%:\t  W_train_loss:3.0523119\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:01 PM |\t   20.0%:\t  W_train_loss:3.0605731\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:01 PM |\t   40.0%:\t  W_train_loss:3.0881703\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:01 PM |\t   60.0%:\t  W_train_loss:2.6263323\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:02 PM |\t   80.0%:\t  W_train_loss:2.6487627\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:02 PM |\t  1e+02%:\t  W_train_loss:3.5211453\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:02 PM |\t  w_train_loss:17.99729561805725,v_train_loss:0\n",
      "06/13 08:20:02 PM |\t  \n",
      "\n",
      "  ----------------epoch:5,\t\tlr_w:0.00025,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:20:02 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:20:02 PM |\t    0.0%:\t  W_train_loss:2.7539983\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:02 PM |\t   20.0%:\t  W_train_loss:2.7605734\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:03 PM |\t   40.0%:\t  W_train_loss:2.7598197\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:03 PM |\t   60.0%:\t  W_train_loss:2.3178520\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:03 PM |\t   80.0%:\t  W_train_loss:2.3907349\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:03 PM |\t  1e+02%:\t  W_train_loss:3.3440404\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:03 PM |\t  w_train_loss:16.32701873779297,v_train_loss:0\n",
      "06/13 08:20:03 PM |\t  \n",
      "\n",
      "  ----------------epoch:6,\t\tlr_w:0.0005,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:20:03 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:20:03 PM |\t    0.0%:\t  W_train_loss:2.6248546\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:04 PM |\t   20.0%:\t  W_train_loss:2.5520077\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:04 PM |\t   40.0%:\t  W_train_loss:2.6169353\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:04 PM |\t   60.0%:\t  W_train_loss:2.1848741\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:04 PM |\t   80.0%:\t  W_train_loss:2.2223632\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:05 PM |\t  1e+02%:\t  W_train_loss:3.1432018\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:05 PM |\t  w_train_loss:15.344236612319946,v_train_loss:0\n",
      "06/13 08:20:05 PM |\t  \n",
      "\n",
      "  ----------------epoch:7,\t\tlr_w:0.0005,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:20:05 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:20:05 PM |\t    0.0%:\t  W_train_loss:2.4545524\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:05 PM |\t   20.0%:\t  W_train_loss:2.3556921\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:05 PM |\t   40.0%:\t  W_train_loss:2.5058777\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:05 PM |\t   60.0%:\t  W_train_loss:2.0168815\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:06 PM |\t   80.0%:\t  W_train_loss:2.0781772\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:06 PM |\t  1e+02%:\t  W_train_loss:2.9201155\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:06 PM |\t  w_train_loss:14.331296443939209,v_train_loss:0\n",
      "06/13 08:20:06 PM |\t  \n",
      "\n",
      "  ----------------epoch:8,\t\tlr_w:0.0005,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:20:06 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:20:06 PM |\t    0.0%:\t  W_train_loss:2.3926225\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:06 PM |\t   20.0%:\t  W_train_loss:2.2200575\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:07 PM |\t   40.0%:\t  W_train_loss:2.3589311\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:07 PM |\t   60.0%:\t  W_train_loss:1.9091778\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:07 PM |\t   80.0%:\t  W_train_loss:1.8943667\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:07 PM |\t  1e+02%:\t  W_train_loss:2.7787914\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:07 PM |\t  w_train_loss:13.55394697189331,v_train_loss:0\n",
      "06/13 08:20:07 PM |\t  \n",
      "\n",
      "  ----------------epoch:9,\t\tlr_w:0.0005,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:20:07 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:20:07 PM |\t    0.0%:\t  W_train_loss:2.2158093\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:08 PM |\t   20.0%:\t  W_train_loss:2.1365998\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:08 PM |\t   40.0%:\t  W_train_loss:2.2000058\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:08 PM |\t   60.0%:\t  W_train_loss:1.8245257\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:08 PM |\t   80.0%:\t  W_train_loss:1.8168275\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:09 PM |\t  1e+02%:\t  W_train_loss:2.6927383\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:09 PM |\t  w_train_loss:12.88650643825531,v_train_loss:0\n",
      "06/13 08:20:09 PM |\t  \n",
      "\n",
      "  ----------------epoch:10,\t\tlr_w:0.000125,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:20:09 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:20:09 PM |\t    0.0%:\t  W_train_loss:2.1123767\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:12 PM |\t  x_decoded[:2]:['translate English to German: Resumption of the session', 'translate English to German: I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.']\n",
      "06/13 08:20:12 PM |\t  pred_decoded[:2]:['Wiederaufnahme der Sitzungsperiode', 'Ich wünsche Ihnen ein schönes Jahr in der nächsten Jahr in der nächsten Jahr in der nächsten Jahr in der nächsten Jahr in der nächsten Jahr in der nächsten Jahr in der nächsten Jahr in der nächsten Jahr in der nächsten Jahr in der nächsten Jahr in der nächsten Jahr']\n",
      "06/13 08:20:12 PM |\t  label_decoded[:2]:['Wiederaufnahme der Sitzungsperiode', 'Ich erkläre die am Freitag, dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen, wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe, daß Sie schöne Ferien hatten.']\n",
      "06/13 08:20:22 PM |\t  computing score...\n",
      "06/13 08:20:22 PM |\t  model_w_in_main sacreBLEU : 13.120340\n",
      "06/13 08:20:22 PM |\t  model_w_in_main test loss : 1.445293\n",
      "06/13 08:20:25 PM |\t  x_decoded[:2]:['translate English to German: Resumption of the session', 'translate English to German: I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.']\n",
      "06/13 08:20:25 PM |\t  pred_decoded[:2]:['.', 'I wish you a happy new year in the hope that you enjoyed a pleasant festive period. I wish you a happy new year in the hope that you enjoyed a pleasant festive period.']\n",
      "06/13 08:20:25 PM |\t  label_decoded[:2]:['Wiederaufnahme der Sitzungsperiode', 'Ich erkläre die am Freitag, dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen, wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe, daß Sie schöne Ferien hatten.']\n",
      "06/13 08:20:36 PM |\t  computing score...\n",
      "06/13 08:20:36 PM |\t  model_v_in_main sacreBLEU : 0.370500\n",
      "06/13 08:20:36 PM |\t  model_v_in_main test loss : 5.315890\n",
      "06/13 08:20:36 PM |\t  ('Attention Weights A : ', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>))\n",
      "06/13 08:20:37 PM |\t   20.0%:\t  W_train_loss:1.9279680\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:38 PM |\t   40.0%:\t  W_train_loss:2.1103201\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:38 PM |\t   60.0%:\t  W_train_loss:1.6428912\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:38 PM |\t   80.0%:\t  W_train_loss:1.6983166\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:38 PM |\t  1e+02%:\t  W_train_loss:2.5749028\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:38 PM |\t  w_train_loss:12.06677532196045,v_train_loss:0\n",
      "06/13 08:20:38 PM |\t  \n",
      "\n",
      "  ----------------epoch:11,\t\tlr_w:0.00025,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:20:38 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:20:39 PM |\t    0.0%:\t  W_train_loss:2.0749354\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:39 PM |\t   20.0%:\t  W_train_loss:1.8623222\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:39 PM |\t   40.0%:\t  W_train_loss:2.0325623\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:39 PM |\t   60.0%:\t  W_train_loss:1.6236687\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:39 PM |\t   80.0%:\t  W_train_loss:1.6101923\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:40 PM |\t  1e+02%:\t  W_train_loss:2.5117571\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:40 PM |\t  w_train_loss:11.71543800830841,v_train_loss:0\n",
      "06/13 08:20:40 PM |\t  \n",
      "\n",
      "  ----------------epoch:12,\t\tlr_w:0.00025,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:20:40 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:20:40 PM |\t    0.0%:\t  W_train_loss:1.9420048\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:40 PM |\t   20.0%:\t  W_train_loss:1.7678605\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:40 PM |\t   40.0%:\t  W_train_loss:1.9214685\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:41 PM |\t   60.0%:\t  W_train_loss:1.5839689\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:41 PM |\t   80.0%:\t  W_train_loss:1.5433190\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:41 PM |\t  1e+02%:\t  W_train_loss:2.4038410\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:41 PM |\t  w_train_loss:11.162462711334229,v_train_loss:0\n",
      "06/13 08:20:41 PM |\t  \n",
      "\n",
      "  ----------------epoch:13,\t\tlr_w:0.00025,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:20:41 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:20:41 PM |\t    0.0%:\t  W_train_loss:1.9599192\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:41 PM |\t   20.0%:\t  W_train_loss:1.7778175\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:42 PM |\t   40.0%:\t  W_train_loss:1.9592319\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:42 PM |\t   60.0%:\t  W_train_loss:1.4850464\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:42 PM |\t   80.0%:\t  W_train_loss:1.4899504\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:42 PM |\t  1e+02%:\t  W_train_loss:2.3469822\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:42 PM |\t  w_train_loss:11.01894760131836,v_train_loss:0\n",
      "06/13 08:20:42 PM |\t  \n",
      "\n",
      "  ----------------epoch:14,\t\tlr_w:0.00025,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:20:42 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:20:43 PM |\t    0.0%:\t  W_train_loss:1.8520800\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:43 PM |\t   20.0%:\t  W_train_loss:1.7008929\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:43 PM |\t   40.0%:\t  W_train_loss:1.8499284\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:43 PM |\t   60.0%:\t  W_train_loss:1.4800631\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:43 PM |\t   80.0%:\t  W_train_loss:1.4886734\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:44 PM |\t  1e+02%:\t  W_train_loss:2.3177259\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:44 PM |\t  w_train_loss:10.689363718032837,v_train_loss:0\n",
      "06/13 08:20:44 PM |\t  \n",
      "\n",
      "  ----------------epoch:15,\t\tlr_w:6.25e-05,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:20:44 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:20:44 PM |\t    0.0%:\t  W_train_loss:1.8803535\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:44 PM |\t   20.0%:\t  W_train_loss:1.6411186\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:44 PM |\t   40.0%:\t  W_train_loss:1.7843003\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:45 PM |\t   60.0%:\t  W_train_loss:1.4680042\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:45 PM |\t   80.0%:\t  W_train_loss:1.4387512\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:45 PM |\t  1e+02%:\t  W_train_loss:2.2634549\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:45 PM |\t  w_train_loss:10.475982785224915,v_train_loss:0\n",
      "06/13 08:20:45 PM |\t  \n",
      "\n",
      "  ----------------epoch:16,\t\tlr_w:0.000125,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:20:45 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:20:45 PM |\t    0.0%:\t  W_train_loss:1.7801164\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:46 PM |\t   20.0%:\t  W_train_loss:1.6897757\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:46 PM |\t   40.0%:\t  W_train_loss:1.7683306\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:46 PM |\t   60.0%:\t  W_train_loss:1.3835402\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:46 PM |\t   80.0%:\t  W_train_loss:1.3411152\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:46 PM |\t  1e+02%:\t  W_train_loss:2.2347984\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:46 PM |\t  w_train_loss:10.197676539421082,v_train_loss:0\n",
      "06/13 08:20:46 PM |\t  \n",
      "\n",
      "  ----------------epoch:17,\t\tlr_w:0.000125,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:20:46 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:20:47 PM |\t    0.0%:\t  W_train_loss:1.7593402\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:47 PM |\t   20.0%:\t  W_train_loss:1.5898762\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:47 PM |\t   40.0%:\t  W_train_loss:1.6928596\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:47 PM |\t   60.0%:\t  W_train_loss:1.3514426\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:48 PM |\t   80.0%:\t  W_train_loss:1.3474295\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:48 PM |\t  1e+02%:\t  W_train_loss:2.2347913\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:48 PM |\t  w_train_loss:9.975739359855652,v_train_loss:0\n",
      "06/13 08:20:48 PM |\t  \n",
      "\n",
      "  ----------------epoch:18,\t\tlr_w:0.000125,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:20:48 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:20:48 PM |\t    0.0%:\t  W_train_loss:1.7993269\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:48 PM |\t   20.0%:\t  W_train_loss:1.5715497\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:48 PM |\t   40.0%:\t  W_train_loss:1.7686797\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:49 PM |\t   60.0%:\t  W_train_loss:1.3257571\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:49 PM |\t   80.0%:\t  W_train_loss:1.3144820\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:49 PM |\t  1e+02%:\t  W_train_loss:2.1815734\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:49 PM |\t  w_train_loss:9.961368799209595,v_train_loss:0\n",
      "06/13 08:20:49 PM |\t  \n",
      "\n",
      "  ----------------epoch:19,\t\tlr_w:0.000125,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:20:49 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:20:49 PM |\t    0.0%:\t  W_train_loss:1.7213484\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:50 PM |\t   20.0%:\t  W_train_loss:1.5272181\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:50 PM |\t   40.0%:\t  W_train_loss:1.7064939\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:50 PM |\t   60.0%:\t  W_train_loss:1.2869924\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:50 PM |\t   80.0%:\t  W_train_loss:1.3353302\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:50 PM |\t  1e+02%:\t  W_train_loss:2.1394632\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:50 PM |\t  w_train_loss:9.716846227645874,v_train_loss:0\n",
      "06/13 08:20:50 PM |\t  \n",
      "\n",
      "  ----------------epoch:20,\t\tlr_w:3.125e-05,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:20:50 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:20:51 PM |\t    0.0%:\t  W_train_loss:1.7177831\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:51 PM |\t   20.0%:\t  W_train_loss:1.4834090\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:51 PM |\t   40.0%:\t  W_train_loss:1.6530819\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:20:54 PM |\t  x_decoded[:2]:['translate English to German: Resumption of the session', 'translate English to German: I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.']\n",
      "06/13 08:20:54 PM |\t  pred_decoded[:2]:['Wiederaufnahme der Sitzungsperiode', 'Ich halte das Sitzungsperiode der Europäischen Parlament in der Sitzungsperiode der Europäischen Parlament in der vergangenen Jahrestagung, und ich möchte ich es wieder a Happy New Year in der hope that you enjoyed a pleasant festive period.']\n",
      "06/13 08:20:54 PM |\t  label_decoded[:2]:['Wiederaufnahme der Sitzungsperiode', 'Ich erkläre die am Freitag, dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen, wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe, daß Sie schöne Ferien hatten.']\n",
      "06/13 08:21:05 PM |\t  computing score...\n",
      "06/13 08:21:05 PM |\t  model_w_in_main sacreBLEU : 20.713471\n",
      "06/13 08:21:05 PM |\t  model_w_in_main test loss : 1.000500\n",
      "06/13 08:21:07 PM |\t  x_decoded[:2]:['translate English to German: Resumption of the session', 'translate English to German: I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.']\n",
      "06/13 08:21:07 PM |\t  pred_decoded[:2]:['.', 'I wish you a happy new year in the hope that you enjoyed a pleasant festive period. I wish you a happy new year in the hope that you enjoyed a pleasant festive period.']\n",
      "06/13 08:21:07 PM |\t  label_decoded[:2]:['Wiederaufnahme der Sitzungsperiode', 'Ich erkläre die am Freitag, dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen, wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe, daß Sie schöne Ferien hatten.']\n",
      "06/13 08:21:19 PM |\t  computing score...\n",
      "06/13 08:21:19 PM |\t  model_v_in_main sacreBLEU : 0.370500\n",
      "06/13 08:21:19 PM |\t  model_v_in_main test loss : 5.315890\n",
      "06/13 08:21:19 PM |\t  ('Attention Weights A : ', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>))\n",
      "06/13 08:21:20 PM |\t   60.0%:\t  W_train_loss:1.3178349\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:20 PM |\t   80.0%:\t  W_train_loss:1.2857435\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:21 PM |\t  1e+02%:\t  W_train_loss:2.1100125\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:21 PM |\t  w_train_loss:9.567864894866943,v_train_loss:0\n",
      "06/13 08:21:21 PM |\t  \n",
      "\n",
      "  ----------------epoch:21,\t\tlr_w:6.25e-05,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:21:21 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:21:21 PM |\t    0.0%:\t  W_train_loss:1.6781769\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:21 PM |\t   20.0%:\t  W_train_loss:1.4858716\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:21 PM |\t   40.0%:\t  W_train_loss:1.7028384\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:22 PM |\t   60.0%:\t  W_train_loss:1.2721430\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:22 PM |\t   80.0%:\t  W_train_loss:1.2585280\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:22 PM |\t  1e+02%:\t  W_train_loss:2.1108577\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:22 PM |\t  w_train_loss:9.508415579795837,v_train_loss:0\n",
      "06/13 08:21:22 PM |\t  \n",
      "\n",
      "  ----------------epoch:22,\t\tlr_w:6.25e-05,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:21:22 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:21:22 PM |\t    0.0%:\t  W_train_loss:1.7186017\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:22 PM |\t   20.0%:\t  W_train_loss:1.5036147\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:23 PM |\t   40.0%:\t  W_train_loss:1.6362326\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:23 PM |\t   60.0%:\t  W_train_loss:1.2593354\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:23 PM |\t   80.0%:\t  W_train_loss:1.2734964\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:23 PM |\t  1e+02%:\t  W_train_loss:2.0722055\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:23 PM |\t  w_train_loss:9.463486313819885,v_train_loss:0\n",
      "06/13 08:21:23 PM |\t  \n",
      "\n",
      "  ----------------epoch:23,\t\tlr_w:6.25e-05,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:21:23 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:21:24 PM |\t    0.0%:\t  W_train_loss:1.6147377\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:24 PM |\t   20.0%:\t  W_train_loss:1.4865458\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:24 PM |\t   40.0%:\t  W_train_loss:1.6438857\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:24 PM |\t   60.0%:\t  W_train_loss:1.2836013\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:24 PM |\t   80.0%:\t  W_train_loss:1.2351221\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:25 PM |\t  1e+02%:\t  W_train_loss:2.0852823\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:25 PM |\t  w_train_loss:9.349174976348877,v_train_loss:0\n",
      "06/13 08:21:25 PM |\t  \n",
      "\n",
      "  ----------------epoch:24,\t\tlr_w:6.25e-05,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:21:25 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:21:25 PM |\t    0.0%:\t  W_train_loss:1.6585163\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:25 PM |\t   20.0%:\t  W_train_loss:1.4985212\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:25 PM |\t   40.0%:\t  W_train_loss:1.6175007\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:26 PM |\t   60.0%:\t  W_train_loss:1.2452736\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:26 PM |\t   80.0%:\t  W_train_loss:1.2583542\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:26 PM |\t  1e+02%:\t  W_train_loss:2.0310392\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:26 PM |\t  w_train_loss:9.309205174446106,v_train_loss:0\n",
      "06/13 08:21:26 PM |\t  \n",
      "\n",
      "  ----------------epoch:25,\t\tlr_w:1.5625e-05,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:21:26 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:21:26 PM |\t    0.0%:\t  W_train_loss:1.5953228\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:27 PM |\t   20.0%:\t  W_train_loss:1.4548136\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:27 PM |\t   40.0%:\t  W_train_loss:1.5956546\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:27 PM |\t   60.0%:\t  W_train_loss:1.2226775\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:27 PM |\t   80.0%:\t  W_train_loss:1.2631845\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:27 PM |\t  1e+02%:\t  W_train_loss:2.0408576\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:27 PM |\t  w_train_loss:9.172510623931885,v_train_loss:0\n",
      "06/13 08:21:27 PM |\t  \n",
      "\n",
      "  ----------------epoch:26,\t\tlr_w:3.125e-05,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:21:27 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:21:28 PM |\t    0.0%:\t  W_train_loss:1.7009695\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:28 PM |\t   20.0%:\t  W_train_loss:1.4055986\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:28 PM |\t   40.0%:\t  W_train_loss:1.6005156\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:28 PM |\t   60.0%:\t  W_train_loss:1.2240744\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:29 PM |\t   80.0%:\t  W_train_loss:1.3122505\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:29 PM |\t  1e+02%:\t  W_train_loss:2.0487859\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:29 PM |\t  w_train_loss:9.292194485664368,v_train_loss:0\n",
      "06/13 08:21:29 PM |\t  \n",
      "\n",
      "  ----------------epoch:27,\t\tlr_w:3.125e-05,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:21:29 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:21:29 PM |\t    0.0%:\t  W_train_loss:1.6322411\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:29 PM |\t   20.0%:\t  W_train_loss:1.3791680\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:29 PM |\t   40.0%:\t  W_train_loss:1.5809559\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:30 PM |\t   60.0%:\t  W_train_loss:1.2306142\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:30 PM |\t   80.0%:\t  W_train_loss:1.2471477\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:30 PM |\t  1e+02%:\t  W_train_loss:2.0395091\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:30 PM |\t  w_train_loss:9.109635949134827,v_train_loss:0\n",
      "06/13 08:21:30 PM |\t  \n",
      "\n",
      "  ----------------epoch:28,\t\tlr_w:3.125e-05,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:21:30 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:21:30 PM |\t    0.0%:\t  W_train_loss:1.6110742\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:31 PM |\t   20.0%:\t  W_train_loss:1.3622739\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:31 PM |\t   40.0%:\t  W_train_loss:1.5985107\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:31 PM |\t   60.0%:\t  W_train_loss:1.2096322\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:31 PM |\t   80.0%:\t  W_train_loss:1.2270191\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:31 PM |\t  1e+02%:\t  W_train_loss:2.0172830\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:31 PM |\t  w_train_loss:9.025793075561523,v_train_loss:0\n",
      "06/13 08:21:31 PM |\t  \n",
      "\n",
      "  ----------------epoch:29,\t\tlr_w:3.125e-05,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:21:31 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:21:32 PM |\t    0.0%:\t  W_train_loss:1.6128592\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:32 PM |\t   20.0%:\t  W_train_loss:1.4261169\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:32 PM |\t   40.0%:\t  W_train_loss:1.5698200\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:32 PM |\t   60.0%:\t  W_train_loss:1.1914718\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:33 PM |\t   80.0%:\t  W_train_loss:1.2008005\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:33 PM |\t  1e+02%:\t  W_train_loss:2.0118012\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:33 PM |\t  w_train_loss:9.012869834899902,v_train_loss:0\n",
      "06/13 08:21:33 PM |\t  \n",
      "\n",
      "  ----------------epoch:30,\t\tlr_w:7.8125e-06,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:21:33 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:21:33 PM |\t    0.0%:\t  W_train_loss:1.6456168\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:33 PM |\t   20.0%:\t  W_train_loss:1.3866377\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:34 PM |\t   40.0%:\t  W_train_loss:1.5955529\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:34 PM |\t   60.0%:\t  W_train_loss:1.2511895\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:34 PM |\t   80.0%:\t  W_train_loss:1.1823409\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:21:37 PM |\t  x_decoded[:2]:['translate English to German: Resumption of the session', 'translate English to German: I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.']\n",
      "06/13 08:21:37 PM |\t  pred_decoded[:2]:['Wiederaufnahme der Sitzungsperiode', 'Ich erhebt sich der Sitzungsperiode des Europäischen Parlaments der Sitzungsperiode des Europäischen Parlaments zur Verfügung stehen, und ich möchte ich Sie a Happy New Year in der hope that you enjoyed a pleasant festive period.']\n",
      "06/13 08:21:37 PM |\t  label_decoded[:2]:['Wiederaufnahme der Sitzungsperiode', 'Ich erkläre die am Freitag, dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen, wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe, daß Sie schöne Ferien hatten.']\n",
      "06/13 08:21:47 PM |\t  computing score...\n",
      "06/13 08:21:48 PM |\t  model_w_in_main sacreBLEU : 21.609205\n",
      "06/13 08:21:48 PM |\t  model_w_in_main test loss : 0.907310\n",
      "06/13 08:21:50 PM |\t  x_decoded[:2]:['translate English to German: Resumption of the session', 'translate English to German: I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.']\n",
      "06/13 08:21:50 PM |\t  pred_decoded[:2]:['.', 'I wish you a happy new year in the hope that you enjoyed a pleasant festive period. I wish you a happy new year in the hope that you enjoyed a pleasant festive period.']\n",
      "06/13 08:21:50 PM |\t  label_decoded[:2]:['Wiederaufnahme der Sitzungsperiode', 'Ich erkläre die am Freitag, dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen, wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe, daß Sie schöne Ferien hatten.']\n",
      "06/13 08:22:02 PM |\t  computing score...\n",
      "06/13 08:22:02 PM |\t  model_v_in_main sacreBLEU : 0.370500\n",
      "06/13 08:22:02 PM |\t  model_v_in_main test loss : 5.315890\n",
      "06/13 08:22:02 PM |\t  ('Attention Weights A : ', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>))\n",
      "06/13 08:22:03 PM |\t  1e+02%:\t  W_train_loss:2.0807083\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:03 PM |\t  w_train_loss:9.142045974731445,v_train_loss:0\n",
      "06/13 08:22:03 PM |\t  \n",
      "\n",
      "  ----------------epoch:31,\t\tlr_w:1.5625e-05,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:22:03 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:22:03 PM |\t    0.0%:\t  W_train_loss:1.5876558\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:04 PM |\t   20.0%:\t  W_train_loss:1.4273975\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:04 PM |\t   40.0%:\t  W_train_loss:1.5654314\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:04 PM |\t   60.0%:\t  W_train_loss:1.2009906\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:04 PM |\t   80.0%:\t  W_train_loss:1.1703217\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:04 PM |\t  1e+02%:\t  W_train_loss:1.9943665\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:04 PM |\t  w_train_loss:8.946163415908813,v_train_loss:0\n",
      "06/13 08:22:04 PM |\t  \n",
      "\n",
      "  ----------------epoch:32,\t\tlr_w:1.5625e-05,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:22:04 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:22:05 PM |\t    0.0%:\t  W_train_loss:1.6046045\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:05 PM |\t   20.0%:\t  W_train_loss:1.4653327\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:05 PM |\t   40.0%:\t  W_train_loss:1.5749711\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:05 PM |\t   60.0%:\t  W_train_loss:1.2395420\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:06 PM |\t   80.0%:\t  W_train_loss:1.1826613\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:06 PM |\t  1e+02%:\t  W_train_loss:1.9992250\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:06 PM |\t  w_train_loss:9.066336631774902,v_train_loss:0\n",
      "06/13 08:22:06 PM |\t  \n",
      "\n",
      "  ----------------epoch:33,\t\tlr_w:1.5625e-05,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:22:06 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:22:06 PM |\t    0.0%:\t  W_train_loss:1.5702049\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:06 PM |\t   20.0%:\t  W_train_loss:1.3558031\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:06 PM |\t   40.0%:\t  W_train_loss:1.5126359\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:07 PM |\t   60.0%:\t  W_train_loss:1.1772039\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:07 PM |\t   80.0%:\t  W_train_loss:1.1575792\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:07 PM |\t  1e+02%:\t  W_train_loss:2.0188093\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:07 PM |\t  w_train_loss:8.792236328125,v_train_loss:0\n",
      "06/13 08:22:07 PM |\t  \n",
      "\n",
      "  ----------------epoch:34,\t\tlr_w:1.5625e-05,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:22:07 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:22:07 PM |\t    0.0%:\t  W_train_loss:1.6295682\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:08 PM |\t   20.0%:\t  W_train_loss:1.3428605\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:08 PM |\t   40.0%:\t  W_train_loss:1.5692376\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:08 PM |\t   60.0%:\t  W_train_loss:1.1614904\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:08 PM |\t   80.0%:\t  W_train_loss:1.1611998\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:08 PM |\t  1e+02%:\t  W_train_loss:2.0267115\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:08 PM |\t  w_train_loss:8.89106798171997,v_train_loss:0\n",
      "06/13 08:22:08 PM |\t  \n",
      "\n",
      "  ----------------epoch:35,\t\tlr_w:3.90625e-06,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:22:08 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:22:09 PM |\t    0.0%:\t  W_train_loss:1.5701824\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:09 PM |\t   20.0%:\t  W_train_loss:1.3553510\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:09 PM |\t   40.0%:\t  W_train_loss:1.5956053\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:09 PM |\t   60.0%:\t  W_train_loss:1.2177235\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:10 PM |\t   80.0%:\t  W_train_loss:1.2116532\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:10 PM |\t  1e+02%:\t  W_train_loss:2.0326042\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:10 PM |\t  w_train_loss:8.98311960697174,v_train_loss:0\n",
      "06/13 08:22:10 PM |\t  \n",
      "\n",
      "  ----------------epoch:36,\t\tlr_w:7.8125e-06,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:22:10 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:22:10 PM |\t    0.0%:\t  W_train_loss:1.5677752\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:10 PM |\t   20.0%:\t  W_train_loss:1.3618019\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:11 PM |\t   40.0%:\t  W_train_loss:1.6106350\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:11 PM |\t   60.0%:\t  W_train_loss:1.1405736\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:11 PM |\t   80.0%:\t  W_train_loss:1.2293966\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:11 PM |\t  1e+02%:\t  W_train_loss:1.9881072\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:11 PM |\t  w_train_loss:8.898289561271667,v_train_loss:0\n",
      "06/13 08:22:11 PM |\t  \n",
      "\n",
      "  ----------------epoch:37,\t\tlr_w:7.8125e-06,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:22:11 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:22:11 PM |\t    0.0%:\t  W_train_loss:1.5321906\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:12 PM |\t   20.0%:\t  W_train_loss:1.3600991\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:12 PM |\t   40.0%:\t  W_train_loss:1.5405892\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:12 PM |\t   60.0%:\t  W_train_loss:1.2063739\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:12 PM |\t   80.0%:\t  W_train_loss:1.2067218\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:13 PM |\t  1e+02%:\t  W_train_loss:2.0193186\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:13 PM |\t  w_train_loss:8.865293145179749,v_train_loss:0\n",
      "06/13 08:22:13 PM |\t  \n",
      "\n",
      "  ----------------epoch:38,\t\tlr_w:7.8125e-06,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:22:13 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:22:13 PM |\t    0.0%:\t  W_train_loss:1.5448238\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:13 PM |\t   20.0%:\t  W_train_loss:1.3930521\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:13 PM |\t   40.0%:\t  W_train_loss:1.6093993\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:13 PM |\t   60.0%:\t  W_train_loss:1.1497099\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:14 PM |\t   80.0%:\t  W_train_loss:1.1336563\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:14 PM |\t  1e+02%:\t  W_train_loss:1.9711957\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:14 PM |\t  w_train_loss:8.801837086677551,v_train_loss:0\n",
      "06/13 08:22:14 PM |\t  \n",
      "\n",
      "  ----------------epoch:39,\t\tlr_w:7.8125e-06,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:22:14 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:22:14 PM |\t    0.0%:\t  W_train_loss:1.6016655\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:14 PM |\t   20.0%:\t  W_train_loss:1.3750796\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:15 PM |\t   40.0%:\t  W_train_loss:1.5883722\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:15 PM |\t   60.0%:\t  W_train_loss:1.1696451\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:15 PM |\t   80.0%:\t  W_train_loss:1.1650656\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:15 PM |\t  1e+02%:\t  W_train_loss:2.0422535\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:15 PM |\t  w_train_loss:8.942081570625305,v_train_loss:0\n",
      "06/13 08:22:15 PM |\t  \n",
      "\n",
      "  ----------------epoch:40,\t\tlr_w:1.953125e-06,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:22:15 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:22:15 PM |\t    0.0%:\t  W_train_loss:1.5201492\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:16 PM |\t   20.0%:\t  W_train_loss:1.3364265\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:16 PM |\t   40.0%:\t  W_train_loss:1.5715435\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:16 PM |\t   60.0%:\t  W_train_loss:1.1776413\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:16 PM |\t   80.0%:\t  W_train_loss:1.2019243\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:17 PM |\t  1e+02%:\t  W_train_loss:1.9919291\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:17 PM |\t  w_train_loss:8.79961383342743,v_train_loss:0\n",
      "06/13 08:22:17 PM |\t  \n",
      "\n",
      "  ----------------epoch:41,\t\tlr_w:3.90625e-06,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:22:17 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:22:17 PM |\t    0.0%:\t  W_train_loss:1.5701045\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:20 PM |\t  x_decoded[:2]:['translate English to German: Resumption of the session', 'translate English to German: I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.']\n",
      "06/13 08:22:20 PM |\t  pred_decoded[:2]:['Wiederaufnahme der Sitzungsperiode', 'Ich beglückwünsche Ihnen einen Sitzungsperiode des Europäischen Parlaments zur Sitzungsperiode des Europäischen Parlaments zur Verfügung stehen, und ich möchte ich Sie a Happy New Year in der hope that you enjoyed a pleasant festive period.']\n",
      "06/13 08:22:20 PM |\t  label_decoded[:2]:['Wiederaufnahme der Sitzungsperiode', 'Ich erkläre die am Freitag, dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen, wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe, daß Sie schöne Ferien hatten.']\n",
      "06/13 08:22:30 PM |\t  computing score...\n",
      "06/13 08:22:30 PM |\t  model_w_in_main sacreBLEU : 22.631828\n",
      "06/13 08:22:30 PM |\t  model_w_in_main test loss : 0.884386\n",
      "06/13 08:22:33 PM |\t  x_decoded[:2]:['translate English to German: Resumption of the session', 'translate English to German: I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.']\n",
      "06/13 08:22:33 PM |\t  pred_decoded[:2]:['.', 'I wish you a happy new year in the hope that you enjoyed a pleasant festive period. I wish you a happy new year in the hope that you enjoyed a pleasant festive period.']\n",
      "06/13 08:22:33 PM |\t  label_decoded[:2]:['Wiederaufnahme der Sitzungsperiode', 'Ich erkläre die am Freitag, dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen, wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe, daß Sie schöne Ferien hatten.']\n",
      "06/13 08:22:44 PM |\t  computing score...\n",
      "06/13 08:22:44 PM |\t  model_v_in_main sacreBLEU : 0.370500\n",
      "06/13 08:22:44 PM |\t  model_v_in_main test loss : 5.315890\n",
      "06/13 08:22:44 PM |\t  ('Attention Weights A : ', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>))\n",
      "06/13 08:22:46 PM |\t   20.0%:\t  W_train_loss:1.4184546\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:46 PM |\t   40.0%:\t  W_train_loss:1.5547665\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:46 PM |\t   60.0%:\t  W_train_loss:1.2131960\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:47 PM |\t   80.0%:\t  W_train_loss:1.1396997\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:47 PM |\t  1e+02%:\t  W_train_loss:2.0009735\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:47 PM |\t  w_train_loss:8.897194862365723,v_train_loss:0\n",
      "06/13 08:22:47 PM |\t  \n",
      "\n",
      "  ----------------epoch:42,\t\tlr_w:3.90625e-06,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:22:47 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:22:47 PM |\t    0.0%:\t  W_train_loss:1.6150527\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:47 PM |\t   20.0%:\t  W_train_loss:1.3900169\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:48 PM |\t   40.0%:\t  W_train_loss:1.5648724\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:48 PM |\t   60.0%:\t  W_train_loss:1.1446395\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:48 PM |\t   80.0%:\t  W_train_loss:1.2135850\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:48 PM |\t  1e+02%:\t  W_train_loss:1.9854126\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:48 PM |\t  w_train_loss:8.913579106330872,v_train_loss:0\n",
      "06/13 08:22:48 PM |\t  \n",
      "\n",
      "  ----------------epoch:43,\t\tlr_w:3.90625e-06,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:22:48 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:22:48 PM |\t    0.0%:\t  W_train_loss:1.5632324\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:49 PM |\t   20.0%:\t  W_train_loss:1.3896136\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:49 PM |\t   40.0%:\t  W_train_loss:1.5966887\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:49 PM |\t   60.0%:\t  W_train_loss:1.2064452\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:49 PM |\t   80.0%:\t  W_train_loss:1.1675396\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:50 PM |\t  1e+02%:\t  W_train_loss:2.0097923\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:50 PM |\t  w_train_loss:8.933311939239502,v_train_loss:0\n",
      "06/13 08:22:50 PM |\t  \n",
      "\n",
      "  ----------------epoch:44,\t\tlr_w:3.90625e-06,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:22:50 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:22:50 PM |\t    0.0%:\t  W_train_loss:1.5972445\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:50 PM |\t   20.0%:\t  W_train_loss:1.3639176\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:50 PM |\t   40.0%:\t  W_train_loss:1.5780742\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:50 PM |\t   60.0%:\t  W_train_loss:1.2275810\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:51 PM |\t   80.0%:\t  W_train_loss:1.1868498\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:51 PM |\t  1e+02%:\t  W_train_loss:1.9916965\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:51 PM |\t  w_train_loss:8.945363640785217,v_train_loss:0\n",
      "06/13 08:22:51 PM |\t  \n",
      "\n",
      "  ----------------epoch:45,\t\tlr_w:9.765625e-07,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:22:51 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:22:51 PM |\t    0.0%:\t  W_train_loss:1.5699327\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:51 PM |\t   20.0%:\t  W_train_loss:1.3707988\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:52 PM |\t   40.0%:\t  W_train_loss:1.5729203\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:52 PM |\t   60.0%:\t  W_train_loss:1.1951468\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:52 PM |\t   80.0%:\t  W_train_loss:1.1812063\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:52 PM |\t  1e+02%:\t  W_train_loss:2.0260446\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:52 PM |\t  w_train_loss:8.916049599647522,v_train_loss:0\n",
      "06/13 08:22:52 PM |\t  \n",
      "\n",
      "  ----------------epoch:46,\t\tlr_w:1.953125e-06,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:22:52 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:22:52 PM |\t    0.0%:\t  W_train_loss:1.5830352\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:53 PM |\t   20.0%:\t  W_train_loss:1.3767076\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:53 PM |\t   40.0%:\t  W_train_loss:1.5619272\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:53 PM |\t   60.0%:\t  W_train_loss:1.2005231\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:53 PM |\t   80.0%:\t  W_train_loss:1.1502252\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:54 PM |\t  1e+02%:\t  W_train_loss:1.9949827\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:54 PM |\t  w_train_loss:8.867401003837585,v_train_loss:0\n",
      "06/13 08:22:54 PM |\t  \n",
      "\n",
      "  ----------------epoch:47,\t\tlr_w:1.953125e-06,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:22:54 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:22:54 PM |\t    0.0%:\t  W_train_loss:1.5798551\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:54 PM |\t   20.0%:\t  W_train_loss:1.3819751\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:54 PM |\t   40.0%:\t  W_train_loss:1.6175973\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:55 PM |\t   60.0%:\t  W_train_loss:1.2025802\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:55 PM |\t   80.0%:\t  W_train_loss:1.1432369\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:55 PM |\t  1e+02%:\t  W_train_loss:1.9627258\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:55 PM |\t  w_train_loss:8.887970328330994,v_train_loss:0\n",
      "06/13 08:22:55 PM |\t  \n",
      "\n",
      "  ----------------epoch:48,\t\tlr_w:1.953125e-06,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:22:55 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:22:55 PM |\t    0.0%:\t  W_train_loss:1.5365906\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:55 PM |\t   20.0%:\t  W_train_loss:1.3970367\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:56 PM |\t   40.0%:\t  W_train_loss:1.5599468\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:56 PM |\t   60.0%:\t  W_train_loss:1.1961114\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:56 PM |\t   80.0%:\t  W_train_loss:1.2397811\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:56 PM |\t  1e+02%:\t  W_train_loss:2.0125558\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:56 PM |\t  w_train_loss:8.942022442817688,v_train_loss:0\n",
      "06/13 08:22:56 PM |\t  \n",
      "\n",
      "  ----------------epoch:49,\t\tlr_w:1.953125e-06,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:22:56 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:22:57 PM |\t    0.0%:\t  W_train_loss:1.5354722\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:57 PM |\t   20.0%:\t  W_train_loss:1.3322929\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:57 PM |\t   40.0%:\t  W_train_loss:1.5347941\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:57 PM |\t   60.0%:\t  W_train_loss:1.1739058\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:57 PM |\t   80.0%:\t  W_train_loss:1.1603876\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:58 PM |\t  1e+02%:\t  W_train_loss:1.9918268\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:58 PM |\t  w_train_loss:8.728679418563843,v_train_loss:0\n",
      "06/13 08:22:58 PM |\t  \n",
      "\n",
      "  ----------------epoch:50,\t\tlr_w:4.8828125e-07,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:22:58 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:22:58 PM |\t    0.0%:\t  W_train_loss:1.5456467\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:58 PM |\t   20.0%:\t  W_train_loss:1.3739773\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:58 PM |\t   40.0%:\t  W_train_loss:1.5473293\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:59 PM |\t   60.0%:\t  W_train_loss:1.1691982\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:59 PM |\t   80.0%:\t  W_train_loss:1.1556692\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:59 PM |\t  1e+02%:\t  W_train_loss:1.9692969\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:59 PM |\t  w_train_loss:8.761117577552795,v_train_loss:0\n",
      "06/13 08:22:59 PM |\t  \n",
      "\n",
      "  ----------------epoch:51,\t\tlr_w:9.765625e-07,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:22:59 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:22:59 PM |\t    0.0%:\t  W_train_loss:1.5449758\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:22:59 PM |\t   20.0%:\t  W_train_loss:1.3819715\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:00 PM |\t   40.0%:\t  W_train_loss:1.5241148\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:03 PM |\t  x_decoded[:2]:['translate English to German: Resumption of the session', 'translate English to German: I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.']\n",
      "06/13 08:23:03 PM |\t  pred_decoded[:2]:['Wiederaufnahme der Sitzungsperiode', 'Ich beglückwünsche Ihnen einen Sitzungsperiode des Europäischen Parlaments zur Sitzungsperiode des Europäischen Parlaments zur Verfügung stehen, und ich möchte ich Sie a Happy New Year in der hope that you enjoyed a pleasant festive period.']\n",
      "06/13 08:23:03 PM |\t  label_decoded[:2]:['Wiederaufnahme der Sitzungsperiode', 'Ich erkläre die am Freitag, dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen, wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe, daß Sie schöne Ferien hatten.']\n",
      "06/13 08:23:13 PM |\t  computing score...\n",
      "06/13 08:23:13 PM |\t  model_w_in_main sacreBLEU : 22.808044\n",
      "06/13 08:23:13 PM |\t  model_w_in_main test loss : 0.878763\n",
      "06/13 08:23:16 PM |\t  x_decoded[:2]:['translate English to German: Resumption of the session', 'translate English to German: I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.']\n",
      "06/13 08:23:16 PM |\t  pred_decoded[:2]:['.', 'I wish you a happy new year in the hope that you enjoyed a pleasant festive period. I wish you a happy new year in the hope that you enjoyed a pleasant festive period.']\n",
      "06/13 08:23:16 PM |\t  label_decoded[:2]:['Wiederaufnahme der Sitzungsperiode', 'Ich erkläre die am Freitag, dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen, wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe, daß Sie schöne Ferien hatten.']\n",
      "06/13 08:23:27 PM |\t  computing score...\n",
      "06/13 08:23:27 PM |\t  model_v_in_main sacreBLEU : 0.370500\n",
      "06/13 08:23:27 PM |\t  model_v_in_main test loss : 5.315890\n",
      "06/13 08:23:27 PM |\t  ('Attention Weights A : ', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>))\n",
      "06/13 08:23:29 PM |\t   60.0%:\t  W_train_loss:1.1516651\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:29 PM |\t   80.0%:\t  W_train_loss:1.1863184\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:29 PM |\t  1e+02%:\t  W_train_loss:2.0159230\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:29 PM |\t  w_train_loss:8.80496859550476,v_train_loss:0\n",
      "06/13 08:23:29 PM |\t  \n",
      "\n",
      "  ----------------epoch:52,\t\tlr_w:9.765625e-07,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:23:29 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:23:29 PM |\t    0.0%:\t  W_train_loss:1.5699621\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:29 PM |\t   20.0%:\t  W_train_loss:1.3623168\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:30 PM |\t   40.0%:\t  W_train_loss:1.5982391\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:30 PM |\t   60.0%:\t  W_train_loss:1.2162863\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:30 PM |\t   80.0%:\t  W_train_loss:1.1784060\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:30 PM |\t  1e+02%:\t  W_train_loss:2.0128734\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:30 PM |\t  w_train_loss:8.93808376789093,v_train_loss:0\n",
      "06/13 08:23:30 PM |\t  \n",
      "\n",
      "  ----------------epoch:53,\t\tlr_w:9.765625e-07,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:23:30 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:23:31 PM |\t    0.0%:\t  W_train_loss:1.5877149\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:31 PM |\t   20.0%:\t  W_train_loss:1.3579533\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:31 PM |\t   40.0%:\t  W_train_loss:1.4758546\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:31 PM |\t   60.0%:\t  W_train_loss:1.1314180\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:31 PM |\t   80.0%:\t  W_train_loss:1.1628385\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:32 PM |\t  1e+02%:\t  W_train_loss:2.0172675\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:32 PM |\t  w_train_loss:8.733046770095825,v_train_loss:0\n",
      "06/13 08:23:32 PM |\t  \n",
      "\n",
      "  ----------------epoch:54,\t\tlr_w:9.765625e-07,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:23:32 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:23:32 PM |\t    0.0%:\t  W_train_loss:1.6132932\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:32 PM |\t   20.0%:\t  W_train_loss:1.3489112\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:32 PM |\t   40.0%:\t  W_train_loss:1.6338466\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:33 PM |\t   60.0%:\t  W_train_loss:1.1535734\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:33 PM |\t   80.0%:\t  W_train_loss:1.1742184\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:33 PM |\t  1e+02%:\t  W_train_loss:2.0142236\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:33 PM |\t  w_train_loss:8.938066363334656,v_train_loss:0\n",
      "06/13 08:23:33 PM |\t  \n",
      "\n",
      "  ----------------epoch:55,\t\tlr_w:2.44140625e-07,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:23:33 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:23:33 PM |\t    0.0%:\t  W_train_loss:1.5977280\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:34 PM |\t   20.0%:\t  W_train_loss:1.3615854\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:34 PM |\t   40.0%:\t  W_train_loss:1.5421368\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:34 PM |\t   60.0%:\t  W_train_loss:1.1599519\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:34 PM |\t   80.0%:\t  W_train_loss:1.1592647\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:34 PM |\t  1e+02%:\t  W_train_loss:1.9752576\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:34 PM |\t  w_train_loss:8.795924425125122,v_train_loss:0\n",
      "06/13 08:23:34 PM |\t  \n",
      "\n",
      "  ----------------epoch:56,\t\tlr_w:4.8828125e-07,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:23:34 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:23:35 PM |\t    0.0%:\t  W_train_loss:1.5383445\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:35 PM |\t   20.0%:\t  W_train_loss:1.3112395\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:35 PM |\t   40.0%:\t  W_train_loss:1.5361407\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:35 PM |\t   60.0%:\t  W_train_loss:1.1969688\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:36 PM |\t   80.0%:\t  W_train_loss:1.1534183\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:36 PM |\t  1e+02%:\t  W_train_loss:1.9807992\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:36 PM |\t  w_train_loss:8.7169109582901,v_train_loss:0\n",
      "06/13 08:23:36 PM |\t  \n",
      "\n",
      "  ----------------epoch:57,\t\tlr_w:4.8828125e-07,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:23:36 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:23:36 PM |\t    0.0%:\t  W_train_loss:1.5730826\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:36 PM |\t   20.0%:\t  W_train_loss:1.3894253\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:36 PM |\t   40.0%:\t  W_train_loss:1.4840151\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:37 PM |\t   60.0%:\t  W_train_loss:1.1417091\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:37 PM |\t   80.0%:\t  W_train_loss:1.2219583\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:37 PM |\t  1e+02%:\t  W_train_loss:1.9840113\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:37 PM |\t  w_train_loss:8.794201612472534,v_train_loss:0\n",
      "06/13 08:23:37 PM |\t  \n",
      "\n",
      "  ----------------epoch:58,\t\tlr_w:4.8828125e-07,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:23:37 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:23:37 PM |\t    0.0%:\t  W_train_loss:1.5794703\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:38 PM |\t   20.0%:\t  W_train_loss:1.3787905\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:38 PM |\t   40.0%:\t  W_train_loss:1.5214101\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:38 PM |\t   60.0%:\t  W_train_loss:1.1792616\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:38 PM |\t   80.0%:\t  W_train_loss:1.1856718\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:38 PM |\t  1e+02%:\t  W_train_loss:1.9330630\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:38 PM |\t  w_train_loss:8.77766728401184,v_train_loss:0\n",
      "06/13 08:23:38 PM |\t  \n",
      "\n",
      "  ----------------epoch:59,\t\tlr_w:4.8828125e-07,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:23:38 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:23:39 PM |\t    0.0%:\t  W_train_loss:1.5614612\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:39 PM |\t   20.0%:\t  W_train_loss:1.3381984\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:39 PM |\t   40.0%:\t  W_train_loss:1.5604860\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:39 PM |\t   60.0%:\t  W_train_loss:1.1504064\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:40 PM |\t   80.0%:\t  W_train_loss:1.1259116\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:40 PM |\t  1e+02%:\t  W_train_loss:1.9886694\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:40 PM |\t  w_train_loss:8.725132942199707,v_train_loss:0\n",
      "06/13 08:23:40 PM |\t  \n",
      "\n",
      "  ----------------epoch:60,\t\tlr_w:1.220703125e-07,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:23:40 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:23:40 PM |\t    0.0%:\t  W_train_loss:1.5877948\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:40 PM |\t   20.0%:\t  W_train_loss:1.3656713\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:40 PM |\t   40.0%:\t  W_train_loss:1.6226211\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:41 PM |\t   60.0%:\t  W_train_loss:1.1690907\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:41 PM |\t   80.0%:\t  W_train_loss:1.1939797\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:41 PM |\t  1e+02%:\t  W_train_loss:2.0723531\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:41 PM |\t  w_train_loss:9.011510729789734,v_train_loss:0\n",
      "06/13 08:23:41 PM |\t  \n",
      "\n",
      "  ----------------epoch:61,\t\tlr_w:2.44140625e-07,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:23:41 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:23:41 PM |\t    0.0%:\t  W_train_loss:1.5333562\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:42 PM |\t   20.0%:\t  W_train_loss:1.4241942\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:42 PM |\t   40.0%:\t  W_train_loss:1.5567226\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:42 PM |\t   60.0%:\t  W_train_loss:1.1742939\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:42 PM |\t   80.0%:\t  W_train_loss:1.1705880\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:23:45 PM |\t  x_decoded[:2]:['translate English to German: Resumption of the session', 'translate English to German: I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.']\n",
      "06/13 08:23:45 PM |\t  pred_decoded[:2]:['Wiederaufnahme der Sitzungsperiode', 'Ich beglückwünsche Ihnen einen Sitzungsperiode des Europäischen Parlaments zur Sitzungsperiode des Europäischen Parlaments zur Verfügung stehen, und ich möchte ich Sie a Happy New Year in der hope that you enjoyed a pleasant festive period.']\n",
      "06/13 08:23:45 PM |\t  label_decoded[:2]:['Wiederaufnahme der Sitzungsperiode', 'Ich erkläre die am Freitag, dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen, wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe, daß Sie schöne Ferien hatten.']\n",
      "06/13 08:23:56 PM |\t  computing score...\n",
      "06/13 08:23:56 PM |\t  model_w_in_main sacreBLEU : 23.264548\n",
      "06/13 08:23:56 PM |\t  model_w_in_main test loss : 0.877526\n",
      "06/13 08:23:58 PM |\t  x_decoded[:2]:['translate English to German: Resumption of the session', 'translate English to German: I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.']\n",
      "06/13 08:23:58 PM |\t  pred_decoded[:2]:['.', 'I wish you a happy new year in the hope that you enjoyed a pleasant festive period. I wish you a happy new year in the hope that you enjoyed a pleasant festive period.']\n",
      "06/13 08:23:58 PM |\t  label_decoded[:2]:['Wiederaufnahme der Sitzungsperiode', 'Ich erkläre die am Freitag, dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen, wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe, daß Sie schöne Ferien hatten.']\n",
      "06/13 08:24:10 PM |\t  computing score...\n",
      "06/13 08:24:10 PM |\t  model_v_in_main sacreBLEU : 0.370500\n",
      "06/13 08:24:10 PM |\t  model_v_in_main test loss : 5.315890\n",
      "06/13 08:24:10 PM |\t  ('Attention Weights A : ', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>))\n",
      "06/13 08:24:11 PM |\t  1e+02%:\t  W_train_loss:1.9136405\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:11 PM |\t  w_train_loss:8.77279543876648,v_train_loss:0\n",
      "06/13 08:24:11 PM |\t  \n",
      "\n",
      "  ----------------epoch:62,\t\tlr_w:2.44140625e-07,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:24:11 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:24:11 PM |\t    0.0%:\t  W_train_loss:1.5731759\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:12 PM |\t   20.0%:\t  W_train_loss:1.3962030\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:12 PM |\t   40.0%:\t  W_train_loss:1.4998996\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:12 PM |\t   60.0%:\t  W_train_loss:1.1654496\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:12 PM |\t   80.0%:\t  W_train_loss:1.1387241\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:13 PM |\t  1e+02%:\t  W_train_loss:1.9951465\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:13 PM |\t  w_train_loss:8.768598794937134,v_train_loss:0\n",
      "06/13 08:24:13 PM |\t  \n",
      "\n",
      "  ----------------epoch:63,\t\tlr_w:2.44140625e-07,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:24:13 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:24:13 PM |\t    0.0%:\t  W_train_loss:1.5718014\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:13 PM |\t   20.0%:\t  W_train_loss:1.3386889\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:13 PM |\t   40.0%:\t  W_train_loss:1.5535181\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:13 PM |\t   60.0%:\t  W_train_loss:1.2084153\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:14 PM |\t   80.0%:\t  W_train_loss:1.1349878\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:14 PM |\t  1e+02%:\t  W_train_loss:1.9997752\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:14 PM |\t  w_train_loss:8.807186603546143,v_train_loss:0\n",
      "06/13 08:24:14 PM |\t  \n",
      "\n",
      "  ----------------epoch:64,\t\tlr_w:2.44140625e-07,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:24:14 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:24:14 PM |\t    0.0%:\t  W_train_loss:1.5427959\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:14 PM |\t   20.0%:\t  W_train_loss:1.2957150\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:15 PM |\t   40.0%:\t  W_train_loss:1.5601821\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:15 PM |\t   60.0%:\t  W_train_loss:1.1614182\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:15 PM |\t   80.0%:\t  W_train_loss:1.1764758\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:15 PM |\t  1e+02%:\t  W_train_loss:1.9607890\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:15 PM |\t  w_train_loss:8.697375893592834,v_train_loss:0\n",
      "06/13 08:24:15 PM |\t  \n",
      "\n",
      "  ----------------epoch:65,\t\tlr_w:6.103515625e-08,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:24:15 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:24:16 PM |\t    0.0%:\t  W_train_loss:1.5648282\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:16 PM |\t   20.0%:\t  W_train_loss:1.3871207\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:16 PM |\t   40.0%:\t  W_train_loss:1.5693489\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:16 PM |\t   60.0%:\t  W_train_loss:1.1904674\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:16 PM |\t   80.0%:\t  W_train_loss:1.1906914\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:17 PM |\t  1e+02%:\t  W_train_loss:1.9901118\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:17 PM |\t  w_train_loss:8.892568349838257,v_train_loss:0\n",
      "06/13 08:24:17 PM |\t  \n",
      "\n",
      "  ----------------epoch:66,\t\tlr_w:1.220703125e-07,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:24:17 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:24:17 PM |\t    0.0%:\t  W_train_loss:1.5504594\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:17 PM |\t   20.0%:\t  W_train_loss:1.3661455\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:17 PM |\t   40.0%:\t  W_train_loss:1.5300093\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:18 PM |\t   60.0%:\t  W_train_loss:1.2007120\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:18 PM |\t   80.0%:\t  W_train_loss:1.2031827\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:18 PM |\t  1e+02%:\t  W_train_loss:1.9342135\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:18 PM |\t  w_train_loss:8.784722328186035,v_train_loss:0\n",
      "06/13 08:24:18 PM |\t  \n",
      "\n",
      "  ----------------epoch:67,\t\tlr_w:1.220703125e-07,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:24:18 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:24:18 PM |\t    0.0%:\t  W_train_loss:1.5906644\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:18 PM |\t   20.0%:\t  W_train_loss:1.3565516\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:19 PM |\t   40.0%:\t  W_train_loss:1.5610754\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:19 PM |\t   60.0%:\t  W_train_loss:1.1487138\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:19 PM |\t   80.0%:\t  W_train_loss:1.1805086\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:19 PM |\t  1e+02%:\t  W_train_loss:2.0142295\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:19 PM |\t  w_train_loss:8.851743459701538,v_train_loss:0\n",
      "06/13 08:24:19 PM |\t  \n",
      "\n",
      "  ----------------epoch:68,\t\tlr_w:1.220703125e-07,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:24:19 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:24:20 PM |\t    0.0%:\t  W_train_loss:1.5935028\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:20 PM |\t   20.0%:\t  W_train_loss:1.4243802\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:20 PM |\t   40.0%:\t  W_train_loss:1.6149807\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:20 PM |\t   60.0%:\t  W_train_loss:1.1852140\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:20 PM |\t   80.0%:\t  W_train_loss:1.1795568\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:21 PM |\t  1e+02%:\t  W_train_loss:1.9556533\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:21 PM |\t  w_train_loss:8.953287839889526,v_train_loss:0\n",
      "06/13 08:24:21 PM |\t  \n",
      "\n",
      "  ----------------epoch:69,\t\tlr_w:1.220703125e-07,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:24:21 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:24:21 PM |\t    0.0%:\t  W_train_loss:1.6025342\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:21 PM |\t   20.0%:\t  W_train_loss:1.3333402\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:21 PM |\t   40.0%:\t  W_train_loss:1.5703516\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:22 PM |\t   60.0%:\t  W_train_loss:1.1787024\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:22 PM |\t   80.0%:\t  W_train_loss:1.1716025\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:22 PM |\t  1e+02%:\t  W_train_loss:1.9805468\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:22 PM |\t  w_train_loss:8.837077617645264,v_train_loss:0\n",
      "06/13 08:24:22 PM |\t  \n",
      "\n",
      "  ----------------epoch:70,\t\tlr_w:3.0517578125e-08,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:24:22 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:24:22 PM |\t    0.0%:\t  W_train_loss:1.6005868\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:23 PM |\t   20.0%:\t  W_train_loss:1.3471160\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:23 PM |\t   40.0%:\t  W_train_loss:1.4863510\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:23 PM |\t   60.0%:\t  W_train_loss:1.1742537\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:23 PM |\t   80.0%:\t  W_train_loss:1.0952052\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:23 PM |\t  1e+02%:\t  W_train_loss:1.9444165\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:23 PM |\t  w_train_loss:8.647929191589355,v_train_loss:0\n",
      "06/13 08:24:23 PM |\t  \n",
      "\n",
      "  ----------------epoch:71,\t\tlr_w:6.103515625e-08,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:24:23 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:24:24 PM |\t    0.0%:\t  W_train_loss:1.5525478\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:24 PM |\t   20.0%:\t  W_train_loss:1.4180486\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:24 PM |\t   40.0%:\t  W_train_loss:1.5343285\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:24 PM |\t   60.0%:\t  W_train_loss:1.1530386\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:25 PM |\t   80.0%:\t  W_train_loss:1.1567290\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:25 PM |\t  1e+02%:\t  W_train_loss:1.9947432\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:25 PM |\t  w_train_loss:8.809435725212097,v_train_loss:0\n",
      "06/13 08:24:25 PM |\t  \n",
      "\n",
      "  ----------------epoch:72,\t\tlr_w:6.103515625e-08,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:24:25 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:24:25 PM |\t    0.0%:\t  W_train_loss:1.5923916\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:28 PM |\t  x_decoded[:2]:['translate English to German: Resumption of the session', 'translate English to German: I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.']\n",
      "06/13 08:24:28 PM |\t  pred_decoded[:2]:['Wiederaufnahme der Sitzungsperiode', 'Ich beglückwünsche Ihnen einen Sitzungsperiode des Europäischen Parlaments zur Sitzungsperiode des Europäischen Parlaments zur Verfügung stehen, und ich möchte ich Sie a Happy New Year in der hope that you enjoyed a pleasant festive period.']\n",
      "06/13 08:24:28 PM |\t  label_decoded[:2]:['Wiederaufnahme der Sitzungsperiode', 'Ich erkläre die am Freitag, dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen, wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe, daß Sie schöne Ferien hatten.']\n",
      "06/13 08:24:39 PM |\t  computing score...\n",
      "06/13 08:24:39 PM |\t  model_w_in_main sacreBLEU : 23.074416\n",
      "06/13 08:24:39 PM |\t  model_w_in_main test loss : 0.877225\n",
      "06/13 08:24:41 PM |\t  x_decoded[:2]:['translate English to German: Resumption of the session', 'translate English to German: I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.']\n",
      "06/13 08:24:41 PM |\t  pred_decoded[:2]:['.', 'I wish you a happy new year in the hope that you enjoyed a pleasant festive period. I wish you a happy new year in the hope that you enjoyed a pleasant festive period.']\n",
      "06/13 08:24:41 PM |\t  label_decoded[:2]:['Wiederaufnahme der Sitzungsperiode', 'Ich erkläre die am Freitag, dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen, wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe, daß Sie schöne Ferien hatten.']\n",
      "06/13 08:24:53 PM |\t  computing score...\n",
      "06/13 08:24:53 PM |\t  model_v_in_main sacreBLEU : 0.370500\n",
      "06/13 08:24:53 PM |\t  model_v_in_main test loss : 5.315890\n",
      "06/13 08:24:53 PM |\t  ('Attention Weights A : ', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>))\n",
      "06/13 08:24:54 PM |\t   20.0%:\t  W_train_loss:1.3454642\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:54 PM |\t   40.0%:\t  W_train_loss:1.5143671\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:54 PM |\t   60.0%:\t  W_train_loss:1.1887910\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:55 PM |\t   80.0%:\t  W_train_loss:1.1831436\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:55 PM |\t  1e+02%:\t  W_train_loss:2.0158827\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:55 PM |\t  w_train_loss:8.84004032611847,v_train_loss:0\n",
      "06/13 08:24:55 PM |\t  \n",
      "\n",
      "  ----------------epoch:73,\t\tlr_w:6.103515625e-08,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:24:55 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:24:55 PM |\t    0.0%:\t  W_train_loss:1.5657759\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:55 PM |\t   20.0%:\t  W_train_loss:1.3180478\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:56 PM |\t   40.0%:\t  W_train_loss:1.5130591\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:56 PM |\t   60.0%:\t  W_train_loss:1.1956792\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:56 PM |\t   80.0%:\t  W_train_loss:1.2014273\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:56 PM |\t  1e+02%:\t  W_train_loss:1.9628741\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:56 PM |\t  w_train_loss:8.756863355636597,v_train_loss:0\n",
      "06/13 08:24:56 PM |\t  \n",
      "\n",
      "  ----------------epoch:74,\t\tlr_w:6.103515625e-08,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:24:56 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:24:57 PM |\t    0.0%:\t  W_train_loss:1.6051972\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:57 PM |\t   20.0%:\t  W_train_loss:1.3823493\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:57 PM |\t   40.0%:\t  W_train_loss:1.5148487\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:57 PM |\t   60.0%:\t  W_train_loss:1.1071320\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:57 PM |\t   80.0%:\t  W_train_loss:1.1609408\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:58 PM |\t  1e+02%:\t  W_train_loss:1.9355029\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:58 PM |\t  w_train_loss:8.705970764160156,v_train_loss:0\n",
      "06/13 08:24:58 PM |\t  \n",
      "\n",
      "  ----------------epoch:75,\t\tlr_w:1.52587890625e-08,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:24:58 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:24:58 PM |\t    0.0%:\t  W_train_loss:1.5522681\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:58 PM |\t   20.0%:\t  W_train_loss:1.3771167\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:58 PM |\t   40.0%:\t  W_train_loss:1.5302579\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:59 PM |\t   60.0%:\t  W_train_loss:1.1412048\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:59 PM |\t   80.0%:\t  W_train_loss:1.1692301\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:59 PM |\t  1e+02%:\t  W_train_loss:1.9551014\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:59 PM |\t  w_train_loss:8.725179076194763,v_train_loss:0\n",
      "06/13 08:24:59 PM |\t  \n",
      "\n",
      "  ----------------epoch:76,\t\tlr_w:3.0517578125e-08,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:24:59 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:24:59 PM |\t    0.0%:\t  W_train_loss:1.5721207\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:24:59 PM |\t   20.0%:\t  W_train_loss:1.3662628\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:00 PM |\t   40.0%:\t  W_train_loss:1.5349700\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:00 PM |\t   60.0%:\t  W_train_loss:1.2431750\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:00 PM |\t   80.0%:\t  W_train_loss:1.1727804\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:00 PM |\t  1e+02%:\t  W_train_loss:1.9506562\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:00 PM |\t  w_train_loss:8.839965105056763,v_train_loss:0\n",
      "06/13 08:25:00 PM |\t  \n",
      "\n",
      "  ----------------epoch:77,\t\tlr_w:3.0517578125e-08,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:25:00 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:25:01 PM |\t    0.0%:\t  W_train_loss:1.6001761\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:01 PM |\t   20.0%:\t  W_train_loss:1.4162985\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:01 PM |\t   40.0%:\t  W_train_loss:1.5399929\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:01 PM |\t   60.0%:\t  W_train_loss:1.2200146\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:01 PM |\t   80.0%:\t  W_train_loss:1.2202294\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:02 PM |\t  1e+02%:\t  W_train_loss:1.9897703\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:02 PM |\t  w_train_loss:8.986481785774231,v_train_loss:0\n",
      "06/13 08:25:02 PM |\t  \n",
      "\n",
      "  ----------------epoch:78,\t\tlr_w:3.0517578125e-08,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:25:02 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:25:02 PM |\t    0.0%:\t  W_train_loss:1.5566936\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:02 PM |\t   20.0%:\t  W_train_loss:1.3684294\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:02 PM |\t   40.0%:\t  W_train_loss:1.6124080\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:03 PM |\t   60.0%:\t  W_train_loss:1.1738372\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:03 PM |\t   80.0%:\t  W_train_loss:1.1564860\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:03 PM |\t  1e+02%:\t  W_train_loss:1.9968147\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:03 PM |\t  w_train_loss:8.86466896533966,v_train_loss:0\n",
      "06/13 08:25:03 PM |\t  \n",
      "\n",
      "  ----------------epoch:79,\t\tlr_w:3.0517578125e-08,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:25:03 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:25:03 PM |\t    0.0%:\t  W_train_loss:1.5901035\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:04 PM |\t   20.0%:\t  W_train_loss:1.3217030\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:04 PM |\t   40.0%:\t  W_train_loss:1.5641445\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:04 PM |\t   60.0%:\t  W_train_loss:1.1535399\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:04 PM |\t   80.0%:\t  W_train_loss:1.1756022\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:04 PM |\t  1e+02%:\t  W_train_loss:1.9406455\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:04 PM |\t  w_train_loss:8.745738506317139,v_train_loss:0\n",
      "06/13 08:25:04 PM |\t  \n",
      "\n",
      "  ----------------epoch:80,\t\tlr_w:7.62939453125e-09,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:25:04 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:25:05 PM |\t    0.0%:\t  W_train_loss:1.5585902\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:05 PM |\t   20.0%:\t  W_train_loss:1.3961904\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:05 PM |\t   40.0%:\t  W_train_loss:1.5456350\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:05 PM |\t   60.0%:\t  W_train_loss:1.1861343\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:06 PM |\t   80.0%:\t  W_train_loss:1.2020912\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:06 PM |\t  1e+02%:\t  W_train_loss:1.9590590\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:06 PM |\t  w_train_loss:8.847700119018555,v_train_loss:0\n",
      "06/13 08:25:06 PM |\t  \n",
      "\n",
      "  ----------------epoch:81,\t\tlr_w:1.52587890625e-08,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:25:06 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:25:06 PM |\t    0.0%:\t  W_train_loss:1.5802071\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:06 PM |\t   20.0%:\t  W_train_loss:1.3468840\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:06 PM |\t   40.0%:\t  W_train_loss:1.5771232\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:07 PM |\t   60.0%:\t  W_train_loss:1.1990533\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:07 PM |\t   80.0%:\t  W_train_loss:1.1227958\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:07 PM |\t  1e+02%:\t  W_train_loss:1.9862270\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:07 PM |\t  w_train_loss:8.81229043006897,v_train_loss:0\n",
      "06/13 08:25:07 PM |\t  \n",
      "\n",
      "  ----------------epoch:82,\t\tlr_w:1.52587890625e-08,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:25:07 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:25:07 PM |\t    0.0%:\t  W_train_loss:1.5581774\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:08 PM |\t   20.0%:\t  W_train_loss:1.3597997\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:08 PM |\t   40.0%:\t  W_train_loss:1.5471841\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:11 PM |\t  x_decoded[:2]:['translate English to German: Resumption of the session', 'translate English to German: I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.']\n",
      "06/13 08:25:11 PM |\t  pred_decoded[:2]:['Wiederaufnahme der Sitzungsperiode', 'Ich beglückwünsche Ihnen einen Sitzungsperiode des Europäischen Parlaments zur Sitzungsperiode des Europäischen Parlaments zur Verfügung stehen, und ich möchte ich Sie a Happy New Year in der hope that you enjoyed a pleasant festive period.']\n",
      "06/13 08:25:11 PM |\t  label_decoded[:2]:['Wiederaufnahme der Sitzungsperiode', 'Ich erkläre die am Freitag, dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen, wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe, daß Sie schöne Ferien hatten.']\n",
      "06/13 08:25:21 PM |\t  computing score...\n",
      "06/13 08:25:21 PM |\t  model_w_in_main sacreBLEU : 23.304609\n",
      "06/13 08:25:21 PM |\t  model_w_in_main test loss : 0.877152\n",
      "06/13 08:25:24 PM |\t  x_decoded[:2]:['translate English to German: Resumption of the session', 'translate English to German: I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.']\n",
      "06/13 08:25:24 PM |\t  pred_decoded[:2]:['.', 'I wish you a happy new year in the hope that you enjoyed a pleasant festive period. I wish you a happy new year in the hope that you enjoyed a pleasant festive period.']\n",
      "06/13 08:25:24 PM |\t  label_decoded[:2]:['Wiederaufnahme der Sitzungsperiode', 'Ich erkläre die am Freitag, dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen, wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe, daß Sie schöne Ferien hatten.']\n",
      "06/13 08:25:35 PM |\t  computing score...\n",
      "06/13 08:25:35 PM |\t  model_v_in_main sacreBLEU : 0.370500\n",
      "06/13 08:25:35 PM |\t  model_v_in_main test loss : 5.315890\n",
      "06/13 08:25:35 PM |\t  ('Attention Weights A : ', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>))\n",
      "06/13 08:25:36 PM |\t   60.0%:\t  W_train_loss:1.1422467\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:37 PM |\t   80.0%:\t  W_train_loss:1.1786070\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:37 PM |\t  1e+02%:\t  W_train_loss:2.0159254\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:37 PM |\t  w_train_loss:8.801940321922302,v_train_loss:0\n",
      "06/13 08:25:37 PM |\t  \n",
      "\n",
      "  ----------------epoch:83,\t\tlr_w:1.52587890625e-08,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:25:37 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:25:37 PM |\t    0.0%:\t  W_train_loss:1.5852273\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:37 PM |\t   20.0%:\t  W_train_loss:1.3750606\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:38 PM |\t   40.0%:\t  W_train_loss:1.5405475\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:38 PM |\t   60.0%:\t  W_train_loss:1.1464084\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:38 PM |\t   80.0%:\t  W_train_loss:1.1776278\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:38 PM |\t  1e+02%:\t  W_train_loss:2.0260286\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:38 PM |\t  w_train_loss:8.850900173187256,v_train_loss:0\n",
      "06/13 08:25:38 PM |\t  \n",
      "\n",
      "  ----------------epoch:84,\t\tlr_w:1.52587890625e-08,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:25:38 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:25:38 PM |\t    0.0%:\t  W_train_loss:1.5776048\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:39 PM |\t   20.0%:\t  W_train_loss:1.3728483\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:39 PM |\t   40.0%:\t  W_train_loss:1.5417922\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:39 PM |\t   60.0%:\t  W_train_loss:1.1965897\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:39 PM |\t   80.0%:\t  W_train_loss:1.1726439\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:40 PM |\t  1e+02%:\t  W_train_loss:1.9523972\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:40 PM |\t  w_train_loss:8.813876032829285,v_train_loss:0\n",
      "06/13 08:25:40 PM |\t  \n",
      "\n",
      "  ----------------epoch:85,\t\tlr_w:3.814697265625e-09,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:25:40 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:25:40 PM |\t    0.0%:\t  W_train_loss:1.5638032\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:40 PM |\t   20.0%:\t  W_train_loss:1.3267939\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:40 PM |\t   40.0%:\t  W_train_loss:1.5544556\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:41 PM |\t   60.0%:\t  W_train_loss:1.2219820\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:41 PM |\t   80.0%:\t  W_train_loss:1.1854115\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:41 PM |\t  1e+02%:\t  W_train_loss:1.9088227\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:41 PM |\t  w_train_loss:8.761268854141235,v_train_loss:0\n",
      "06/13 08:25:41 PM |\t  \n",
      "\n",
      "  ----------------epoch:86,\t\tlr_w:7.62939453125e-09,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:25:41 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:25:41 PM |\t    0.0%:\t  W_train_loss:1.5475156\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:41 PM |\t   20.0%:\t  W_train_loss:1.3639140\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:42 PM |\t   40.0%:\t  W_train_loss:1.5724752\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:42 PM |\t   60.0%:\t  W_train_loss:1.1950507\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:42 PM |\t   80.0%:\t  W_train_loss:1.1730671\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:42 PM |\t  1e+02%:\t  W_train_loss:2.0314593\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:42 PM |\t  w_train_loss:8.883481979370117,v_train_loss:0\n",
      "06/13 08:25:42 PM |\t  \n",
      "\n",
      "  ----------------epoch:87,\t\tlr_w:7.62939453125e-09,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:25:42 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:25:43 PM |\t    0.0%:\t  W_train_loss:1.5667036\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:43 PM |\t   20.0%:\t  W_train_loss:1.3558910\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:43 PM |\t   40.0%:\t  W_train_loss:1.5375655\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:43 PM |\t   60.0%:\t  W_train_loss:1.1834080\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:43 PM |\t   80.0%:\t  W_train_loss:1.1575283\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:44 PM |\t  1e+02%:\t  W_train_loss:1.9973726\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:44 PM |\t  w_train_loss:8.798468947410583,v_train_loss:0\n",
      "06/13 08:25:44 PM |\t  \n",
      "\n",
      "  ----------------epoch:88,\t\tlr_w:7.62939453125e-09,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:25:44 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:25:44 PM |\t    0.0%:\t  W_train_loss:1.5654213\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:44 PM |\t   20.0%:\t  W_train_loss:1.3859310\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:44 PM |\t   40.0%:\t  W_train_loss:1.6168004\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:45 PM |\t   60.0%:\t  W_train_loss:1.2040873\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:45 PM |\t   80.0%:\t  W_train_loss:1.1775424\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:45 PM |\t  1e+02%:\t  W_train_loss:1.9519783\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:45 PM |\t  w_train_loss:8.901760816574097,v_train_loss:0\n",
      "06/13 08:25:45 PM |\t  \n",
      "\n",
      "  ----------------epoch:89,\t\tlr_w:7.62939453125e-09,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:25:45 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:25:45 PM |\t    0.0%:\t  W_train_loss:1.6065098\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:45 PM |\t   20.0%:\t  W_train_loss:1.3548353\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:46 PM |\t   40.0%:\t  W_train_loss:1.5362272\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:46 PM |\t   60.0%:\t  W_train_loss:1.1892853\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:46 PM |\t   80.0%:\t  W_train_loss:1.2150528\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:46 PM |\t  1e+02%:\t  W_train_loss:1.9118633\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:46 PM |\t  w_train_loss:8.81377375125885,v_train_loss:0\n",
      "06/13 08:25:46 PM |\t  \n",
      "\n",
      "  ----------------epoch:90,\t\tlr_w:1.9073486328125e-09,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:25:46 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:25:47 PM |\t    0.0%:\t  W_train_loss:1.4990547\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:47 PM |\t   20.0%:\t  W_train_loss:1.2968855\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:47 PM |\t   40.0%:\t  W_train_loss:1.5080466\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:47 PM |\t   60.0%:\t  W_train_loss:1.2083251\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:47 PM |\t   80.0%:\t  W_train_loss:1.1498657\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:48 PM |\t  1e+02%:\t  W_train_loss:2.0058432\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:48 PM |\t  w_train_loss:8.668020844459534,v_train_loss:0\n",
      "06/13 08:25:48 PM |\t  \n",
      "\n",
      "  ----------------epoch:91,\t\tlr_w:3.814697265625e-09,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:25:48 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:25:48 PM |\t    0.0%:\t  W_train_loss:1.5839694\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:48 PM |\t   20.0%:\t  W_train_loss:1.3817673\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:48 PM |\t   40.0%:\t  W_train_loss:1.5391459\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:49 PM |\t   60.0%:\t  W_train_loss:1.1584913\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:49 PM |\t   80.0%:\t  W_train_loss:1.1638004\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:49 PM |\t  1e+02%:\t  W_train_loss:1.9935997\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:49 PM |\t  w_train_loss:8.820773839950562,v_train_loss:0\n",
      "06/13 08:25:49 PM |\t  \n",
      "\n",
      "  ----------------epoch:92,\t\tlr_w:3.814697265625e-09,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:25:49 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:25:49 PM |\t    0.0%:\t  W_train_loss:1.5691930\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:50 PM |\t   20.0%:\t  W_train_loss:1.3784493\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:50 PM |\t   40.0%:\t  W_train_loss:1.5310612\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:50 PM |\t   60.0%:\t  W_train_loss:1.2116261\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:50 PM |\t   80.0%:\t  W_train_loss:1.2074373\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:25:53 PM |\t  x_decoded[:2]:['translate English to German: Resumption of the session', 'translate English to German: I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.']\n",
      "06/13 08:25:53 PM |\t  pred_decoded[:2]:['Wiederaufnahme der Sitzungsperiode', 'Ich beglückwünsche Ihnen einen Sitzungsperiode des Europäischen Parlaments zur Sitzungsperiode des Europäischen Parlaments zur Verfügung stehen, und ich möchte ich Sie a Happy New Year in der hope that you enjoyed a pleasant festive period.']\n",
      "06/13 08:25:53 PM |\t  label_decoded[:2]:['Wiederaufnahme der Sitzungsperiode', 'Ich erkläre die am Freitag, dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen, wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe, daß Sie schöne Ferien hatten.']\n",
      "06/13 08:26:04 PM |\t  computing score...\n",
      "06/13 08:26:04 PM |\t  model_w_in_main sacreBLEU : 23.304609\n",
      "06/13 08:26:04 PM |\t  model_w_in_main test loss : 0.877139\n",
      "06/13 08:26:06 PM |\t  x_decoded[:2]:['translate English to German: Resumption of the session', 'translate English to German: I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.']\n",
      "06/13 08:26:06 PM |\t  pred_decoded[:2]:['.', 'I wish you a happy new year in the hope that you enjoyed a pleasant festive period. I wish you a happy new year in the hope that you enjoyed a pleasant festive period.']\n",
      "06/13 08:26:06 PM |\t  label_decoded[:2]:['Wiederaufnahme der Sitzungsperiode', 'Ich erkläre die am Freitag, dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen, wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe, daß Sie schöne Ferien hatten.']\n",
      "06/13 08:26:18 PM |\t  computing score...\n",
      "06/13 08:26:18 PM |\t  model_v_in_main sacreBLEU : 0.370500\n",
      "06/13 08:26:18 PM |\t  model_v_in_main test loss : 5.315890\n",
      "06/13 08:26:18 PM |\t  ('Attention Weights A : ', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>))\n",
      "06/13 08:26:19 PM |\t  1e+02%:\t  W_train_loss:1.9560273\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:19 PM |\t  w_train_loss:8.85379409790039,v_train_loss:0\n",
      "06/13 08:26:19 PM |\t  \n",
      "\n",
      "  ----------------epoch:93,\t\tlr_w:3.814697265625e-09,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:26:19 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:26:19 PM |\t    0.0%:\t  W_train_loss:1.5719388\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:20 PM |\t   20.0%:\t  W_train_loss:1.3764769\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:20 PM |\t   40.0%:\t  W_train_loss:1.5465389\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:20 PM |\t   60.0%:\t  W_train_loss:1.1547780\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:20 PM |\t   80.0%:\t  W_train_loss:1.1269186\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:21 PM |\t  1e+02%:\t  W_train_loss:1.9767492\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:21 PM |\t  w_train_loss:8.753400325775146,v_train_loss:0\n",
      "06/13 08:26:21 PM |\t  \n",
      "\n",
      "  ----------------epoch:94,\t\tlr_w:3.814697265625e-09,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:26:21 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:26:21 PM |\t    0.0%:\t  W_train_loss:1.5914927\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:21 PM |\t   20.0%:\t  W_train_loss:1.3632860\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:21 PM |\t   40.0%:\t  W_train_loss:1.5939109\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:21 PM |\t   60.0%:\t  W_train_loss:1.1979971\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:22 PM |\t   80.0%:\t  W_train_loss:1.1782768\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:22 PM |\t  1e+02%:\t  W_train_loss:1.9828832\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:22 PM |\t  w_train_loss:8.907846689224243,v_train_loss:0\n",
      "06/13 08:26:22 PM |\t  \n",
      "\n",
      "  ----------------epoch:95,\t\tlr_w:9.5367431640625e-10,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:26:22 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:26:22 PM |\t    0.0%:\t  W_train_loss:1.6009572\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:22 PM |\t   20.0%:\t  W_train_loss:1.3558903\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:23 PM |\t   40.0%:\t  W_train_loss:1.5721139\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:23 PM |\t   60.0%:\t  W_train_loss:1.1583700\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:23 PM |\t   80.0%:\t  W_train_loss:1.1678278\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:23 PM |\t  1e+02%:\t  W_train_loss:1.9905441\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:23 PM |\t  w_train_loss:8.84570324420929,v_train_loss:0\n",
      "06/13 08:26:23 PM |\t  \n",
      "\n",
      "  ----------------epoch:96,\t\tlr_w:1.9073486328125e-09,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:26:23 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:26:23 PM |\t    0.0%:\t  W_train_loss:1.5497906\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:24 PM |\t   20.0%:\t  W_train_loss:1.3572738\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:24 PM |\t   40.0%:\t  W_train_loss:1.4993491\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:24 PM |\t   60.0%:\t  W_train_loss:1.1883156\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:24 PM |\t   80.0%:\t  W_train_loss:1.1951598\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:25 PM |\t  1e+02%:\t  W_train_loss:1.9587355\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:25 PM |\t  w_train_loss:8.748624444007874,v_train_loss:0\n",
      "06/13 08:26:25 PM |\t  \n",
      "\n",
      "  ----------------epoch:97,\t\tlr_w:1.9073486328125e-09,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:26:25 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:26:25 PM |\t    0.0%:\t  W_train_loss:1.5813328\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:25 PM |\t   20.0%:\t  W_train_loss:1.3712441\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:25 PM |\t   40.0%:\t  W_train_loss:1.5574777\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:25 PM |\t   60.0%:\t  W_train_loss:1.1838537\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:26 PM |\t   80.0%:\t  W_train_loss:1.1525426\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:26 PM |\t  1e+02%:\t  W_train_loss:1.9808720\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:26 PM |\t  w_train_loss:8.827322959899902,v_train_loss:0\n",
      "06/13 08:26:26 PM |\t  \n",
      "\n",
      "  ----------------epoch:98,\t\tlr_w:1.9073486328125e-09,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:26:26 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:26:26 PM |\t    0.0%:\t  W_train_loss:1.5632706\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:26 PM |\t   20.0%:\t  W_train_loss:1.3931382\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:27 PM |\t   40.0%:\t  W_train_loss:1.4906170\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:27 PM |\t   60.0%:\t  W_train_loss:1.1432600\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:27 PM |\t   80.0%:\t  W_train_loss:1.1841218\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:27 PM |\t  1e+02%:\t  W_train_loss:1.9711516\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:27 PM |\t  w_train_loss:8.745559215545654,v_train_loss:0\n",
      "06/13 08:26:27 PM |\t  \n",
      "\n",
      "  ----------------epoch:99,\t\tlr_w:1.9073486328125e-09,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:26:27 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:26:28 PM |\t    0.0%:\t  W_train_loss:1.5565060\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:28 PM |\t   20.0%:\t  W_train_loss:1.3683116\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:28 PM |\t   40.0%:\t  W_train_loss:1.5324295\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:28 PM |\t   60.0%:\t  W_train_loss:1.1451985\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:28 PM |\t   80.0%:\t  W_train_loss:1.1869602\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:29 PM |\t  1e+02%:\t  W_train_loss:1.9539495\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:29 PM |\t  w_train_loss:8.74335527420044,v_train_loss:0\n",
      "06/13 08:26:29 PM |\t  \n",
      "\n",
      "  ----------------epoch:100,\t\tlr_w:4.76837158203125e-10,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:26:29 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:26:29 PM |\t    0.0%:\t  W_train_loss:1.5809150\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:29 PM |\t   20.0%:\t  W_train_loss:1.3650405\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:29 PM |\t   40.0%:\t  W_train_loss:1.5705404\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:30 PM |\t   60.0%:\t  W_train_loss:1.1831822\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:30 PM |\t   80.0%:\t  W_train_loss:1.2307889\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:30 PM |\t  1e+02%:\t  W_train_loss:1.9897500\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:30 PM |\t  w_train_loss:8.920217156410217,v_train_loss:0\n",
      "06/13 08:26:30 PM |\t  \n",
      "\n",
      "  ----------------epoch:101,\t\tlr_w:9.5367431640625e-10,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:26:30 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:26:30 PM |\t    0.0%:\t  W_train_loss:1.5553260\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:30 PM |\t   20.0%:\t  W_train_loss:1.4129336\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:31 PM |\t   40.0%:\t  W_train_loss:1.5138502\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:31 PM |\t   60.0%:\t  W_train_loss:1.1622343\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:31 PM |\t   80.0%:\t  W_train_loss:1.1714931\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:31 PM |\t  1e+02%:\t  W_train_loss:2.0006232\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:31 PM |\t  w_train_loss:8.816460371017456,v_train_loss:0\n",
      "06/13 08:26:31 PM |\t  \n",
      "\n",
      "  ----------------epoch:102,\t\tlr_w:9.5367431640625e-10,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:26:31 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:26:32 PM |\t    0.0%:\t  W_train_loss:1.5548165\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:32 PM |\t   20.0%:\t  W_train_loss:1.3797472\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:32 PM |\t   40.0%:\t  W_train_loss:1.6088990\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:32 PM |\t   60.0%:\t  W_train_loss:1.2052253\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:32 PM |\t   80.0%:\t  W_train_loss:1.1728640\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:33 PM |\t  1e+02%:\t  W_train_loss:1.9785099\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:33 PM |\t  w_train_loss:8.900061845779419,v_train_loss:0\n",
      "06/13 08:26:33 PM |\t  \n",
      "\n",
      "  ----------------epoch:103,\t\tlr_w:9.5367431640625e-10,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:26:33 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:26:33 PM |\t    0.0%:\t  W_train_loss:1.5632062\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:26:36 PM |\t  x_decoded[:2]:['translate English to German: Resumption of the session', 'translate English to German: I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.']\n",
      "06/13 08:26:36 PM |\t  pred_decoded[:2]:['Wiederaufnahme der Sitzungsperiode', 'Ich beglückwünsche Ihnen einen Sitzungsperiode des Europäischen Parlaments zur Sitzungsperiode des Europäischen Parlaments zur Verfügung stehen, und ich möchte ich Sie a Happy New Year in der hope that you enjoyed a pleasant festive period.']\n",
      "06/13 08:26:36 PM |\t  label_decoded[:2]:['Wiederaufnahme der Sitzungsperiode', 'Ich erkläre die am Freitag, dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen, wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe, daß Sie schöne Ferien hatten.']\n",
      "06/13 08:26:46 PM |\t  computing score...\n",
      "06/13 08:26:46 PM |\t  model_w_in_main sacreBLEU : 23.303282\n",
      "06/13 08:26:46 PM |\t  model_w_in_main test loss : 0.877142\n",
      "06/13 08:26:49 PM |\t  x_decoded[:2]:['translate English to German: Resumption of the session', 'translate English to German: I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.']\n",
      "06/13 08:26:49 PM |\t  pred_decoded[:2]:['.', 'I wish you a happy new year in the hope that you enjoyed a pleasant festive period. I wish you a happy new year in the hope that you enjoyed a pleasant festive period.']\n",
      "06/13 08:26:49 PM |\t  label_decoded[:2]:['Wiederaufnahme der Sitzungsperiode', 'Ich erkläre die am Freitag, dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen, wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe, daß Sie schöne Ferien hatten.']\n",
      "06/13 08:27:00 PM |\t  computing score...\n",
      "06/13 08:27:00 PM |\t  model_v_in_main sacreBLEU : 0.370500\n",
      "06/13 08:27:00 PM |\t  model_v_in_main test loss : 5.315890\n",
      "06/13 08:27:00 PM |\t  ('Attention Weights A : ', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>))\n",
      "06/13 08:27:02 PM |\t   20.0%:\t  W_train_loss:1.3780470\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:02 PM |\t   40.0%:\t  W_train_loss:1.4961653\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:02 PM |\t   60.0%:\t  W_train_loss:1.1746430\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:02 PM |\t   80.0%:\t  W_train_loss:1.1897588\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:03 PM |\t  1e+02%:\t  W_train_loss:1.9673063\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:03 PM |\t  w_train_loss:8.769126534461975,v_train_loss:0\n",
      "06/13 08:27:03 PM |\t  \n",
      "\n",
      "  ----------------epoch:104,\t\tlr_w:9.5367431640625e-10,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:27:03 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:27:03 PM |\t    0.0%:\t  W_train_loss:1.6074746\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:03 PM |\t   20.0%:\t  W_train_loss:1.3598330\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:03 PM |\t   40.0%:\t  W_train_loss:1.5551345\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:03 PM |\t   60.0%:\t  W_train_loss:1.1763680\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:04 PM |\t   80.0%:\t  W_train_loss:1.1932216\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:04 PM |\t  1e+02%:\t  W_train_loss:2.0160079\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:04 PM |\t  w_train_loss:8.908039569854736,v_train_loss:0\n",
      "06/13 08:27:04 PM |\t  \n",
      "\n",
      "  ----------------epoch:105,\t\tlr_w:2.384185791015625e-10,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:27:04 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:27:04 PM |\t    0.0%:\t  W_train_loss:1.5564795\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:04 PM |\t   20.0%:\t  W_train_loss:1.4067143\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:05 PM |\t   40.0%:\t  W_train_loss:1.5307580\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:05 PM |\t   60.0%:\t  W_train_loss:1.1993835\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:05 PM |\t   80.0%:\t  W_train_loss:1.1722119\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:05 PM |\t  1e+02%:\t  W_train_loss:2.0015950\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:05 PM |\t  w_train_loss:8.86714220046997,v_train_loss:0\n",
      "06/13 08:27:05 PM |\t  \n",
      "\n",
      "  ----------------epoch:106,\t\tlr_w:4.76837158203125e-10,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:27:05 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:27:05 PM |\t    0.0%:\t  W_train_loss:1.5423813\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:06 PM |\t   20.0%:\t  W_train_loss:1.3983258\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:06 PM |\t   40.0%:\t  W_train_loss:1.5183777\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:06 PM |\t   60.0%:\t  W_train_loss:1.1820862\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:06 PM |\t   80.0%:\t  W_train_loss:1.2136879\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:07 PM |\t  1e+02%:\t  W_train_loss:1.9927061\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:07 PM |\t  w_train_loss:8.847564935684204,v_train_loss:0\n",
      "06/13 08:27:07 PM |\t  \n",
      "\n",
      "  ----------------epoch:107,\t\tlr_w:4.76837158203125e-10,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:27:07 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:27:07 PM |\t    0.0%:\t  W_train_loss:1.5791880\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:07 PM |\t   20.0%:\t  W_train_loss:1.4038382\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:07 PM |\t   40.0%:\t  W_train_loss:1.5815061\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:08 PM |\t   60.0%:\t  W_train_loss:1.1996346\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:08 PM |\t   80.0%:\t  W_train_loss:1.2022965\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:08 PM |\t  1e+02%:\t  W_train_loss:1.9601922\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:08 PM |\t  w_train_loss:8.926655530929565,v_train_loss:0\n",
      "06/13 08:27:08 PM |\t  \n",
      "\n",
      "  ----------------epoch:108,\t\tlr_w:4.76837158203125e-10,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:27:08 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:27:08 PM |\t    0.0%:\t  W_train_loss:1.5226141\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:08 PM |\t   20.0%:\t  W_train_loss:1.3779445\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:09 PM |\t   40.0%:\t  W_train_loss:1.5419736\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:09 PM |\t   60.0%:\t  W_train_loss:1.1813198\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:09 PM |\t   80.0%:\t  W_train_loss:1.1445217\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:09 PM |\t  1e+02%:\t  W_train_loss:1.9639740\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:09 PM |\t  w_train_loss:8.7323477268219,v_train_loss:0\n",
      "06/13 08:27:09 PM |\t  \n",
      "\n",
      "  ----------------epoch:109,\t\tlr_w:4.76837158203125e-10,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:27:09 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:27:10 PM |\t    0.0%:\t  W_train_loss:1.5674295\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:10 PM |\t   20.0%:\t  W_train_loss:1.4038155\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:10 PM |\t   40.0%:\t  W_train_loss:1.5292507\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:10 PM |\t   60.0%:\t  W_train_loss:1.2126169\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:10 PM |\t   80.0%:\t  W_train_loss:1.2467822\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:11 PM |\t  1e+02%:\t  W_train_loss:2.0388081\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:11 PM |\t  w_train_loss:8.998703002929688,v_train_loss:0\n",
      "06/13 08:27:11 PM |\t  \n",
      "\n",
      "  ----------------epoch:110,\t\tlr_w:1.1920928955078125e-10,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:27:11 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:27:11 PM |\t    0.0%:\t  W_train_loss:1.6340823\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:11 PM |\t   20.0%:\t  W_train_loss:1.3755286\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:11 PM |\t   40.0%:\t  W_train_loss:1.5770783\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:12 PM |\t   60.0%:\t  W_train_loss:1.2050564\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:12 PM |\t   80.0%:\t  W_train_loss:1.0910498\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:12 PM |\t  1e+02%:\t  W_train_loss:1.9912260\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:12 PM |\t  w_train_loss:8.874021410942078,v_train_loss:0\n",
      "06/13 08:27:12 PM |\t  \n",
      "\n",
      "  ----------------epoch:111,\t\tlr_w:2.384185791015625e-10,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:27:12 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:27:12 PM |\t    0.0%:\t  W_train_loss:1.5588381\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:12 PM |\t   20.0%:\t  W_train_loss:1.3157405\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:13 PM |\t   40.0%:\t  W_train_loss:1.5132358\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:13 PM |\t   60.0%:\t  W_train_loss:1.1567290\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:13 PM |\t   80.0%:\t  W_train_loss:1.1891969\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:13 PM |\t  1e+02%:\t  W_train_loss:2.0016074\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:13 PM |\t  w_train_loss:8.735347747802734,v_train_loss:0\n",
      "06/13 08:27:13 PM |\t  \n",
      "\n",
      "  ----------------epoch:112,\t\tlr_w:2.384185791015625e-10,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:27:13 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:27:14 PM |\t    0.0%:\t  W_train_loss:1.5928884\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:14 PM |\t   20.0%:\t  W_train_loss:1.3804164\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:14 PM |\t   40.0%:\t  W_train_loss:1.5524368\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:14 PM |\t   60.0%:\t  W_train_loss:1.1841222\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:14 PM |\t   80.0%:\t  W_train_loss:1.1648948\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:15 PM |\t  1e+02%:\t  W_train_loss:1.9531201\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:15 PM |\t  w_train_loss:8.827878713607788,v_train_loss:0\n",
      "06/13 08:27:15 PM |\t  \n",
      "\n",
      "  ----------------epoch:113,\t\tlr_w:2.384185791015625e-10,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:27:15 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:27:15 PM |\t    0.0%:\t  W_train_loss:1.5489378\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:15 PM |\t   20.0%:\t  W_train_loss:1.3747375\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:15 PM |\t   40.0%:\t  W_train_loss:1.5683514\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:18 PM |\t  x_decoded[:2]:['translate English to German: Resumption of the session', 'translate English to German: I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.']\n",
      "06/13 08:27:18 PM |\t  pred_decoded[:2]:['Wiederaufnahme der Sitzungsperiode', 'Ich beglückwünsche Ihnen einen Sitzungsperiode des Europäischen Parlaments zur Sitzungsperiode des Europäischen Parlaments zur Verfügung stehen, und ich möchte ich Sie a Happy New Year in der hope that you enjoyed a pleasant festive period.']\n",
      "06/13 08:27:18 PM |\t  label_decoded[:2]:['Wiederaufnahme der Sitzungsperiode', 'Ich erkläre die am Freitag, dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen, wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe, daß Sie schöne Ferien hatten.']\n",
      "06/13 08:27:29 PM |\t  computing score...\n",
      "06/13 08:27:29 PM |\t  model_w_in_main sacreBLEU : 23.238621\n",
      "06/13 08:27:29 PM |\t  model_w_in_main test loss : 0.877139\n",
      "06/13 08:27:32 PM |\t  x_decoded[:2]:['translate English to German: Resumption of the session', 'translate English to German: I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.']\n",
      "06/13 08:27:32 PM |\t  pred_decoded[:2]:['.', 'I wish you a happy new year in the hope that you enjoyed a pleasant festive period. I wish you a happy new year in the hope that you enjoyed a pleasant festive period.']\n",
      "06/13 08:27:32 PM |\t  label_decoded[:2]:['Wiederaufnahme der Sitzungsperiode', 'Ich erkläre die am Freitag, dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen, wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe, daß Sie schöne Ferien hatten.']\n",
      "06/13 08:27:43 PM |\t  computing score...\n",
      "06/13 08:27:43 PM |\t  model_v_in_main sacreBLEU : 0.370500\n",
      "06/13 08:27:43 PM |\t  model_v_in_main test loss : 5.315890\n",
      "06/13 08:27:43 PM |\t  ('Attention Weights A : ', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>))\n",
      "06/13 08:27:45 PM |\t   60.0%:\t  W_train_loss:1.2113087\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:45 PM |\t   80.0%:\t  W_train_loss:1.1799806\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:45 PM |\t  1e+02%:\t  W_train_loss:1.9519274\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:45 PM |\t  w_train_loss:8.835243463516235,v_train_loss:0\n",
      "06/13 08:27:45 PM |\t  \n",
      "\n",
      "  ----------------epoch:114,\t\tlr_w:2.384185791015625e-10,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:27:45 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:27:45 PM |\t    0.0%:\t  W_train_loss:1.5535631\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:45 PM |\t   20.0%:\t  W_train_loss:1.3070825\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:46 PM |\t   40.0%:\t  W_train_loss:1.5339800\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:46 PM |\t   60.0%:\t  W_train_loss:1.1853544\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:46 PM |\t   80.0%:\t  W_train_loss:1.1387190\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:46 PM |\t  1e+02%:\t  W_train_loss:1.9757899\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:46 PM |\t  w_train_loss:8.694488883018494,v_train_loss:0\n",
      "06/13 08:27:46 PM |\t  \n",
      "\n",
      "  ----------------epoch:115,\t\tlr_w:5.960464477539063e-11,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:27:46 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:27:47 PM |\t    0.0%:\t  W_train_loss:1.5657064\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:47 PM |\t   20.0%:\t  W_train_loss:1.3411396\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:47 PM |\t   40.0%:\t  W_train_loss:1.5599527\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:47 PM |\t   60.0%:\t  W_train_loss:1.1850665\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:47 PM |\t   80.0%:\t  W_train_loss:1.1458285\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:48 PM |\t  1e+02%:\t  W_train_loss:1.9844781\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:48 PM |\t  w_train_loss:8.782171726226807,v_train_loss:0\n",
      "06/13 08:27:48 PM |\t  \n",
      "\n",
      "  ----------------epoch:116,\t\tlr_w:1.1920928955078125e-10,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:27:48 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:27:48 PM |\t    0.0%:\t  W_train_loss:1.5942202\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:48 PM |\t   20.0%:\t  W_train_loss:1.3170083\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:48 PM |\t   40.0%:\t  W_train_loss:1.5188624\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:49 PM |\t   60.0%:\t  W_train_loss:1.1677185\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:49 PM |\t   80.0%:\t  W_train_loss:1.1630368\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:49 PM |\t  1e+02%:\t  W_train_loss:1.9601808\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:49 PM |\t  w_train_loss:8.72102689743042,v_train_loss:0\n",
      "06/13 08:27:49 PM |\t  \n",
      "\n",
      "  ----------------epoch:117,\t\tlr_w:1.1920928955078125e-10,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:27:49 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:27:49 PM |\t    0.0%:\t  W_train_loss:1.5664804\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:50 PM |\t   20.0%:\t  W_train_loss:1.3750298\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:50 PM |\t   40.0%:\t  W_train_loss:1.5123141\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:50 PM |\t   60.0%:\t  W_train_loss:1.1858288\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:50 PM |\t   80.0%:\t  W_train_loss:1.1568621\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:51 PM |\t  1e+02%:\t  W_train_loss:1.9449240\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:51 PM |\t  w_train_loss:8.74143922328949,v_train_loss:0\n",
      "06/13 08:27:51 PM |\t  \n",
      "\n",
      "  ----------------epoch:118,\t\tlr_w:1.1920928955078125e-10,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:27:51 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:27:51 PM |\t    0.0%:\t  W_train_loss:1.5699534\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:51 PM |\t   20.0%:\t  W_train_loss:1.3824925\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:51 PM |\t   40.0%:\t  W_train_loss:1.5355750\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:51 PM |\t   60.0%:\t  W_train_loss:1.1279805\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:52 PM |\t   80.0%:\t  W_train_loss:1.2271671\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:52 PM |\t  1e+02%:\t  W_train_loss:1.9888520\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:52 PM |\t  w_train_loss:8.83202064037323,v_train_loss:0\n",
      "06/13 08:27:52 PM |\t  \n",
      "\n",
      "  ----------------epoch:119,\t\tlr_w:1.1920928955078125e-10,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:27:52 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:27:52 PM |\t    0.0%:\t  W_train_loss:1.5966365\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:52 PM |\t   20.0%:\t  W_train_loss:1.3403251\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:53 PM |\t   40.0%:\t  W_train_loss:1.5514510\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:53 PM |\t   60.0%:\t  W_train_loss:1.1900423\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:53 PM |\t   80.0%:\t  W_train_loss:1.1981854\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:53 PM |\t  1e+02%:\t  W_train_loss:1.9694413\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:53 PM |\t  w_train_loss:8.846081614494324,v_train_loss:0\n",
      "06/13 08:27:53 PM |\t  \n",
      "\n",
      "  ----------------epoch:120,\t\tlr_w:2.980232238769531e-11,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:27:53 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:27:53 PM |\t    0.0%:\t  W_train_loss:1.5378348\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:54 PM |\t   20.0%:\t  W_train_loss:1.4278133\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:54 PM |\t   40.0%:\t  W_train_loss:1.5541792\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:54 PM |\t   60.0%:\t  W_train_loss:1.1613744\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:54 PM |\t   80.0%:\t  W_train_loss:1.1266309\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:55 PM |\t  1e+02%:\t  W_train_loss:1.9659319\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:55 PM |\t  w_train_loss:8.773764491081238,v_train_loss:0\n",
      "06/13 08:27:55 PM |\t  \n",
      "\n",
      "  ----------------epoch:121,\t\tlr_w:5.960464477539063e-11,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:27:55 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:27:55 PM |\t    0.0%:\t  W_train_loss:1.5545793\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:55 PM |\t   20.0%:\t  W_train_loss:1.3414062\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:55 PM |\t   40.0%:\t  W_train_loss:1.5158198\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:55 PM |\t   60.0%:\t  W_train_loss:1.1795660\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:56 PM |\t   80.0%:\t  W_train_loss:1.1864274\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:56 PM |\t  1e+02%:\t  W_train_loss:1.9713537\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:56 PM |\t  w_train_loss:8.749152302742004,v_train_loss:0\n",
      "06/13 08:27:56 PM |\t  \n",
      "\n",
      "  ----------------epoch:122,\t\tlr_w:5.960464477539063e-11,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:27:56 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:27:56 PM |\t    0.0%:\t  W_train_loss:1.5534618\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:56 PM |\t   20.0%:\t  W_train_loss:1.3730733\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:57 PM |\t   40.0%:\t  W_train_loss:1.5180825\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:57 PM |\t   60.0%:\t  W_train_loss:1.1893281\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:57 PM |\t   80.0%:\t  W_train_loss:1.1481483\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:57 PM |\t  1e+02%:\t  W_train_loss:2.0114257\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:57 PM |\t  w_train_loss:8.793519735336304,v_train_loss:0\n",
      "06/13 08:27:57 PM |\t  \n",
      "\n",
      "  ----------------epoch:123,\t\tlr_w:5.960464477539063e-11,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:27:57 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:27:57 PM |\t    0.0%:\t  W_train_loss:1.5610794\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:58 PM |\t   20.0%:\t  W_train_loss:1.3399451\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:58 PM |\t   40.0%:\t  W_train_loss:1.5340042\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:58 PM |\t   60.0%:\t  W_train_loss:1.2020127\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:27:58 PM |\t   80.0%:\t  W_train_loss:1.1700290\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:01 PM |\t  x_decoded[:2]:['translate English to German: Resumption of the session', 'translate English to German: I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.']\n",
      "06/13 08:28:01 PM |\t  pred_decoded[:2]:['Wiederaufnahme der Sitzungsperiode', 'Ich beglückwünsche Ihnen einen Sitzungsperiode des Europäischen Parlaments zur Sitzungsperiode des Europäischen Parlaments zur Verfügung stehen, und ich möchte ich Sie a Happy New Year in der hope that you enjoyed a pleasant festive period.']\n",
      "06/13 08:28:01 PM |\t  label_decoded[:2]:['Wiederaufnahme der Sitzungsperiode', 'Ich erkläre die am Freitag, dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen, wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe, daß Sie schöne Ferien hatten.']\n",
      "06/13 08:28:12 PM |\t  computing score...\n",
      "06/13 08:28:12 PM |\t  model_w_in_main sacreBLEU : 23.303282\n",
      "06/13 08:28:12 PM |\t  model_w_in_main test loss : 0.877146\n",
      "06/13 08:28:15 PM |\t  x_decoded[:2]:['translate English to German: Resumption of the session', 'translate English to German: I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.']\n",
      "06/13 08:28:15 PM |\t  pred_decoded[:2]:['.', 'I wish you a happy new year in the hope that you enjoyed a pleasant festive period. I wish you a happy new year in the hope that you enjoyed a pleasant festive period.']\n",
      "06/13 08:28:15 PM |\t  label_decoded[:2]:['Wiederaufnahme der Sitzungsperiode', 'Ich erkläre die am Freitag, dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen, wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe, daß Sie schöne Ferien hatten.']\n",
      "06/13 08:28:26 PM |\t  computing score...\n",
      "06/13 08:28:26 PM |\t  model_v_in_main sacreBLEU : 0.370500\n",
      "06/13 08:28:26 PM |\t  model_v_in_main test loss : 5.315890\n",
      "06/13 08:28:26 PM |\t  ('Attention Weights A : ', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>))\n",
      "06/13 08:28:28 PM |\t  1e+02%:\t  W_train_loss:2.0210500\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:28 PM |\t  w_train_loss:8.828120350837708,v_train_loss:0\n",
      "06/13 08:28:28 PM |\t  \n",
      "\n",
      "  ----------------epoch:124,\t\tlr_w:5.960464477539063e-11,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:28:28 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:28:28 PM |\t    0.0%:\t  W_train_loss:1.6032009\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:28 PM |\t   20.0%:\t  W_train_loss:1.3993433\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:28 PM |\t   40.0%:\t  W_train_loss:1.5492669\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:28 PM |\t   60.0%:\t  W_train_loss:1.1635772\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:29 PM |\t   80.0%:\t  W_train_loss:1.1818572\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:29 PM |\t  1e+02%:\t  W_train_loss:1.9584398\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:29 PM |\t  w_train_loss:8.855685353279114,v_train_loss:0\n",
      "06/13 08:28:29 PM |\t  \n",
      "\n",
      "  ----------------epoch:125,\t\tlr_w:1.4901161193847657e-11,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:28:29 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:28:29 PM |\t    0.0%:\t  W_train_loss:1.5662602\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:29 PM |\t   20.0%:\t  W_train_loss:1.3640673\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:30 PM |\t   40.0%:\t  W_train_loss:1.5677438\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:30 PM |\t   60.0%:\t  W_train_loss:1.1490434\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:30 PM |\t   80.0%:\t  W_train_loss:1.1839364\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:30 PM |\t  1e+02%:\t  W_train_loss:1.9939258\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:30 PM |\t  w_train_loss:8.824976921081543,v_train_loss:0\n",
      "06/13 08:28:30 PM |\t  \n",
      "\n",
      "  ----------------epoch:126,\t\tlr_w:2.980232238769531e-11,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:28:30 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:28:31 PM |\t    0.0%:\t  W_train_loss:1.5919120\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:31 PM |\t   20.0%:\t  W_train_loss:1.3914654\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:31 PM |\t   40.0%:\t  W_train_loss:1.5570714\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:31 PM |\t   60.0%:\t  W_train_loss:1.1863689\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:31 PM |\t   80.0%:\t  W_train_loss:1.1880374\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:32 PM |\t  1e+02%:\t  W_train_loss:2.0040083\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:32 PM |\t  w_train_loss:8.918863534927368,v_train_loss:0\n",
      "06/13 08:28:32 PM |\t  \n",
      "\n",
      "  ----------------epoch:127,\t\tlr_w:2.980232238769531e-11,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:28:32 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:28:32 PM |\t    0.0%:\t  W_train_loss:1.5989549\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:32 PM |\t   20.0%:\t  W_train_loss:1.3866124\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:32 PM |\t   40.0%:\t  W_train_loss:1.5261856\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:33 PM |\t   60.0%:\t  W_train_loss:1.1435455\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:33 PM |\t   80.0%:\t  W_train_loss:1.2286476\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:33 PM |\t  1e+02%:\t  W_train_loss:1.9691231\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:33 PM |\t  w_train_loss:8.853069186210632,v_train_loss:0\n",
      "06/13 08:28:33 PM |\t  \n",
      "\n",
      "  ----------------epoch:128,\t\tlr_w:2.980232238769531e-11,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:28:33 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:28:33 PM |\t    0.0%:\t  W_train_loss:1.5818648\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:33 PM |\t   20.0%:\t  W_train_loss:1.3406700\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:34 PM |\t   40.0%:\t  W_train_loss:1.5031729\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:34 PM |\t   60.0%:\t  W_train_loss:1.1849351\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:34 PM |\t   80.0%:\t  W_train_loss:1.1909196\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:34 PM |\t  1e+02%:\t  W_train_loss:1.9573473\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:34 PM |\t  w_train_loss:8.758909702301025,v_train_loss:0\n",
      "06/13 08:28:34 PM |\t  \n",
      "\n",
      "  ----------------epoch:129,\t\tlr_w:2.980232238769531e-11,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:28:34 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:28:35 PM |\t    0.0%:\t  W_train_loss:1.5838690\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:35 PM |\t   20.0%:\t  W_train_loss:1.2876759\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:35 PM |\t   40.0%:\t  W_train_loss:1.5516694\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:35 PM |\t   60.0%:\t  W_train_loss:1.1697454\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:36 PM |\t   80.0%:\t  W_train_loss:1.1577475\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:36 PM |\t  1e+02%:\t  W_train_loss:1.9468105\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:36 PM |\t  w_train_loss:8.69751763343811,v_train_loss:0\n",
      "06/13 08:28:36 PM |\t  \n",
      "\n",
      "  ----------------epoch:130,\t\tlr_w:7.450580596923828e-12,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:28:36 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:28:36 PM |\t    0.0%:\t  W_train_loss:1.6047239\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:36 PM |\t   20.0%:\t  W_train_loss:1.3523343\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:36 PM |\t   40.0%:\t  W_train_loss:1.5167716\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:37 PM |\t   60.0%:\t  W_train_loss:1.1809020\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:37 PM |\t   80.0%:\t  W_train_loss:1.1814144\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:37 PM |\t  1e+02%:\t  W_train_loss:1.9651421\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:37 PM |\t  w_train_loss:8.80128824710846,v_train_loss:0\n",
      "06/13 08:28:37 PM |\t  \n",
      "\n",
      "  ----------------epoch:131,\t\tlr_w:1.4901161193847657e-11,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:28:37 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:28:37 PM |\t    0.0%:\t  W_train_loss:1.5751026\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:38 PM |\t   20.0%:\t  W_train_loss:1.3772225\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:38 PM |\t   40.0%:\t  W_train_loss:1.5565865\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:38 PM |\t   60.0%:\t  W_train_loss:1.1906514\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:38 PM |\t   80.0%:\t  W_train_loss:1.1871639\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:38 PM |\t  1e+02%:\t  W_train_loss:1.9896762\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:38 PM |\t  w_train_loss:8.876403212547302,v_train_loss:0\n",
      "06/13 08:28:38 PM |\t  \n",
      "\n",
      "  ----------------epoch:132,\t\tlr_w:1.4901161193847657e-11,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:28:38 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:28:39 PM |\t    0.0%:\t  W_train_loss:1.6161582\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:39 PM |\t   20.0%:\t  W_train_loss:1.3690680\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:39 PM |\t   40.0%:\t  W_train_loss:1.5654583\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:39 PM |\t   60.0%:\t  W_train_loss:1.1713574\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:40 PM |\t   80.0%:\t  W_train_loss:1.1481230\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:40 PM |\t  1e+02%:\t  W_train_loss:2.0084591\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:40 PM |\t  w_train_loss:8.878624081611633,v_train_loss:0\n",
      "06/13 08:28:40 PM |\t  \n",
      "\n",
      "  ----------------epoch:133,\t\tlr_w:1.4901161193847657e-11,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:28:40 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:28:40 PM |\t    0.0%:\t  W_train_loss:1.6265489\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:40 PM |\t   20.0%:\t  W_train_loss:1.3855186\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:41 PM |\t   40.0%:\t  W_train_loss:1.4790704\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:41 PM |\t   60.0%:\t  W_train_loss:1.1712476\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:41 PM |\t   80.0%:\t  W_train_loss:1.1979036\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:41 PM |\t  1e+02%:\t  W_train_loss:2.0241566\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:41 PM |\t  w_train_loss:8.884445667266846,v_train_loss:0\n",
      "06/13 08:28:41 PM |\t  \n",
      "\n",
      "  ----------------epoch:134,\t\tlr_w:1.4901161193847657e-11,\t\tlr_v:0.0,\t\tlr_A:0----------------\n",
      "06/13 08:28:41 PM |\t  split size:[32, 0, 0, 0]\n",
      "06/13 08:28:41 PM |\t    0.0%:\t  W_train_loss:1.5709229\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 08:28:44 PM |\t  x_decoded[:2]:['translate English to German: Resumption of the session', 'translate English to German: I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.']\n",
      "06/13 08:28:44 PM |\t  pred_decoded[:2]:['Wiederaufnahme der Sitzungsperiode', 'Ich beglückwünsche Ihnen einen Sitzungsperiode des Europäischen Parlaments zur Sitzungsperiode des Europäischen Parlaments zur Verfügung stehen, und ich möchte ich Sie a Happy New Year in der hope that you enjoyed a pleasant festive period.']\n",
      "06/13 08:28:44 PM |\t  label_decoded[:2]:['Wiederaufnahme der Sitzungsperiode', 'Ich erkläre die am Freitag, dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen, wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe, daß Sie schöne Ferien hatten.']\n",
      "06/13 08:28:55 PM |\t  computing score...\n",
      "06/13 08:28:55 PM |\t  model_w_in_main sacreBLEU : 23.303282\n",
      "06/13 08:28:55 PM |\t  model_w_in_main test loss : 0.877145\n",
      "06/13 08:28:58 PM |\t  x_decoded[:2]:['translate English to German: Resumption of the session', 'translate English to German: I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.']\n",
      "06/13 08:28:58 PM |\t  pred_decoded[:2]:['.', 'I wish you a happy new year in the hope that you enjoyed a pleasant festive period. I wish you a happy new year in the hope that you enjoyed a pleasant festive period.']\n",
      "06/13 08:28:58 PM |\t  label_decoded[:2]:['Wiederaufnahme der Sitzungsperiode', 'Ich erkläre die am Freitag, dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen, wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe, daß Sie schöne Ferien hatten.']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_60736/1495694478.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"\\n\\n  ----------------epoch:{epoch},\\t\\tlr_w:{lr_w},\\t\\tlr_v:{lr_v},\\t\\tlr_A:{args.A_lr}----------------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mw_train_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv_train_loss\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mmy_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_v\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0marchitect\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_optimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv_optimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr_w\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr_v\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtot_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mscheduler_w\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_60736/2532097730.py\u001b[0m in \u001b[0;36mmy_train\u001b[1;34m(epoch, _dataloader, validdataloader, w_model, v_model, architect, A, w_optimizer, v_optimizer, lr_w, lr_v, tot_iter)\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtot_iter\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_num\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtot_iter\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[0mmy_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[0mmy_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_v\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m             \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Attention Weights A : \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_v\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'./model/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'model_w.pt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#+now+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_60736/1461293833.py\u001b[0m in \u001b[0;36mmy_test\u001b[1;34m(_dataloader, model, epoch)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0macc\u001b[0m\u001b[1;33m+=\u001b[0m \u001b[0mls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mcounter\u001b[0m\u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mpre\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_dataloaderx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0mx_decoded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_dataloaderx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mskip_special_tokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mpred_decoded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpre\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mskip_special_tokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mg:\\GitCode\\Self-teaching-for-machine-translation\\T5_scratch\\T5.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, input_ids, num_beams, max_length)\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_beams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0moutput_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_beams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_beams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlength_penalty\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m0.6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrepetition_penalty\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;31m## sampling with top_p\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, typical_p, repetition_penalty, bad_words_ids, force_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, stopping_criteria, constraints, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, exponential_decay_length_penalty, **model_kwargs)\u001b[0m\n\u001b[0;32m   1313\u001b[0m             )\n\u001b[0;32m   1314\u001b[0m             \u001b[1;31m# 12. run beam search\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1315\u001b[1;33m             return self.beam_search(\n\u001b[0m\u001b[0;32m   1316\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1317\u001b[0m                 \u001b[0mbeam_scorer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\generation_utils.py\u001b[0m in \u001b[0;36mbeam_search\u001b[1;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[0;32m   2208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2209\u001b[0m             \u001b[1;31m# stateless\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2210\u001b[1;33m             beam_outputs = beam_scorer.process(\n\u001b[0m\u001b[0;32m   2211\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2212\u001b[0m                 \u001b[0mnext_token_scores\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\generation_beam_search.py\u001b[0m in \u001b[0;36mprocess\u001b[1;34m(self, input_ids, next_scores, next_tokens, next_indices, pad_token_id, eos_token_id)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m             \u001b[1;31m# Check if we are done so that we can save a pad step if all(done)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 279\u001b[1;33m             self._done[batch_idx] = self._done[batch_idx] or beam_hyp.is_done(\n\u001b[0m\u001b[0;32m    280\u001b[0m                 \u001b[0mnext_scores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcur_len\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m             )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# if(args.valid_begin==1):\n",
    "#     my_test(valid_dataloader,model_w,-1) #before train\n",
    "#     my_test(valid_dataloader,model_v,-1)  \n",
    "\n",
    "tot_iter = [0]\n",
    "for epoch in range(args.epochs):\n",
    "    lr_w = scheduler_w.get_lr()[0]\n",
    "    lr_v = scheduler_v.get_lr()[0]\n",
    "\n",
    "    logging.info(f\"\\n\\n  ----------------epoch:{epoch},\\t\\tlr_w:{lr_w},\\t\\tlr_v:{lr_v},\\t\\tlr_A:{args.A_lr}----------------\")\n",
    "\n",
    "    w_train_loss,v_train_loss =  my_train(epoch, train_dataloader, valid_dataloader, model_w, model_v,  architect, A, w_optimizer, v_optimizer, lr_w,lr_v,tot_iter)\n",
    "    \n",
    "    scheduler_w.step()\n",
    "    scheduler_v.step()\n",
    "\n",
    "\n",
    "    logging.info(f\"w_train_loss:{w_train_loss},v_train_loss:{v_train_loss}\")\n",
    "    # wandb.log({'w_train_loss': w_train_loss, 'v_train_loss':v_train_loss})\n",
    "\n",
    "\n",
    "\n",
    "torch.save(model_v,'./model/'+now+'model_w.pt')\n",
    "torch.save(model_v,'./model/'+now+'model_v.pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.6343e-03,  1.6985e-04,  4.6182e-05,  ..., -4.5622e-05,\n",
       "           4.9963e-05, -7.9150e-05],\n",
       "         [ 8.2149e-05, -4.7620e-05,  8.2381e-05,  ...,  8.6653e-05,\n",
       "           1.1960e-04,  3.4265e-06],\n",
       "         [ 5.5713e-06,  9.0648e-05, -3.2042e-05,  ..., -4.1399e-05,\n",
       "          -5.0304e-05, -9.8498e-05],\n",
       "         ...,\n",
       "         [ 1.6356e-03,  1.6731e-04,  4.5340e-05,  ..., -5.2783e-05,\n",
       "           4.2435e-05, -8.5164e-05],\n",
       "         [ 1.6356e-03,  1.6731e-04,  4.5343e-05,  ..., -5.2783e-05,\n",
       "           4.2434e-05, -8.5163e-05],\n",
       "         [ 1.6356e-03,  1.6731e-04,  4.5342e-05,  ..., -5.2784e-05,\n",
       "           4.2434e-05, -8.5163e-05]],\n",
       "\n",
       "        [[ 1.6345e-03,  1.6776e-04,  4.2936e-05,  ..., -4.4132e-05,\n",
       "           5.1346e-05, -7.9345e-05],\n",
       "         [-7.6601e-06, -3.0543e-05, -5.0514e-05,  ...,  1.1752e-05,\n",
       "          -1.2760e-04,  1.2106e-05],\n",
       "         [ 2.6243e-05, -3.8717e-05,  8.9031e-05,  ...,  4.1839e-05,\n",
       "          -1.4667e-05,  3.6620e-05],\n",
       "         ...,\n",
       "         [ 1.6364e-03,  1.7076e-04,  4.0118e-05,  ..., -4.6903e-05,\n",
       "           4.4114e-05, -8.4955e-05],\n",
       "         [ 1.6364e-03,  1.7077e-04,  4.0118e-05,  ..., -4.6904e-05,\n",
       "           4.4115e-05, -8.4954e-05],\n",
       "         [ 1.6364e-03,  1.7077e-04,  4.0116e-05,  ..., -4.6902e-05,\n",
       "           4.4116e-05, -8.4954e-05]],\n",
       "\n",
       "        [[ 1.6347e-03,  1.6664e-04,  4.3874e-05,  ..., -4.6535e-05,\n",
       "           5.1058e-05, -7.8006e-05],\n",
       "         [ 8.2920e-05, -5.1228e-05,  8.0187e-05,  ...,  8.5533e-05,\n",
       "           1.2085e-04,  4.4378e-06],\n",
       "         [-8.3324e-06, -6.6662e-05, -4.1717e-06,  ...,  8.9557e-05,\n",
       "           1.4526e-05,  7.6432e-05],\n",
       "         ...,\n",
       "         [ 1.6358e-03,  1.6664e-04,  4.4311e-05,  ..., -5.2517e-05,\n",
       "           4.4142e-05, -8.3808e-05],\n",
       "         [ 1.6358e-03,  1.6663e-04,  4.4312e-05,  ..., -5.2520e-05,\n",
       "           4.4142e-05, -8.3808e-05],\n",
       "         [ 1.6358e-03,  1.6663e-04,  4.4311e-05,  ..., -5.2518e-05,\n",
       "           4.4142e-05, -8.3806e-05]],\n",
       "\n",
       "        [[ 1.6357e-03,  1.6781e-04,  4.4269e-05,  ..., -4.4928e-05,\n",
       "           4.8897e-05, -7.9563e-05],\n",
       "         [ 1.3823e-04, -6.3264e-05,  6.3322e-05,  ..., -2.6144e-05,\n",
       "           5.9140e-05, -1.2902e-05],\n",
       "         [ 6.3026e-05,  5.7359e-05, -7.1889e-05,  ...,  9.2064e-06,\n",
       "          -2.3302e-06,  3.5582e-06],\n",
       "         ...,\n",
       "         [ 1.6376e-03,  1.6354e-04,  4.5136e-05,  ..., -5.1854e-05,\n",
       "           4.0205e-05, -8.6836e-05],\n",
       "         [ 1.6376e-03,  1.6354e-04,  4.5135e-05,  ..., -5.1851e-05,\n",
       "           4.0201e-05, -8.6841e-05],\n",
       "         [ 1.6376e-03,  1.6354e-04,  4.5136e-05,  ..., -5.1853e-05,\n",
       "           4.0202e-05, -8.6839e-05]]], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load('logits.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'main_v.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_175828/2885071301.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mm1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'main_v.pt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mm1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mm2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'unrolled_v.pt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mm2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'encoding'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 594\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    595\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m             \u001b[1;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'w'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'main_v.pt'"
     ]
    }
   ],
   "source": [
    "m1 = torch.load('main_v.pt')\n",
    "m1.eval()\n",
    "m2 = torch.load('unrolled_v.pt')\n",
    "m2.eval()\n",
    "''\n",
    "for k1, k2 in zip(m1.state_dict(), m2.state_dict()):\n",
    "    v1= m1.state_dict()[k1]\n",
    "    v2= m2.state_dict()[k2]\n",
    "    print(k1,k2)\n",
    "    # print(v1,v2)\n",
    "    print((abs(v1.data-v2.data)).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(1)\n",
    "a.add(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('python38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d33c3b0ef123e851f98887a8750ca7da758e4ff258891935cfe6ff9c0394387"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
