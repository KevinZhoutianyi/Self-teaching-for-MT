{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd() \n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from T5 import *\n",
    "import torch\n",
    "from datasets import load_dataset,load_metric\n",
    "from transformers import T5Tokenizer,AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import torch_optimizer as optim\n",
    "from transformers.optimization import Adafactor, AdafactorSchedule\n",
    "from MT_hyperparams import seed_,max_length,target_language\n",
    "import torch.backends.cudnn as cudnn\n",
    "from utils import *\n",
    "from attention_params import *\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, SubsetRandomSampler\n",
    "from torch.autograd import Variable\n",
    "from losses import *\n",
    "from architect import *\n",
    "import logging\n",
    "import sys\n",
    "import transformers\n",
    "import time\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(\"main\")\n",
    "\n",
    "\n",
    "parser.add_argument('--valid_num_points', type=int,             default = 100, help='validation data number')\n",
    "parser.add_argument('--train_num_points', type=int,             default = 200, help='train data number')\n",
    "parser.add_argument('--test_num_points', type=int,              default = 50, help='train data number')\n",
    "\n",
    "parser.add_argument('--batch_size', type=int,                   default=16,     help='Batch size')\n",
    "parser.add_argument('--train_w_num_points', type=int,           default=4,      help='train_w_num_points for each batch')\n",
    "parser.add_argument('--train_v_synthetic_num_points', type=int, default=8,      help='train_v_synthetic_num_points for each batch')\n",
    "parser.add_argument('--train_v_num_points', type=int,           default=0,      help='train_v_num_points for each batch')\n",
    "parser.add_argument('--train_A_num_points', type=int,           default=4,      help='train_A_num_points decay for each batch')\n",
    "\n",
    "parser.add_argument('--gpu', type=int,                          default=0,      help='gpu device id')\n",
    "parser.add_argument('--num_workers', type=int,                  default=0,      help='num_workers')\n",
    "parser.add_argument('--model_name_teacher', type=str,           default='google/t5-small-lm-adapt',      help='model_name')\n",
    "parser.add_argument('--model_name_student', type=str,           default='google/t5-small-lm-adapt',      help='model_name')\n",
    "parser.add_argument('--exp_name', type=str,                     default='T5spec',      help='experiment name')\n",
    "parser.add_argument('--rep_num', type=int,                      default=50,      help='report times for 1 epoch')\n",
    "parser.add_argument('--test_num', type=int,                     default=2000,      help='test times for 1 epoch')\n",
    "\n",
    "parser.add_argument('--epochs', type=int,                       default=500,     help='num of training epochs')\n",
    "parser.add_argument('--pre_epochs', type=int,                   default=0,      help='train model W for x epoch first')\n",
    "parser.add_argument('--grad_clip', type=float,                  default=1,      help='gradient clipping')\n",
    "parser.add_argument('--grad_acc_count', type=float,             default=-1,      help='gradient accumulate steps')\n",
    "\n",
    "parser.add_argument('--w_lr', type=float,                       default=1e-3,   help='learning rate for w')\n",
    "parser.add_argument('--unrolled_w_lr', type=float,              default=1e-3,   help='learning rate for w')\n",
    "parser.add_argument('--v_lr', type=float,                       default=1e-3,   help='learning rate for v')\n",
    "parser.add_argument('--unrolled_v_lr', type=float,              default=1e-3,   help='learning rate for v')\n",
    "parser.add_argument('--A_lr', type=float,                       default=1e-3,   help='learning rate for A')\n",
    "parser.add_argument('--learning_rate_min', type=float,          default=1e-8,   help='learning_rate_min')\n",
    "parser.add_argument('--decay', type=float,                      default=1e-3,   help='weight decay')\n",
    "parser.add_argument('--beta1', type=float,                      default=0.9,    help='momentum')\n",
    "parser.add_argument('--beta2', type=float,                      default=0.98,    help='momentum')\n",
    "parser.add_argument('--warm', type=float,                       default=10,    help='warmup step')\n",
    "parser.add_argument('--num_step_lr', type=float,                default=1,    help='warmup step')\n",
    "parser.add_argument('--decay_lr', type=float,                   default=0.7,    help='warmup step')\n",
    "# parser.add_argument('--smoothing', type=float,                  default=0.1,    help='labelsmoothing')\n",
    "\n",
    "\n",
    "parser.add_argument('--traindata_loss_ratio', type=float,       default=0.5,    help='human translated data ratio')\n",
    "parser.add_argument('--syndata_loss_ratio', type=float,         default=0.5,    help='augmented dataset ratio')\n",
    "\n",
    "parser.add_argument('--valid_begin', type=int,                  default=1,      help='whether valid before train')\n",
    "parser.add_argument('--train_A', type=int,                      default=1 ,     help='whether train A')\n",
    "\n",
    "\n",
    "\n",
    "args = parser.parse_args(args=[])#(args=['--batch_size', '8',  '--no_cuda'])#used in ipynb\n",
    "args.test_num = args.test_num//args.batch_size * args.batch_size\n",
    "args.rep_num = args.rep_num//args.batch_size * args.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33monlydrinkwater\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.18 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.17"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>g:\\GitCode\\Self-teaching-for-machine-translation\\T5_scratch\\wandb\\run-20220614_174933-g7nw3pra</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/onlydrinkwater/Selftraining/runs/g7nw3pra\" target=\"_blank\">T5spec</a></strong> to <a href=\"https://wandb.ai/onlydrinkwater/Selftraining\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/onlydrinkwater/Selftraining/runs/g7nw3pra?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x2ed8df973d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://wandb.ai/ check the running status online\n",
    "import wandb\n",
    "os.environ['WANDB_API_KEY']='a166474b1b7ad33a0549adaaec19a2f6d3f91d87'\n",
    "os.environ['WANDB_NAME']=args.exp_name\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "wandb.init(project=\"Selftraining\",config=args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/14 05:49:42 PM |\t  Reusing dataset wmt14 (C:\\Users\\kevin\\.cache\\huggingface\\datasets\\wmt14\\de-en\\1.0.0\\d239eaf0ff090d28da19b6bc9758e24634d84de0a1ef092f0b5c54e6f132d7e2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  7.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/14 05:49:42 PM |\t  Namespace(A_lr=0, batch_size=16, beta1=0.9, beta2=0.98, decay=0.001, decay_lr=0.7, epochs=500, exp_name='T5spec', gpu=0, grad_acc_count=-1, grad_clip=1, learning_rate_min=1e-08, model_name_student='google/t5-small-lm-adapt', model_name_teacher='google/t5-small-lm-adapt', num_step_lr=1, num_workers=0, pre_epochs=0, rep_num=48, syndata_loss_ratio=0.5, test_num=2000, test_num_points=50, train_A=1, train_A_num_points=4, train_num_points=200, train_v_num_points=0, train_v_synthetic_num_points=8, train_w_num_points=4, traindata_loss_ratio=0.5, unrolled_v_lr=0.001, unrolled_w_lr=0.001, v_lr=0.001, valid_begin=1, valid_num_points=100, w_lr=0.001, warm=10)\n",
      "06/14 05:49:42 PM |\t  DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 4508785\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 3000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 3003\n",
      "    })\n",
      "})\n",
      "06/14 05:49:42 PM |\t  {'translation': {'de': 'Ich bitte Sie, sich zu einer Schweigeminute zu erheben.', 'en': \"Please rise, then, for this minute' s silence.\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# logging file\n",
    "now = time.strftime(\"%Y-%m-%d-%H_%M_%S\", time.localtime(time.time()))\n",
    "\n",
    "log_format = '%(asctime)s |\\t  %(message)s'\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO,\n",
    "                    format=log_format, datefmt='%m/%d %I:%M:%S %p')\n",
    "fh = logging.FileHandler(os.path.join(\n",
    "    \"./log/\", now+'.txt'), 'w', encoding=\"UTF-8\")\n",
    "fh.setFormatter(logging.Formatter(log_format))\n",
    "logging.getLogger().addHandler(fh)\n",
    "dataset = load_dataset('wmt14', 'de-en')\n",
    "\n",
    "logging.info(args)\n",
    "logging.info(dataset)\n",
    "logging.info(dataset['train'][5])\n",
    "\n",
    "\n",
    "# Setting the seeds\n",
    "np.random.seed(seed_)\n",
    "torch.cuda.set_device(args.gpu)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cudnn.benchmark = True\n",
    "torch.manual_seed(seed_)\n",
    "cudnn.enabled = True\n",
    "torch.cuda.manual_seed(seed_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/14 05:49:44 PM |\t  modelsize:76.961152MB\n",
      "06/14 05:49:46 PM |\t  modelsize:76.961152MB\n"
     ]
    }
   ],
   "source": [
    "modelname = args.model_name_teacher\n",
    "pretrained  =  AutoModelForSeq2SeqLM.from_pretrained(modelname)\n",
    "pathname = modelname.replace('/','')\n",
    "logging.info(f'modelsize:{count_parameters_in_MB(pretrained)}MB')\n",
    "torch.save(pretrained,pathname+'.pt')\n",
    "\n",
    "modelname = args.model_name_student\n",
    "pretrained  =  AutoModelForSeq2SeqLM.from_pretrained(modelname)\n",
    "pathname = modelname.replace('/','')\n",
    "logging.info(f'modelsize:{count_parameters_in_MB(pretrained)}MB')\n",
    "torch.save(pretrained,pathname+'.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/14 05:49:48 PM |\t  Loading cached shuffled indices for dataset at C:\\Users\\kevin\\.cache\\huggingface\\datasets\\wmt14\\de-en\\1.0.0\\d239eaf0ff090d28da19b6bc9758e24634d84de0a1ef092f0b5c54e6f132d7e2\\cache-fcff064badad2159.arrow\n",
      "06/14 05:49:48 PM |\t  Loading cached shuffled indices for dataset at C:\\Users\\kevin\\.cache\\huggingface\\datasets\\wmt14\\de-en\\1.0.0\\d239eaf0ff090d28da19b6bc9758e24634d84de0a1ef092f0b5c54e6f132d7e2\\cache-ef861152e003e0c7.arrow\n",
      "06/14 05:49:48 PM |\t  Loading cached shuffled indices for dataset at C:\\Users\\kevin\\.cache\\huggingface\\datasets\\wmt14\\de-en\\1.0.0\\d239eaf0ff090d28da19b6bc9758e24634d84de0a1ef092f0b5c54e6f132d7e2\\cache-848b25adc701ab2b.arrow\n",
      "06/14 05:49:48 PM |\t  train len: 192\n",
      "06/14 05:49:48 PM |\t  train_w_num_points_len: 48\n",
      "06/14 05:49:48 PM |\t  train_v_synthetic_num_points_len: 96\n",
      "06/14 05:49:48 PM |\t  train_v_num_points_len: 0\n",
      "06/14 05:49:48 PM |\t  train_A_num_points_len: 48\n",
      "06/14 05:49:49 PM |\t  valid len: 100\n",
      "06/14 05:49:49 PM |\t  test len: 50\n",
      "06/14 05:49:49 PM |\t  {'de': 'Dank unseres Personals und Geräteparks sind wir täglich rund um die Uhr in der Lage, uns allen erdenklichen Herausforderungen zu stellen.', 'en': 'translate English to German: Our staff and equipment stands ready to answer any challenges 24/7.'}\n",
      "06/14 05:49:49 PM |\t  {'de': 'Diese Entscheidung rief in der Öffentlichkeit eine lebhafte Diskussion hervor.', 'en': 'translate English to German: The resolution caused lively public debate.'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# preprocess the data, make a dataloader\n",
    "import random\n",
    "modelname = args.model_name_teacher\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelname)\n",
    "criterion = torch.nn.CrossEntropyLoss( reduction='none')#teacher shouldn't have label smoothing, especially when student got same size.\n",
    "criterion_v = torch.nn.CrossEntropyLoss( reduction='none')#,label_smoothing=args.smoothing) #without LS, V may be too confident to that syn data, and LS do well for real data also.\n",
    "\n",
    "\n",
    "\n",
    "train = dataset['train'].shuffle(seed=seed_).select(range(args.train_num_points))\n",
    "valid = dataset['validation'].shuffle(seed=seed_).select(range(args.valid_num_points))\n",
    "test = dataset['test'].shuffle(seed=seed_).select(range(args.test_num_points))#[L_t+L_v:L_t+L_v+L_test]\n",
    "train = train['translation']\n",
    "valid = valid['translation']\n",
    "test = test['translation']\n",
    "def preprocess(dat):\n",
    "    for t in dat:\n",
    "        t['en'] = \"translate English to German: \" + t['en']  #needed for T5\n",
    "preprocess(train)\n",
    "preprocess(valid)\n",
    "preprocess(test)\n",
    "#TODO: Syn_input should be monolingual data, should try en-fo's en. cuz wmt may align\n",
    "num_batch = args.train_num_points//args.batch_size\n",
    "train = train[:args.batch_size*num_batch]\n",
    "logging.info(\"train len: %d\",len(train))\n",
    "\n",
    "'''\n",
    "each mini batch consist of : \n",
    "1. data to train W\n",
    "2. monolingual data to generate parallel data\n",
    "3. data to train V\n",
    "4. data to train A\n",
    "'''\n",
    "train_w_num_points_len = num_batch * args.train_w_num_points\n",
    "train_v_synthetic_num_points_len = num_batch * args.train_v_synthetic_num_points\n",
    "train_v_num_points_len = num_batch * args.train_v_num_points\n",
    "train_A_num_points_len = num_batch * args.train_A_num_points\n",
    "logging.info(\"train_w_num_points_len: %d\",train_w_num_points_len)\n",
    "logging.info(\"train_v_synthetic_num_points_len: %d\",train_v_synthetic_num_points_len)\n",
    "logging.info(\"train_v_num_points_len: %d\",train_v_num_points_len)\n",
    "logging.info(\"train_A_num_points_len: %d\",train_A_num_points_len)\n",
    "\n",
    "attn_idx_list = torch.arange(train_w_num_points_len).cuda()\n",
    "logging.info(\"valid len: %d\",len(valid))\n",
    "logging.info(\"test len: %d\" ,len(test))\n",
    "logging.info(train[2])\n",
    "logging.info(valid[2])\n",
    "# logging.info(test[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get train data start\n",
      "get train data end\n",
      "06/14 05:49:49 PM |\t  train data get\n",
      "06/14 05:49:49 PM |\t  train data loader get\n",
      "06/14 05:49:49 PM |\t  valid data loader get\n",
      "06/14 05:49:49 PM |\t  test data loader get\n"
     ]
    }
   ],
   "source": [
    "target_language  = 'de'\n",
    "train_data = get_train_Dataset(train, tokenizer)# Create the DataLoader for our training set.\n",
    "logging.info('train data get')\n",
    "train_dataloader = DataLoader(train_data, sampler= SequentialSampler(train_data), \n",
    "                        batch_size=args.batch_size, pin_memory=args.num_workers>0, num_workers=args.num_workers)\n",
    "logging.info('train data loader get')\n",
    "valid_data = get_aux_dataset(valid, tokenizer)# Create the DataLoader for our training set.\n",
    "valid_dataloader = DataLoader(valid_data, sampler=SequentialSampler(valid_data), \n",
    "                        batch_size=args.batch_size, pin_memory=args.num_workers>0, num_workers=args.num_workers)\n",
    "logging.info('valid data loader get')\n",
    "test_data = get_aux_dataset(test, tokenizer)# Create the DataLoader for our training set.\n",
    "test_dataloader = DataLoader(test_data, sampler=SequentialSampler(test_data),\n",
    "                        batch_size=args.batch_size, pin_memory=args.num_workers>0, num_workers=args.num_workers)#, sampler=RandomSampler(test_data)\n",
    "logging.info('test data loader get')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "A = attention_params(train_w_num_points_len)#half of train regarded as u\n",
    "A = A.cuda()\n",
    "\n",
    "\n",
    "\n",
    "# TODO: model loaded from saved model\n",
    "model_w = T5(criterion=criterion, tokenizer= tokenizer, args = args, name = 'model_w_in_main')\n",
    "model_w = model_w.cuda()\n",
    "w_optimizer = torch.optim.Adam(model_w.parameters(),  lr= args.w_lr ,  betas=(args.beta1, args.beta2) ,eps=1e-9 )\n",
    "# w_optimizer = Adafactor(model_w.parameters(), lr = args.w_lr ,scale_parameter=False, relative_step=False , warmup_init=False,clip_threshold=1,beta1=0,eps=( 1e-30,0.001))\n",
    "scheduler_w  =   StepLR(w_optimizer, step_size=args.num_step_lr, gamma=args.decay_lr)\n",
    "# scheduler_w  = Scheduler(w_optimizer,dim_embed=512, warmup_steps=args.warm, initlr = args.w_lr)\n",
    "\n",
    "\n",
    "\n",
    "model_v = T5(criterion=criterion_v, tokenizer= tokenizer, args = args, name = 'model_v_in_main')\n",
    "model_v = model_v.cuda()\n",
    "v_optimizer = torch.optim.Adam(model_v.parameters(),  lr= args.v_lr ,  betas=(args.beta1,args.beta2) ,eps=1e-9  )\n",
    "# v_optimizer =Adafactor(model_v.parameters(), lr = args.v_lr ,scale_parameter=False, relative_step=False , warmup_init=False,clip_threshold=1,beta1=0,eps=( 1e-30,0.001))\n",
    "scheduler_v  =   StepLR(v_optimizer, step_size=args.num_step_lr, gamma=args.decay_lr)\n",
    "# scheduler_v  = Scheduler(v_optimizer,dim_embed=512, warmup_steps=args.warm, initlr = args.v_lr)\n",
    "\n",
    "\n",
    "architect = Architect(model_w, model_v,  A, args)\n",
    "scheduler_A  =   StepLR(architect.optimizer_A, step_size=args.num_step_lr, gamma=args.decay_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def my_test(_dataloader,model,epoch):\n",
    "    # logging.info(f\"GPU mem before test:{getGPUMem(device)}%\")\n",
    "    acc = 0\n",
    "    counter = 0\n",
    "    model.eval()\n",
    "    metric_sacrebleu =  load_metric('sacrebleu')\n",
    "    # metric_bleu =  load_metric('bleu')\n",
    "    \n",
    "    for step, batch in enumerate(_dataloader):\n",
    "        \n",
    "        test_dataloaderx = Variable(batch[0], requires_grad=False).to(device, non_blocking=False)[:args.train_w_num_points]\n",
    "        test_dataloaderx_attn = Variable(batch[1], requires_grad=False).to(device, non_blocking=False)[:args.train_w_num_points]\n",
    "        test_dataloadery = Variable(batch[2], requires_grad=False).to(device, non_blocking=False)[:args.train_w_num_points]\n",
    "        test_dataloadery_attn = Variable(batch[3], requires_grad=False).to(device, non_blocking=False)[:args.train_w_num_points]\n",
    "        ls = my_loss(test_dataloaderx,test_dataloaderx_attn,test_dataloadery,test_dataloadery_attn,model)\n",
    "        acc+= ls.item()\n",
    "        counter+= 1\n",
    "        pre = model.generate(test_dataloaderx)\n",
    "        x_decoded = tokenizer.batch_decode(test_dataloaderx,skip_special_tokens=True)\n",
    "        pred_decoded = tokenizer.batch_decode(pre,skip_special_tokens=True)\n",
    "        label_decoded =  tokenizer.batch_decode(test_dataloadery,skip_special_tokens=True)\n",
    "        \n",
    "        pred_str = [x  for x in pred_decoded]\n",
    "        label_str = [[x] for x in label_decoded]\n",
    "        # pred_list = [x.split()  for x in pred_decoded]\n",
    "        # label_list = [[x.split()] for x in label_decoded]\n",
    "        metric_sacrebleu.add_batch(predictions=pred_str, references=label_str)\n",
    "        # metric_bleu.add_batch(predictions=pred_list, references=label_list)\n",
    "        if  step==0:\n",
    "            logging.info(f'x_decoded[:2]:{x_decoded[:2]}')\n",
    "            logging.info(f'pred_decoded[:2]:{pred_decoded[:2]}')\n",
    "            logging.info(f'label_decoded[:2]:{label_decoded[:2]}')\n",
    "            \n",
    "            \n",
    "    logging.info('computing score...') \n",
    "    sacrebleu_score = metric_sacrebleu.compute()\n",
    "    # bleu_score = metric_bleu.compute()\n",
    "    logging.info('%s sacreBLEU : %f',model.name,sacrebleu_score['score'])#TODO:bleu may be wrong cuz max length\n",
    "    # logging.info('%s BLEU : %f',model.name,bleu_score['bleu'])\n",
    "    logging.info('%s test loss : %f',model.name,acc/(counter))\n",
    "    wandb.log({'sacreBLEU'+model.name: sacrebleu_score['score']})\n",
    "    wandb.log({'test_loss'+model.name: acc/counter})\n",
    "    # del test_dataloaderx,acc,counter,test_dataloaderx_attn,sacrebleu_score,bleu_score,test_dataloadery,test_dataloadery_attn,ls,pre,x_decoded,pred_decoded,label_decoded,pred_str,label_str,pred_list,label_list\n",
    "    # gc.collect()\n",
    "    # torch.cuda.empty_cache()\n",
    "    model.train()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_train(epoch, _dataloader, validdataloader, w_model, v_model, architect, A, w_optimizer, v_optimizer, lr_w, lr_v, tot_iter):\n",
    "\n",
    "    objs_w = AvgrageMeter()\n",
    "    objs_v_syn = AvgrageMeter()\n",
    "    objs_v_train = AvgrageMeter()\n",
    "    objs_v_star_val = AvgrageMeter()\n",
    "    objs_v_val = AvgrageMeter()\n",
    "    v_trainloss_acc = 0\n",
    "    w_trainloss_acc = 0\n",
    "    # now  train_x is [num of batch, datasize], so its seperate batch for the code below\n",
    "    wsize = args.train_w_num_points\n",
    "    synsize = args.train_v_synthetic_num_points\n",
    "    vsize = args.train_v_num_points\n",
    "    vtrainsize = vsize+synsize\n",
    "    vtrainsize_total = train_v_num_points_len+train_v_synthetic_num_points_len\n",
    "    Asize = args.train_A_num_points\n",
    "    loader_len = len(_dataloader)\n",
    "    split_size = [wsize, synsize, vsize, Asize]\n",
    "    bs = args.batch_size\n",
    "    w_model.train()\n",
    "    v_model.train()\n",
    "\n",
    "    logging.info(f\"split size:{split_size}\")\n",
    "    for step, batch in enumerate(_dataloader):\n",
    "        tot_iter[0] += bs\n",
    "        \n",
    "\n",
    "        # logging.info(f\"GPU mem :{getGPUMem(device)}%\")\n",
    "        train_x = Variable(batch[0], requires_grad=False).to(\n",
    "            device, non_blocking=False)\n",
    "        train_x_attn = Variable(batch[1], requires_grad=False).to(\n",
    "            device, non_blocking=False)\n",
    "        train_y = Variable(batch[2], requires_grad=False).to(\n",
    "            device, non_blocking=False)\n",
    "        train_y_attn = Variable(batch[3], requires_grad=False).to(\n",
    "            device, non_blocking=False)\n",
    "        (input_w, input_syn, input_v, input_A_v) = torch.split(train_x, split_size)\n",
    "        (input_w_attn, input_syn_attn, input_v_attn,\n",
    "         input_A_v_attn) = torch.split(train_x_attn, split_size)\n",
    "        (output_w, _, output_v, output_A_v) = torch.split(train_y, split_size)\n",
    "        (output_w_attn, _, output_v_attn, output_A_v_attn) = torch.split(\n",
    "            train_y_attn, split_size)\n",
    "        attn_idx = attn_idx_list[wsize*step:(wsize*step+wsize)]\n",
    "        if(True):# let v train on syn data and w data\n",
    "            input_v = input_w\n",
    "            input_v_attn = input_w_attn\n",
    "            output_v = output_w\n",
    "            output_v_attn = output_w_attn\n",
    "            vsize = wsize\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if (args.train_A == 1):\n",
    "            epsilon_w = args.unrolled_w_lr\n",
    "            epsilon_v  = args.unrolled_v_lr\n",
    "            v_star_val_loss = architect.step(input_w,  output_w, input_w_attn, output_w_attn, w_optimizer,\n",
    "                                             input_v, input_v_attn, output_v, output_v_attn, input_syn, input_syn_attn,\n",
    "                                             input_A_v, input_A_v_attn, output_A_v, output_A_v_attn, v_optimizer,\n",
    "                                             attn_idx, epsilon_w, epsilon_v)\n",
    "            objs_v_star_val.update(v_star_val_loss, Asize)\n",
    "\n",
    "        w_optimizer.zero_grad()\n",
    "   \n",
    "        loss_w = CTG_loss(input_w, input_w_attn, output_w,\n",
    "                          output_w_attn, attn_idx, A, w_model)\n",
    "        w_trainloss_acc += loss_w.item()\n",
    "        loss_w.backward()\n",
    "        objs_w.update(loss_w.item(), wsize)\n",
    "        w_optimizer.step()\n",
    "        # assert False\n",
    "\n",
    "\n",
    "        v_optimizer.zero_grad()\n",
    "        loss_aug = calc_loss_aug(input_syn, input_syn_attn, w_model, v_model)\n",
    "\n",
    "        loss = my_loss2(input_v, input_v_attn, output_v,\n",
    "                        output_v_attn, v_model)\n",
    "        v_loss = (args.traindata_loss_ratio*loss +\n",
    "                  loss_aug*args.syndata_loss_ratio)\n",
    "        v_trainloss_acc += v_loss.item()\n",
    "        v_loss.backward()\n",
    "        objs_v_syn.update(loss_aug.item(), synsize)\n",
    "        objs_v_train.update(loss.item(), vsize)\n",
    "        v_optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            valloss = my_loss2(input_A_v, input_A_v_attn,  output_A_v, output_A_v_attn,v_model)\n",
    "            objs_v_val.update(valloss.item(), Asize)\n",
    "\n",
    "        progress = 100*(step)/(loader_len-1)\n",
    "        if(tot_iter[0] % args.test_num == 0 and tot_iter[0] != 0):\n",
    "            my_test(validdataloader, model_w, epoch)\n",
    "            my_test(validdataloader, model_v, epoch)\n",
    "            logging.info(str((\"Attention Weights A : \", A.ReLU(A.alpha))))\n",
    "            torch.save(model_v,'./model/'+'model_w.pt')#+now+\n",
    "            torch.save(model_v,'./model/'+'model_v.pt')\n",
    "            torch.save(A,'./model/'+'A.pt')\n",
    "\n",
    "        if(tot_iter[0] % args.rep_num == 0 and tot_iter[0] != 0):\n",
    "            logging.info(f\"{progress:5.3}%:\\t  W_train_loss:{objs_w.avg:^.7f}\\tV_train_syn_loss:{objs_v_syn.avg:^.7f}\\tV_train_loss:{objs_v_train.avg:^.7f}\\t  V_star_val_loss:{objs_v_star_val.avg:^.7f}\\t  V_val_loss:{objs_v_val.avg:^.7f}\")\n",
    "            wandb.log({'W_train_loss': objs_w.avg})\n",
    "            wandb.log({'V_train_syn_loss': objs_v_syn.avg})\n",
    "            wandb.log({'V_train_loss': objs_v_train.avg})\n",
    "            wandb.log({'V_star_val_loss': objs_v_star_val.avg})\n",
    "            wandb.log({'V_val_loss': objs_v_val.avg})\n",
    "            objs_v_syn.reset()\n",
    "            objs_v_train.reset()\n",
    "            objs_w.reset()\n",
    "            objs_v_star_val.reset()\n",
    "            objs_v_val.reset()\n",
    "\n",
    "    return w_trainloss_acc, v_trainloss_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/14 05:52:20 PM |\t  \n",
      "\n",
      "  ----------------epoch:0,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:0----------------\n",
      "06/14 05:52:20 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/14 05:52:40 PM |\t   18.2%:\t  W_train_loss:4.9878020\tV_train_syn_loss:1.5304304\tV_train_loss:5.2945946\t  V_star_val_loss:6.0054390\t  V_val_loss:5.3848392\n",
      "06/14 05:53:00 PM |\t   45.5%:\t  W_train_loss:5.3374494\tV_train_syn_loss:1.3822225\tV_train_loss:5.4936560\t  V_star_val_loss:5.1119064\t  V_val_loss:5.0197908\n",
      "06/14 05:53:19 PM |\t   72.7%:\t  W_train_loss:5.0916417\tV_train_syn_loss:1.1127076\tV_train_loss:5.1253916\t  V_star_val_loss:5.1931046\t  V_val_loss:5.2040051\n",
      "06/14 05:53:38 PM |\t  1e+02%:\t  W_train_loss:5.1754185\tV_train_syn_loss:1.3087645\tV_train_loss:5.1915418\t  V_star_val_loss:5.3402176\t  V_val_loss:5.4103292\n",
      "06/14 05:53:38 PM |\t  w_train_loss:61.77693510055542,v_train_loss:39.658963203430176\n",
      "06/14 05:53:38 PM |\t  \n",
      "\n",
      "  ----------------epoch:1,\t\tlr_w:0.00049,\t\tlr_v:0.00049,\t\tlr_A:0----------------\n",
      "06/14 05:53:38 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/14 05:53:58 PM |\t   18.2%:\t  W_train_loss:3.7979291\tV_train_syn_loss:0.9397361\tV_train_loss:4.0360081\t  V_star_val_loss:5.0111394\t  V_val_loss:5.0451611\n",
      "06/14 05:54:17 PM |\t   45.5%:\t  W_train_loss:4.1970476\tV_train_syn_loss:1.1442777\tV_train_loss:4.4859333\t  V_star_val_loss:4.9726912\t  V_val_loss:5.0422115\n",
      "06/14 05:54:36 PM |\t   72.7%:\t  W_train_loss:4.2015489\tV_train_syn_loss:1.5289977\tV_train_loss:4.2767903\t  V_star_val_loss:4.9412551\t  V_val_loss:5.0569954\n",
      "06/14 05:54:56 PM |\t  1e+02%:\t  W_train_loss:4.0836051\tV_train_syn_loss:1.5502637\tV_train_loss:4.2714051\t  V_star_val_loss:5.2465051\t  V_val_loss:5.2102184\n",
      "06/14 05:54:56 PM |\t  w_train_loss:48.840392112731934,v_train_loss:33.3501181602478\n",
      "06/14 05:54:56 PM |\t  \n",
      "\n",
      "  ----------------epoch:2,\t\tlr_w:0.000343,\t\tlr_v:0.000343,\t\tlr_A:0----------------\n",
      "06/14 05:54:56 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/14 05:55:16 PM |\t   18.2%:\t  W_train_loss:2.9691416\tV_train_syn_loss:1.3108026\tV_train_loss:3.5398125\t  V_star_val_loss:5.0576539\t  V_val_loss:4.9860479\n",
      "06/14 05:55:36 PM |\t   45.5%:\t  W_train_loss:3.4127196\tV_train_syn_loss:1.6541957\tV_train_loss:3.7057008\t  V_star_val_loss:4.7847330\t  V_val_loss:4.8818566\n",
      "06/14 05:55:55 PM |\t   72.7%:\t  W_train_loss:3.5154407\tV_train_syn_loss:1.8142349\tV_train_loss:3.7505850\t  V_star_val_loss:4.9168434\t  V_val_loss:4.9679610\n",
      "06/14 05:56:14 PM |\t  1e+02%:\t  W_train_loss:3.3667697\tV_train_syn_loss:2.2923591\tV_train_loss:3.7396584\t  V_star_val_loss:5.2844407\t  V_val_loss:5.2938004\n",
      "06/14 05:56:14 PM |\t  w_train_loss:39.79221487045288,v_train_loss:32.711024045944214\n",
      "06/14 05:56:14 PM |\t  \n",
      "\n",
      "  ----------------epoch:3,\t\tlr_w:0.00024009999999999998,\t\tlr_v:0.00024009999999999998,\t\tlr_A:0----------------\n",
      "06/14 05:56:14 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/14 05:56:34 PM |\t   18.2%:\t  W_train_loss:2.5484824\tV_train_syn_loss:2.0294612\tV_train_loss:3.0871190\t  V_star_val_loss:5.0652256\t  V_val_loss:4.9399646\n",
      "06/14 05:56:53 PM |\t   45.5%:\t  W_train_loss:2.8603168\tV_train_syn_loss:1.4344635\tV_train_loss:3.4227905\t  V_star_val_loss:4.9939498\t  V_val_loss:4.9002991\n",
      "06/14 05:57:12 PM |\t   72.7%:\t  W_train_loss:3.1002403\tV_train_syn_loss:1.6093827\tV_train_loss:3.4768109\t  V_star_val_loss:4.9958550\t  V_val_loss:4.9448098\n",
      "06/14 05:57:30 PM |\t  1e+02%:\t  W_train_loss:2.8555901\tV_train_syn_loss:1.8450139\tV_train_loss:3.4234842\t  V_star_val_loss:5.5350407\t  V_val_loss:5.4908226\n",
      "06/14 05:57:30 PM |\t  w_train_loss:34.093888998031616,v_train_loss:30.492788553237915\n",
      "06/14 05:57:30 PM |\t  \n",
      "\n",
      "  ----------------epoch:4,\t\tlr_w:0.00016806999999999998,\t\tlr_v:0.00016806999999999998,\t\tlr_A:0----------------\n",
      "06/14 05:57:30 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/14 05:57:49 PM |\t   18.2%:\t  W_train_loss:2.2261879\tV_train_syn_loss:1.7709297\tV_train_loss:2.8609179\t  V_star_val_loss:5.1413480\t  V_val_loss:5.1992853\n",
      "06/14 05:58:08 PM |\t   45.5%:\t  W_train_loss:2.6333296\tV_train_syn_loss:1.8601988\tV_train_loss:3.0886494\t  V_star_val_loss:4.9167070\t  V_val_loss:5.0252625\n",
      "06/14 05:58:27 PM |\t   72.7%:\t  W_train_loss:2.7361135\tV_train_syn_loss:2.1070983\tV_train_loss:3.1006317\t  V_star_val_loss:4.9610496\t  V_val_loss:4.9858079\n",
      "06/14 05:58:45 PM |\t  1e+02%:\t  W_train_loss:2.6299392\tV_train_syn_loss:1.7547345\tV_train_loss:3.1336493\t  V_star_val_loss:5.4452880\t  V_val_loss:5.3547977\n",
      "06/14 05:58:45 PM |\t  w_train_loss:30.67671048641205,v_train_loss:29.515214562416077\n",
      "06/14 05:58:45 PM |\t  \n",
      "\n",
      "  ----------------epoch:5,\t\tlr_w:0.00011764899999999998,\t\tlr_v:0.00011764899999999998,\t\tlr_A:0----------------\n",
      "06/14 05:58:45 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/14 05:59:04 PM |\t   18.2%:\t  W_train_loss:2.0903253\tV_train_syn_loss:1.9696788\tV_train_loss:2.6681945\t  V_star_val_loss:4.9499300\t  V_val_loss:5.1156651\n",
      "06/14 05:59:23 PM |\t   45.5%:\t  W_train_loss:2.3891032\tV_train_syn_loss:1.9018225\tV_train_loss:2.9116911\t  V_star_val_loss:4.8810403\t  V_val_loss:4.9394256\n",
      "06/14 05:59:42 PM |\t   72.7%:\t  W_train_loss:2.5107938\tV_train_syn_loss:2.0416580\tV_train_loss:3.0664858\t  V_star_val_loss:4.9594611\t  V_val_loss:4.9318201\n",
      "06/14 06:00:00 PM |\t  1e+02%:\t  W_train_loss:2.4367425\tV_train_syn_loss:1.8164482\tV_train_loss:2.9553689\t  V_star_val_loss:5.3770219\t  V_val_loss:5.3767455\n",
      "06/14 06:00:00 PM |\t  w_train_loss:28.28089439868927,v_train_loss:28.997021436691284\n",
      "06/14 06:00:00 PM |\t  \n",
      "\n",
      "  ----------------epoch:6,\t\tlr_w:8.235429999999999e-05,\t\tlr_v:8.235429999999999e-05,\t\tlr_A:0----------------\n",
      "06/14 06:00:00 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/14 06:00:17 PM |\t   18.2%:\t  W_train_loss:1.8468821\tV_train_syn_loss:1.6706429\tV_train_loss:2.4846737\t  V_star_val_loss:4.9991738\t  V_val_loss:5.0572913\n",
      "06/14 06:00:36 PM |\t   45.5%:\t  W_train_loss:2.2741795\tV_train_syn_loss:1.9187583\tV_train_loss:2.7885925\t  V_star_val_loss:5.0375822\t  V_val_loss:4.9933085\n",
      "06/14 06:00:55 PM |\t   72.7%:\t  W_train_loss:2.4768547\tV_train_syn_loss:2.2371816\tV_train_loss:2.9126192\t  V_star_val_loss:4.9992498\t  V_val_loss:4.9730261\n",
      "06/14 06:01:13 PM |\t  1e+02%:\t  W_train_loss:2.2862319\tV_train_syn_loss:2.2305540\tV_train_loss:2.6852365\t  V_star_val_loss:5.4421930\t  V_val_loss:5.4989384\n",
      "06/14 06:01:13 PM |\t  w_train_loss:26.65244483947754,v_train_loss:28.392388105392456\n",
      "06/14 06:01:13 PM |\t  \n",
      "\n",
      "  ----------------epoch:7,\t\tlr_w:5.764800999999999e-05,\t\tlr_v:5.764800999999999e-05,\t\tlr_A:0----------------\n",
      "06/14 06:01:13 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/14 06:01:32 PM |\t   18.2%:\t  W_train_loss:1.8065798\tV_train_syn_loss:1.9597529\tV_train_loss:2.4378643\t  V_star_val_loss:5.1279828\t  V_val_loss:5.0930255\n",
      "06/14 06:01:51 PM |\t   45.5%:\t  W_train_loss:2.1151458\tV_train_syn_loss:1.5441628\tV_train_loss:2.6748095\t  V_star_val_loss:5.1476212\t  V_val_loss:5.1245842\n",
      "06/14 06:02:10 PM |\t   72.7%:\t  W_train_loss:2.3539201\tV_train_syn_loss:2.6352711\tV_train_loss:2.8133094\t  V_star_val_loss:5.0234671\t  V_val_loss:5.0611262\n",
      "06/14 06:02:29 PM |\t  1e+02%:\t  W_train_loss:2.0467911\tV_train_syn_loss:2.1321771\tV_train_loss:2.6510496\t  V_star_val_loss:5.6899039\t  V_val_loss:5.5664035\n",
      "06/14 06:02:29 PM |\t  w_train_loss:24.967310547828674,v_train_loss:28.272594451904297\n",
      "06/14 06:02:29 PM |\t  \n",
      "\n",
      "  ----------------epoch:8,\t\tlr_w:4.035360699999999e-05,\t\tlr_v:4.035360699999999e-05,\t\tlr_A:0----------------\n",
      "06/14 06:02:29 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/14 06:02:48 PM |\t   18.2%:\t  W_train_loss:1.7341227\tV_train_syn_loss:2.1649710\tV_train_loss:2.3376172\t  V_star_val_loss:5.1499182\t  V_val_loss:5.1184743\n",
      "06/14 06:03:07 PM |\t   45.5%:\t  W_train_loss:2.1800123\tV_train_syn_loss:2.0868093\tV_train_loss:2.6554972\t  V_star_val_loss:5.1270102\t  V_val_loss:5.0126471\n",
      "06/14 06:03:27 PM |\t   72.7%:\t  W_train_loss:2.2679029\tV_train_syn_loss:2.5910244\tV_train_loss:2.7168610\t  V_star_val_loss:5.0973312\t  V_val_loss:4.9124816\n",
      "06/14 06:03:46 PM |\t  1e+02%:\t  W_train_loss:2.1098703\tV_train_syn_loss:2.3097541\tV_train_loss:2.5473206\t  V_star_val_loss:5.4810705\t  V_val_loss:5.3376060\n",
      "06/14 06:03:46 PM |\t  w_train_loss:24.87572431564331,v_train_loss:29.114782333374023\n",
      "06/14 06:03:46 PM |\t  \n",
      "\n",
      "  ----------------epoch:9,\t\tlr_w:2.8247524899999994e-05,\t\tlr_v:2.8247524899999994e-05,\t\tlr_A:0----------------\n",
      "06/14 06:03:46 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/14 06:04:04 PM |\t   18.2%:\t  W_train_loss:1.7085121\tV_train_syn_loss:1.6895829\tV_train_loss:2.3475353\t  V_star_val_loss:5.1865004\t  V_val_loss:5.1559321\n",
      "06/14 06:04:23 PM |\t   45.5%:\t  W_train_loss:2.0819444\tV_train_syn_loss:2.3261055\tV_train_loss:2.5915806\t  V_star_val_loss:5.1477807\t  V_val_loss:5.0428168\n",
      "06/14 06:04:42 PM |\t   72.7%:\t  W_train_loss:2.2810919\tV_train_syn_loss:2.1620492\tV_train_loss:2.7057220\t  V_star_val_loss:4.9923442\t  V_val_loss:4.9982923\n",
      "06/14 06:05:01 PM |\t  1e+02%:\t  W_train_loss:2.0505343\tV_train_syn_loss:2.3760764\tV_train_loss:2.5062979\t  V_star_val_loss:5.4278415\t  V_val_loss:5.4477140\n",
      "06/14 06:05:01 PM |\t  w_train_loss:24.36624848842621,v_train_loss:28.057425022125244\n",
      "06/14 06:05:01 PM |\t  \n",
      "\n",
      "  ----------------epoch:10,\t\tlr_w:1.9773267429999995e-05,\t\tlr_v:1.9773267429999995e-05,\t\tlr_A:0----------------\n",
      "06/14 06:05:01 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/14 06:05:20 PM |\t   18.2%:\t  W_train_loss:1.6705071\tV_train_syn_loss:2.1556945\tV_train_loss:2.2906561\t  V_star_val_loss:5.2553568\t  V_val_loss:5.0522922\n",
      "06/14 06:05:34 PM |\t  x_decoded[:2]:['translate English to German: Sometimes no, because in its extreme it can lead people to take absurd physical risks, gamble or indulge in substance abuse as a way to ease it, research shows.', 'translate English to German: The city is mentioned in ancient Greek and ancient Egyptian legends.']\n",
      "06/14 06:05:34 PM |\t  pred_decoded[:2]:['Die Mengele ist in der Lage in its extreme ist, die Psychiatry der Welt ist, die Psychiatry ist, die Psychiatry ist, die Psychiatry ist, die Psychiatry ist, die Psychiatry ist, die', 'Die Stadt ist in ancient Greek and ancient Egyptian myths.']\n",
      "06/14 06:05:34 PM |\t  label_decoded[:2]:['Manchmal nicht, denn im Extremfall führt sie dazu, dass Menschen extreme körperliche Risiken auf sich nehmen und dem Glücksspiel oder Drogen verfallen, um sie zu lindern - das haben Studien gezeigt.', 'Die Stadt wird in altgriechischen und altägyptischen Legenden erwähnt.']\n",
      "06/14 06:05:41 PM |\t  computing score...\n",
      "06/14 06:05:41 PM |\t  model_w_in_main sacreBLEU : 1.567849\n",
      "06/14 06:05:41 PM |\t  model_w_in_main test loss : 5.619430\n",
      "06/14 06:05:43 PM |\t  x_decoded[:2]:['translate English to German: Sometimes no, because in its extreme it can lead people to take absurd physical risks, gamble or indulge in substance abuse as a way to ease it, research shows.', 'translate English to German: The city is mentioned in ancient Greek and ancient Egyptian legends.']\n",
      "06/14 06:05:43 PM |\t  pred_decoded[:2]:['Die Die Die Die Die Die Die Die Die Die Die Die Die Die Die Die Die Die Die Die Die Die Die Die Die Die Die Die Die Die Die Die Die Die Die Die Die Die Die Die Die Die Die Die Die Die Die Die Die Die Die Die Die Die Die Die Die Die Die Die Die Die Die', 'Das city ist in ancient Greek and ancient Egyptian legends.']\n",
      "06/14 06:05:43 PM |\t  label_decoded[:2]:['Manchmal nicht, denn im Extremfall führt sie dazu, dass Menschen extreme körperliche Risiken auf sich nehmen und dem Glücksspiel oder Drogen verfallen, um sie zu lindern - das haben Studien gezeigt.', 'Die Stadt wird in altgriechischen und altägyptischen Legenden erwähnt.']\n",
      "06/14 06:05:50 PM |\t  computing score...\n",
      "06/14 06:05:50 PM |\t  model_v_in_main sacreBLEU : 0.692955\n",
      "06/14 06:05:50 PM |\t  model_v_in_main test loss : 5.080356\n",
      "06/14 06:05:50 PM |\t  ('Attention Weights A : ', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>))\n",
      "06/14 06:05:58 PM |\t   45.5%:\t  W_train_loss:1.9708751\tV_train_syn_loss:2.5331735\tV_train_loss:2.5770880\t  V_star_val_loss:4.9617033\t  V_val_loss:5.1819364\n",
      "06/14 06:06:16 PM |\t   72.7%:\t  W_train_loss:2.2019335\tV_train_syn_loss:2.4008380\tV_train_loss:2.7089808\t  V_star_val_loss:5.0933251\t  V_val_loss:5.1126060\n",
      "06/14 06:06:35 PM |\t  1e+02%:\t  W_train_loss:2.0637016\tV_train_syn_loss:2.7977602\tV_train_loss:2.5430134\t  V_star_val_loss:5.5230878\t  V_val_loss:5.3560886\n",
      "06/14 06:06:35 PM |\t  w_train_loss:23.721051812171936,v_train_loss:30.010806560516357\n",
      "06/14 06:06:35 PM |\t  \n",
      "\n",
      "  ----------------epoch:11,\t\tlr_w:1.3841287200999995e-05,\t\tlr_v:1.3841287200999995e-05,\t\tlr_A:0----------------\n",
      "06/14 06:06:35 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/14 06:06:54 PM |\t   18.2%:\t  W_train_loss:1.6827933\tV_train_syn_loss:2.0193292\tV_train_loss:2.2564842\t  V_star_val_loss:5.1407814\t  V_val_loss:5.2454267\n",
      "06/14 06:07:12 PM |\t   45.5%:\t  W_train_loss:2.0430440\tV_train_syn_loss:1.9699296\tV_train_loss:2.5437229\t  V_star_val_loss:4.9718958\t  V_val_loss:5.1068021\n",
      "06/14 06:07:31 PM |\t   72.7%:\t  W_train_loss:2.2846622\tV_train_syn_loss:1.8876690\tV_train_loss:2.6817179\t  V_star_val_loss:4.9950741\t  V_val_loss:5.0478253\n",
      "06/14 06:07:48 PM |\t  1e+02%:\t  W_train_loss:1.9440629\tV_train_syn_loss:2.1052913\tV_train_loss:2.5359938\t  V_star_val_loss:5.5047283\t  V_val_loss:5.6293985\n",
      "06/14 06:07:48 PM |\t  w_train_loss:23.86368715763092,v_train_loss:27.00020694732666\n",
      "06/14 06:07:48 PM |\t  \n",
      "\n",
      "  ----------------epoch:12,\t\tlr_w:9.688901040699997e-06,\t\tlr_v:9.688901040699997e-06,\t\tlr_A:0----------------\n",
      "06/14 06:07:48 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/14 06:08:07 PM |\t   18.2%:\t  W_train_loss:1.6448385\tV_train_syn_loss:2.1470139\tV_train_loss:2.3104832\t  V_star_val_loss:5.2109361\t  V_val_loss:5.0010947\n",
      "06/14 06:08:25 PM |\t   45.5%:\t  W_train_loss:1.9157089\tV_train_syn_loss:2.0451665\tV_train_loss:2.5035674\t  V_star_val_loss:5.1191800\t  V_val_loss:5.0104980\n",
      "06/14 06:08:44 PM |\t   72.7%:\t  W_train_loss:2.2096013\tV_train_syn_loss:2.3628097\tV_train_loss:2.7179788\t  V_star_val_loss:5.0567883\t  V_val_loss:4.9899728\n",
      "06/14 06:09:02 PM |\t  1e+02%:\t  W_train_loss:2.0093025\tV_train_syn_loss:2.4677591\tV_train_loss:2.4580976\t  V_star_val_loss:5.6419635\t  V_val_loss:5.6131810\n",
      "06/14 06:09:02 PM |\t  w_train_loss:23.338353514671326,v_train_loss:28.519314765930176\n",
      "06/14 06:09:02 PM |\t  \n",
      "\n",
      "  ----------------epoch:13,\t\tlr_w:6.782230728489997e-06,\t\tlr_v:6.782230728489997e-06,\t\tlr_A:0----------------\n",
      "06/14 06:09:02 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/14 06:09:20 PM |\t   18.2%:\t  W_train_loss:1.4865851\tV_train_syn_loss:1.9082638\tV_train_loss:2.2130138\t  V_star_val_loss:5.2137313\t  V_val_loss:5.1524442\n",
      "06/14 06:09:38 PM |\t   45.5%:\t  W_train_loss:2.0530830\tV_train_syn_loss:1.7216899\tV_train_loss:2.5815303\t  V_star_val_loss:5.0589263\t  V_val_loss:5.1720751\n",
      "06/14 06:09:56 PM |\t   72.7%:\t  W_train_loss:2.1570475\tV_train_syn_loss:1.9954512\tV_train_loss:2.7159149\t  V_star_val_loss:5.0612725\t  V_val_loss:5.0461453\n",
      "06/14 06:10:15 PM |\t  1e+02%:\t  W_train_loss:1.9591950\tV_train_syn_loss:2.3718516\tV_train_loss:2.4659665\t  V_star_val_loss:5.4817905\t  V_val_loss:5.6339863\n",
      "06/14 06:10:15 PM |\t  w_train_loss:22.967731833457947,v_train_loss:26.960522770881653\n",
      "06/14 06:10:15 PM |\t  \n",
      "\n",
      "  ----------------epoch:14,\t\tlr_w:4.747561509942998e-06,\t\tlr_v:4.747561509942998e-06,\t\tlr_A:0----------------\n",
      "06/14 06:10:15 PM |\t  split size:[4, 8, 0, 4]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_66120/1114895497.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"\\n\\n  ----------------epoch:{epoch},\\t\\tlr_w:{lr_w},\\t\\tlr_v:{lr_v},\\t\\tlr_A:{args.A_lr}----------------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mw_train_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv_train_loss\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mmy_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_v\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0marchitect\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_optimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv_optimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr_w\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr_v\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtot_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mscheduler_w\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_66120/2492786787.py\u001b[0m in \u001b[0;36mmy_train\u001b[1;34m(epoch, _dataloader, validdataloader, w_model, v_model, architect, A, w_optimizer, v_optimizer, lr_w, lr_v, tot_iter)\u001b[0m\n\u001b[0;32m     55\u001b[0m             \u001b[0mepsilon_w\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munrolled_w_lr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m             \u001b[0mepsilon_v\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munrolled_v_lr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m             v_star_val_loss = architect.step(input_w,  output_w, input_w_attn, output_w_attn, w_optimizer,\n\u001b[0m\u001b[0;32m     58\u001b[0m                                              \u001b[0minput_v\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_v_attn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_v\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_v_attn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_syn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_syn_attn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m                                              \u001b[0minput_A_v\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_A_v_attn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_A_v\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_A_v_attn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv_optimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mg:\\GitCode\\Self-teaching-for-machine-translation\\T5_scratch\\architect.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, input_w, output_w, input_w_attn, output_w_attn, w_optimizer, input_v, input_v_attn, output_v, output_v_attn, input_syn, input_syn_attn, input_A_v, input_A_v_attn, output_A_v, output_A_v_attn, v_optimizer, attn_idx, lr_w, lr_v)\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[0mvector_s_dash\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0munrolled_v_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m         implicit_grads_A = self._outer_A(vector_s_dash, input_w, output_w, input_w_attn,\n\u001b[0m\u001b[0;32m    180\u001b[0m                                          output_w_attn, input_v, input_v_attn, attn_idx, unrolled_w_model, lr_w, lr_v)\n\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mg:\\GitCode\\Self-teaching-for-machine-translation\\T5_scratch\\architect.py\u001b[0m in \u001b[0;36m_outer_A\u001b[1;34m(self, vector_s_dash, w_input, w_target, w_input_attn, w_target_attn, input_v, input_v_attn, attn_idx, unrolled_w_model, eta_w, eta_v, r)\u001b[0m\n\u001b[0;32m    242\u001b[0m             input_v, input_v_attn, unrolled_w_model, self.v_model)\n\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 244\u001b[1;33m         vector_dash = torch.autograd.grad(\n\u001b[0m\u001b[0;32m    245\u001b[0m             loss_aug_m, unrolled_w_model.parameters(), retain_graph=True)\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[1;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m     return Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    235\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_outputs_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m         inputs, allow_unused, accumulate_grad=False)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# if(args.valid_begin==1):\n",
    "#     my_test(valid_dataloader,model_w,-1) #before train\n",
    "#     my_test(valid_dataloader,model_v,-1)  \n",
    "\n",
    "tot_iter = [0]\n",
    "for epoch in range(args.epochs):\n",
    "    lr_w = scheduler_w.get_lr()[0]\n",
    "    lr_v = scheduler_v.get_lr()[0]\n",
    "    lr_A = scheduler_A.get_lr()[0]\n",
    "\n",
    "    logging.info(f\"\\n\\n  ----------------epoch:{epoch},\\t\\tlr_w:{lr_w},\\t\\tlr_v:{lr_v},\\t\\tlr_A:{args.A_lr}----------------\")\n",
    "\n",
    "    w_train_loss,v_train_loss =  my_train(epoch, train_dataloader, valid_dataloader, model_w, model_v,  architect, A, w_optimizer, v_optimizer, lr_w,lr_v,tot_iter)\n",
    "    \n",
    "    scheduler_w.step()\n",
    "    scheduler_v.step()\n",
    "    scheduler_A.step()\n",
    "\n",
    "\n",
    "    logging.info(f\"w_train_loss:{w_train_loss},v_train_loss:{v_train_loss}\")\n",
    "    # wandb.log({'w_train_loss': w_train_loss, 'v_train_loss':v_train_loss})\n",
    "\n",
    "\n",
    "\n",
    "torch.save(model_v,'./model/'+now+'model_w.pt')\n",
    "torch.save(model_v,'./model/'+now+'model_v.pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.6343e-03,  1.6985e-04,  4.6182e-05,  ..., -4.5622e-05,\n",
       "           4.9963e-05, -7.9150e-05],\n",
       "         [ 8.2149e-05, -4.7620e-05,  8.2381e-05,  ...,  8.6653e-05,\n",
       "           1.1960e-04,  3.4265e-06],\n",
       "         [ 5.5713e-06,  9.0648e-05, -3.2042e-05,  ..., -4.1399e-05,\n",
       "          -5.0304e-05, -9.8498e-05],\n",
       "         ...,\n",
       "         [ 1.6356e-03,  1.6731e-04,  4.5340e-05,  ..., -5.2783e-05,\n",
       "           4.2435e-05, -8.5164e-05],\n",
       "         [ 1.6356e-03,  1.6731e-04,  4.5343e-05,  ..., -5.2783e-05,\n",
       "           4.2434e-05, -8.5163e-05],\n",
       "         [ 1.6356e-03,  1.6731e-04,  4.5342e-05,  ..., -5.2784e-05,\n",
       "           4.2434e-05, -8.5163e-05]],\n",
       "\n",
       "        [[ 1.6345e-03,  1.6776e-04,  4.2936e-05,  ..., -4.4132e-05,\n",
       "           5.1346e-05, -7.9345e-05],\n",
       "         [-7.6601e-06, -3.0543e-05, -5.0514e-05,  ...,  1.1752e-05,\n",
       "          -1.2760e-04,  1.2106e-05],\n",
       "         [ 2.6243e-05, -3.8717e-05,  8.9031e-05,  ...,  4.1839e-05,\n",
       "          -1.4667e-05,  3.6620e-05],\n",
       "         ...,\n",
       "         [ 1.6364e-03,  1.7076e-04,  4.0118e-05,  ..., -4.6903e-05,\n",
       "           4.4114e-05, -8.4955e-05],\n",
       "         [ 1.6364e-03,  1.7077e-04,  4.0118e-05,  ..., -4.6904e-05,\n",
       "           4.4115e-05, -8.4954e-05],\n",
       "         [ 1.6364e-03,  1.7077e-04,  4.0116e-05,  ..., -4.6902e-05,\n",
       "           4.4116e-05, -8.4954e-05]],\n",
       "\n",
       "        [[ 1.6347e-03,  1.6664e-04,  4.3874e-05,  ..., -4.6535e-05,\n",
       "           5.1058e-05, -7.8006e-05],\n",
       "         [ 8.2920e-05, -5.1228e-05,  8.0187e-05,  ...,  8.5533e-05,\n",
       "           1.2085e-04,  4.4378e-06],\n",
       "         [-8.3324e-06, -6.6662e-05, -4.1717e-06,  ...,  8.9557e-05,\n",
       "           1.4526e-05,  7.6432e-05],\n",
       "         ...,\n",
       "         [ 1.6358e-03,  1.6664e-04,  4.4311e-05,  ..., -5.2517e-05,\n",
       "           4.4142e-05, -8.3808e-05],\n",
       "         [ 1.6358e-03,  1.6663e-04,  4.4312e-05,  ..., -5.2520e-05,\n",
       "           4.4142e-05, -8.3808e-05],\n",
       "         [ 1.6358e-03,  1.6663e-04,  4.4311e-05,  ..., -5.2518e-05,\n",
       "           4.4142e-05, -8.3806e-05]],\n",
       "\n",
       "        [[ 1.6357e-03,  1.6781e-04,  4.4269e-05,  ..., -4.4928e-05,\n",
       "           4.8897e-05, -7.9563e-05],\n",
       "         [ 1.3823e-04, -6.3264e-05,  6.3322e-05,  ..., -2.6144e-05,\n",
       "           5.9140e-05, -1.2902e-05],\n",
       "         [ 6.3026e-05,  5.7359e-05, -7.1889e-05,  ...,  9.2064e-06,\n",
       "          -2.3302e-06,  3.5582e-06],\n",
       "         ...,\n",
       "         [ 1.6376e-03,  1.6354e-04,  4.5136e-05,  ..., -5.1854e-05,\n",
       "           4.0205e-05, -8.6836e-05],\n",
       "         [ 1.6376e-03,  1.6354e-04,  4.5135e-05,  ..., -5.1851e-05,\n",
       "           4.0201e-05, -8.6841e-05],\n",
       "         [ 1.6376e-03,  1.6354e-04,  4.5136e-05,  ..., -5.1853e-05,\n",
       "           4.0202e-05, -8.6839e-05]]], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load('logits.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'main_v.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_175828/2885071301.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mm1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'main_v.pt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mm1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mm2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'unrolled_v.pt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mm2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'encoding'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 594\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    595\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m             \u001b[1;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'w'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'main_v.pt'"
     ]
    }
   ],
   "source": [
    "m1 = torch.load('main_v.pt')\n",
    "m1.eval()\n",
    "m2 = torch.load('unrolled_v.pt')\n",
    "m2.eval()\n",
    "''\n",
    "for k1, k2 in zip(m1.state_dict(), m2.state_dict()):\n",
    "    v1= m1.state_dict()[k1]\n",
    "    v2= m2.state_dict()[k2]\n",
    "    print(k1,k2)\n",
    "    # print(v1,v2)\n",
    "    print((abs(v1.data-v2.data)).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(1)\n",
    "a.add(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('python38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d33c3b0ef123e851f98887a8750ca7da758e4ff258891935cfe6ff9c0394387"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
