{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd() \n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from T5 import *\n",
    "import torch\n",
    "from datasets import load_dataset,load_metric\n",
    "from transformers import T5Tokenizer,AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import torch_optimizer as optim\n",
    "from transformers.optimization import Adafactor, AdafactorSchedule\n",
    "from MT_hyperparams import seed_,max_length,target_language\n",
    "import torch.backends.cudnn as cudnn\n",
    "from utils import *\n",
    "from attention_params import *\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, SubsetRandomSampler\n",
    "from torch.autograd import Variable\n",
    "from losses import *\n",
    "from architect import *\n",
    "import logging\n",
    "import sys\n",
    "import transformers\n",
    "import time\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from os.path import exists\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(\"main\")\n",
    "\n",
    "\n",
    "parser.add_argument('--valid_num_points', type=int,             default = 100, help='validation data number')\n",
    "parser.add_argument('--train_num_points', type=int,             default = 200, help='train data number')\n",
    "parser.add_argument('--test_num_points', type=int,              default = 50, help='train data number')\n",
    "\n",
    "parser.add_argument('--batch_size', type=int,                   default=16,     help='Batch size')\n",
    "parser.add_argument('--train_w_num_points', type=int,           default=4,      help='train_w_num_points for each batch')\n",
    "parser.add_argument('--train_v_synthetic_num_points', type=int, default=8,      help='train_v_synthetic_num_points for each batch')\n",
    "parser.add_argument('--train_v_num_points', type=int,           default=0,      help='train_v_num_points for each batch')\n",
    "parser.add_argument('--train_A_num_points', type=int,           default=4,      help='train_A_num_points decay for each batch')\n",
    "\n",
    "parser.add_argument('--gpu', type=int,                          default=0,      help='gpu device id')\n",
    "parser.add_argument('--num_workers', type=int,                  default=0,      help='num_workers')\n",
    "parser.add_argument('--model_name_teacher', type=str,           default='google/t5-small-lm-adapt',      help='model_name')\n",
    "parser.add_argument('--model_name_student', type=str,           default='google/t5-small-lm-adapt',      help='model_name')\n",
    "parser.add_argument('--exp_name', type=str,                     default='T5spec',      help='experiment name')\n",
    "parser.add_argument('--rep_num', type=int,                      default=50,      help='report times for 1 epoch')\n",
    "parser.add_argument('--test_num', type=int,                     default=2000,      help='test times for 1 epoch')\n",
    "\n",
    "parser.add_argument('--epochs', type=int,                       default=500,     help='num of training epochs')\n",
    "parser.add_argument('--pre_epochs', type=int,                   default=0,      help='train model W for x epoch first')\n",
    "parser.add_argument('--grad_clip', type=float,                  default=1,      help='gradient clipping')\n",
    "parser.add_argument('--grad_acc_count', type=float,             default=-1,      help='gradient accumulate steps')\n",
    "\n",
    "parser.add_argument('--w_lr', type=float,                       default=1e-3,   help='learning rate for w')\n",
    "parser.add_argument('--unrolled_w_lr', type=float,              default=1e-3,   help='learning rate for w')\n",
    "parser.add_argument('--v_lr', type=float,                       default=1e-3,   help='learning rate for v')\n",
    "parser.add_argument('--unrolled_v_lr', type=float,              default=1e-3,   help='learning rate for v')\n",
    "parser.add_argument('--A_lr', type=float,                       default=1e-3,   help='learning rate for A')\n",
    "parser.add_argument('--learning_rate_min', type=float,          default=1e-8,   help='learning_rate_min')\n",
    "parser.add_argument('--decay', type=float,                      default=1e-3,   help='weight decay')\n",
    "parser.add_argument('--beta1', type=float,                      default=0.9,    help='momentum')\n",
    "parser.add_argument('--beta2', type=float,                      default=0.98,    help='momentum')\n",
    "parser.add_argument('--warm', type=float,                       default=10,    help='warmup step')\n",
    "parser.add_argument('--num_step_lr', type=float,                default=1,    help='warmup step')\n",
    "parser.add_argument('--decay_lr', type=float,                   default=0.7,    help='warmup step')\n",
    "# parser.add_argument('--smoothing', type=float,                  default=0.1,    help='labelsmoothing')\n",
    "\n",
    "\n",
    "parser.add_argument('--traindata_loss_ratio', type=float,       default=0.5,    help='human translated data ratio')\n",
    "parser.add_argument('--syndata_loss_ratio', type=float,         default=0.5,    help='augmented dataset ratio')\n",
    "\n",
    "parser.add_argument('--valid_begin', type=int,                  default=1,      help='whether valid before train')\n",
    "parser.add_argument('--train_A', type=int,                      default=1 ,     help='whether train A')\n",
    "\n",
    "\n",
    "\n",
    "args = parser.parse_args(args=[])#(args=['--batch_size', '8',  '--no_cuda'])#used in ipynb\n",
    "args.test_num = args.test_num//args.batch_size * args.batch_size\n",
    "args.rep_num = args.rep_num//args.batch_size * args.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33monlydrinkwater\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.18 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.17"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>g:\\GitCode\\Self-teaching-for-machine-translation\\T5_scratch\\wandb\\run-20220615_000232-11dqbnya</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/onlydrinkwater/Selftraining/runs/11dqbnya\" target=\"_blank\">T5spec</a></strong> to <a href=\"https://wandb.ai/onlydrinkwater/Selftraining\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/onlydrinkwater/Selftraining/runs/11dqbnya?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x15ddf290c40>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://wandb.ai/ check the running status online\n",
    "import wandb\n",
    "os.environ['WANDB_API_KEY']='a166474b1b7ad33a0549adaaec19a2f6d3f91d87'\n",
    "os.environ['WANDB_NAME']=args.exp_name\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "wandb.init(project=\"Selftraining\",config=args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/15 12:04:42 AM |\t  Reusing dataset wmt14 (C:\\Users\\kevin\\.cache\\huggingface\\datasets\\wmt14\\de-en\\1.0.0\\d239eaf0ff090d28da19b6bc9758e24634d84de0a1ef092f0b5c54e6f132d7e2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 31.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/15 12:04:42 AM |\t  Namespace(A_lr=0.001, batch_size=16, beta1=0.9, beta2=0.98, decay=0.001, decay_lr=0.7, epochs=500, exp_name='T5spec', gpu=0, grad_acc_count=-1, grad_clip=1, learning_rate_min=1e-08, model_name_student='google/t5-small-lm-adapt', model_name_teacher='google/t5-small-lm-adapt', num_step_lr=1, num_workers=0, pre_epochs=0, rep_num=48, syndata_loss_ratio=0.5, test_num=2000, test_num_points=50, train_A=1, train_A_num_points=4, train_num_points=200, train_v_num_points=0, train_v_synthetic_num_points=8, train_w_num_points=4, traindata_loss_ratio=0.5, unrolled_v_lr=0.001, unrolled_w_lr=0.001, v_lr=0.001, valid_begin=1, valid_num_points=100, w_lr=0.001, warm=10)\n",
      "06/15 12:04:42 AM |\t  DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 4508785\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 3000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 3003\n",
      "    })\n",
      "})\n",
      "06/15 12:04:42 AM |\t  {'translation': {'de': 'Ich bitte Sie, sich zu einer Schweigeminute zu erheben.', 'en': \"Please rise, then, for this minute' s silence.\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# logging file\n",
    "now = time.strftime(\"%Y-%m-%d-%H_%M_%S\", time.localtime(time.time()))\n",
    "\n",
    "log_format = '%(asctime)s |\\t  %(message)s'\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO,\n",
    "                    format=log_format, datefmt='%m/%d %I:%M:%S %p')\n",
    "fh = logging.FileHandler(os.path.join(\n",
    "    \"./log/\", now+'.txt'), 'w', encoding=\"UTF-8\")\n",
    "fh.setFormatter(logging.Formatter(log_format))\n",
    "logging.getLogger().addHandler(fh)\n",
    "dataset = load_dataset('wmt14', 'de-en')\n",
    "\n",
    "logging.info(args)\n",
    "logging.info(dataset)\n",
    "logging.info(dataset['train'][5])\n",
    "\n",
    "\n",
    "# Setting the seeds\n",
    "np.random.seed(seed_)\n",
    "torch.cuda.set_device(args.gpu)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cudnn.benchmark = True\n",
    "torch.manual_seed(seed_)\n",
    "cudnn.enabled = True\n",
    "torch.cuda.manual_seed(seed_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/15 12:04:44 AM |\t  modelsize:76.961152MB\n",
      "06/15 12:04:46 AM |\t  modelsize:76.961152MB\n"
     ]
    }
   ],
   "source": [
    "modelname = args.model_name_teacher\n",
    "pretrained  =  AutoModelForSeq2SeqLM.from_pretrained(modelname)\n",
    "pathname = modelname.replace('/','')\n",
    "logging.info(f'modelsize:{count_parameters_in_MB(pretrained)}MB')\n",
    "\n",
    "if(exists(pathname+'.pt')==False):\n",
    "    logging.info(f'saving to {pathname}')\n",
    "    torch.save(pretrained,pathname+'.pt')\n",
    "\n",
    "modelname = args.model_name_student\n",
    "pretrained  =  AutoModelForSeq2SeqLM.from_pretrained(modelname)\n",
    "pathname = modelname.replace('/','')\n",
    "logging.info(f'modelsize:{count_parameters_in_MB(pretrained)}MB')\n",
    "if(exists(pathname+'.pt')==False):\n",
    "    logging.info(f'saving to {pathname}')\n",
    "    torch.save(pretrained,pathname+'.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/14 08:12:45 PM |\t  Loading cached shuffled indices for dataset at C:\\Users\\kevin\\.cache\\huggingface\\datasets\\wmt14\\de-en\\1.0.0\\d239eaf0ff090d28da19b6bc9758e24634d84de0a1ef092f0b5c54e6f132d7e2\\cache-fcff064badad2159.arrow\n",
      "06/14 08:12:45 PM |\t  Loading cached shuffled indices for dataset at C:\\Users\\kevin\\.cache\\huggingface\\datasets\\wmt14\\de-en\\1.0.0\\d239eaf0ff090d28da19b6bc9758e24634d84de0a1ef092f0b5c54e6f132d7e2\\cache-ef861152e003e0c7.arrow\n",
      "06/14 08:12:45 PM |\t  Loading cached shuffled indices for dataset at C:\\Users\\kevin\\.cache\\huggingface\\datasets\\wmt14\\de-en\\1.0.0\\d239eaf0ff090d28da19b6bc9758e24634d84de0a1ef092f0b5c54e6f132d7e2\\cache-848b25adc701ab2b.arrow\n",
      "06/14 08:12:45 PM |\t  train len: 192\n",
      "06/14 08:12:45 PM |\t  train_w_num_points_len: 48\n",
      "06/14 08:12:45 PM |\t  train_v_synthetic_num_points_len: 96\n",
      "06/14 08:12:45 PM |\t  train_v_num_points_len: 0\n",
      "06/14 08:12:45 PM |\t  train_A_num_points_len: 48\n",
      "06/14 08:12:45 PM |\t  valid len: 100\n",
      "06/14 08:12:45 PM |\t  test len: 50\n",
      "06/14 08:12:45 PM |\t  {'de': 'Dank unseres Personals und Geräteparks sind wir täglich rund um die Uhr in der Lage, uns allen erdenklichen Herausforderungen zu stellen.', 'en': 'translate English to German: Our staff and equipment stands ready to answer any challenges 24/7.'}\n",
      "06/14 08:12:45 PM |\t  {'de': 'Diese Entscheidung rief in der Öffentlichkeit eine lebhafte Diskussion hervor.', 'en': 'translate English to German: The resolution caused lively public debate.'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# preprocess the data, make a dataloader\n",
    "import random\n",
    "modelname = args.model_name_teacher\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelname)\n",
    "criterion = torch.nn.CrossEntropyLoss( reduction='none')#teacher shouldn't have label smoothing, especially when student got same size.\n",
    "criterion_v = torch.nn.CrossEntropyLoss( reduction='none')#,label_smoothing=args.smoothing) #without LS, V may be too confident to that syn data, and LS do well for real data also.\n",
    "\n",
    "\n",
    "\n",
    "train = dataset['train'].shuffle(seed=seed_).select(range(args.train_num_points))\n",
    "valid = dataset['validation'].shuffle(seed=seed_).select(range(args.valid_num_points))\n",
    "test = dataset['test'].shuffle(seed=seed_).select(range(args.test_num_points))#[L_t+L_v:L_t+L_v+L_test]\n",
    "train = train['translation']\n",
    "valid = valid['translation']\n",
    "test = test['translation']\n",
    "def preprocess(dat):\n",
    "    for t in dat:\n",
    "        t['en'] = \"translate English to German: \" + t['en']  #needed for T5\n",
    "preprocess(train)\n",
    "preprocess(valid)\n",
    "preprocess(test)\n",
    "#TODO: Syn_input should be monolingual data, should try en-fo's en. cuz wmt may align\n",
    "num_batch = args.train_num_points//args.batch_size\n",
    "train = train[:args.batch_size*num_batch]\n",
    "logging.info(\"train len: %d\",len(train))\n",
    "\n",
    "'''\n",
    "each mini batch consist of : \n",
    "1. data to train W\n",
    "2. monolingual data to generate parallel data\n",
    "3. data to train V\n",
    "4. data to train A\n",
    "'''\n",
    "train_w_num_points_len = num_batch * args.train_w_num_points\n",
    "train_v_synthetic_num_points_len = num_batch * args.train_v_synthetic_num_points\n",
    "train_v_num_points_len = num_batch * args.train_v_num_points\n",
    "train_A_num_points_len = num_batch * args.train_A_num_points\n",
    "logging.info(\"train_w_num_points_len: %d\",train_w_num_points_len)\n",
    "logging.info(\"train_v_synthetic_num_points_len: %d\",train_v_synthetic_num_points_len)\n",
    "logging.info(\"train_v_num_points_len: %d\",train_v_num_points_len)\n",
    "logging.info(\"train_A_num_points_len: %d\",train_A_num_points_len)\n",
    "\n",
    "attn_idx_list = torch.arange(train_w_num_points_len).cuda()\n",
    "logging.info(\"valid len: %d\",len(valid))\n",
    "logging.info(\"test len: %d\" ,len(test))\n",
    "logging.info(train[2])\n",
    "logging.info(valid[2])\n",
    "# logging.info(test[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get train data start\n",
      "get train data end\n",
      "06/14 08:12:45 PM |\t  train data get\n",
      "06/14 08:12:45 PM |\t  train data loader get\n",
      "06/14 08:12:45 PM |\t  valid data loader get\n",
      "06/14 08:12:45 PM |\t  test data loader get\n"
     ]
    }
   ],
   "source": [
    "target_language  = 'de'\n",
    "train_data = get_train_Dataset(train, tokenizer)# Create the DataLoader for our training set.\n",
    "logging.info('train data get')\n",
    "train_dataloader = DataLoader(train_data, sampler= SequentialSampler(train_data), \n",
    "                        batch_size=args.batch_size, pin_memory=args.num_workers>0, num_workers=args.num_workers)\n",
    "logging.info('train data loader get')\n",
    "valid_data = get_aux_dataset(valid, tokenizer)# Create the DataLoader for our training set.\n",
    "valid_dataloader = DataLoader(valid_data, sampler=SequentialSampler(valid_data), \n",
    "                        batch_size=args.batch_size, pin_memory=args.num_workers>0, num_workers=args.num_workers)\n",
    "logging.info('valid data loader get')\n",
    "test_data = get_aux_dataset(test, tokenizer)# Create the DataLoader for our training set.\n",
    "test_dataloader = DataLoader(test_data, sampler=SequentialSampler(test_data),\n",
    "                        batch_size=args.batch_size, pin_memory=args.num_workers>0, num_workers=args.num_workers)#, sampler=RandomSampler(test_data)\n",
    "logging.info('test data loader get')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "A = attention_params(train_w_num_points_len)#half of train regarded as u\n",
    "A = A.cuda()\n",
    "\n",
    "\n",
    "\n",
    "# TODO: model loaded from saved model\n",
    "model_w = T5(criterion=criterion, tokenizer= tokenizer, args = args, name = 'model_w_in_main')\n",
    "model_w = model_w.cuda()\n",
    "w_optimizer = torch.optim.Adam(model_w.parameters(),  lr= args.w_lr ,  betas=(args.beta1, args.beta2) ,eps=1e-9 )\n",
    "# w_optimizer = Adafactor(model_w.parameters(), lr = args.w_lr ,scale_parameter=False, relative_step=False , warmup_init=False,clip_threshold=1,beta1=0,eps=( 1e-30,0.001))\n",
    "scheduler_w  =   StepLR(w_optimizer, step_size=args.num_step_lr, gamma=args.decay_lr)\n",
    "# scheduler_w  = Scheduler(w_optimizer,dim_embed=512, warmup_steps=args.warm, initlr = args.w_lr)\n",
    "\n",
    "\n",
    "\n",
    "model_v = T5(criterion=criterion_v, tokenizer= tokenizer, args = args, name = 'model_v_in_main')\n",
    "model_v = model_v.cuda()\n",
    "v_optimizer = torch.optim.Adam(model_v.parameters(),  lr= args.v_lr ,  betas=(args.beta1,args.beta2) ,eps=1e-9  )\n",
    "# v_optimizer =Adafactor(model_v.parameters(), lr = args.v_lr ,scale_parameter=False, relative_step=False , warmup_init=False,clip_threshold=1,beta1=0,eps=( 1e-30,0.001))\n",
    "scheduler_v  =   StepLR(v_optimizer, step_size=args.num_step_lr, gamma=args.decay_lr)\n",
    "# scheduler_v  = Scheduler(v_optimizer,dim_embed=512, warmup_steps=args.warm, initlr = args.v_lr)\n",
    "\n",
    "\n",
    "architect = Architect(model_w, model_v,  A, args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def my_test(_dataloader,model,epoch):\n",
    "    # logging.info(f\"GPU mem before test:{getGPUMem(device)}%\")\n",
    "    acc = 0\n",
    "    counter = 0\n",
    "    model.eval()\n",
    "    metric_sacrebleu =  load_metric('sacrebleu')\n",
    "    # metric_bleu =  load_metric('bleu')\n",
    "    \n",
    "    for step, batch in enumerate(_dataloader):\n",
    "        \n",
    "        test_dataloaderx = Variable(batch[0], requires_grad=False).to(device, non_blocking=False)[:args.train_w_num_points]\n",
    "        test_dataloaderx_attn = Variable(batch[1], requires_grad=False).to(device, non_blocking=False)[:args.train_w_num_points]\n",
    "        test_dataloadery = Variable(batch[2], requires_grad=False).to(device, non_blocking=False)[:args.train_w_num_points]\n",
    "        test_dataloadery_attn = Variable(batch[3], requires_grad=False).to(device, non_blocking=False)[:args.train_w_num_points]\n",
    "        ls = my_loss(test_dataloaderx,test_dataloaderx_attn,test_dataloadery,test_dataloadery_attn,model)\n",
    "        acc+= ls.item()\n",
    "        counter+= 1\n",
    "        pre = model.generate(test_dataloaderx)\n",
    "        x_decoded = tokenizer.batch_decode(test_dataloaderx,skip_special_tokens=True)\n",
    "        pred_decoded = tokenizer.batch_decode(pre,skip_special_tokens=True)\n",
    "        label_decoded =  tokenizer.batch_decode(test_dataloadery,skip_special_tokens=True)\n",
    "        \n",
    "        pred_str = [x  for x in pred_decoded]\n",
    "        label_str = [[x] for x in label_decoded]\n",
    "        # pred_list = [x.split()  for x in pred_decoded]\n",
    "        # label_list = [[x.split()] for x in label_decoded]\n",
    "        metric_sacrebleu.add_batch(predictions=pred_str, references=label_str)\n",
    "        # metric_bleu.add_batch(predictions=pred_list, references=label_list)\n",
    "        if  step==0:\n",
    "            logging.info(f'x_decoded[:2]:{x_decoded[:2]}')\n",
    "            logging.info(f'pred_decoded[:2]:{pred_decoded[:2]}')\n",
    "            logging.info(f'label_decoded[:2]:{label_decoded[:2]}')\n",
    "            \n",
    "            \n",
    "    logging.info('computing score...') \n",
    "    sacrebleu_score = metric_sacrebleu.compute()\n",
    "    # bleu_score = metric_bleu.compute()\n",
    "    logging.info('%s sacreBLEU : %f',model.name,sacrebleu_score['score'])#TODO:bleu may be wrong cuz max length\n",
    "    # logging.info('%s BLEU : %f',model.name,bleu_score['bleu'])\n",
    "    logging.info('%s test loss : %f',model.name,acc/(counter))\n",
    "    wandb.log({'sacreBLEU'+model.name: sacrebleu_score['score']})\n",
    "    wandb.log({'test_loss'+model.name: acc/counter})\n",
    "    # del test_dataloaderx,acc,counter,test_dataloaderx_attn,sacrebleu_score,bleu_score,test_dataloadery,test_dataloadery_attn,ls,pre,x_decoded,pred_decoded,label_decoded,pred_str,label_str,pred_list,label_list\n",
    "    # gc.collect()\n",
    "    # torch.cuda.empty_cache()\n",
    "    model.train()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_train(epoch, _dataloader, validdataloader, w_model, v_model, architect, A, w_optimizer, v_optimizer, lr_w, lr_v, tot_iter):\n",
    "\n",
    "    objs_w = AvgrageMeter()\n",
    "    objs_v_syn = AvgrageMeter()\n",
    "    objs_v_train = AvgrageMeter()\n",
    "    objs_v_star_val = AvgrageMeter()\n",
    "    objs_v_val = AvgrageMeter()\n",
    "    v_trainloss_acc = 0\n",
    "    w_trainloss_acc = 0\n",
    "    # now  train_x is [num of batch, datasize], so its seperate batch for the code below\n",
    "    wsize = args.train_w_num_points\n",
    "    synsize = args.train_v_synthetic_num_points\n",
    "    vsize = args.train_v_num_points\n",
    "    vtrainsize = vsize+synsize\n",
    "    vtrainsize_total = train_v_num_points_len+train_v_synthetic_num_points_len\n",
    "    Asize = args.train_A_num_points\n",
    "    loader_len = len(_dataloader)\n",
    "    split_size = [wsize, synsize, vsize, Asize]\n",
    "    bs = args.batch_size\n",
    "    w_model.eval()\n",
    "    v_model.eval()\n",
    "\n",
    "    logging.info(f\"split size:{split_size}\")\n",
    "    for step, batch in enumerate(_dataloader):\n",
    "        tot_iter[0] += bs\n",
    "        \n",
    "\n",
    "        # logging.info(f\"GPU mem :{getGPUMem(device)}%\")\n",
    "        train_x = Variable(batch[0], requires_grad=False).to(\n",
    "            device, non_blocking=False)\n",
    "        train_x_attn = Variable(batch[1], requires_grad=False).to(\n",
    "            device, non_blocking=False)\n",
    "        train_y = Variable(batch[2], requires_grad=False).to(\n",
    "            device, non_blocking=False)\n",
    "        train_y_attn = Variable(batch[3], requires_grad=False).to(\n",
    "            device, non_blocking=False)\n",
    "        (input_w, input_syn, input_v, input_A_v) = torch.split(train_x, split_size)\n",
    "        (input_w_attn, input_syn_attn, input_v_attn,\n",
    "         input_A_v_attn) = torch.split(train_x_attn, split_size)\n",
    "        (output_w, _, output_v, output_A_v) = torch.split(train_y, split_size)\n",
    "        (output_w_attn, _, output_v_attn, output_A_v_attn) = torch.split(\n",
    "            train_y_attn, split_size)\n",
    "        attn_idx = attn_idx_list[wsize*step:(wsize*step+wsize)]\n",
    "        if(True):# let v train on syn data and w data\n",
    "            input_v = input_w\n",
    "            input_v_attn = input_w_attn\n",
    "            output_v = output_w\n",
    "            output_v_attn = output_w_attn\n",
    "            vsize = wsize\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if (args.train_A == 1):\n",
    "            epsilon_w = args.unrolled_w_lr\n",
    "            epsilon_v  = args.unrolled_v_lr\n",
    "            v_star_val_loss = architect.step(input_w,  output_w, input_w_attn, output_w_attn, w_optimizer,\n",
    "                                             input_v, input_v_attn, output_v, output_v_attn, input_syn, input_syn_attn,\n",
    "                                             input_A_v, input_A_v_attn, output_A_v, output_A_v_attn, v_optimizer,\n",
    "                                             attn_idx, epsilon_w, epsilon_v)\n",
    "            objs_v_star_val.update(v_star_val_loss, Asize)\n",
    "\n",
    "        w_optimizer.zero_grad()\n",
    "   \n",
    "        loss_w = CTG_loss(input_w, input_w_attn, output_w,\n",
    "                          output_w_attn, attn_idx, A, w_model)\n",
    "        w_trainloss_acc += loss_w.item()\n",
    "        loss_w.backward()\n",
    "        objs_w.update(loss_w.item(), wsize)\n",
    "        w_optimizer.step()\n",
    "        # assert False\n",
    "\n",
    "\n",
    "        v_optimizer.zero_grad()\n",
    "        loss_aug = calc_loss_aug(input_syn, input_syn_attn, w_model, v_model)\n",
    "\n",
    "        loss = my_loss2(input_v, input_v_attn, output_v,\n",
    "                        output_v_attn, v_model)\n",
    "        v_loss = (args.traindata_loss_ratio*loss +\n",
    "                  loss_aug*args.syndata_loss_ratio)\n",
    "        v_trainloss_acc += v_loss.item()\n",
    "        v_loss.backward()\n",
    "        objs_v_syn.update(loss_aug.item(), synsize)\n",
    "        objs_v_train.update(loss.item(), vsize)\n",
    "        v_optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            valloss = my_loss2(input_A_v, input_A_v_attn,  output_A_v, output_A_v_attn,v_model)\n",
    "            objs_v_val.update(valloss.item(), Asize)\n",
    "\n",
    "        progress = 100*(step)/(loader_len-1)\n",
    "        if(tot_iter[0] % args.test_num == 0 and tot_iter[0] != 0):\n",
    "            my_test(validdataloader, model_w, epoch)\n",
    "            my_test(validdataloader, model_v, epoch)\n",
    "            logging.info(str((\"Attention Weights A : \", A.ReLU(A.alpha))))\n",
    "            torch.save(model_v,'./model/'+'model_w.pt')#+now+\n",
    "            torch.save(model_v,'./model/'+'model_v.pt')\n",
    "            torch.save(A,'./model/'+'A.pt')\n",
    "\n",
    "        if(tot_iter[0] % args.rep_num == 0 and tot_iter[0] != 0):\n",
    "            logging.info(f\"{progress:5.3}%:\\t  W_train_loss:{objs_w.avg:^.7f}\\tV_train_syn_loss:{objs_v_syn.avg:^.7f}\\tV_train_loss:{objs_v_train.avg:^.7f}\\t  V_star_val_loss:{objs_v_star_val.avg:^.7f}\\t  V_val_loss:{objs_v_val.avg:^.7f}\")\n",
    "            wandb.log({'W_train_loss': objs_w.avg})\n",
    "            wandb.log({'V_train_syn_loss': objs_v_syn.avg})\n",
    "            wandb.log({'V_train_loss': objs_v_train.avg})\n",
    "            wandb.log({'V_star_val_loss': objs_v_star_val.avg})\n",
    "            wandb.log({'V_val_loss': objs_v_val.avg})\n",
    "            objs_v_syn.reset()\n",
    "            objs_v_train.reset()\n",
    "            objs_w.reset()\n",
    "            objs_v_star_val.reset()\n",
    "            objs_v_val.reset()\n",
    "\n",
    "    return w_trainloss_acc, v_trainloss_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/14 08:21:23 PM |\t  \n",
      "\n",
      "  ----------------epoch:0,\t\tlr_w:8.235429999999999e-05,\t\tlr_v:8.235429999999999e-05,\t\tlr_A:8.235429999999999e-05----------------\n",
      "06/14 08:21:23 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/14 08:21:42 PM |\t   18.2%:\t  W_train_loss:0.1016503\tV_train_syn_loss:0.9590130\tV_train_loss:0.3693464\t  V_star_val_loss:6.6715509\t  V_val_loss:6.5905439\n",
      "06/14 08:22:01 PM |\t   45.5%:\t  W_train_loss:0.1950039\tV_train_syn_loss:1.4304089\tV_train_loss:0.5200895\t  V_star_val_loss:6.1058151\t  V_val_loss:5.9806525\n",
      "06/14 08:22:20 PM |\t   72.7%:\t  W_train_loss:0.1737433\tV_train_syn_loss:1.4695971\tV_train_loss:0.5560506\t  V_star_val_loss:6.3496173\t  V_val_loss:6.2664250\n",
      "06/14 08:22:38 PM |\t  1e+02%:\t  W_train_loss:0.1567626\tV_train_syn_loss:1.4056017\tV_train_loss:0.4432565\t  V_star_val_loss:7.3080637\t  V_val_loss:7.3099904\n",
      "06/14 08:22:38 PM |\t  w_train_loss:1.8814805895090103,v_train_loss:10.730045557022095\n",
      "06/14 08:22:38 PM |\t  \n",
      "\n",
      "  ----------------epoch:1,\t\tlr_w:5.764800999999999e-05,\t\tlr_v:5.764800999999999e-05,\t\tlr_A:5.764800999999999e-05----------------\n",
      "06/14 08:22:38 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/14 08:22:56 PM |\t   18.2%:\t  W_train_loss:0.0678648\tV_train_syn_loss:1.2749955\tV_train_loss:0.2804809\t  V_star_val_loss:6.7921871\t  V_val_loss:6.7360309\n",
      "06/14 08:23:14 PM |\t   45.5%:\t  W_train_loss:0.1358656\tV_train_syn_loss:1.3753622\tV_train_loss:0.4329641\t  V_star_val_loss:6.0912401\t  V_val_loss:6.0144746\n",
      "06/14 08:23:33 PM |\t   72.7%:\t  W_train_loss:0.1208209\tV_train_syn_loss:1.4065853\tV_train_loss:0.4608687\t  V_star_val_loss:6.3356541\t  V_val_loss:6.2743324\n",
      "06/14 08:23:50 PM |\t  1e+02%:\t  W_train_loss:0.1177151\tV_train_syn_loss:1.2795974\tV_train_loss:0.3744625\t  V_star_val_loss:7.5246116\t  V_val_loss:7.3994492\n",
      "06/14 08:23:50 PM |\t  w_train_loss:1.3267990201711655,v_train_loss:10.3279749751091\n",
      "06/14 08:23:50 PM |\t  \n",
      "\n",
      "  ----------------epoch:2,\t\tlr_w:4.035360699999999e-05,\t\tlr_v:4.035360699999999e-05,\t\tlr_A:4.035360699999999e-05----------------\n",
      "06/14 08:23:50 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/14 08:24:09 PM |\t   18.2%:\t  W_train_loss:0.0546309\tV_train_syn_loss:1.2937476\tV_train_loss:0.2385970\t  V_star_val_loss:6.8170261\t  V_val_loss:6.7983104\n",
      "06/14 08:24:27 PM |\t   45.5%:\t  W_train_loss:0.1052055\tV_train_syn_loss:1.2524098\tV_train_loss:0.3802557\t  V_star_val_loss:6.0951411\t  V_val_loss:6.0514913\n",
      "06/14 08:24:46 PM |\t   72.7%:\t  W_train_loss:0.0970099\tV_train_syn_loss:1.0977006\tV_train_loss:0.3996019\t  V_star_val_loss:6.4486372\t  V_val_loss:6.3510753\n",
      "06/14 08:25:04 PM |\t  1e+02%:\t  W_train_loss:0.0924247\tV_train_syn_loss:1.2247571\tV_train_loss:0.3247829\t  V_star_val_loss:7.5655041\t  V_val_loss:7.4572005\n",
      "06/14 08:25:04 PM |\t  w_train_loss:1.0478131361305714,v_train_loss:9.317779004573822\n",
      "06/14 08:25:04 PM |\t  \n",
      "\n",
      "  ----------------epoch:3,\t\tlr_w:2.8247524899999994e-05,\t\tlr_v:2.8247524899999994e-05,\t\tlr_A:2.8247524899999994e-05----------------\n",
      "06/14 08:25:04 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/14 08:25:21 PM |\t   18.2%:\t  W_train_loss:0.0470906\tV_train_syn_loss:1.2895633\tV_train_loss:0.2088201\t  V_star_val_loss:7.0191895\t  V_val_loss:6.8696680\n",
      "06/14 08:25:39 PM |\t   45.5%:\t  W_train_loss:0.0873941\tV_train_syn_loss:1.1133613\tV_train_loss:0.3442731\t  V_star_val_loss:6.1176613\t  V_val_loss:6.1005570\n",
      "06/14 08:25:58 PM |\t   72.7%:\t  W_train_loss:0.0826256\tV_train_syn_loss:1.2550236\tV_train_loss:0.3610333\t  V_star_val_loss:6.5373999\t  V_val_loss:6.4220686\n",
      "06/14 08:26:17 PM |\t  1e+02%:\t  W_train_loss:0.0770027\tV_train_syn_loss:1.2621959\tV_train_loss:0.2936426\t  V_star_val_loss:7.6541301\t  V_val_loss:7.5185720\n",
      "06/14 08:26:17 PM |\t  w_train_loss:0.8823390007019043,v_train_loss:9.191869854927063\n",
      "06/14 08:26:17 PM |\t  \n",
      "\n",
      "  ----------------epoch:4,\t\tlr_w:1.9773267429999995e-05,\t\tlr_v:1.9773267429999995e-05,\t\tlr_A:1.9773267429999995e-05----------------\n",
      "06/14 08:26:17 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/14 08:26:34 PM |\t   18.2%:\t  W_train_loss:0.0420710\tV_train_syn_loss:1.3148187\tV_train_loss:0.1902903\t  V_star_val_loss:7.0559367\t  V_val_loss:6.9317689\n",
      "06/14 08:26:52 PM |\t   45.5%:\t  W_train_loss:0.0746417\tV_train_syn_loss:1.1399180\tV_train_loss:0.3192853\t  V_star_val_loss:6.1575020\t  V_val_loss:6.1299046\n",
      "06/14 08:27:11 PM |\t   72.7%:\t  W_train_loss:0.0738382\tV_train_syn_loss:1.1750551\tV_train_loss:0.3363713\t  V_star_val_loss:6.4769359\t  V_val_loss:6.4589086\n",
      "06/14 08:27:29 PM |\t  1e+02%:\t  W_train_loss:0.0672501\tV_train_syn_loss:1.2029836\tV_train_loss:0.2754533\t  V_star_val_loss:7.6191947\t  V_val_loss:7.5549787\n",
      "06/14 08:27:29 PM |\t  w_train_loss:0.7734030559659004,v_train_loss:8.93126356601715\n",
      "06/14 08:27:29 PM |\t  \n",
      "\n",
      "  ----------------epoch:5,\t\tlr_w:1.3841287200999995e-05,\t\tlr_v:1.3841287200999995e-05,\t\tlr_A:1.3841287200999995e-05----------------\n",
      "06/14 08:27:29 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/14 08:27:47 PM |\t   18.2%:\t  W_train_loss:0.0386510\tV_train_syn_loss:1.1355949\tV_train_loss:0.1788191\t  V_star_val_loss:7.0541218\t  V_val_loss:6.9615877\n",
      "06/14 08:28:06 PM |\t   45.5%:\t  W_train_loss:0.0680272\tV_train_syn_loss:1.1739081\tV_train_loss:0.3030286\t  V_star_val_loss:6.2315505\t  V_val_loss:6.1461806\n",
      "06/14 08:28:25 PM |\t   72.7%:\t  W_train_loss:0.0683049\tV_train_syn_loss:1.0502127\tV_train_loss:0.3199640\t  V_star_val_loss:6.5327953\t  V_val_loss:6.4832225\n",
      "06/14 08:28:41 PM |\t  1e+02%:\t  W_train_loss:0.0609102\tV_train_syn_loss:1.2316056\tV_train_loss:0.2626930\t  V_star_val_loss:7.6053573\t  V_val_loss:7.5780156\n",
      "06/14 08:28:41 PM |\t  w_train_loss:0.7076800912618637,v_train_loss:8.483739137649536\n",
      "06/14 08:28:41 PM |\t  \n",
      "\n",
      "  ----------------epoch:6,\t\tlr_w:9.688901040699997e-06,\t\tlr_v:9.688901040699997e-06,\t\tlr_A:9.688901040699997e-06----------------\n",
      "06/14 08:28:41 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/14 08:28:59 PM |\t   18.2%:\t  W_train_loss:0.0362160\tV_train_syn_loss:1.0931547\tV_train_loss:0.1709711\t  V_star_val_loss:7.0824847\t  V_val_loss:6.9886859\n",
      "06/14 08:29:17 PM |\t   45.5%:\t  W_train_loss:0.0642917\tV_train_syn_loss:1.2280743\tV_train_loss:0.2916868\t  V_star_val_loss:6.2194985\t  V_val_loss:6.1616151\n",
      "06/14 08:29:36 PM |\t   72.7%:\t  W_train_loss:0.0645598\tV_train_syn_loss:1.1013531\tV_train_loss:0.3087521\t  V_star_val_loss:6.5262370\t  V_val_loss:6.5034202\n",
      "06/14 08:29:55 PM |\t  1e+02%:\t  W_train_loss:0.0566577\tV_train_syn_loss:1.2117664\tV_train_loss:0.2533626\t  V_star_val_loss:7.6918867\t  V_val_loss:7.5954496\n",
      "06/14 08:29:55 PM |\t  w_train_loss:0.6651755981147289,v_train_loss:8.48868179321289\n",
      "06/14 08:29:55 PM |\t  \n",
      "\n",
      "  ----------------epoch:7,\t\tlr_w:6.782230728489997e-06,\t\tlr_v:6.782230728489997e-06,\t\tlr_A:6.782230728489997e-06----------------\n",
      "06/14 08:29:55 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/14 08:30:13 PM |\t   18.2%:\t  W_train_loss:0.0345191\tV_train_syn_loss:1.1539071\tV_train_loss:0.1655435\t  V_star_val_loss:7.1646562\t  V_val_loss:7.0074121\n",
      "06/14 08:30:31 PM |\t   45.5%:\t  W_train_loss:0.0616251\tV_train_syn_loss:1.1304060\tV_train_loss:0.2837293\t  V_star_val_loss:6.2261101\t  V_val_loss:6.1746062\n",
      "06/14 08:30:51 PM |\t   72.7%:\t  W_train_loss:0.0620204\tV_train_syn_loss:1.0045299\tV_train_loss:0.3009358\t  V_star_val_loss:6.5856083\t  V_val_loss:6.5210892\n",
      "06/14 08:31:09 PM |\t  1e+02%:\t  W_train_loss:0.0537109\tV_train_syn_loss:1.1181061\tV_train_loss:0.2468505\t  V_star_val_loss:7.6734462\t  V_val_loss:7.6106259\n",
      "06/14 08:31:09 PM |\t  w_train_loss:0.6356266271322966,v_train_loss:8.106012105941772\n",
      "06/14 08:31:09 PM |\t  \n",
      "\n",
      "  ----------------epoch:8,\t\tlr_w:4.747561509942998e-06,\t\tlr_v:4.747561509942998e-06,\t\tlr_A:4.747561509942998e-06----------------\n",
      "06/14 08:31:09 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/14 08:31:27 PM |\t   18.2%:\t  W_train_loss:0.0332842\tV_train_syn_loss:1.2792360\tV_train_loss:0.1617371\t  V_star_val_loss:7.1130582\t  V_val_loss:7.0219022\n",
      "06/14 08:31:45 PM |\t   45.5%:\t  W_train_loss:0.0596881\tV_train_syn_loss:1.0475647\tV_train_loss:0.2781586\t  V_star_val_loss:6.2052800\t  V_val_loss:6.1846132\n",
      "06/14 08:32:04 PM |\t   72.7%:\t  W_train_loss:0.0602231\tV_train_syn_loss:0.9654846\tV_train_loss:0.2955028\t  V_star_val_loss:6.6139881\t  V_val_loss:6.5341285\n",
      "06/14 08:32:21 PM |\t  1e+02%:\t  W_train_loss:0.0515785\tV_train_syn_loss:1.1198224\tV_train_loss:0.2423961\t  V_star_val_loss:7.6897796\t  V_val_loss:7.6204569\n",
      "06/14 08:32:21 PM |\t  w_train_loss:0.6143217589706182,v_train_loss:8.084853529930115\n",
      "06/14 08:32:21 PM |\t  \n",
      "\n",
      "  ----------------epoch:9,\t\tlr_w:3.323293056960098e-06,\t\tlr_v:3.323293056960098e-06,\t\tlr_A:3.323293056960098e-06----------------\n",
      "06/14 08:32:21 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/14 08:32:39 PM |\t   18.2%:\t  W_train_loss:0.0323777\tV_train_syn_loss:1.3264832\tV_train_loss:0.1592359\t  V_star_val_loss:7.1327707\t  V_val_loss:7.0304772\n",
      "06/14 08:32:58 PM |\t   45.5%:\t  W_train_loss:0.0582463\tV_train_syn_loss:1.1024925\tV_train_loss:0.2742811\t  V_star_val_loss:6.2154686\t  V_val_loss:6.1923415\n",
      "06/14 08:33:17 PM |\t   72.7%:\t  W_train_loss:0.0589354\tV_train_syn_loss:1.0809419\tV_train_loss:0.2916146\t  V_star_val_loss:6.6118452\t  V_val_loss:6.5452696\n",
      "06/14 08:33:35 PM |\t  1e+02%:\t  W_train_loss:0.0500488\tV_train_syn_loss:1.1169002\tV_train_loss:0.2392552\t  V_star_val_loss:7.7040275\t  V_val_loss:7.6275066\n",
      "06/14 08:33:35 PM |\t  w_train_loss:0.5988243874162436,v_train_loss:8.386806786060333\n",
      "06/14 08:33:35 PM |\t  \n",
      "\n",
      "  ----------------epoch:10,\t\tlr_w:2.3263051398720685e-06,\t\tlr_v:2.3263051398720685e-06,\t\tlr_A:2.3263051398720685e-06----------------\n",
      "06/14 08:33:35 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/14 08:33:53 PM |\t   18.2%:\t  W_train_loss:0.0317033\tV_train_syn_loss:1.2299036\tV_train_loss:0.1575025\t  V_star_val_loss:7.1613909\t  V_val_loss:7.0357348\n",
      "06/14 08:34:07 PM |\t  x_decoded[:2]:['translate English to German: Sometimes no, because in its extreme it can lead people to take absurd physical risks, gamble or indulge in substance abuse as a way to ease it, research shows.', 'translate English to German: The city is mentioned in ancient Greek and ancient Egyptian legends.']\n",
      "06/14 08:34:07 PM |\t  pred_decoded[:2]:['Diem Sourbate berichtet, immersing in the wrath of a wrath of a wrath of a wrath of a wrath of a wrath of a wrath of a ', 'Die Stadt ist eingar das city der Stadt gegründet worden worden worden worden.']\n",
      "06/14 08:34:07 PM |\t  label_decoded[:2]:['Manchmal nicht, denn im Extremfall führt sie dazu, dass Menschen extreme körperliche Risiken auf sich nehmen und dem Glücksspiel oder Drogen verfallen, um sie zu lindern - das haben Studien gezeigt.', 'Die Stadt wird in altgriechischen und altägyptischen Legenden erwähnt.']\n",
      "06/14 08:34:14 PM |\t  computing score...\n",
      "06/14 08:34:14 PM |\t  model_w_in_main sacreBLEU : 0.982196\n",
      "06/14 08:34:14 PM |\t  model_w_in_main test loss : 7.596435\n",
      "06/14 08:34:16 PM |\t  x_decoded[:2]:['translate English to German: Sometimes no, because in its extreme it can lead people to take absurd physical risks, gamble or indulge in substance abuse as a way to ease it, research shows.', 'translate English to German: The city is mentioned in ancient Greek and ancient Egyptian legends.']\n",
      "06/14 08:34:16 PM |\t  pred_decoded[:2]:['Diembearbeitungen: Diembearbeitungen: Diembearbeitungen: Diembearbeitungen ist diembearbeitungen, diembearbeitungen, diembearbeitungen, diembearbeitungen, diembearbeitungen,', 'Die city ist in ancient Greek and ancient Egyptian legends.']\n",
      "06/14 08:34:16 PM |\t  label_decoded[:2]:['Manchmal nicht, denn im Extremfall führt sie dazu, dass Menschen extreme körperliche Risiken auf sich nehmen und dem Glücksspiel oder Drogen verfallen, um sie zu lindern - das haben Studien gezeigt.', 'Die Stadt wird in altgriechischen und altägyptischen Legenden erwähnt.']\n",
      "06/14 08:34:24 PM |\t  computing score...\n",
      "06/14 08:34:24 PM |\t  model_v_in_main sacreBLEU : 0.671255\n",
      "06/14 08:34:24 PM |\t  model_v_in_main test loss : 6.931439\n",
      "06/14 08:34:24 PM |\t  ('Attention Weights A : ', tensor([0.9949, 1.0044, 0.9896, 0.9901, 0.9942, 1.0083, 1.0057, 0.9963, 1.0057,\n",
      "        0.9962, 0.9965, 1.0055, 0.9946, 1.0000, 0.9944, 0.9965, 1.0067, 0.9998,\n",
      "        1.0011, 1.0066, 0.9928, 0.9931, 0.9995, 0.9941, 0.9983, 0.9966, 0.9991,\n",
      "        0.9996, 1.0022, 0.9971, 1.0057, 1.0060, 0.9969, 0.9984, 1.0007, 1.0002,\n",
      "        0.9955, 1.0051, 0.9986, 1.0053, 1.0053, 0.9970, 1.0055, 1.0010, 0.9944,\n",
      "        0.9955, 0.9961, 0.9946], device='cuda:0', grad_fn=<ReluBackward0>))\n",
      "06/14 08:34:31 PM |\t   45.5%:\t  W_train_loss:0.7757309\tV_train_syn_loss:2.7374962\tV_train_loss:0.9027725\t  V_star_val_loss:5.9488468\t  V_val_loss:6.5645452\n",
      "06/14 08:34:50 PM |\t   72.7%:\t  W_train_loss:2.9015396\tV_train_syn_loss:6.2965973\tV_train_loss:2.7517693\t  V_star_val_loss:5.3003484\t  V_val_loss:7.4336251\n",
      "06/14 08:35:09 PM |\t  1e+02%:\t  W_train_loss:2.2146255\tV_train_syn_loss:5.8205490\tV_train_loss:2.4374028\t  V_star_val_loss:5.5746786\t  V_val_loss:7.8862883\n",
      "06/14 08:35:09 PM |\t  w_train_loss:17.770797919481993,v_train_loss:33.50098937749863\n",
      "06/14 08:35:09 PM |\t  \n",
      "\n",
      "  ----------------epoch:11,\t\tlr_w:1.6284135979104478e-06,\t\tlr_v:1.6284135979104478e-06,\t\tlr_A:1.6284135979104478e-06----------------\n",
      "06/14 08:35:09 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/14 08:35:28 PM |\t   18.2%:\t  W_train_loss:0.0313849\tV_train_syn_loss:1.1931590\tV_train_loss:0.1577432\t  V_star_val_loss:5.5091775\t  V_val_loss:6.9812616\n",
      "06/14 08:35:46 PM |\t   45.5%:\t  W_train_loss:0.0571361\tV_train_syn_loss:1.0741456\tV_train_loss:0.2723131\t  V_star_val_loss:5.1309583\t  V_val_loss:6.1394154\n",
      "06/14 08:36:05 PM |\t   72.7%:\t  W_train_loss:0.0581531\tV_train_syn_loss:1.2386375\tV_train_loss:0.2904320\t  V_star_val_loss:5.5533287\t  V_val_loss:6.4862008\n",
      "06/14 08:36:22 PM |\t  1e+02%:\t  W_train_loss:0.0493497\tV_train_syn_loss:1.4050719\tV_train_loss:0.2403398\t  V_star_val_loss:6.5165342\t  V_val_loss:7.5510120\n",
      "06/14 08:36:22 PM |\t  w_train_loss:0.5880715101957321,v_train_loss:8.807763159275055\n",
      "06/14 08:36:22 PM |\t  \n",
      "\n",
      "  ----------------epoch:12,\t\tlr_w:1.1398895185373134e-06,\t\tlr_v:1.1398895185373134e-06,\t\tlr_A:1.1398895185373134e-06----------------\n",
      "06/14 08:36:22 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/14 08:36:40 PM |\t   18.2%:\t  W_train_loss:0.0313742\tV_train_syn_loss:1.2022937\tV_train_loss:0.1583756\t  V_star_val_loss:6.2864146\t  V_val_loss:6.9479923\n",
      "06/14 08:36:58 PM |\t   45.5%:\t  W_train_loss:0.0571544\tV_train_syn_loss:1.1321896\tV_train_loss:0.2726407\t  V_star_val_loss:5.7483457\t  V_val_loss:6.1207399\n",
      "06/14 08:37:16 PM |\t   72.7%:\t  W_train_loss:0.0581537\tV_train_syn_loss:1.2005315\tV_train_loss:0.2905063\t  V_star_val_loss:6.1875836\t  V_val_loss:6.4727214\n",
      "06/14 08:37:35 PM |\t  1e+02%:\t  W_train_loss:0.0493356\tV_train_syn_loss:1.3629366\tV_train_loss:0.2403018\t  V_star_val_loss:7.1784738\t  V_val_loss:7.5411522\n",
      "06/14 08:37:35 PM |\t  w_train_loss:0.5880538076162338,v_train_loss:8.789663553237915\n",
      "06/14 08:37:35 PM |\t  \n",
      "\n",
      "  ----------------epoch:13,\t\tlr_w:7.979226629761193e-07,\t\tlr_v:7.979226629761193e-07,\t\tlr_A:7.979226629761193e-07----------------\n",
      "06/14 08:37:35 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/14 08:37:52 PM |\t   18.2%:\t  W_train_loss:0.0313352\tV_train_syn_loss:1.1570339\tV_train_loss:0.1583159\t  V_star_val_loss:6.7198757\t  V_val_loss:6.9405923\n",
      "06/14 08:38:11 PM |\t   45.5%:\t  W_train_loss:0.0571032\tV_train_syn_loss:1.1338995\tV_train_loss:0.2722668\t  V_star_val_loss:6.0344407\t  V_val_loss:6.1164716\n",
      "06/14 08:38:29 PM |\t   72.7%:\t  W_train_loss:0.0581122\tV_train_syn_loss:1.2055941\tV_train_loss:0.2901208\t  V_star_val_loss:6.4522518\t  V_val_loss:6.4703205\n",
      "06/14 08:38:48 PM |\t  1e+02%:\t  W_train_loss:0.0492503\tV_train_syn_loss:1.3367043\tV_train_loss:0.2399997\t  V_star_val_loss:7.4220153\t  V_val_loss:7.5387642\n",
      "06/14 08:38:48 PM |\t  w_train_loss:0.5874024853110313,v_train_loss:8.690902352333069\n",
      "06/14 08:38:48 PM |\t  \n",
      "\n",
      "  ----------------epoch:14,\t\tlr_w:5.585458640832835e-07,\t\tlr_v:5.585458640832835e-07,\t\tlr_A:5.585458640832835e-07----------------\n",
      "06/14 08:38:48 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/14 08:39:06 PM |\t   18.2%:\t  W_train_loss:0.0312889\tV_train_syn_loss:1.1262081\tV_train_loss:0.1581238\t  V_star_val_loss:6.8775581\t  V_val_loss:6.9390297\n",
      "06/14 08:39:25 PM |\t   45.5%:\t  W_train_loss:0.0570475\tV_train_syn_loss:1.1199514\tV_train_loss:0.2719179\t  V_star_val_loss:6.1528878\t  V_val_loss:6.1155659\n",
      "06/14 08:39:44 PM |\t   72.7%:\t  W_train_loss:0.0580374\tV_train_syn_loss:1.2218301\tV_train_loss:0.2897566\t  V_star_val_loss:6.5162079\t  V_val_loss:6.4701435\n",
      "06/14 08:40:02 PM |\t  1e+02%:\t  W_train_loss:0.0491827\tV_train_syn_loss:1.3312071\tV_train_loss:0.2396499\t  V_star_val_loss:7.4987481\t  V_val_loss:7.5378764\n",
      "06/14 08:40:02 PM |\t  w_train_loss:0.5866693332791328,v_train_loss:8.63796716928482\n",
      "06/14 08:40:02 PM |\t  \n",
      "\n",
      "  ----------------epoch:15,\t\tlr_w:3.9098210485829847e-07,\t\tlr_v:3.9098210485829847e-07,\t\tlr_A:3.9098210485829847e-07----------------\n",
      "06/14 08:40:02 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/14 08:40:19 PM |\t   18.2%:\t  W_train_loss:0.0312541\tV_train_syn_loss:1.1913432\tV_train_loss:0.1579250\t  V_star_val_loss:6.9234289\t  V_val_loss:6.9388472\n",
      "06/14 08:40:38 PM |\t   45.5%:\t  W_train_loss:0.0569822\tV_train_syn_loss:1.1266946\tV_train_loss:0.2716056\t  V_star_val_loss:6.1815459\t  V_val_loss:6.1154315\n",
      "06/14 08:40:57 PM |\t   72.7%:\t  W_train_loss:0.0579958\tV_train_syn_loss:1.2499578\tV_train_loss:0.2894504\t  V_star_val_loss:6.5510977\t  V_val_loss:6.4702819\n",
      "06/14 08:41:14 PM |\t  1e+02%:\t  W_train_loss:0.0491240\tV_train_syn_loss:1.3165850\tV_train_loss:0.2394185\t  V_star_val_loss:7.5121862\t  V_val_loss:7.5374668\n",
      "06/14 08:41:14 PM |\t  w_train_loss:0.5860681682825089,v_train_loss:8.764470160007477\n",
      "06/14 08:41:14 PM |\t  \n",
      "\n",
      "  ----------------epoch:16,\t\tlr_w:2.736874734008089e-07,\t\tlr_v:2.736874734008089e-07,\t\tlr_A:2.736874734008089e-07----------------\n",
      "06/14 08:41:14 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/14 08:41:33 PM |\t   18.2%:\t  W_train_loss:0.0312265\tV_train_syn_loss:1.1187097\tV_train_loss:0.1577885\t  V_star_val_loss:6.9593547\t  V_val_loss:6.9388534\n",
      "06/14 08:41:51 PM |\t   45.5%:\t  W_train_loss:0.0569450\tV_train_syn_loss:1.1122455\tV_train_loss:0.2713597\t  V_star_val_loss:6.2142378\t  V_val_loss:6.1156928\n",
      "06/14 08:42:10 PM |\t   72.7%:\t  W_train_loss:0.0579586\tV_train_syn_loss:1.1852602\tV_train_loss:0.2892262\t  V_star_val_loss:6.6045992\t  V_val_loss:6.4708691\n",
      "06/14 08:42:28 PM |\t  1e+02%:\t  W_train_loss:0.0490755\tV_train_syn_loss:1.3243134\tV_train_loss:0.2392305\t  V_star_val_loss:7.5651735\t  V_val_loss:7.5379194\n",
      "06/14 08:42:28 PM |\t  w_train_loss:0.5856166575103998,v_train_loss:8.547200441360474\n",
      "06/14 08:42:28 PM |\t  \n",
      "\n",
      "  ----------------epoch:17,\t\tlr_w:1.9158123138056623e-07,\t\tlr_v:1.9158123138056623e-07,\t\tlr_A:1.9158123138056623e-07----------------\n",
      "06/14 08:42:28 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/14 08:42:46 PM |\t   18.2%:\t  W_train_loss:0.0312021\tV_train_syn_loss:1.1174908\tV_train_loss:0.1577093\t  V_star_val_loss:6.9865150\t  V_val_loss:6.9389366\n",
      "06/14 08:43:04 PM |\t   45.5%:\t  W_train_loss:0.0569088\tV_train_syn_loss:1.0158286\tV_train_loss:0.2711785\t  V_star_val_loss:6.2371430\t  V_val_loss:6.1158687\n",
      "06/14 08:43:22 PM |\t   72.7%:\t  W_train_loss:0.0579300\tV_train_syn_loss:1.2058496\tV_train_loss:0.2890746\t  V_star_val_loss:6.6314980\t  V_val_loss:6.4708886\n",
      "06/14 08:43:40 PM |\t  1e+02%:\t  W_train_loss:0.0490394\tV_train_syn_loss:1.3222333\tV_train_loss:0.2390847\t  V_star_val_loss:7.5869813\t  V_val_loss:7.5373281\n",
      "06/14 08:43:40 PM |\t  w_train_loss:0.5852407738566399,v_train_loss:8.427673935890198\n",
      "06/14 08:43:40 PM |\t  \n",
      "\n",
      "  ----------------epoch:18,\t\tlr_w:1.3410686196639635e-07,\t\tlr_v:1.3410686196639635e-07,\t\tlr_A:1.3410686196639635e-07----------------\n",
      "06/14 08:43:40 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/14 08:43:58 PM |\t   18.2%:\t  W_train_loss:0.0311933\tV_train_syn_loss:1.1294098\tV_train_loss:0.1576199\t  V_star_val_loss:7.0246957\t  V_val_loss:6.9390248\n",
      "06/14 08:44:16 PM |\t   45.5%:\t  W_train_loss:0.0568864\tV_train_syn_loss:1.0488625\tV_train_loss:0.2710648\t  V_star_val_loss:6.2386176\t  V_val_loss:6.1158396\n",
      "06/14 08:44:36 PM |\t   72.7%:\t  W_train_loss:0.0579039\tV_train_syn_loss:1.1605344\tV_train_loss:0.2889401\t  V_star_val_loss:6.6418371\t  V_val_loss:6.4710019\n",
      "06/14 08:44:53 PM |\t  1e+02%:\t  W_train_loss:0.0490136\tV_train_syn_loss:1.3206411\tV_train_loss:0.2389667\t  V_star_val_loss:7.6189305\t  V_val_loss:7.5377170\n",
      "06/14 08:44:53 PM |\t  w_train_loss:0.5849916562438011,v_train_loss:8.424059212207794\n",
      "06/14 08:44:53 PM |\t  \n",
      "\n",
      "  ----------------epoch:19,\t\tlr_w:9.387480337647744e-08,\t\tlr_v:9.387480337647744e-08,\t\tlr_A:9.387480337647744e-08----------------\n",
      "06/14 08:44:53 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/14 08:45:11 PM |\t   18.2%:\t  W_train_loss:0.0311804\tV_train_syn_loss:1.1284025\tV_train_loss:0.1575541\t  V_star_val_loss:7.0362714\t  V_val_loss:6.9390513\n",
      "06/14 08:45:30 PM |\t   45.5%:\t  W_train_loss:0.0568794\tV_train_syn_loss:1.1012192\tV_train_loss:0.2709796\t  V_star_val_loss:6.2364438\t  V_val_loss:6.1158053\n",
      "06/14 08:45:49 PM |\t   72.7%:\t  W_train_loss:0.0578789\tV_train_syn_loss:1.2103268\tV_train_loss:0.2888489\t  V_star_val_loss:6.6516380\t  V_val_loss:6.4712079\n",
      "06/14 08:46:06 PM |\t  1e+02%:\t  W_train_loss:0.0489935\tV_train_syn_loss:1.3388339\tV_train_loss:0.2389059\t  V_star_val_loss:7.5996952\t  V_val_loss:7.5373945\n",
      "06/14 08:46:06 PM |\t  w_train_loss:0.5847965646535158,v_train_loss:8.602606415748596\n",
      "06/14 08:46:06 PM |\t  \n",
      "\n",
      "  ----------------epoch:20,\t\tlr_w:6.57123623635342e-08,\t\tlr_v:6.57123623635342e-08,\t\tlr_A:6.57123623635342e-08----------------\n",
      "06/14 08:46:06 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/14 08:46:24 PM |\t   18.2%:\t  W_train_loss:0.0311640\tV_train_syn_loss:1.1276070\tV_train_loss:0.1574955\t  V_star_val_loss:7.0084499\t  V_val_loss:6.9394342\n",
      "06/14 08:46:43 PM |\t   45.5%:\t  W_train_loss:0.0568402\tV_train_syn_loss:1.0137088\tV_train_loss:0.2709517\t  V_star_val_loss:6.2325576\t  V_val_loss:6.1160092\n",
      "06/14 08:47:02 PM |\t   72.7%:\t  W_train_loss:0.0578756\tV_train_syn_loss:1.2055369\tV_train_loss:0.2887978\t  V_star_val_loss:6.6350226\t  V_val_loss:6.4713993\n",
      "06/14 08:47:10 PM |\t  x_decoded[:2]:['translate English to German: Sometimes no, because in its extreme it can lead people to take absurd physical risks, gamble or indulge in substance abuse as a way to ease it, research shows.', 'translate English to German: The city is mentioned in ancient Greek and ancient Egyptian legends.']\n",
      "06/14 08:47:10 PM |\t  pred_decoded[:2]:['Diem Sourbate ist so beliebten Sie man sich selbst festgestellt, dieen Sie man sich selbst festgestellt haben, dieen Sie man sich selbst festgestellt haben, dieen Sie man sich selbst festgestellt haben, dieen Sie man sich selbst festgestellt haben, dieen Sie man sich selbst festgestellt haben, in der', 'Das ist bei Ancient Greek and Ancient Egyptian Herbs.']\n",
      "06/14 08:47:10 PM |\t  label_decoded[:2]:['Manchmal nicht, denn im Extremfall führt sie dazu, dass Menschen extreme körperliche Risiken auf sich nehmen und dem Glücksspiel oder Drogen verfallen, um sie zu lindern - das haben Studien gezeigt.', 'Die Stadt wird in altgriechischen und altägyptischen Legenden erwähnt.']\n",
      "06/14 08:47:17 PM |\t  computing score...\n",
      "06/14 08:47:17 PM |\t  model_w_in_main sacreBLEU : 1.092172\n",
      "06/14 08:47:17 PM |\t  model_w_in_main test loss : 7.579867\n",
      "06/14 08:47:18 PM |\t  x_decoded[:2]:['translate English to German: Sometimes no, because in its extreme it can lead people to take absurd physical risks, gamble or indulge in substance abuse as a way to ease it, research shows.', 'translate English to German: The city is mentioned in ancient Greek and ancient Egyptian legends.']\n",
      "06/14 08:47:18 PM |\t  pred_decoded[:2]:['Diemists der mich ist, diemist, diemist, diemist, diemist, diemist, diemist, diemist, diemist, diemist, diemist, diemist, diemist, diemist, diemist', 'Die city ist in ancient Greek and ancient Egyptian legends.']\n",
      "06/14 08:47:18 PM |\t  label_decoded[:2]:['Manchmal nicht, denn im Extremfall führt sie dazu, dass Menschen extreme körperliche Risiken auf sich nehmen und dem Glücksspiel oder Drogen verfallen, um sie zu lindern - das haben Studien gezeigt.', 'Die Stadt wird in altgriechischen und altägyptischen Legenden erwähnt.']\n",
      "06/14 08:47:26 PM |\t  computing score...\n",
      "06/14 08:47:26 PM |\t  model_v_in_main sacreBLEU : 0.713805\n",
      "06/14 08:47:26 PM |\t  model_v_in_main test loss : 6.848462\n",
      "06/14 08:47:26 PM |\t  ('Attention Weights A : ', tensor([0.9949, 1.0044, 0.9896, 0.9901, 0.9942, 1.0083, 1.0057, 0.9963, 1.0057,\n",
      "        0.9962, 0.9965, 1.0055, 0.9946, 1.0000, 0.9944, 0.9965, 1.0067, 0.9998,\n",
      "        1.0012, 1.0066, 0.9929, 0.9931, 0.9995, 0.9941, 0.9983, 0.9966, 0.9991,\n",
      "        0.9996, 1.0022, 0.9971, 1.0057, 1.0060, 0.9969, 0.9984, 1.0007, 1.0002,\n",
      "        0.9955, 1.0051, 0.9986, 1.0053, 1.0053, 0.9971, 1.0055, 1.0010, 0.9944,\n",
      "        0.9955, 0.9961, 0.9947], device='cuda:0', grad_fn=<ReluBackward0>))\n",
      "06/14 08:47:38 PM |\t  1e+02%:\t  W_train_loss:1.5577650\tV_train_syn_loss:4.3046737\tV_train_loss:1.7461854\t  V_star_val_loss:6.7517516\t  V_val_loss:7.9505002\n",
      "06/14 08:47:38 PM |\t  w_train_loss:5.11093426682055,v_train_loss:15.172434985637665\n",
      "06/14 08:47:38 PM |\t  \n",
      "\n",
      "  ----------------epoch:21,\t\tlr_w:4.5998653654473935e-08,\t\tlr_v:4.5998653654473935e-08,\t\tlr_A:4.5998653654473935e-08----------------\n",
      "06/14 08:47:38 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/14 08:47:57 PM |\t   18.2%:\t  W_train_loss:0.0311557\tV_train_syn_loss:1.1128798\tV_train_loss:0.1574972\t  V_star_val_loss:6.0997299\t  V_val_loss:6.9389375\n",
      "06/14 08:48:16 PM |\t   45.5%:\t  W_train_loss:0.0568462\tV_train_syn_loss:1.0211376\tV_train_loss:0.2709130\t  V_star_val_loss:5.5872043\t  V_val_loss:6.1157894\n",
      "06/14 08:48:35 PM |\t   72.7%:\t  W_train_loss:0.0578699\tV_train_syn_loss:1.1659051\tV_train_loss:0.2887559\t  V_star_val_loss:6.1415714\t  V_val_loss:6.4712989\n",
      "06/14 08:48:52 PM |\t  1e+02%:\t  W_train_loss:0.0489763\tV_train_syn_loss:1.3184572\tV_train_loss:0.2388502\t  V_star_val_loss:7.0963852\t  V_val_loss:7.5371218\n",
      "06/14 08:48:52 PM |\t  w_train_loss:0.5845439303666353,v_train_loss:8.361594021320343\n",
      "06/14 08:48:52 PM |\t  \n",
      "\n",
      "  ----------------epoch:22,\t\tlr_w:3.219905755813175e-08,\t\tlr_v:3.219905755813175e-08,\t\tlr_A:3.219905755813175e-08----------------\n",
      "06/14 08:48:52 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/14 08:49:10 PM |\t   18.2%:\t  W_train_loss:0.0311633\tV_train_syn_loss:1.1304145\tV_train_loss:0.1574875\t  V_star_val_loss:6.6617117\t  V_val_loss:6.9386706\n",
      "06/14 08:49:29 PM |\t   45.5%:\t  W_train_loss:0.0568469\tV_train_syn_loss:1.1340371\tV_train_loss:0.2708682\t  V_star_val_loss:6.0139726\t  V_val_loss:6.1153935\n",
      "06/14 08:49:47 PM |\t   72.7%:\t  W_train_loss:0.0578637\tV_train_syn_loss:1.1847872\tV_train_loss:0.2887485\t  V_star_val_loss:6.4372787\t  V_val_loss:6.4708678\n",
      "06/14 08:50:05 PM |\t  1e+02%:\t  W_train_loss:0.0489735\tV_train_syn_loss:1.3182320\tV_train_loss:0.2388089\t  V_star_val_loss:7.4430248\t  V_val_loss:7.5368554\n",
      "06/14 08:50:05 PM |\t  w_train_loss:0.5845423378050327,v_train_loss:8.585075736045837\n",
      "06/14 08:50:05 PM |\t  \n",
      "\n",
      "  ----------------epoch:23,\t\tlr_w:2.2539340290692225e-08,\t\tlr_v:2.2539340290692225e-08,\t\tlr_A:2.2539340290692225e-08----------------\n",
      "06/14 08:50:05 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/14 08:50:24 PM |\t   18.2%:\t  W_train_loss:0.0311506\tV_train_syn_loss:1.1457671\tV_train_loss:0.1575020\t  V_star_val_loss:6.8791167\t  V_val_loss:6.9385252\n",
      "06/14 08:50:42 PM |\t   45.5%:\t  W_train_loss:0.0568420\tV_train_syn_loss:1.0376792\tV_train_loss:0.2708479\t  V_star_val_loss:6.1590684\t  V_val_loss:6.1154232\n",
      "06/14 08:51:00 PM |\t   72.7%:\t  W_train_loss:0.0578594\tV_train_syn_loss:1.2501783\tV_train_loss:0.2887343\t  V_star_val_loss:6.5319468\t  V_val_loss:6.4710944\n",
      "06/14 08:51:17 PM |\t  1e+02%:\t  W_train_loss:0.0489695\tV_train_syn_loss:1.3179527\tV_train_loss:0.2388098\t  V_star_val_loss:7.5027404\t  V_val_loss:7.5369910\n",
      "06/14 08:51:17 PM |\t  w_train_loss:0.5844645015895367,v_train_loss:8.561206877231598\n",
      "06/14 08:51:17 PM |\t  \n",
      "\n",
      "  ----------------epoch:24,\t\tlr_w:1.5777538203484557e-08,\t\tlr_v:1.5777538203484557e-08,\t\tlr_A:1.5777538203484557e-08----------------\n",
      "06/14 08:51:17 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/14 08:51:36 PM |\t   18.2%:\t  W_train_loss:0.0311587\tV_train_syn_loss:1.1300050\tV_train_loss:0.1574754\t  V_star_val_loss:6.9853307\t  V_val_loss:6.9386153\n",
      "06/14 08:51:55 PM |\t   45.5%:\t  W_train_loss:0.0568453\tV_train_syn_loss:1.0207111\tV_train_loss:0.2708327\t  V_star_val_loss:6.2214986\t  V_val_loss:6.1154060\n",
      "06/14 08:52:14 PM |\t   72.7%:\t  W_train_loss:0.0578569\tV_train_syn_loss:1.1838451\tV_train_loss:0.2887259\t  V_star_val_loss:6.6271545\t  V_val_loss:6.4708670\n",
      "06/14 08:52:32 PM |\t  1e+02%:\t  W_train_loss:0.0489701\tV_train_syn_loss:1.3178996\tV_train_loss:0.2387980\t  V_star_val_loss:7.5992889\t  V_val_loss:7.5370256\n",
      "06/14 08:52:32 PM |\t  w_train_loss:0.5844927988946438,v_train_loss:8.412439346313477\n",
      "06/14 08:52:32 PM |\t  \n",
      "\n",
      "  ----------------epoch:25,\t\tlr_w:1.104427674243919e-08,\t\tlr_v:1.104427674243919e-08,\t\tlr_A:1.104427674243919e-08----------------\n",
      "06/14 08:52:32 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/14 08:52:50 PM |\t   18.2%:\t  W_train_loss:0.0311492\tV_train_syn_loss:1.1829820\tV_train_loss:0.1574575\t  V_star_val_loss:7.0391045\t  V_val_loss:6.9386225\n",
      "06/14 08:53:09 PM |\t   45.5%:\t  W_train_loss:0.0568403\tV_train_syn_loss:1.0375003\tV_train_loss:0.2708433\t  V_star_val_loss:6.2444620\t  V_val_loss:6.1153475\n",
      "06/14 08:53:29 PM |\t   72.7%:\t  W_train_loss:0.0578589\tV_train_syn_loss:1.2157754\tV_train_loss:0.2887255\t  V_star_val_loss:6.6153447\t  V_val_loss:6.4709984\n",
      "06/14 08:53:46 PM |\t  1e+02%:\t  W_train_loss:0.0489663\tV_train_syn_loss:1.3177708\tV_train_loss:0.2387974\t  V_star_val_loss:7.6054923\t  V_val_loss:7.5367748\n",
      "06/14 08:53:46 PM |\t  w_train_loss:0.5844442993402481,v_train_loss:8.564778506755829\n",
      "06/14 08:53:46 PM |\t  \n",
      "\n",
      "  ----------------epoch:26,\t\tlr_w:7.730993719707432e-09,\t\tlr_v:7.730993719707432e-09,\t\tlr_A:7.730993719707432e-09----------------\n",
      "06/14 08:53:46 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/14 08:54:05 PM |\t   18.2%:\t  W_train_loss:0.0311540\tV_train_syn_loss:1.1261617\tV_train_loss:0.1574778\t  V_star_val_loss:7.0148543\t  V_val_loss:6.9385912\n",
      "06/14 08:54:24 PM |\t   45.5%:\t  W_train_loss:0.0568460\tV_train_syn_loss:1.0374030\tV_train_loss:0.2708212\t  V_star_val_loss:6.2437747\t  V_val_loss:6.1152763\n",
      "06/14 08:54:43 PM |\t   72.7%:\t  W_train_loss:0.0578522\tV_train_syn_loss:1.2270744\tV_train_loss:0.2887201\t  V_star_val_loss:6.6271955\t  V_val_loss:6.4710221\n",
      "06/14 08:55:00 PM |\t  1e+02%:\t  W_train_loss:0.0489693\tV_train_syn_loss:1.3512724\tV_train_loss:0.2387965\t  V_star_val_loss:7.6204632\t  V_val_loss:7.5366890\n",
      "06/14 08:55:00 PM |\t  w_train_loss:0.5844644773751497,v_train_loss:8.546590805053711\n",
      "06/14 08:55:00 PM |\t  \n",
      "\n",
      "  ----------------epoch:27,\t\tlr_w:5.411695603795202e-09,\t\tlr_v:5.411695603795202e-09,\t\tlr_A:5.411695603795202e-09----------------\n",
      "06/14 08:55:00 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/14 08:55:19 PM |\t   18.2%:\t  W_train_loss:0.0311592\tV_train_syn_loss:1.1344542\tV_train_loss:0.1574574\t  V_star_val_loss:7.0290982\t  V_val_loss:6.9385338\n",
      "06/14 08:55:37 PM |\t   45.5%:\t  W_train_loss:0.0568339\tV_train_syn_loss:1.0466767\tV_train_loss:0.2708542\t  V_star_val_loss:6.2326107\t  V_val_loss:6.1154369\n",
      "06/14 08:55:57 PM |\t   72.7%:\t  W_train_loss:0.0578689\tV_train_syn_loss:1.2296890\tV_train_loss:0.2887177\t  V_star_val_loss:6.6341070\t  V_val_loss:6.4708670\n",
      "06/14 08:56:15 PM |\t  1e+02%:\t  W_train_loss:0.0489690\tV_train_syn_loss:1.3177280\tV_train_loss:0.2387875\t  V_star_val_loss:7.6448523\t  V_val_loss:7.5370725\n",
      "06/14 08:56:15 PM |\t  w_train_loss:0.5844932943582535,v_train_loss:8.526547014713287\n",
      "06/14 08:56:15 PM |\t  \n",
      "\n",
      "  ----------------epoch:28,\t\tlr_w:3.788186922656641e-09,\t\tlr_v:3.788186922656641e-09,\t\tlr_A:3.788186922656641e-09----------------\n",
      "06/14 08:56:15 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/14 08:56:33 PM |\t   18.2%:\t  W_train_loss:0.0311566\tV_train_syn_loss:1.1261936\tV_train_loss:0.1574423\t  V_star_val_loss:7.0273314\t  V_val_loss:6.9383817\n",
      "06/14 08:56:52 PM |\t   45.5%:\t  W_train_loss:0.0568451\tV_train_syn_loss:1.0205082\tV_train_loss:0.2708349\t  V_star_val_loss:6.2459429\t  V_val_loss:6.1155357\n",
      "06/14 08:57:11 PM |\t   72.7%:\t  W_train_loss:0.0578601\tV_train_syn_loss:1.2044043\tV_train_loss:0.2887261\t  V_star_val_loss:6.6416335\t  V_val_loss:6.4707955\n",
      "06/14 08:57:29 PM |\t  1e+02%:\t  W_train_loss:0.0489806\tV_train_syn_loss:1.3384714\tV_train_loss:0.2388149\t  V_star_val_loss:7.6534357\t  V_val_loss:7.5368412\n",
      "06/14 08:57:29 PM |\t  w_train_loss:0.584527438506484,v_train_loss:8.468093633651733\n",
      "06/14 08:57:29 PM |\t  \n",
      "\n",
      "  ----------------epoch:29,\t\tlr_w:2.651730845859649e-09,\t\tlr_v:2.651730845859649e-09,\t\tlr_A:2.651730845859649e-09----------------\n",
      "06/14 08:57:29 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/14 08:57:47 PM |\t   18.2%:\t  W_train_loss:0.0311594\tV_train_syn_loss:1.1194919\tV_train_loss:0.1574698\t  V_star_val_loss:7.0336825\t  V_val_loss:6.9385276\n",
      "06/14 08:58:05 PM |\t   45.5%:\t  W_train_loss:0.0568255\tV_train_syn_loss:1.0997551\tV_train_loss:0.2708388\t  V_star_val_loss:6.2392449\t  V_val_loss:6.1154391\n",
      "06/14 08:58:24 PM |\t   72.7%:\t  W_train_loss:0.0578638\tV_train_syn_loss:1.1797912\tV_train_loss:0.2887067\t  V_star_val_loss:6.6529067\t  V_val_loss:6.4709970\n",
      "06/14 08:58:42 PM |\t  1e+02%:\t  W_train_loss:0.0489660\tV_train_syn_loss:1.3177385\tV_train_loss:0.2388046\t  V_star_val_loss:7.6818671\t  V_val_loss:7.5363987\n",
      "06/14 08:58:42 PM |\t  w_train_loss:0.5844442415982485,v_train_loss:8.508894681930542\n",
      "06/14 08:58:42 PM |\t  \n",
      "\n",
      "  ----------------epoch:30,\t\tlr_w:1.856211592101754e-09,\t\tlr_v:1.856211592101754e-09,\t\tlr_A:1.856211592101754e-09----------------\n",
      "06/14 08:58:42 PM |\t  split size:[4, 8, 0, 4]\n",
      "06/14 08:59:00 PM |\t   18.2%:\t  W_train_loss:0.0311553\tV_train_syn_loss:1.1371457\tV_train_loss:0.1574519\t  V_star_val_loss:7.0288553\t  V_val_loss:6.9385370\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_99560/877182758.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"\\n\\n  ----------------epoch:{epoch},\\t\\tlr_w:{lr_w},\\t\\tlr_v:{lr_v},\\t\\tlr_A:{lr_A}----------------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mw_train_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv_train_loss\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mmy_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_v\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0marchitect\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_optimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv_optimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr_w\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr_v\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtot_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mscheduler_w\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_99560/152604624.py\u001b[0m in \u001b[0;36mmy_train\u001b[1;34m(epoch, _dataloader, validdataloader, w_model, v_model, architect, A, w_optimizer, v_optimizer, lr_w, lr_v, tot_iter)\u001b[0m\n\u001b[0;32m     55\u001b[0m             \u001b[0mepsilon_w\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munrolled_w_lr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m             \u001b[0mepsilon_v\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munrolled_v_lr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m             v_star_val_loss = architect.step(input_w,  output_w, input_w_attn, output_w_attn, w_optimizer,\n\u001b[0m\u001b[0;32m     58\u001b[0m                                              \u001b[0minput_v\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_v_attn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_v\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_v_attn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_syn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_syn_attn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m                                              \u001b[0minput_A_v\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_A_v_attn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_A_v\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_A_v_attn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv_optimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mg:\\GitCode\\Self-teaching-for-machine-translation\\T5_scratch\\architect.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, input_w, output_w, input_w_attn, output_w_attn, w_optimizer, input_v, input_v_attn, output_v, output_v_attn, input_syn, input_syn_attn, input_A_v, input_A_v_attn, output_A_v, output_A_v_attn, v_optimizer, attn_idx, lr_w, lr_v)\u001b[0m\n\u001b[0;32m    182\u001b[0m         \u001b[0mvector_s_dash\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0munrolled_v_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m         implicit_grads_A = self._outer_A(vector_s_dash, input_w, output_w, input_w_attn,\n\u001b[0m\u001b[0;32m    185\u001b[0m                                          output_w_attn, input_v, input_v_attn, attn_idx, unrolled_w_model, lr_w, lr_v)\n\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mg:\\GitCode\\Self-teaching-for-machine-translation\\T5_scratch\\architect.py\u001b[0m in \u001b[0;36m_outer_A\u001b[1;34m(self, vector_s_dash, w_input, w_target, w_input_attn, w_target_attn, input_v, input_v_attn, attn_idx, unrolled_w_model, eta_w, eta_v, r)\u001b[0m\n\u001b[0;32m    244\u001b[0m             \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mR1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 246\u001b[1;33m         loss_aug_m = calc_loss_aug(\n\u001b[0m\u001b[0;32m    247\u001b[0m             input_v, input_v_attn, unrolled_w_model, self.v_model)\n\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mg:\\GitCode\\Self-teaching-for-machine-translation\\T5_scratch\\losses.py\u001b[0m in \u001b[0;36mcalc_loss_aug\u001b[1;34m(input_syn_ids, input_syn_attn, w_model, v_model)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcalc_loss_aug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_syn_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_syn_attn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[0mw_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mturnoff_dropout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m     \u001b[0moutput_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_syn_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_beams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;31m# print(output_ids)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[0matt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0moutput_ids\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mg:\\GitCode\\Self-teaching-for-machine-translation\\T5_scratch\\T5.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, input_ids, num_beams, max_length)\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_beams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0moutput_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_beams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_beams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlength_penalty\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m0.6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrepetition_penalty\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cache\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;31m## sampling with top_p\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, typical_p, repetition_penalty, bad_words_ids, force_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, stopping_criteria, constraints, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, exponential_decay_length_penalty, **model_kwargs)\u001b[0m\n\u001b[0;32m   1252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1253\u001b[0m             \u001b[1;31m# 10. run greedy search\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1254\u001b[1;33m             return self.greedy_search(\n\u001b[0m\u001b[0;32m   1255\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogits_processor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\generation_utils.py\u001b[0m in \u001b[0;36mgreedy_search\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[0;32m   1636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1637\u001b[0m             \u001b[1;31m# forward pass to get next token\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1638\u001b[1;33m             outputs = self(\n\u001b[0m\u001b[0;32m   1639\u001b[0m                 \u001b[1;33m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1640\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1637\u001b[0m         \u001b[1;31m# Decode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1638\u001b[1;33m         decoder_outputs = self.decoder(\n\u001b[0m\u001b[0;32m   1639\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1640\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecoder_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1031\u001b[0m                 )\n\u001b[0;32m   1032\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1033\u001b[1;33m                 layer_outputs = layer_module(\n\u001b[0m\u001b[0;32m   1034\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1035\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[0;32m    718\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m         \u001b[1;31m# Apply Feed Forward layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 720\u001b[1;33m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    721\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    722\u001b[0m         \u001b[1;31m# clamp inf values to enable fp16 training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    326\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m         \u001b[0mforwarded_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m         \u001b[0mforwarded_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDenseReluDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforwarded_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    329\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhidden_states\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforwarded_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    305\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhidden_gelu\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mhidden_linear\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1846\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1847\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# if(args.valid_begin==1):\n",
    "#     my_test(valid_dataloader,model_w,-1) #before train\n",
    "#     my_test(valid_dataloader,model_v,-1)  \n",
    "\n",
    "tot_iter = [0]\n",
    "for epoch in range(args.epochs):\n",
    "    lr_w = scheduler_w.get_lr()[0]\n",
    "    lr_v = scheduler_v.get_lr()[0]\n",
    "    lr_A = architect.scheduler_A.get_lr()[0]\n",
    "\n",
    "    logging.info(f\"\\n\\n  ----------------epoch:{epoch},\\t\\tlr_w:{lr_w},\\t\\tlr_v:{lr_v},\\t\\tlr_A:{lr_A}----------------\")\n",
    "\n",
    "    w_train_loss,v_train_loss =  my_train(epoch, train_dataloader, valid_dataloader, model_w, model_v,  architect, A, w_optimizer, v_optimizer, lr_w,lr_v,tot_iter)\n",
    "    \n",
    "    scheduler_w.step()\n",
    "    scheduler_v.step()\n",
    "    architect.scheduler_A.step()\n",
    "\n",
    "\n",
    "    logging.info(f\"w_train_loss:{w_train_loss},v_train_loss:{v_train_loss}\")\n",
    "    # wandb.log({'w_train_loss': w_train_loss, 'v_train_loss':v_train_loss})\n",
    "\n",
    "\n",
    "\n",
    "torch.save(model_v,'./model/'+now+'model_w.pt')\n",
    "torch.save(model_v,'./model/'+now+'model_v.pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 256,    3, 1050, 2494,    1]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 256,    3, 1050, 2494,    1]], device='cuda:0')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x  = tokenize(['im kevin'],tokenizer,512,True)[0]\n",
    "print(x)\n",
    "x = torch.tensor(x,device='cuda')\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,    6,  256,    3, 1050, 2494,    6,  256,    3, 1050, 2494,    6,\n",
       "          256,    3, 1050, 2494,    6,  256,    3, 1050, 2494,    6,  256,    3,\n",
       "         1050, 2494,    6,  256,    3, 1050, 2494,    6,  256,    3, 1050, 2494,\n",
       "            6,  256,    3, 1050, 2494,    6,  256,    3, 1050, 2494,    6,  256,\n",
       "            3, 1050, 2494,    6,  256,    3, 1050, 2494,    6,  256,    3, 1050,\n",
       "         2494,    6,  256,    3]], device='cuda:0')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w.model.generate(input_ids = x, num_beams = 4, early_stopping = True, max_length = max_length, length_penalty =0.6, repetition_penalty = 0.8, use_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'main_v.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_175828/2885071301.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mm1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'main_v.pt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mm1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mm2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'unrolled_v.pt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mm2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'encoding'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 594\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    595\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m             \u001b[1;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'w'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'main_v.pt'"
     ]
    }
   ],
   "source": [
    "m1 = torch.load('main_v.pt')\n",
    "m1.eval()\n",
    "m2 = torch.load('unrolled_v.pt')\n",
    "m2.eval()\n",
    "''\n",
    "for k1, k2 in zip(m1.state_dict(), m2.state_dict()):\n",
    "    v1= m1.state_dict()[k1]\n",
    "    v2= m2.state_dict()[k2]\n",
    "    print(k1,k2)\n",
    "    # print(v1,v2)\n",
    "    print((abs(v1.data-v2.data)).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(1)\n",
    "a.add(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('python38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d33c3b0ef123e851f98887a8750ca7da758e4ff258891935cfe6ff9c0394387"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
