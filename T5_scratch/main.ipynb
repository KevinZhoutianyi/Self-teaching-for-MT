{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd() \n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from T5 import *\n",
    "import torch\n",
    "from datasets import load_dataset,load_metric\n",
    "from transformers import T5Tokenizer,AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import torch_optimizer as optim\n",
    "from transformers.optimization import Adafactor, AdafactorSchedule\n",
    "from MT_hyperparams import seed_,max_length,target_language\n",
    "import torch.backends.cudnn as cudnn\n",
    "from utils import *\n",
    "from attention_params import *\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, SubsetRandomSampler\n",
    "from torch.autograd import Variable\n",
    "from losses import *\n",
    "from architect import *\n",
    "import logging\n",
    "import sys\n",
    "import transformers\n",
    "import time\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(\"main\")\n",
    "\n",
    "\n",
    "parser.add_argument('--valid_num_points', type=int,             default = 100, help='validation data number')\n",
    "parser.add_argument('--train_num_points', type=int,             default = 200, help='train data number')\n",
    "parser.add_argument('--test_num_points', type=int,              default = 50, help='train data number')\n",
    "\n",
    "parser.add_argument('--batch_size', type=int,                   default=16,     help='Batch size')\n",
    "parser.add_argument('--train_w_num_points', type=int,           default=4,      help='train_w_num_points for each batch')\n",
    "parser.add_argument('--train_v_synthetic_num_points', type=int, default=4,      help='train_v_synthetic_num_points for each batch')\n",
    "parser.add_argument('--train_v_num_points', type=int,           default=4,      help='train_v_num_points for each batch')\n",
    "parser.add_argument('--train_A_num_points', type=int,           default=4,      help='train_A_num_points decay for each batch')\n",
    "\n",
    "parser.add_argument('--gpu', type=int,                          default=0,      help='gpu device id')\n",
    "parser.add_argument('--num_workers', type=int,                  default=0,      help='num_workers')\n",
    "parser.add_argument('--model_name_teacher', type=str,           default='google/t5-small-lm-adapt',      help='model_name')\n",
    "parser.add_argument('--model_name_student', type=str,           default='google/t5-small-lm-adapt',      help='model_name')\n",
    "parser.add_argument('--exp_name', type=str,                     default='T5spec',      help='experiment name')\n",
    "parser.add_argument('--rep_num', type=int,                      default=50,      help='report times for 1 epoch')\n",
    "parser.add_argument('--test_num', type=int,                     default=2000,      help='test times for 1 epoch')\n",
    "\n",
    "parser.add_argument('--epochs', type=int,                       default=500,     help='num of training epochs')\n",
    "parser.add_argument('--pre_epochs', type=int,                   default=0,      help='train model W for x epoch first')\n",
    "parser.add_argument('--grad_clip', type=float,                  default=1,      help='gradient clipping')\n",
    "parser.add_argument('--grad_acc_count', type=float,             default=-1,      help='gradient accumulate steps')\n",
    "\n",
    "parser.add_argument('--w_lr', type=float,                       default=1e-3,   help='learning rate for w')\n",
    "parser.add_argument('--unrolled_w_lr', type=float,              default=1e-3,   help='learning rate for w')\n",
    "parser.add_argument('--v_lr', type=float,                       default=1e-3,   help='learning rate for v')\n",
    "parser.add_argument('--unrolled_v_lr', type=float,              default=1e-3,   help='learning rate for v')\n",
    "parser.add_argument('--A_lr', type=float,                       default=1e-2,   help='learning rate for A')\n",
    "parser.add_argument('--learning_rate_min', type=float,          default=1e-8,   help='learning_rate_min')\n",
    "parser.add_argument('--decay', type=float,                      default=1e-3,   help='weight decay')\n",
    "parser.add_argument('--beta1', type=float,                      default=0.9,    help='momentum')\n",
    "parser.add_argument('--beta2', type=float,                      default=0.98,    help='momentum')\n",
    "parser.add_argument('--warm', type=float,                       default=10,    help='warmup step')\n",
    "parser.add_argument('--num_step_lr', type=float,                default=1,    help='warmup step')\n",
    "parser.add_argument('--decay_lr', type=float,                   default=0.7,    help='warmup step')\n",
    "# parser.add_argument('--smoothing', type=float,                  default=0.1,    help='labelsmoothing')\n",
    "\n",
    "\n",
    "parser.add_argument('--traindata_loss_ratio', type=float,       default=0,    help='human translated data ratio')\n",
    "parser.add_argument('--syndata_loss_ratio', type=float,         default=1,    help='augmented dataset ratio')\n",
    "\n",
    "parser.add_argument('--valid_begin', type=int,                  default=1,      help='whether valid before train')\n",
    "parser.add_argument('--train_A', type=int,                      default=1 ,     help='whether train A')\n",
    "\n",
    "\n",
    "\n",
    "args = parser.parse_args(args=[])#(args=['--batch_size', '8',  '--no_cuda'])#used in ipynb\n",
    "args.test_num = args.test_num//args.batch_size * args.batch_size\n",
    "args.rep_num = args.rep_num//args.batch_size * args.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33monlydrinkwater\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.18 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.17"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>g:\\GitCode\\Self-teaching-for-machine-translation\\T5_scratch\\wandb\\run-20220614_111448-2n9wc2pq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/onlydrinkwater/Selftraining/runs/2n9wc2pq\" target=\"_blank\">T5spec</a></strong> to <a href=\"https://wandb.ai/onlydrinkwater/Selftraining\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/onlydrinkwater/Selftraining/runs/2n9wc2pq?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x14031c5f790>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://wandb.ai/ check the running status online\n",
    "import wandb\n",
    "os.environ['WANDB_API_KEY']='a166474b1b7ad33a0549adaaec19a2f6d3f91d87'\n",
    "os.environ['WANDB_NAME']=args.exp_name\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "wandb.init(project=\"Selftraining\",config=args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/14 11:14:56 AM |\t  Reusing dataset wmt14 (C:\\Users\\kevin\\.cache\\huggingface\\datasets\\wmt14\\de-en\\1.0.0\\d239eaf0ff090d28da19b6bc9758e24634d84de0a1ef092f0b5c54e6f132d7e2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 32.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/14 11:14:56 AM |\t  Namespace(A_lr=0.01, batch_size=16, beta1=0.9, beta2=0.98, decay=0.001, decay_lr=0.7, epochs=500, exp_name='T5spec', gpu=0, grad_acc_count=-1, grad_clip=1, learning_rate_min=1e-08, model_name_student='google/t5-small-lm-adapt', model_name_teacher='google/t5-small-lm-adapt', num_step_lr=1, num_workers=0, pre_epochs=0, rep_num=48, syndata_loss_ratio=1, test_num=2000, train_A=1, train_A_num_points=4, train_num_points=200, train_v_num_points=4, train_v_synthetic_num_points=4, train_w_num_points=4, traindata_loss_ratio=0, unrolled_v_lr=0.001, unrolled_w_lr=0.001, v_lr=0.001, valid_begin=1, valid_num_points=100, w_lr=0.001, warm=10)\n",
      "06/14 11:14:56 AM |\t  DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 4508785\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 3000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 3003\n",
      "    })\n",
      "})\n",
      "06/14 11:14:56 AM |\t  {'translation': {'de': 'Ich bitte Sie, sich zu einer Schweigeminute zu erheben.', 'en': \"Please rise, then, for this minute' s silence.\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# logging file\n",
    "now = time.strftime(\"%Y-%m-%d-%H_%M_%S\", time.localtime(time.time()))\n",
    "\n",
    "log_format = '%(asctime)s |\\t  %(message)s'\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO,\n",
    "                    format=log_format, datefmt='%m/%d %I:%M:%S %p')\n",
    "fh = logging.FileHandler(os.path.join(\n",
    "    \"./log/\", now+'.txt'), 'w', encoding=\"UTF-8\")\n",
    "fh.setFormatter(logging.Formatter(log_format))\n",
    "logging.getLogger().addHandler(fh)\n",
    "dataset = load_dataset('wmt14', 'de-en')\n",
    "\n",
    "logging.info(args)\n",
    "logging.info(dataset)\n",
    "logging.info(dataset['train'][5])\n",
    "\n",
    "\n",
    "# Setting the seeds\n",
    "np.random.seed(seed_)\n",
    "torch.cuda.set_device(args.gpu)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cudnn.benchmark = True\n",
    "torch.manual_seed(seed_)\n",
    "cudnn.enabled = True\n",
    "torch.cuda.manual_seed(seed_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/14 11:14:58 AM |\t  modelsize:76.961152MB\n",
      "06/14 11:15:00 AM |\t  modelsize:76.961152MB\n"
     ]
    }
   ],
   "source": [
    "modelname = args.model_name_teacher\n",
    "pretrained  =  AutoModelForSeq2SeqLM.from_pretrained(modelname)\n",
    "pathname = modelname.replace('/','')\n",
    "logging.info(f'modelsize:{count_parameters_in_MB(pretrained)}MB')\n",
    "torch.save(pretrained,pathname+'.pt')\n",
    "\n",
    "modelname = args.model_name_student\n",
    "pretrained  =  AutoModelForSeq2SeqLM.from_pretrained(modelname)\n",
    "pathname = modelname.replace('/','')\n",
    "logging.info(f'modelsize:{count_parameters_in_MB(pretrained)}MB')\n",
    "torch.save(pretrained,pathname+'.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/14 11:15:10 AM |\t  Loading cached shuffled indices for dataset at C:\\Users\\kevin\\.cache\\huggingface\\datasets\\wmt14\\de-en\\1.0.0\\d239eaf0ff090d28da19b6bc9758e24634d84de0a1ef092f0b5c54e6f132d7e2\\cache-fcff064badad2159.arrow\n",
      "06/14 11:15:10 AM |\t  Loading cached shuffled indices for dataset at C:\\Users\\kevin\\.cache\\huggingface\\datasets\\wmt14\\de-en\\1.0.0\\d239eaf0ff090d28da19b6bc9758e24634d84de0a1ef092f0b5c54e6f132d7e2\\cache-ef861152e003e0c7.arrow\n",
      "06/14 11:15:10 AM |\t  train len: 192\n",
      "06/14 11:15:10 AM |\t  train_w_num_points_len: 48\n",
      "06/14 11:15:10 AM |\t  train_v_synthetic_num_points_len: 48\n",
      "06/14 11:15:10 AM |\t  train_v_num_points_len: 48\n",
      "06/14 11:15:10 AM |\t  train_A_num_points_len: 48\n",
      "06/14 11:15:10 AM |\t  valid len: 100\n",
      "06/14 11:15:10 AM |\t  {'de': 'Dank unseres Personals und Geräteparks sind wir täglich rund um die Uhr in der Lage, uns allen erdenklichen Herausforderungen zu stellen.', 'en': 'translate English to German: Our staff and equipment stands ready to answer any challenges 24/7.'}\n",
      "06/14 11:15:10 AM |\t  {'de': 'Diese Entscheidung rief in der Öffentlichkeit eine lebhafte Diskussion hervor.', 'en': 'translate English to German: The resolution caused lively public debate.'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# preprocess the data, make a dataloader\n",
    "import random\n",
    "modelname = args.model_name_teacher\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelname)\n",
    "criterion = torch.nn.CrossEntropyLoss( reduction='none')#teacher shouldn't have label smoothing, especially when student got same size.\n",
    "criterion_v = torch.nn.CrossEntropyLoss( reduction='none')#,label_smoothing=args.smoothing) #without LS, V may be too confident to that syn data, and LS do well for real data also.\n",
    "\n",
    "\n",
    "\n",
    "train = dataset['train'].shuffle(seed=seed_).select(range(args.train_num_points))\n",
    "valid = dataset['validation'].shuffle(seed=seed_).select(range(args.valid_num_points))\n",
    "test = dataset['test'].shuffle(seed=seed_).select(range(args.test_num_points))#[L_t+L_v:L_t+L_v+L_test]\n",
    "train = train['translation']\n",
    "valid = valid['translation']\n",
    "test = test['translation']\n",
    "def preprocess(dat):\n",
    "    for t in dat:\n",
    "        t['en'] = \"translate English to German: \" + t['en']  #needed for T5\n",
    "preprocess(train)\n",
    "preprocess(valid)\n",
    "preprocess(test)\n",
    "#TODO: Syn_input should be monolingual data, should try en-fo's en. cuz wmt may align\n",
    "num_batch = args.train_num_points//args.batch_size\n",
    "train = train[:args.batch_size*num_batch]\n",
    "logging.info(\"train len: %d\",len(train))\n",
    "\n",
    "'''\n",
    "each mini batch consist of : \n",
    "1. data to train W\n",
    "2. monolingual data to generate parallel data\n",
    "3. data to train V\n",
    "4. data to train A\n",
    "'''\n",
    "train_w_num_points_len = num_batch * args.train_w_num_points\n",
    "train_v_synthetic_num_points_len = num_batch * args.train_v_synthetic_num_points\n",
    "train_v_num_points_len = num_batch * args.train_v_num_points\n",
    "train_A_num_points_len = num_batch * args.train_A_num_points\n",
    "logging.info(\"train_w_num_points_len: %d\",train_w_num_points_len)\n",
    "logging.info(\"train_v_synthetic_num_points_len: %d\",train_v_synthetic_num_points_len)\n",
    "logging.info(\"train_v_num_points_len: %d\",train_v_num_points_len)\n",
    "logging.info(\"train_A_num_points_len: %d\",train_A_num_points_len)\n",
    "\n",
    "attn_idx_list = torch.arange(train_w_num_points_len).cuda()\n",
    "logging.info(\"valid len: %d\",len(valid))\n",
    "logging.info(\"test len: %d\" ,len(test))\n",
    "logging.info(train[2])\n",
    "logging.info(valid[2])\n",
    "# logging.info(test[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get train data start\n",
      "get train data end\n",
      "06/14 11:15:27 AM |\t  train data get\n",
      "06/14 11:15:27 AM |\t  train data loader get\n",
      "06/14 11:15:27 AM |\t  valid data loader get\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11400/4096697347.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m                         batch_size=args.batch_size, pin_memory=args.num_workers>0, num_workers=args.num_workers)\n\u001b[0;32m     10\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'valid data loader get'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mtest_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_aux_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m# Create the DataLoader for our training set.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m test_dataloader = DataLoader(test_data, sampler=SequentialSampler(test_data),\n\u001b[0;32m     13\u001b[0m                         batch_size=args.batch_size, pin_memory=args.num_workers>0, num_workers=args.num_workers)#, sampler=RandomSampler(test_data)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "target_language  = 'de'\n",
    "train_data = get_train_Dataset(train, tokenizer)# Create the DataLoader for our training set.\n",
    "logging.info('train data get')\n",
    "train_dataloader = DataLoader(train_data, sampler= SequentialSampler(train_data), \n",
    "                        batch_size=args.batch_size, pin_memory=args.num_workers>0, num_workers=args.num_workers)\n",
    "logging.info('train data loader get')\n",
    "valid_data = get_aux_dataset(valid, tokenizer)# Create the DataLoader for our training set.\n",
    "valid_dataloader = DataLoader(valid_data, sampler=SequentialSampler(valid_data), \n",
    "                        batch_size=args.batch_size, pin_memory=args.num_workers>0, num_workers=args.num_workers)\n",
    "logging.info('valid data loader get')\n",
    "test_data = get_aux_dataset(test, tokenizer)# Create the DataLoader for our training set.\n",
    "test_dataloader = DataLoader(test_data, sampler=SequentialSampler(test_data),\n",
    "                        batch_size=args.batch_size, pin_memory=args.num_workers>0, num_workers=args.num_workers)#, sampler=RandomSampler(test_data)\n",
    "logging.info('test data loader get')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "A = attention_params(train_w_num_points_len)#half of train regarded as u\n",
    "A = A.cuda()\n",
    "\n",
    "\n",
    "\n",
    "# TODO: model loaded from saved model\n",
    "model_w = T5(criterion=criterion, tokenizer= tokenizer, args = args, name = 'model_w_in_main')\n",
    "model_w = model_w.cuda()\n",
    "w_optimizer = torch.optim.Adam(model_w.parameters(),  lr= args.w_lr ,  betas=(args.beta1, args.beta2) ,eps=1e-9 )\n",
    "# w_optimizer = Adafactor(model_w.parameters(), lr = args.w_lr ,scale_parameter=False, relative_step=False , warmup_init=False,clip_threshold=1,beta1=0,eps=( 1e-30,0.001))\n",
    "scheduler_w  =   StepLR(w_optimizer, step_size=args.num_step_lr, gamma=args.decay_lr)\n",
    "# scheduler_w  = Scheduler(w_optimizer,dim_embed=512, warmup_steps=args.warm, initlr = args.w_lr)\n",
    "\n",
    "\n",
    "\n",
    "model_v = T5(criterion=criterion_v, tokenizer= tokenizer, args = args, name = 'model_v_in_main')\n",
    "model_v = model_v.cuda()\n",
    "v_optimizer = torch.optim.Adam(model_v.parameters(),  lr= args.v_lr ,  betas=(args.beta1,args.beta2) ,eps=1e-9  )\n",
    "# v_optimizer =Adafactor(model_v.parameters(), lr = args.v_lr ,scale_parameter=False, relative_step=False , warmup_init=False,clip_threshold=1,beta1=0,eps=( 1e-30,0.001))\n",
    "scheduler_v  =   StepLR(v_optimizer, step_size=args.num_step_lr, gamma=args.decay_lr)\n",
    "# scheduler_v  = Scheduler(v_optimizer,dim_embed=512, warmup_steps=args.warm, initlr = args.v_lr)\n",
    "\n",
    "\n",
    "architect = Architect(model_w, model_v,  A, args)\n",
    "scheduler_A  =   StepLR(architect.optimizer_A, step_size=args.num_step_lr, gamma=args.decay_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def my_test(_dataloader,model,epoch):\n",
    "    # logging.info(f\"GPU mem before test:{getGPUMem(device)}%\")\n",
    "    acc = 0\n",
    "    counter = 0\n",
    "    model.eval()\n",
    "    metric_sacrebleu =  load_metric('sacrebleu')\n",
    "    # metric_bleu =  load_metric('bleu')\n",
    "    \n",
    "    for step, batch in enumerate(_dataloader):\n",
    "        \n",
    "        test_dataloaderx = Variable(batch[0], requires_grad=False).to(device, non_blocking=False)[:args.train_w_num_points]\n",
    "        test_dataloaderx_attn = Variable(batch[1], requires_grad=False).to(device, non_blocking=False)[:args.train_w_num_points]\n",
    "        test_dataloadery = Variable(batch[2], requires_grad=False).to(device, non_blocking=False)[:args.train_w_num_points]\n",
    "        test_dataloadery_attn = Variable(batch[3], requires_grad=False).to(device, non_blocking=False)[:args.train_w_num_points]\n",
    "        ls = my_loss(test_dataloaderx,test_dataloaderx_attn,test_dataloadery,test_dataloadery_attn,model)\n",
    "        acc+= ls.item()\n",
    "        counter+= 1\n",
    "        pre = model.generate(test_dataloaderx)\n",
    "        x_decoded = tokenizer.batch_decode(test_dataloaderx,skip_special_tokens=True)\n",
    "        pred_decoded = tokenizer.batch_decode(pre,skip_special_tokens=True)\n",
    "        label_decoded =  tokenizer.batch_decode(test_dataloadery,skip_special_tokens=True)\n",
    "        \n",
    "        pred_str = [x  for x in pred_decoded]\n",
    "        label_str = [[x] for x in label_decoded]\n",
    "        # pred_list = [x.split()  for x in pred_decoded]\n",
    "        # label_list = [[x.split()] for x in label_decoded]\n",
    "        metric_sacrebleu.add_batch(predictions=pred_str, references=label_str)\n",
    "        # metric_bleu.add_batch(predictions=pred_list, references=label_list)\n",
    "        if  step==0:\n",
    "            logging.info(f'x_decoded[:2]:{x_decoded[:2]}')\n",
    "            logging.info(f'pred_decoded[:2]:{pred_decoded[:2]}')\n",
    "            logging.info(f'label_decoded[:2]:{label_decoded[:2]}')\n",
    "            \n",
    "            \n",
    "    logging.info('computing score...') \n",
    "    sacrebleu_score = metric_sacrebleu.compute()\n",
    "    # bleu_score = metric_bleu.compute()\n",
    "    logging.info('%s sacreBLEU : %f',model.name,sacrebleu_score['score'])#TODO:bleu may be wrong cuz max length\n",
    "    # logging.info('%s BLEU : %f',model.name,bleu_score['bleu'])\n",
    "    logging.info('%s test loss : %f',model.name,acc/(counter))\n",
    "    wandb.log({'sacreBLEU'+model.name: sacrebleu_score['score']})\n",
    "    wandb.log({'test_loss'+model.name: acc/counter})\n",
    "    # del test_dataloaderx,acc,counter,test_dataloaderx_attn,sacrebleu_score,bleu_score,test_dataloadery,test_dataloadery_attn,ls,pre,x_decoded,pred_decoded,label_decoded,pred_str,label_str,pred_list,label_list\n",
    "    # gc.collect()\n",
    "    # torch.cuda.empty_cache()\n",
    "    model.train()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_train(epoch, _dataloader, validdataloader, w_model, v_model, architect, A, w_optimizer, v_optimizer, lr_w, lr_v, tot_iter):\n",
    "\n",
    "    objs_w = AvgrageMeter()\n",
    "    objs_v_syn = AvgrageMeter()\n",
    "    objs_v_train = AvgrageMeter()\n",
    "    objs_v_star_val = AvgrageMeter()\n",
    "    objs_v_val = AvgrageMeter()\n",
    "    v_trainloss_acc = 0\n",
    "    w_trainloss_acc = 0\n",
    "    # now  train_x is [num of batch, datasize], so its seperate batch for the code below\n",
    "    wsize = args.train_w_num_points\n",
    "    synsize = args.train_v_synthetic_num_points\n",
    "    vsize = args.train_v_num_points\n",
    "    vtrainsize = vsize+synsize\n",
    "    vtrainsize_total = train_v_num_points_len+train_v_synthetic_num_points_len\n",
    "    Asize = args.train_A_num_points\n",
    "    loader_len = len(_dataloader)\n",
    "    split_size = [wsize, synsize, vsize, Asize]\n",
    "    bs = args.batch_size\n",
    "    w_model.train()\n",
    "    v_model.train()\n",
    "\n",
    "    logging.info(f\"split size:{split_size}\")\n",
    "    for step, batch in enumerate(_dataloader):\n",
    "        tot_iter[0] += bs\n",
    "        \n",
    "\n",
    "        # logging.info(f\"GPU mem :{getGPUMem(device)}%\")\n",
    "        train_x = Variable(batch[0], requires_grad=False).to(\n",
    "            device, non_blocking=False)\n",
    "        train_x_attn = Variable(batch[1], requires_grad=False).to(\n",
    "            device, non_blocking=False)\n",
    "        train_y = Variable(batch[2], requires_grad=False).to(\n",
    "            device, non_blocking=False)\n",
    "        train_y_attn = Variable(batch[3], requires_grad=False).to(\n",
    "            device, non_blocking=False)\n",
    "        (input_w, input_syn, input_v, input_A_v) = torch.split(train_x, split_size)\n",
    "        (input_w_attn, input_syn_attn, input_v_attn,\n",
    "         input_A_v_attn) = torch.split(train_x_attn, split_size)\n",
    "        (output_w, _, output_v, output_A_v) = torch.split(train_y, split_size)\n",
    "        (output_w_attn, _, output_v_attn, output_A_v_attn) = torch.split(\n",
    "            train_y_attn, split_size)\n",
    "        attn_idx = attn_idx_list[wsize*step:(wsize*step+wsize)]\n",
    "\n",
    "\n",
    "        # if (args.train_A == 1):\n",
    "        #     epsilon_w = args.unrolled_w_lr\n",
    "        #     epsilon_v  = args.unrolled_v_lr\n",
    "        #     v_star_val_loss = architect.step(input_w,  output_w, input_w_attn, output_w_attn, w_optimizer,\n",
    "        #                                      input_v, input_v_attn, output_v, output_v_attn, input_syn, input_syn_attn,\n",
    "        #                                      input_A_v, input_A_v_attn, output_A_v, output_A_v_attn, v_optimizer,\n",
    "        #                                      attn_idx, epsilon_w, epsilon_v)\n",
    "        #     objs_v_star_val.update(v_star_val_loss, Asize)\n",
    "\n",
    "        w_optimizer.zero_grad()\n",
    "   \n",
    "        loss_w = CTG_loss(input_w, input_w_attn, output_w,\n",
    "                          output_w_attn, attn_idx, A, w_model)\n",
    "        w_trainloss_acc += loss_w.item()\n",
    "        loss_w.backward()\n",
    "        objs_w.update(loss_w.item(), wsize)\n",
    "        w_optimizer.step()\n",
    "        # assert False\n",
    "\n",
    "\n",
    "        # v_optimizer.zero_grad()\n",
    "        # loss_aug = calc_loss_aug(input_syn, input_syn_attn, w_model, v_model)\n",
    "        # loss = my_loss2(input_v, input_v_attn, output_v,\n",
    "        #                 output_v_attn, v_model)\n",
    "        # v_loss = (args.traindata_loss_ratio*loss +\n",
    "        #           loss_aug*args.syndata_loss_ratio)\n",
    "        # v_trainloss_acc += v_loss.item()\n",
    "        # v_loss.backward()\n",
    "        # objs_v_syn.update(loss_aug.item(), synsize)\n",
    "        # objs_v_train.update(loss.item(), vsize)\n",
    "        # v_optimizer.step()\n",
    "\n",
    "        # with torch.no_grad():\n",
    "        #     valloss = my_loss2(input_A_v, input_A_v_attn,  output_A_v, output_A_v_attn,v_model)\n",
    "        #     objs_v_val.update(valloss.item(), Asize)\n",
    "\n",
    "        progress = 100*(step)/(loader_len-1)\n",
    "        if(tot_iter[0] % args.test_num == 0 and tot_iter[0] != 0):\n",
    "            my_test(validdataloader, model_w, epoch)\n",
    "            my_test(validdataloader, model_v, epoch)\n",
    "            logging.info(str((\"Attention Weights A : \", A.ReLU(A.alpha))))\n",
    "            torch.save(model_v,'./model/'+'model_w.pt')#+now+\n",
    "            torch.save(model_v,'./model/'+'model_v.pt')\n",
    "\n",
    "        if(tot_iter[0] % args.rep_num == 0 and tot_iter[0] != 0):\n",
    "            logging.info(f\"{progress:5.3}%:\\t  W_train_loss:{objs_w.avg:^.7f}\\tV_train_syn_loss:{objs_v_syn.avg:^.7f}\\tV_train_loss:{objs_v_train.avg:^.7f}\\t  V_star_val_loss:{objs_v_star_val.avg:^.7f}\\t  V_val_loss:{objs_v_val.avg:^.7f}\")\n",
    "            wandb.log({'W_train_loss': objs_w.avg})\n",
    "            wandb.log({'V_train_syn_loss': objs_v_syn.avg})\n",
    "            wandb.log({'V_train_loss': objs_v_train.avg})\n",
    "            wandb.log({'V_star_val_loss': objs_v_star_val.avg})\n",
    "            wandb.log({'V_val_loss': objs_v_val.avg})\n",
    "            objs_v_syn.reset()\n",
    "            objs_v_train.reset()\n",
    "            objs_w.reset()\n",
    "            objs_v_star_val.reset()\n",
    "            objs_v_val.reset()\n",
    "\n",
    "    return w_trainloss_acc, v_trainloss_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/13 11:39:50 PM |\t  \n",
      "\n",
      "  ----------------epoch:0,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:0.01----------------\n",
      "06/13 11:39:50 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:39:53 PM |\t   18.2%:\t  W_train_loss:5.7078438\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:39:54 PM |\t   45.5%:\t  W_train_loss:5.5725072\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:39:54 PM |\t   72.7%:\t  W_train_loss:4.9043355\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:39:55 PM |\t  1e+02%:\t  W_train_loss:5.3090471\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:39:55 PM |\t  w_train_loss:64.48120069503784,v_train_loss:0\n",
      "06/13 11:39:55 PM |\t  \n",
      "\n",
      "  ----------------epoch:1,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:0.01----------------\n",
      "06/13 11:39:55 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:39:55 PM |\t   18.2%:\t  W_train_loss:4.0835767\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:39:55 PM |\t   45.5%:\t  W_train_loss:4.1653383\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:39:56 PM |\t   72.7%:\t  W_train_loss:3.6981320\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:39:56 PM |\t  1e+02%:\t  W_train_loss:4.1165590\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:39:56 PM |\t  w_train_loss:48.190818071365356,v_train_loss:0\n",
      "06/13 11:39:56 PM |\t  \n",
      "\n",
      "  ----------------epoch:2,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:0.01----------------\n",
      "06/13 11:39:56 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:39:56 PM |\t   18.2%:\t  W_train_loss:3.3608380\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:39:57 PM |\t   45.5%:\t  W_train_loss:3.4827851\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:39:57 PM |\t   72.7%:\t  W_train_loss:2.6887694\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:39:58 PM |\t  1e+02%:\t  W_train_loss:3.1413479\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:39:58 PM |\t  w_train_loss:38.02122116088867,v_train_loss:0\n",
      "06/13 11:39:58 PM |\t  \n",
      "\n",
      "  ----------------epoch:3,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:0.01----------------\n",
      "06/13 11:39:58 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:39:58 PM |\t   18.2%:\t  W_train_loss:2.7765350\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:39:58 PM |\t   45.5%:\t  W_train_loss:2.8718516\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:39:59 PM |\t   72.7%:\t  W_train_loss:2.0588575\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:39:59 PM |\t  1e+02%:\t  W_train_loss:2.3889273\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:39:59 PM |\t  w_train_loss:30.288514494895935,v_train_loss:0\n",
      "06/13 11:39:59 PM |\t  \n",
      "\n",
      "  ----------------epoch:4,\t\tlr_w:0.001,\t\tlr_v:0.001,\t\tlr_A:0.01----------------\n",
      "06/13 11:39:59 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:40:00 PM |\t   18.2%:\t  W_train_loss:2.2937373\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:00 PM |\t   45.5%:\t  W_train_loss:2.4828014\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:00 PM |\t   72.7%:\t  W_train_loss:1.6404738\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:01 PM |\t  1e+02%:\t  W_train_loss:1.7847920\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:01 PM |\t  w_train_loss:24.60541331768036,v_train_loss:0\n",
      "06/13 11:40:01 PM |\t  \n",
      "\n",
      "  ----------------epoch:5,\t\tlr_w:0.0008100000000000001,\t\tlr_v:0.0008100000000000001,\t\tlr_A:0.01----------------\n",
      "06/13 11:40:01 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:40:01 PM |\t   18.2%:\t  W_train_loss:1.9228826\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:01 PM |\t   45.5%:\t  W_train_loss:1.9916063\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:02 PM |\t   72.7%:\t  W_train_loss:1.3821044\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:02 PM |\t  1e+02%:\t  W_train_loss:1.3044634\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:02 PM |\t  w_train_loss:19.803170323371887,v_train_loss:0\n",
      "06/13 11:40:02 PM |\t  \n",
      "\n",
      "  ----------------epoch:6,\t\tlr_w:0.0009000000000000001,\t\tlr_v:0.0009000000000000001,\t\tlr_A:0.01----------------\n",
      "06/13 11:40:02 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:40:03 PM |\t   18.2%:\t  W_train_loss:1.6329820\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:03 PM |\t   45.5%:\t  W_train_loss:1.7188037\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:03 PM |\t   72.7%:\t  W_train_loss:0.9948102\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:04 PM |\t  1e+02%:\t  W_train_loss:1.0583558\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:04 PM |\t  w_train_loss:16.214854836463928,v_train_loss:0\n",
      "06/13 11:40:04 PM |\t  \n",
      "\n",
      "  ----------------epoch:7,\t\tlr_w:0.0009000000000000001,\t\tlr_v:0.0009000000000000001,\t\tlr_A:0.01----------------\n",
      "06/13 11:40:04 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:40:04 PM |\t   18.2%:\t  W_train_loss:1.3155741\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:05 PM |\t   45.5%:\t  W_train_loss:1.4773236\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:05 PM |\t   72.7%:\t  W_train_loss:0.8920782\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:05 PM |\t  1e+02%:\t  W_train_loss:0.8989975\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:05 PM |\t  w_train_loss:13.751919984817505,v_train_loss:0\n",
      "06/13 11:40:05 PM |\t  \n",
      "\n",
      "  ----------------epoch:8,\t\tlr_w:0.0009000000000000001,\t\tlr_v:0.0009000000000000001,\t\tlr_A:0.01----------------\n",
      "06/13 11:40:05 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:40:06 PM |\t   18.2%:\t  W_train_loss:1.1996028\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:06 PM |\t   45.5%:\t  W_train_loss:1.2271801\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:07 PM |\t   72.7%:\t  W_train_loss:0.7792533\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:07 PM |\t  1e+02%:\t  W_train_loss:0.6779359\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:07 PM |\t  w_train_loss:11.65191638469696,v_train_loss:0\n",
      "06/13 11:40:07 PM |\t  \n",
      "\n",
      "  ----------------epoch:9,\t\tlr_w:0.0009000000000000001,\t\tlr_v:0.0009000000000000001,\t\tlr_A:0.01----------------\n",
      "06/13 11:40:07 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:40:07 PM |\t   18.2%:\t  W_train_loss:0.9897392\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:08 PM |\t   45.5%:\t  W_train_loss:1.0641876\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:08 PM |\t   72.7%:\t  W_train_loss:0.6179372\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:08 PM |\t  1e+02%:\t  W_train_loss:0.6315619\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:08 PM |\t  w_train_loss:9.910277664661407,v_train_loss:0\n",
      "06/13 11:40:08 PM |\t  \n",
      "\n",
      "  ----------------epoch:10,\t\tlr_w:0.000729,\t\tlr_v:0.000729,\t\tlr_A:0.01----------------\n",
      "06/13 11:40:08 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:40:09 PM |\t   18.2%:\t  W_train_loss:0.8316064\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:10 PM |\t  x_decoded[:2]:['translate English to German: A Republican strategy to counter the re-election of Obama', 'translate English to German: Republican leaders justified their policy by the need to combat electoral fraud.']\n",
      "06/13 11:40:10 PM |\t  pred_decoded[:2]:['Wiederaufnahme der Sitzungsperiode', 'Das war der Beschluß.']\n",
      "06/13 11:40:10 PM |\t  label_decoded[:2]:['Eine republikanische Strategie, um der Wiederwahl von Obama entgegenzutreten', 'Die Führungskräfte der Republikaner rechtfertigen ihre Politik mit der Notwendigkeit, den Wahlbetrug zu bekämpfen.']\n",
      "06/13 11:40:17 PM |\t  computing score...\n",
      "06/13 11:40:17 PM |\t  model_w_in_main sacreBLEU : 0.302568\n",
      "06/13 11:40:17 PM |\t  model_w_in_main test loss : 7.043092\n",
      "06/13 11:40:19 PM |\t  x_decoded[:2]:['translate English to German: A Republican strategy to counter the re-election of Obama', 'translate English to German: Republican leaders justified their policy by the need to combat electoral fraud.']\n",
      "06/13 11:40:19 PM |\t  pred_decoded[:2]:['.', 'In a letter to the Associated Press, the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported']\n",
      "06/13 11:40:19 PM |\t  label_decoded[:2]:['Eine republikanische Strategie, um der Wiederwahl von Obama entgegenzutreten', 'Die Führungskräfte der Republikaner rechtfertigen ihre Politik mit der Notwendigkeit, den Wahlbetrug zu bekämpfen.']\n",
      "06/13 11:40:26 PM |\t  computing score...\n",
      "06/13 11:40:26 PM |\t  model_v_in_main sacreBLEU : 0.194037\n",
      "06/13 11:40:26 PM |\t  model_v_in_main test loss : 5.270808\n",
      "06/13 11:40:26 PM |\t  ('Attention Weights A : ', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>))\n",
      "06/13 11:40:28 PM |\t   45.5%:\t  W_train_loss:0.9170178\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:28 PM |\t   72.7%:\t  W_train_loss:0.5650195\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:29 PM |\t  1e+02%:\t  W_train_loss:0.4481087\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:29 PM |\t  w_train_loss:8.285257488489151,v_train_loss:0\n",
      "06/13 11:40:29 PM |\t  \n",
      "\n",
      "  ----------------epoch:11,\t\tlr_w:0.0008100000000000001,\t\tlr_v:0.0008100000000000001,\t\tlr_A:0.01----------------\n",
      "06/13 11:40:29 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:40:29 PM |\t   18.2%:\t  W_train_loss:0.6630326\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:29 PM |\t   45.5%:\t  W_train_loss:0.6380525\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:30 PM |\t   72.7%:\t  W_train_loss:0.4513185\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:30 PM |\t  1e+02%:\t  W_train_loss:0.4062530\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:30 PM |\t  w_train_loss:6.475969821214676,v_train_loss:0\n",
      "06/13 11:40:30 PM |\t  \n",
      "\n",
      "  ----------------epoch:12,\t\tlr_w:0.0008100000000000001,\t\tlr_v:0.0008100000000000001,\t\tlr_A:0.01----------------\n",
      "06/13 11:40:30 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:40:31 PM |\t   18.2%:\t  W_train_loss:0.5677289\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:31 PM |\t   45.5%:\t  W_train_loss:0.6501823\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:31 PM |\t   72.7%:\t  W_train_loss:0.3421427\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:32 PM |\t  1e+02%:\t  W_train_loss:0.3853167\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:32 PM |\t  w_train_loss:5.836111932992935,v_train_loss:0\n",
      "06/13 11:40:32 PM |\t  \n",
      "\n",
      "  ----------------epoch:13,\t\tlr_w:0.0008100000000000001,\t\tlr_v:0.0008100000000000001,\t\tlr_A:0.01----------------\n",
      "06/13 11:40:32 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:40:32 PM |\t   18.2%:\t  W_train_loss:0.5046302\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:32 PM |\t   45.5%:\t  W_train_loss:0.5310071\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:33 PM |\t   72.7%:\t  W_train_loss:0.3037035\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:33 PM |\t  1e+02%:\t  W_train_loss:0.3117201\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:33 PM |\t  w_train_loss:4.953182578086853,v_train_loss:0\n",
      "06/13 11:40:33 PM |\t  \n",
      "\n",
      "  ----------------epoch:14,\t\tlr_w:0.0008100000000000001,\t\tlr_v:0.0008100000000000001,\t\tlr_A:0.01----------------\n",
      "06/13 11:40:33 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:40:34 PM |\t   18.2%:\t  W_train_loss:0.3877145\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:34 PM |\t   45.5%:\t  W_train_loss:0.4512895\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:34 PM |\t   72.7%:\t  W_train_loss:0.2563160\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:35 PM |\t  1e+02%:\t  W_train_loss:0.2358235\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:35 PM |\t  w_train_loss:3.9934303760528564,v_train_loss:0\n",
      "06/13 11:40:35 PM |\t  \n",
      "\n",
      "  ----------------epoch:15,\t\tlr_w:0.0006561000000000001,\t\tlr_v:0.0006561000000000001,\t\tlr_A:0.01----------------\n",
      "06/13 11:40:35 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:40:35 PM |\t   18.2%:\t  W_train_loss:0.4278477\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:35 PM |\t   45.5%:\t  W_train_loss:0.3920308\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:36 PM |\t   72.7%:\t  W_train_loss:0.2565738\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:36 PM |\t  1e+02%:\t  W_train_loss:0.2302515\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:36 PM |\t  w_train_loss:3.9201111644506454,v_train_loss:0\n",
      "06/13 11:40:36 PM |\t  \n",
      "\n",
      "  ----------------epoch:16,\t\tlr_w:0.000729,\t\tlr_v:0.000729,\t\tlr_A:0.01----------------\n",
      "06/13 11:40:36 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:40:37 PM |\t   18.2%:\t  W_train_loss:0.2815123\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:37 PM |\t   45.5%:\t  W_train_loss:0.3277882\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:37 PM |\t   72.7%:\t  W_train_loss:0.2173546\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:38 PM |\t  1e+02%:\t  W_train_loss:0.1324875\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:38 PM |\t  w_train_loss:2.8774276226758957,v_train_loss:0\n",
      "06/13 11:40:38 PM |\t  \n",
      "\n",
      "  ----------------epoch:17,\t\tlr_w:0.000729,\t\tlr_v:0.000729,\t\tlr_A:0.01----------------\n",
      "06/13 11:40:38 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:40:38 PM |\t   18.2%:\t  W_train_loss:0.3005124\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:39 PM |\t   45.5%:\t  W_train_loss:0.2554441\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:39 PM |\t   72.7%:\t  W_train_loss:0.1883514\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:39 PM |\t  1e+02%:\t  W_train_loss:0.2395353\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:39 PM |\t  w_train_loss:2.9515295922756195,v_train_loss:0\n",
      "06/13 11:40:39 PM |\t  \n",
      "\n",
      "  ----------------epoch:18,\t\tlr_w:0.000729,\t\tlr_v:0.000729,\t\tlr_A:0.01----------------\n",
      "06/13 11:40:39 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:40:40 PM |\t   18.2%:\t  W_train_loss:0.2211772\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:40 PM |\t   45.5%:\t  W_train_loss:0.2580864\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:41 PM |\t   72.7%:\t  W_train_loss:0.1324845\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:41 PM |\t  1e+02%:\t  W_train_loss:0.1196053\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:41 PM |\t  w_train_loss:2.194060131907463,v_train_loss:0\n",
      "06/13 11:40:41 PM |\t  \n",
      "\n",
      "  ----------------epoch:19,\t\tlr_w:0.000729,\t\tlr_v:0.000729,\t\tlr_A:0.01----------------\n",
      "06/13 11:40:41 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:40:41 PM |\t   18.2%:\t  W_train_loss:0.1904051\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:42 PM |\t   45.5%:\t  W_train_loss:0.1886793\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:42 PM |\t   72.7%:\t  W_train_loss:0.1252118\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:43 PM |\t  1e+02%:\t  W_train_loss:0.1264271\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:43 PM |\t  w_train_loss:1.892169788479805,v_train_loss:0\n",
      "06/13 11:40:43 PM |\t  \n",
      "\n",
      "  ----------------epoch:20,\t\tlr_w:0.00059049,\t\tlr_v:0.00059049,\t\tlr_A:0.01----------------\n",
      "06/13 11:40:43 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:40:43 PM |\t   18.2%:\t  W_train_loss:0.1783064\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:43 PM |\t   45.5%:\t  W_train_loss:0.2038905\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:44 PM |\t   72.7%:\t  W_train_loss:0.1459425\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:40:45 PM |\t  x_decoded[:2]:['translate English to German: A Republican strategy to counter the re-election of Obama', 'translate English to German: Republican leaders justified their policy by the need to combat electoral fraud.']\n",
      "06/13 11:40:45 PM |\t  pred_decoded[:2]:['Wiederaufnahme der Präsidentin', 'Das war der Beschluß.']\n",
      "06/13 11:40:45 PM |\t  label_decoded[:2]:['Eine republikanische Strategie, um der Wiederwahl von Obama entgegenzutreten', 'Die Führungskräfte der Republikaner rechtfertigen ihre Politik mit der Notwendigkeit, den Wahlbetrug zu bekämpfen.']\n",
      "06/13 11:40:51 PM |\t  computing score...\n",
      "06/13 11:40:51 PM |\t  model_w_in_main sacreBLEU : 0.340023\n",
      "06/13 11:40:51 PM |\t  model_w_in_main test loss : 8.460066\n",
      "06/13 11:40:52 PM |\t  x_decoded[:2]:['translate English to German: A Republican strategy to counter the re-election of Obama', 'translate English to German: Republican leaders justified their policy by the need to combat electoral fraud.']\n",
      "06/13 11:40:52 PM |\t  pred_decoded[:2]:['.', 'In a letter to the Associated Press, the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported']\n",
      "06/13 11:40:52 PM |\t  label_decoded[:2]:['Eine republikanische Strategie, um der Wiederwahl von Obama entgegenzutreten', 'Die Führungskräfte der Republikaner rechtfertigen ihre Politik mit der Notwendigkeit, den Wahlbetrug zu bekämpfen.']\n",
      "06/13 11:41:00 PM |\t  computing score...\n",
      "06/13 11:41:00 PM |\t  model_v_in_main sacreBLEU : 0.194037\n",
      "06/13 11:41:00 PM |\t  model_v_in_main test loss : 5.270808\n",
      "06/13 11:41:00 PM |\t  ('Attention Weights A : ', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>))\n",
      "06/13 11:41:02 PM |\t  1e+02%:\t  W_train_loss:0.1240855\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:02 PM |\t  w_train_loss:1.9566746205091476,v_train_loss:0\n",
      "06/13 11:41:02 PM |\t  \n",
      "\n",
      "  ----------------epoch:21,\t\tlr_w:0.0006561000000000001,\t\tlr_v:0.0006561000000000001,\t\tlr_A:0.01----------------\n",
      "06/13 11:41:02 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:41:02 PM |\t   18.2%:\t  W_train_loss:0.1724110\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:02 PM |\t   45.5%:\t  W_train_loss:0.1808311\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:03 PM |\t   72.7%:\t  W_train_loss:0.1261477\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:03 PM |\t  1e+02%:\t  W_train_loss:0.0809143\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:03 PM |\t  w_train_loss:1.680912647396326,v_train_loss:0\n",
      "06/13 11:41:03 PM |\t  \n",
      "\n",
      "  ----------------epoch:22,\t\tlr_w:0.0006561000000000001,\t\tlr_v:0.0006561000000000001,\t\tlr_A:0.01----------------\n",
      "06/13 11:41:03 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:41:04 PM |\t   18.2%:\t  W_train_loss:0.1255849\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:04 PM |\t   45.5%:\t  W_train_loss:0.1456778\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:04 PM |\t   72.7%:\t  W_train_loss:0.1014650\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:05 PM |\t  1e+02%:\t  W_train_loss:0.0659062\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:05 PM |\t  w_train_loss:1.3159016594290733,v_train_loss:0\n",
      "06/13 11:41:05 PM |\t  \n",
      "\n",
      "  ----------------epoch:23,\t\tlr_w:0.0006561000000000001,\t\tlr_v:0.0006561000000000001,\t\tlr_A:0.01----------------\n",
      "06/13 11:41:05 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:41:05 PM |\t   18.2%:\t  W_train_loss:0.1013136\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:05 PM |\t   45.5%:\t  W_train_loss:0.1615362\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:06 PM |\t   72.7%:\t  W_train_loss:0.0723967\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:06 PM |\t  1e+02%:\t  W_train_loss:0.0594871\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:06 PM |\t  w_train_loss:1.184200519695878,v_train_loss:0\n",
      "06/13 11:41:06 PM |\t  \n",
      "\n",
      "  ----------------epoch:24,\t\tlr_w:0.0006561000000000001,\t\tlr_v:0.0006561000000000001,\t\tlr_A:0.01----------------\n",
      "06/13 11:41:06 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:41:07 PM |\t   18.2%:\t  W_train_loss:0.1086140\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:07 PM |\t   45.5%:\t  W_train_loss:0.1458409\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:07 PM |\t   72.7%:\t  W_train_loss:0.0984335\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:08 PM |\t  1e+02%:\t  W_train_loss:0.0690486\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:08 PM |\t  w_train_loss:1.2658109292387962,v_train_loss:0\n",
      "06/13 11:41:08 PM |\t  \n",
      "\n",
      "  ----------------epoch:25,\t\tlr_w:0.000531441,\t\tlr_v:0.000531441,\t\tlr_A:0.01----------------\n",
      "06/13 11:41:08 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:41:08 PM |\t   18.2%:\t  W_train_loss:0.0970713\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:09 PM |\t   45.5%:\t  W_train_loss:0.0890696\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:09 PM |\t   72.7%:\t  W_train_loss:0.0988291\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:09 PM |\t  1e+02%:\t  W_train_loss:0.0585746\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:09 PM |\t  w_train_loss:1.0306336618959904,v_train_loss:0\n",
      "06/13 11:41:09 PM |\t  \n",
      "\n",
      "  ----------------epoch:26,\t\tlr_w:0.00059049,\t\tlr_v:0.00059049,\t\tlr_A:0.01----------------\n",
      "06/13 11:41:09 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:41:10 PM |\t   18.2%:\t  W_train_loss:0.0802845\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:10 PM |\t   45.5%:\t  W_train_loss:0.1066672\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:10 PM |\t   72.7%:\t  W_train_loss:0.0479876\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:11 PM |\t  1e+02%:\t  W_train_loss:0.0465702\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:11 PM |\t  w_train_loss:0.8445286210626364,v_train_loss:0\n",
      "06/13 11:41:11 PM |\t  \n",
      "\n",
      "  ----------------epoch:27,\t\tlr_w:0.00059049,\t\tlr_v:0.00059049,\t\tlr_A:0.01----------------\n",
      "06/13 11:41:11 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:41:11 PM |\t   18.2%:\t  W_train_loss:0.0816677\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:12 PM |\t   45.5%:\t  W_train_loss:0.0949645\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:12 PM |\t   72.7%:\t  W_train_loss:0.0482712\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:12 PM |\t  1e+02%:\t  W_train_loss:0.0410977\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:12 PM |\t  w_train_loss:0.7980033103376627,v_train_loss:0\n",
      "06/13 11:41:12 PM |\t  \n",
      "\n",
      "  ----------------epoch:28,\t\tlr_w:0.00059049,\t\tlr_v:0.00059049,\t\tlr_A:0.01----------------\n",
      "06/13 11:41:12 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:41:13 PM |\t   18.2%:\t  W_train_loss:0.0536677\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:13 PM |\t   45.5%:\t  W_train_loss:0.0954054\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:14 PM |\t   72.7%:\t  W_train_loss:0.0969495\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:14 PM |\t  1e+02%:\t  W_train_loss:0.0353934\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:14 PM |\t  w_train_loss:0.8442481849342585,v_train_loss:0\n",
      "06/13 11:41:14 PM |\t  \n",
      "\n",
      "  ----------------epoch:29,\t\tlr_w:0.00059049,\t\tlr_v:0.00059049,\t\tlr_A:0.01----------------\n",
      "06/13 11:41:14 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:41:14 PM |\t   18.2%:\t  W_train_loss:0.0514332\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:15 PM |\t   45.5%:\t  W_train_loss:0.1120512\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:15 PM |\t   72.7%:\t  W_train_loss:0.0618145\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:16 PM |\t  1e+02%:\t  W_train_loss:0.0651567\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:16 PM |\t  w_train_loss:0.8713669739663601,v_train_loss:0\n",
      "06/13 11:41:16 PM |\t  \n",
      "\n",
      "  ----------------epoch:30,\t\tlr_w:0.0004782969,\t\tlr_v:0.0004782969,\t\tlr_A:0.01----------------\n",
      "06/13 11:41:16 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:41:16 PM |\t   18.2%:\t  W_train_loss:0.0744677\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:16 PM |\t   45.5%:\t  W_train_loss:0.0820603\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:17 PM |\t   72.7%:\t  W_train_loss:0.0694370\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:17 PM |\t  1e+02%:\t  W_train_loss:0.0624560\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:17 PM |\t  w_train_loss:0.8652632925659418,v_train_loss:0\n",
      "06/13 11:41:17 PM |\t  \n",
      "\n",
      "  ----------------epoch:31,\t\tlr_w:0.000531441,\t\tlr_v:0.000531441,\t\tlr_A:0.01----------------\n",
      "06/13 11:41:17 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:41:19 PM |\t  x_decoded[:2]:['translate English to German: A Republican strategy to counter the re-election of Obama', 'translate English to German: Republican leaders justified their policy by the need to combat electoral fraud.']\n",
      "06/13 11:41:19 PM |\t  pred_decoded[:2]:['Wiederaufnahme der Sitzungsperiode', 'Das war der Beschluß.']\n",
      "06/13 11:41:19 PM |\t  label_decoded[:2]:['Eine republikanische Strategie, um der Wiederwahl von Obama entgegenzutreten', 'Die Führungskräfte der Republikaner rechtfertigen ihre Politik mit der Notwendigkeit, den Wahlbetrug zu bekämpfen.']\n",
      "06/13 11:41:24 PM |\t  computing score...\n",
      "06/13 11:41:24 PM |\t  model_w_in_main sacreBLEU : 0.358677\n",
      "06/13 11:41:24 PM |\t  model_w_in_main test loss : 9.213349\n",
      "06/13 11:41:26 PM |\t  x_decoded[:2]:['translate English to German: A Republican strategy to counter the re-election of Obama', 'translate English to German: Republican leaders justified their policy by the need to combat electoral fraud.']\n",
      "06/13 11:41:26 PM |\t  pred_decoded[:2]:['.', 'In a letter to the Associated Press, the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported']\n",
      "06/13 11:41:26 PM |\t  label_decoded[:2]:['Eine republikanische Strategie, um der Wiederwahl von Obama entgegenzutreten', 'Die Führungskräfte der Republikaner rechtfertigen ihre Politik mit der Notwendigkeit, den Wahlbetrug zu bekämpfen.']\n",
      "06/13 11:41:33 PM |\t  computing score...\n",
      "06/13 11:41:33 PM |\t  model_v_in_main sacreBLEU : 0.194037\n",
      "06/13 11:41:33 PM |\t  model_v_in_main test loss : 5.270808\n",
      "06/13 11:41:33 PM |\t  ('Attention Weights A : ', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>))\n",
      "06/13 11:41:35 PM |\t   18.2%:\t  W_train_loss:0.1014291\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:35 PM |\t   45.5%:\t  W_train_loss:0.0857805\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:36 PM |\t   72.7%:\t  W_train_loss:0.0456330\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:36 PM |\t  1e+02%:\t  W_train_loss:0.0400665\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:36 PM |\t  w_train_loss:0.8187274523079395,v_train_loss:0\n",
      "06/13 11:41:36 PM |\t  \n",
      "\n",
      "  ----------------epoch:32,\t\tlr_w:0.000531441,\t\tlr_v:0.000531441,\t\tlr_A:0.01----------------\n",
      "06/13 11:41:36 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:41:36 PM |\t   18.2%:\t  W_train_loss:0.0745078\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:37 PM |\t   45.5%:\t  W_train_loss:0.0784993\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:37 PM |\t   72.7%:\t  W_train_loss:0.0341917\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:37 PM |\t  1e+02%:\t  W_train_loss:0.0388162\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:37 PM |\t  w_train_loss:0.6780450530350208,v_train_loss:0\n",
      "06/13 11:41:37 PM |\t  \n",
      "\n",
      "  ----------------epoch:33,\t\tlr_w:0.000531441,\t\tlr_v:0.000531441,\t\tlr_A:0.01----------------\n",
      "06/13 11:41:37 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:41:38 PM |\t   18.2%:\t  W_train_loss:0.0756855\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:38 PM |\t   45.5%:\t  W_train_loss:0.0635156\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:39 PM |\t   72.7%:\t  W_train_loss:0.0951726\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:39 PM |\t  1e+02%:\t  W_train_loss:0.0267398\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:39 PM |\t  w_train_loss:0.7833403116092086,v_train_loss:0\n",
      "06/13 11:41:39 PM |\t  \n",
      "\n",
      "  ----------------epoch:34,\t\tlr_w:0.000531441,\t\tlr_v:0.000531441,\t\tlr_A:0.01----------------\n",
      "06/13 11:41:39 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:41:39 PM |\t   18.2%:\t  W_train_loss:0.0596169\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:40 PM |\t   45.5%:\t  W_train_loss:0.0756013\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:40 PM |\t   72.7%:\t  W_train_loss:0.0437262\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:40 PM |\t  1e+02%:\t  W_train_loss:0.0282475\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:40 PM |\t  w_train_loss:0.6215758146718144,v_train_loss:0\n",
      "06/13 11:41:40 PM |\t  \n",
      "\n",
      "  ----------------epoch:35,\t\tlr_w:0.00043046721,\t\tlr_v:0.00043046721,\t\tlr_A:0.01----------------\n",
      "06/13 11:41:40 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:41:41 PM |\t   18.2%:\t  W_train_loss:0.0507472\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:41 PM |\t   45.5%:\t  W_train_loss:0.0503905\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:42 PM |\t   72.7%:\t  W_train_loss:0.0407127\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:42 PM |\t  1e+02%:\t  W_train_loss:0.0355533\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:42 PM |\t  w_train_loss:0.5322113800793886,v_train_loss:0\n",
      "06/13 11:41:42 PM |\t  \n",
      "\n",
      "  ----------------epoch:36,\t\tlr_w:0.0004782969,\t\tlr_v:0.0004782969,\t\tlr_A:0.01----------------\n",
      "06/13 11:41:42 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:41:42 PM |\t   18.2%:\t  W_train_loss:0.0409611\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:43 PM |\t   45.5%:\t  W_train_loss:0.0594068\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:43 PM |\t   72.7%:\t  W_train_loss:0.0414571\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:43 PM |\t  1e+02%:\t  W_train_loss:0.0355242\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:43 PM |\t  w_train_loss:0.5320473946630955,v_train_loss:0\n",
      "06/13 11:41:43 PM |\t  \n",
      "\n",
      "  ----------------epoch:37,\t\tlr_w:0.0004782969,\t\tlr_v:0.0004782969,\t\tlr_A:0.01----------------\n",
      "06/13 11:41:43 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:41:44 PM |\t   18.2%:\t  W_train_loss:0.0383488\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:44 PM |\t   45.5%:\t  W_train_loss:0.0583061\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:45 PM |\t   72.7%:\t  W_train_loss:0.0245758\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:45 PM |\t  1e+02%:\t  W_train_loss:0.0233017\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:45 PM |\t  w_train_loss:0.43359701335430145,v_train_loss:0\n",
      "06/13 11:41:45 PM |\t  \n",
      "\n",
      "  ----------------epoch:38,\t\tlr_w:0.0004782969,\t\tlr_v:0.0004782969,\t\tlr_A:0.01----------------\n",
      "06/13 11:41:45 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:41:45 PM |\t   18.2%:\t  W_train_loss:0.0448817\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:46 PM |\t   45.5%:\t  W_train_loss:0.0608442\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:46 PM |\t   72.7%:\t  W_train_loss:0.0204818\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:46 PM |\t  1e+02%:\t  W_train_loss:0.0275011\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:46 PM |\t  w_train_loss:0.4611263070255518,v_train_loss:0\n",
      "06/13 11:41:46 PM |\t  \n",
      "\n",
      "  ----------------epoch:39,\t\tlr_w:0.0004782969,\t\tlr_v:0.0004782969,\t\tlr_A:0.01----------------\n",
      "06/13 11:41:47 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:41:47 PM |\t   18.2%:\t  W_train_loss:0.0461308\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:47 PM |\t   45.5%:\t  W_train_loss:0.0999166\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:48 PM |\t   72.7%:\t  W_train_loss:0.0271164\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:48 PM |\t  1e+02%:\t  W_train_loss:0.0373660\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:48 PM |\t  w_train_loss:0.6315891426056623,v_train_loss:0\n",
      "06/13 11:41:48 PM |\t  \n",
      "\n",
      "  ----------------epoch:40,\t\tlr_w:0.000387420489,\t\tlr_v:0.000387420489,\t\tlr_A:0.01----------------\n",
      "06/13 11:41:48 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:41:48 PM |\t   18.2%:\t  W_train_loss:0.0413230\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:49 PM |\t   45.5%:\t  W_train_loss:0.0483502\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:49 PM |\t   72.7%:\t  W_train_loss:0.0373090\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:50 PM |\t  1e+02%:\t  W_train_loss:0.0394418\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:50 PM |\t  w_train_loss:0.49927184358239174,v_train_loss:0\n",
      "06/13 11:41:50 PM |\t  \n",
      "\n",
      "  ----------------epoch:41,\t\tlr_w:0.00043046721,\t\tlr_v:0.00043046721,\t\tlr_A:0.01----------------\n",
      "06/13 11:41:50 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:41:50 PM |\t   18.2%:\t  W_train_loss:0.0335911\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:50 PM |\t   45.5%:\t  W_train_loss:0.0587901\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:41:52 PM |\t  x_decoded[:2]:['translate English to German: A Republican strategy to counter the re-election of Obama', 'translate English to German: Republican leaders justified their policy by the need to combat electoral fraud.']\n",
      "06/13 11:41:52 PM |\t  pred_decoded[:2]:['Wiederaufnahme der re-election der Präsidentin zu re-election von Präsidentin und re-election von Präsidentin.', 'Das war der Beschluß.']\n",
      "06/13 11:41:52 PM |\t  label_decoded[:2]:['Eine republikanische Strategie, um der Wiederwahl von Obama entgegenzutreten', 'Die Führungskräfte der Republikaner rechtfertigen ihre Politik mit der Notwendigkeit, den Wahlbetrug zu bekämpfen.']\n",
      "06/13 11:41:58 PM |\t  computing score...\n",
      "06/13 11:41:58 PM |\t  model_w_in_main sacreBLEU : 0.460581\n",
      "06/13 11:41:58 PM |\t  model_w_in_main test loss : 9.491105\n",
      "06/13 11:42:00 PM |\t  x_decoded[:2]:['translate English to German: A Republican strategy to counter the re-election of Obama', 'translate English to German: Republican leaders justified their policy by the need to combat electoral fraud.']\n",
      "06/13 11:42:00 PM |\t  pred_decoded[:2]:['.', 'In a letter to the Associated Press, the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported']\n",
      "06/13 11:42:00 PM |\t  label_decoded[:2]:['Eine republikanische Strategie, um der Wiederwahl von Obama entgegenzutreten', 'Die Führungskräfte der Republikaner rechtfertigen ihre Politik mit der Notwendigkeit, den Wahlbetrug zu bekämpfen.']\n",
      "06/13 11:42:07 PM |\t  computing score...\n",
      "06/13 11:42:07 PM |\t  model_v_in_main sacreBLEU : 0.194037\n",
      "06/13 11:42:07 PM |\t  model_v_in_main test loss : 5.270808\n",
      "06/13 11:42:07 PM |\t  ('Attention Weights A : ', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>))\n",
      "06/13 11:42:09 PM |\t   72.7%:\t  W_train_loss:0.0143828\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:09 PM |\t  1e+02%:\t  W_train_loss:0.0177333\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:09 PM |\t  w_train_loss:0.3734917896799743,v_train_loss:0\n",
      "06/13 11:42:09 PM |\t  \n",
      "\n",
      "  ----------------epoch:42,\t\tlr_w:0.00043046721,\t\tlr_v:0.00043046721,\t\tlr_A:0.01----------------\n",
      "06/13 11:42:09 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:42:09 PM |\t   18.2%:\t  W_train_loss:0.0459342\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:10 PM |\t   45.5%:\t  W_train_loss:0.0605138\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:10 PM |\t   72.7%:\t  W_train_loss:0.0343890\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:11 PM |\t  1e+02%:\t  W_train_loss:0.0242152\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:11 PM |\t  w_train_loss:0.4951565247029066,v_train_loss:0\n",
      "06/13 11:42:11 PM |\t  \n",
      "\n",
      "  ----------------epoch:43,\t\tlr_w:0.00043046721,\t\tlr_v:0.00043046721,\t\tlr_A:0.01----------------\n",
      "06/13 11:42:11 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:42:11 PM |\t   18.2%:\t  W_train_loss:0.0309095\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:11 PM |\t   45.5%:\t  W_train_loss:0.0633312\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:12 PM |\t   72.7%:\t  W_train_loss:0.0487424\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:12 PM |\t  1e+02%:\t  W_train_loss:0.0179047\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:12 PM |\t  w_train_loss:0.48266306053847075,v_train_loss:0\n",
      "06/13 11:42:12 PM |\t  \n",
      "\n",
      "  ----------------epoch:44,\t\tlr_w:0.00043046721,\t\tlr_v:0.00043046721,\t\tlr_A:0.01----------------\n",
      "06/13 11:42:12 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:42:12 PM |\t   18.2%:\t  W_train_loss:0.0367832\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:13 PM |\t   45.5%:\t  W_train_loss:0.0454074\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:13 PM |\t   72.7%:\t  W_train_loss:0.0195050\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:14 PM |\t  1e+02%:\t  W_train_loss:0.0321503\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:14 PM |\t  w_train_loss:0.4015378188341856,v_train_loss:0\n",
      "06/13 11:42:14 PM |\t  \n",
      "\n",
      "  ----------------epoch:45,\t\tlr_w:0.0003486784401,\t\tlr_v:0.0003486784401,\t\tlr_A:0.01----------------\n",
      "06/13 11:42:14 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:42:14 PM |\t   18.2%:\t  W_train_loss:0.0178884\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:14 PM |\t   45.5%:\t  W_train_loss:0.0216015\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:15 PM |\t   72.7%:\t  W_train_loss:0.0607020\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:15 PM |\t  1e+02%:\t  W_train_loss:0.0229427\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:15 PM |\t  w_train_loss:0.36940380884334445,v_train_loss:0\n",
      "06/13 11:42:15 PM |\t  \n",
      "\n",
      "  ----------------epoch:46,\t\tlr_w:0.000387420489,\t\tlr_v:0.000387420489,\t\tlr_A:0.01----------------\n",
      "06/13 11:42:15 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:42:15 PM |\t   18.2%:\t  W_train_loss:0.0279535\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:16 PM |\t   45.5%:\t  W_train_loss:0.0293926\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:16 PM |\t   72.7%:\t  W_train_loss:0.0225375\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:17 PM |\t  1e+02%:\t  W_train_loss:0.0243872\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:17 PM |\t  w_train_loss:0.31281241215765476,v_train_loss:0\n",
      "06/13 11:42:17 PM |\t  \n",
      "\n",
      "  ----------------epoch:47,\t\tlr_w:0.000387420489,\t\tlr_v:0.000387420489,\t\tlr_A:0.01----------------\n",
      "06/13 11:42:17 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:42:17 PM |\t   18.2%:\t  W_train_loss:0.0319922\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:17 PM |\t   45.5%:\t  W_train_loss:0.0366508\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:18 PM |\t   72.7%:\t  W_train_loss:0.0239018\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:18 PM |\t  1e+02%:\t  W_train_loss:0.0170709\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:18 PM |\t  w_train_loss:0.3288473058491945,v_train_loss:0\n",
      "06/13 11:42:18 PM |\t  \n",
      "\n",
      "  ----------------epoch:48,\t\tlr_w:0.000387420489,\t\tlr_v:0.000387420489,\t\tlr_A:0.01----------------\n",
      "06/13 11:42:18 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:42:18 PM |\t   18.2%:\t  W_train_loss:0.0232013\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:19 PM |\t   45.5%:\t  W_train_loss:0.0357945\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:19 PM |\t   72.7%:\t  W_train_loss:0.0109569\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:20 PM |\t  1e+02%:\t  W_train_loss:0.0194646\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:20 PM |\t  w_train_loss:0.26825179206207395,v_train_loss:0\n",
      "06/13 11:42:20 PM |\t  \n",
      "\n",
      "  ----------------epoch:49,\t\tlr_w:0.000387420489,\t\tlr_v:0.000387420489,\t\tlr_A:0.01----------------\n",
      "06/13 11:42:20 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:42:20 PM |\t   18.2%:\t  W_train_loss:0.0193309\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:20 PM |\t   45.5%:\t  W_train_loss:0.0331119\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:21 PM |\t   72.7%:\t  W_train_loss:0.0159204\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:21 PM |\t  1e+02%:\t  W_train_loss:0.0154057\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:21 PM |\t  w_train_loss:0.2513065515086055,v_train_loss:0\n",
      "06/13 11:42:21 PM |\t  \n",
      "\n",
      "  ----------------epoch:50,\t\tlr_w:0.00031381059609000004,\t\tlr_v:0.00031381059609000004,\t\tlr_A:0.01----------------\n",
      "06/13 11:42:21 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:42:21 PM |\t   18.2%:\t  W_train_loss:0.0307543\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:22 PM |\t   45.5%:\t  W_train_loss:0.0156246\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:22 PM |\t   72.7%:\t  W_train_loss:0.0177049\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:23 PM |\t  1e+02%:\t  W_train_loss:0.0148345\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:23 PM |\t  w_train_loss:0.23675525095313787,v_train_loss:0\n",
      "06/13 11:42:23 PM |\t  \n",
      "\n",
      "  ----------------epoch:51,\t\tlr_w:0.0003486784401,\t\tlr_v:0.0003486784401,\t\tlr_A:0.01----------------\n",
      "06/13 11:42:23 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:42:23 PM |\t   18.2%:\t  W_train_loss:0.0335304\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:23 PM |\t   45.5%:\t  W_train_loss:0.0203782\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:24 PM |\t   72.7%:\t  W_train_loss:0.0109305\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:24 PM |\t  1e+02%:\t  W_train_loss:0.0073180\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:24 PM |\t  w_train_loss:0.21647153003141284,v_train_loss:0\n",
      "06/13 11:42:24 PM |\t  \n",
      "\n",
      "  ----------------epoch:52,\t\tlr_w:0.0003486784401,\t\tlr_v:0.0003486784401,\t\tlr_A:0.01----------------\n",
      "06/13 11:42:24 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:42:26 PM |\t  x_decoded[:2]:['translate English to German: A Republican strategy to counter the re-election of Obama', 'translate English to German: Republican leaders justified their policy by the need to combat electoral fraud.']\n",
      "06/13 11:42:26 PM |\t  pred_decoded[:2]:['Nach der Tagesordnung lehnt den Antrag der Präsidentin entschieden ab!', 'Das war der Beschluß.']\n",
      "06/13 11:42:26 PM |\t  label_decoded[:2]:['Eine republikanische Strategie, um der Wiederwahl von Obama entgegenzutreten', 'Die Führungskräfte der Republikaner rechtfertigen ihre Politik mit der Notwendigkeit, den Wahlbetrug zu bekämpfen.']\n",
      "06/13 11:42:30 PM |\t  computing score...\n",
      "06/13 11:42:30 PM |\t  model_w_in_main sacreBLEU : 0.488555\n",
      "06/13 11:42:30 PM |\t  model_w_in_main test loss : 9.672888\n",
      "06/13 11:42:32 PM |\t  x_decoded[:2]:['translate English to German: A Republican strategy to counter the re-election of Obama', 'translate English to German: Republican leaders justified their policy by the need to combat electoral fraud.']\n",
      "06/13 11:42:32 PM |\t  pred_decoded[:2]:['.', 'In a letter to the Associated Press, the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported']\n",
      "06/13 11:42:32 PM |\t  label_decoded[:2]:['Eine republikanische Strategie, um der Wiederwahl von Obama entgegenzutreten', 'Die Führungskräfte der Republikaner rechtfertigen ihre Politik mit der Notwendigkeit, den Wahlbetrug zu bekämpfen.']\n",
      "06/13 11:42:40 PM |\t  computing score...\n",
      "06/13 11:42:40 PM |\t  model_v_in_main sacreBLEU : 0.194037\n",
      "06/13 11:42:40 PM |\t  model_v_in_main test loss : 5.270808\n",
      "06/13 11:42:40 PM |\t  ('Attention Weights A : ', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>))\n",
      "06/13 11:42:42 PM |\t   18.2%:\t  W_train_loss:0.0189498\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:42 PM |\t   45.5%:\t  W_train_loss:0.0483409\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:42 PM |\t   72.7%:\t  W_train_loss:0.0057589\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:43 PM |\t  1e+02%:\t  W_train_loss:0.0072038\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:43 PM |\t  w_train_loss:0.24076020484790206,v_train_loss:0\n",
      "06/13 11:42:43 PM |\t  \n",
      "\n",
      "  ----------------epoch:53,\t\tlr_w:0.0003486784401,\t\tlr_v:0.0003486784401,\t\tlr_A:0.01----------------\n",
      "06/13 11:42:43 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:42:43 PM |\t   18.2%:\t  W_train_loss:0.0224551\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:44 PM |\t   45.5%:\t  W_train_loss:0.0165814\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:44 PM |\t   72.7%:\t  W_train_loss:0.0259955\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:44 PM |\t  1e+02%:\t  W_train_loss:0.0164561\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:44 PM |\t  w_train_loss:0.24446416134014726,v_train_loss:0\n",
      "06/13 11:42:44 PM |\t  \n",
      "\n",
      "  ----------------epoch:54,\t\tlr_w:0.0003486784401,\t\tlr_v:0.0003486784401,\t\tlr_A:0.01----------------\n",
      "06/13 11:42:44 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:42:45 PM |\t   18.2%:\t  W_train_loss:0.0182277\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:45 PM |\t   45.5%:\t  W_train_loss:0.0379379\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:45 PM |\t   72.7%:\t  W_train_loss:0.0201019\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:46 PM |\t  1e+02%:\t  W_train_loss:0.0119868\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:46 PM |\t  w_train_loss:0.26476321183145046,v_train_loss:0\n",
      "06/13 11:42:46 PM |\t  \n",
      "\n",
      "  ----------------epoch:55,\t\tlr_w:0.00028242953648100003,\t\tlr_v:0.00028242953648100003,\t\tlr_A:0.01----------------\n",
      "06/13 11:42:46 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:42:46 PM |\t   18.2%:\t  W_train_loss:0.0203894\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:47 PM |\t   45.5%:\t  W_train_loss:0.0250603\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:47 PM |\t   72.7%:\t  W_train_loss:0.0157248\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:47 PM |\t  1e+02%:\t  W_train_loss:0.0151430\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:47 PM |\t  w_train_loss:0.22895248606801033,v_train_loss:0\n",
      "06/13 11:42:47 PM |\t  \n",
      "\n",
      "  ----------------epoch:56,\t\tlr_w:0.00031381059609000004,\t\tlr_v:0.00031381059609000004,\t\tlr_A:0.01----------------\n",
      "06/13 11:42:47 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:42:48 PM |\t   18.2%:\t  W_train_loss:0.0669513\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:48 PM |\t   45.5%:\t  W_train_loss:0.0351482\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:48 PM |\t   72.7%:\t  W_train_loss:0.0240169\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:49 PM |\t  1e+02%:\t  W_train_loss:0.0187143\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:49 PM |\t  w_train_loss:0.43449220061302185,v_train_loss:0\n",
      "06/13 11:42:49 PM |\t  \n",
      "\n",
      "  ----------------epoch:57,\t\tlr_w:0.00031381059609000004,\t\tlr_v:0.00031381059609000004,\t\tlr_A:0.01----------------\n",
      "06/13 11:42:49 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:42:49 PM |\t   18.2%:\t  W_train_loss:0.0220310\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:50 PM |\t   45.5%:\t  W_train_loss:0.0197590\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:50 PM |\t   72.7%:\t  W_train_loss:0.0146505\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:50 PM |\t  1e+02%:\t  W_train_loss:0.0063921\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:50 PM |\t  w_train_loss:0.18849762342870235,v_train_loss:0\n",
      "06/13 11:42:50 PM |\t  \n",
      "\n",
      "  ----------------epoch:58,\t\tlr_w:0.00031381059609000004,\t\tlr_v:0.00031381059609000004,\t\tlr_A:0.01----------------\n",
      "06/13 11:42:50 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:42:51 PM |\t   18.2%:\t  W_train_loss:0.0220857\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:51 PM |\t   45.5%:\t  W_train_loss:0.0235456\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:52 PM |\t   72.7%:\t  W_train_loss:0.0112191\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:52 PM |\t  1e+02%:\t  W_train_loss:0.0190675\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:52 PM |\t  w_train_loss:0.22775391768664122,v_train_loss:0\n",
      "06/13 11:42:52 PM |\t  \n",
      "\n",
      "  ----------------epoch:59,\t\tlr_w:0.00031381059609000004,\t\tlr_v:0.00031381059609000004,\t\tlr_A:0.01----------------\n",
      "06/13 11:42:52 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:42:52 PM |\t   18.2%:\t  W_train_loss:0.0208700\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:53 PM |\t   45.5%:\t  W_train_loss:0.0517170\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:53 PM |\t   72.7%:\t  W_train_loss:0.0097667\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:53 PM |\t  1e+02%:\t  W_train_loss:0.0073094\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:53 PM |\t  w_train_loss:0.26898942654952407,v_train_loss:0\n",
      "06/13 11:42:53 PM |\t  \n",
      "\n",
      "  ----------------epoch:60,\t\tlr_w:0.00025418658283290005,\t\tlr_v:0.00025418658283290005,\t\tlr_A:0.01----------------\n",
      "06/13 11:42:53 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:42:54 PM |\t   18.2%:\t  W_train_loss:0.0135321\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:54 PM |\t   45.5%:\t  W_train_loss:0.0167015\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:55 PM |\t   72.7%:\t  W_train_loss:0.0222995\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:55 PM |\t  1e+02%:\t  W_train_loss:0.0043811\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:55 PM |\t  w_train_loss:0.17074236110784113,v_train_loss:0\n",
      "06/13 11:42:55 PM |\t  \n",
      "\n",
      "  ----------------epoch:61,\t\tlr_w:0.00028242953648100003,\t\tlr_v:0.00028242953648100003,\t\tlr_A:0.01----------------\n",
      "06/13 11:42:55 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:42:55 PM |\t   18.2%:\t  W_train_loss:0.0220365\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:56 PM |\t   45.5%:\t  W_train_loss:0.0167446\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:56 PM |\t   72.7%:\t  W_train_loss:0.0101988\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:56 PM |\t  1e+02%:\t  W_train_loss:0.0043328\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:56 PM |\t  w_train_loss:0.1599379808176309,v_train_loss:0\n",
      "06/13 11:42:56 PM |\t  \n",
      "\n",
      "  ----------------epoch:62,\t\tlr_w:0.00028242953648100003,\t\tlr_v:0.00028242953648100003,\t\tlr_A:0.01----------------\n",
      "06/13 11:42:56 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:42:57 PM |\t   18.2%:\t  W_train_loss:0.0538389\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:42:58 PM |\t  x_decoded[:2]:['translate English to German: A Republican strategy to counter the re-election of Obama', 'translate English to German: Republican leaders justified their policy by the need to combat electoral fraud.']\n",
      "06/13 11:42:58 PM |\t  pred_decoded[:2]:['Wiederaufnahme der Sitzungsperiode', 'Das war der Beschluß.']\n",
      "06/13 11:42:58 PM |\t  label_decoded[:2]:['Eine republikanische Strategie, um der Wiederwahl von Obama entgegenzutreten', 'Die Führungskräfte der Republikaner rechtfertigen ihre Politik mit der Notwendigkeit, den Wahlbetrug zu bekämpfen.']\n",
      "06/13 11:43:03 PM |\t  computing score...\n",
      "06/13 11:43:03 PM |\t  model_w_in_main sacreBLEU : 0.414666\n",
      "06/13 11:43:03 PM |\t  model_w_in_main test loss : 10.077135\n",
      "06/13 11:43:05 PM |\t  x_decoded[:2]:['translate English to German: A Republican strategy to counter the re-election of Obama', 'translate English to German: Republican leaders justified their policy by the need to combat electoral fraud.']\n",
      "06/13 11:43:05 PM |\t  pred_decoded[:2]:['.', 'In a letter to the Associated Press, the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported']\n",
      "06/13 11:43:05 PM |\t  label_decoded[:2]:['Eine republikanische Strategie, um der Wiederwahl von Obama entgegenzutreten', 'Die Führungskräfte der Republikaner rechtfertigen ihre Politik mit der Notwendigkeit, den Wahlbetrug zu bekämpfen.']\n",
      "06/13 11:43:12 PM |\t  computing score...\n",
      "06/13 11:43:12 PM |\t  model_v_in_main sacreBLEU : 0.194037\n",
      "06/13 11:43:12 PM |\t  model_v_in_main test loss : 5.270808\n",
      "06/13 11:43:12 PM |\t  ('Attention Weights A : ', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>))\n",
      "06/13 11:43:14 PM |\t   45.5%:\t  W_train_loss:0.0165020\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:14 PM |\t   72.7%:\t  W_train_loss:0.0067014\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:14 PM |\t  1e+02%:\t  W_train_loss:0.0107587\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:14 PM |\t  w_train_loss:0.2634029514156282,v_train_loss:0\n",
      "06/13 11:43:14 PM |\t  \n",
      "\n",
      "  ----------------epoch:63,\t\tlr_w:0.00028242953648100003,\t\tlr_v:0.00028242953648100003,\t\tlr_A:0.01----------------\n",
      "06/13 11:43:14 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:43:15 PM |\t   18.2%:\t  W_train_loss:0.0288096\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:15 PM |\t   45.5%:\t  W_train_loss:0.0289541\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:16 PM |\t   72.7%:\t  W_train_loss:0.0107628\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:16 PM |\t  1e+02%:\t  W_train_loss:0.0050650\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:16 PM |\t  w_train_loss:0.22077433543745428,v_train_loss:0\n",
      "06/13 11:43:16 PM |\t  \n",
      "\n",
      "  ----------------epoch:64,\t\tlr_w:0.00028242953648100003,\t\tlr_v:0.00028242953648100003,\t\tlr_A:0.01----------------\n",
      "06/13 11:43:16 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:43:16 PM |\t   18.2%:\t  W_train_loss:0.0158389\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:17 PM |\t   45.5%:\t  W_train_loss:0.0150153\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:17 PM |\t   72.7%:\t  W_train_loss:0.0101132\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:18 PM |\t  1e+02%:\t  W_train_loss:0.0073576\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:18 PM |\t  w_train_loss:0.14497485966421664,v_train_loss:0\n",
      "06/13 11:43:18 PM |\t  \n",
      "\n",
      "  ----------------epoch:65,\t\tlr_w:0.00022876792454961005,\t\tlr_v:0.00022876792454961005,\t\tlr_A:0.01----------------\n",
      "06/13 11:43:18 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:43:18 PM |\t   18.2%:\t  W_train_loss:0.0224867\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:18 PM |\t   45.5%:\t  W_train_loss:0.0215606\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:19 PM |\t   72.7%:\t  W_train_loss:0.0064628\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:19 PM |\t  1e+02%:\t  W_train_loss:0.0081510\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:19 PM |\t  w_train_loss:0.17598334979265928,v_train_loss:0\n",
      "06/13 11:43:19 PM |\t  \n",
      "\n",
      "  ----------------epoch:66,\t\tlr_w:0.00025418658283290005,\t\tlr_v:0.00025418658283290005,\t\tlr_A:0.01----------------\n",
      "06/13 11:43:19 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:43:19 PM |\t   18.2%:\t  W_train_loss:0.0127674\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:20 PM |\t   45.5%:\t  W_train_loss:0.0125555\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:20 PM |\t   72.7%:\t  W_train_loss:0.0068601\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:21 PM |\t  1e+02%:\t  W_train_loss:0.0113708\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:21 PM |\t  w_train_loss:0.13066132937092334,v_train_loss:0\n",
      "06/13 11:43:21 PM |\t  \n",
      "\n",
      "  ----------------epoch:67,\t\tlr_w:0.00025418658283290005,\t\tlr_v:0.00025418658283290005,\t\tlr_A:0.01----------------\n",
      "06/13 11:43:21 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:43:21 PM |\t   18.2%:\t  W_train_loss:0.0215758\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:21 PM |\t   45.5%:\t  W_train_loss:0.0137654\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:22 PM |\t   72.7%:\t  W_train_loss:0.0222126\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:22 PM |\t  1e+02%:\t  W_train_loss:0.0132318\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:22 PM |\t  w_train_loss:0.2123571156989783,v_train_loss:0\n",
      "06/13 11:43:22 PM |\t  \n",
      "\n",
      "  ----------------epoch:68,\t\tlr_w:0.00025418658283290005,\t\tlr_v:0.00025418658283290005,\t\tlr_A:0.01----------------\n",
      "06/13 11:43:22 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:43:23 PM |\t   18.2%:\t  W_train_loss:0.0099813\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:23 PM |\t   45.5%:\t  W_train_loss:0.0189907\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:23 PM |\t   72.7%:\t  W_train_loss:0.0100753\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:24 PM |\t  1e+02%:\t  W_train_loss:0.0244902\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:24 PM |\t  w_train_loss:0.19061249075457454,v_train_loss:0\n",
      "06/13 11:43:24 PM |\t  \n",
      "\n",
      "  ----------------epoch:69,\t\tlr_w:0.00025418658283290005,\t\tlr_v:0.00025418658283290005,\t\tlr_A:0.01----------------\n",
      "06/13 11:43:24 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:43:24 PM |\t   18.2%:\t  W_train_loss:0.0093460\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:24 PM |\t   45.5%:\t  W_train_loss:0.0156196\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:25 PM |\t   72.7%:\t  W_train_loss:0.0057691\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:25 PM |\t  1e+02%:\t  W_train_loss:0.0146688\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:25 PM |\t  w_train_loss:0.13621068105567247,v_train_loss:0\n",
      "06/13 11:43:25 PM |\t  \n",
      "\n",
      "  ----------------epoch:70,\t\tlr_w:0.00020589113209464906,\t\tlr_v:0.00020589113209464906,\t\tlr_A:0.01----------------\n",
      "06/13 11:43:25 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:43:26 PM |\t   18.2%:\t  W_train_loss:0.0100510\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:26 PM |\t   45.5%:\t  W_train_loss:0.0210475\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:26 PM |\t   72.7%:\t  W_train_loss:0.0093471\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:27 PM |\t  1e+02%:\t  W_train_loss:0.0089905\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:27 PM |\t  w_train_loss:0.1483085546642542,v_train_loss:0\n",
      "06/13 11:43:27 PM |\t  \n",
      "\n",
      "  ----------------epoch:71,\t\tlr_w:0.00022876792454961005,\t\tlr_v:0.00022876792454961005,\t\tlr_A:0.01----------------\n",
      "06/13 11:43:27 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:43:27 PM |\t   18.2%:\t  W_train_loss:0.0195544\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:27 PM |\t   45.5%:\t  W_train_loss:0.0217854\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:28 PM |\t   72.7%:\t  W_train_loss:0.0080222\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:28 PM |\t  1e+02%:\t  W_train_loss:0.0060145\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:28 PM |\t  w_train_loss:0.1661296805832535,v_train_loss:0\n",
      "06/13 11:43:28 PM |\t  \n",
      "\n",
      "  ----------------epoch:72,\t\tlr_w:0.00022876792454961005,\t\tlr_v:0.00022876792454961005,\t\tlr_A:0.01----------------\n",
      "06/13 11:43:28 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:43:29 PM |\t   18.2%:\t  W_train_loss:0.0314863\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:29 PM |\t   45.5%:\t  W_train_loss:0.0186218\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:29 PM |\t   72.7%:\t  W_train_loss:0.0068250\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:32 PM |\t  x_decoded[:2]:['translate English to German: A Republican strategy to counter the re-election of Obama', 'translate English to German: Republican leaders justified their policy by the need to combat electoral fraud.']\n",
      "06/13 11:43:32 PM |\t  pred_decoded[:2]:['Wiederaufnahme der re-election der re-election der re-election von Herrn von der re-election der re-election der re-election von Herrn von der re-election der re-election der re-e', 'Das war der Beschluß.']\n",
      "06/13 11:43:32 PM |\t  label_decoded[:2]:['Eine republikanische Strategie, um der Wiederwahl von Obama entgegenzutreten', 'Die Führungskräfte der Republikaner rechtfertigen ihre Politik mit der Notwendigkeit, den Wahlbetrug zu bekämpfen.']\n",
      "06/13 11:43:36 PM |\t  computing score...\n",
      "06/13 11:43:36 PM |\t  model_w_in_main sacreBLEU : 0.365393\n",
      "06/13 11:43:36 PM |\t  model_w_in_main test loss : 10.275890\n",
      "06/13 11:43:38 PM |\t  x_decoded[:2]:['translate English to German: A Republican strategy to counter the re-election of Obama', 'translate English to German: Republican leaders justified their policy by the need to combat electoral fraud.']\n",
      "06/13 11:43:38 PM |\t  pred_decoded[:2]:['.', 'In a letter to the Associated Press, the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported']\n",
      "06/13 11:43:38 PM |\t  label_decoded[:2]:['Eine republikanische Strategie, um der Wiederwahl von Obama entgegenzutreten', 'Die Führungskräfte der Republikaner rechtfertigen ihre Politik mit der Notwendigkeit, den Wahlbetrug zu bekämpfen.']\n",
      "06/13 11:43:45 PM |\t  computing score...\n",
      "06/13 11:43:45 PM |\t  model_v_in_main sacreBLEU : 0.194037\n",
      "06/13 11:43:45 PM |\t  model_v_in_main test loss : 5.270808\n",
      "06/13 11:43:45 PM |\t  ('Attention Weights A : ', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>))\n",
      "06/13 11:43:47 PM |\t  1e+02%:\t  W_train_loss:0.0045746\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:47 PM |\t  w_train_loss:0.18452312401495874,v_train_loss:0\n",
      "06/13 11:43:47 PM |\t  \n",
      "\n",
      "  ----------------epoch:73,\t\tlr_w:0.00022876792454961005,\t\tlr_v:0.00022876792454961005,\t\tlr_A:0.01----------------\n",
      "06/13 11:43:47 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:43:47 PM |\t   18.2%:\t  W_train_loss:0.0162958\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:47 PM |\t   45.5%:\t  W_train_loss:0.0420383\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:48 PM |\t   72.7%:\t  W_train_loss:0.0064894\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:48 PM |\t  1e+02%:\t  W_train_loss:0.0159763\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:48 PM |\t  w_train_loss:0.24239946226589382,v_train_loss:0\n",
      "06/13 11:43:48 PM |\t  \n",
      "\n",
      "  ----------------epoch:74,\t\tlr_w:0.00022876792454961005,\t\tlr_v:0.00022876792454961005,\t\tlr_A:0.01----------------\n",
      "06/13 11:43:48 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:43:48 PM |\t   18.2%:\t  W_train_loss:0.0281817\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:49 PM |\t   45.5%:\t  W_train_loss:0.0183352\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:49 PM |\t   72.7%:\t  W_train_loss:0.0100108\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:50 PM |\t  1e+02%:\t  W_train_loss:0.0141852\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:50 PM |\t  w_train_loss:0.21213881019502878,v_train_loss:0\n",
      "06/13 11:43:50 PM |\t  \n",
      "\n",
      "  ----------------epoch:75,\t\tlr_w:0.00018530201888518417,\t\tlr_v:0.00018530201888518417,\t\tlr_A:0.01----------------\n",
      "06/13 11:43:50 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:43:50 PM |\t   18.2%:\t  W_train_loss:0.0093209\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:50 PM |\t   45.5%:\t  W_train_loss:0.0117611\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:51 PM |\t   72.7%:\t  W_train_loss:0.0169433\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:51 PM |\t  1e+02%:\t  W_train_loss:0.0066145\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:51 PM |\t  w_train_loss:0.13391953276004642,v_train_loss:0\n",
      "06/13 11:43:51 PM |\t  \n",
      "\n",
      "  ----------------epoch:76,\t\tlr_w:0.00020589113209464906,\t\tlr_v:0.00020589113209464906,\t\tlr_A:0.01----------------\n",
      "06/13 11:43:51 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:43:51 PM |\t   18.2%:\t  W_train_loss:0.0085937\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:52 PM |\t   45.5%:\t  W_train_loss:0.0112779\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:52 PM |\t   72.7%:\t  W_train_loss:0.0073262\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:53 PM |\t  1e+02%:\t  W_train_loss:0.0074593\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:53 PM |\t  w_train_loss:0.10397128178738058,v_train_loss:0\n",
      "06/13 11:43:53 PM |\t  \n",
      "\n",
      "  ----------------epoch:77,\t\tlr_w:0.00020589113209464906,\t\tlr_v:0.00020589113209464906,\t\tlr_A:0.01----------------\n",
      "06/13 11:43:53 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:43:53 PM |\t   18.2%:\t  W_train_loss:0.0082050\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:53 PM |\t   45.5%:\t  W_train_loss:0.0145135\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:54 PM |\t   72.7%:\t  W_train_loss:0.0040980\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:54 PM |\t  1e+02%:\t  W_train_loss:0.0049998\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:54 PM |\t  w_train_loss:0.09544870618265122,v_train_loss:0\n",
      "06/13 11:43:54 PM |\t  \n",
      "\n",
      "  ----------------epoch:78,\t\tlr_w:0.00020589113209464906,\t\tlr_v:0.00020589113209464906,\t\tlr_A:0.01----------------\n",
      "06/13 11:43:54 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:43:54 PM |\t   18.2%:\t  W_train_loss:0.0070533\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:55 PM |\t   45.5%:\t  W_train_loss:0.0043511\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:55 PM |\t   72.7%:\t  W_train_loss:0.0190127\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:56 PM |\t  1e+02%:\t  W_train_loss:0.0062733\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:56 PM |\t  w_train_loss:0.11007089423947036,v_train_loss:0\n",
      "06/13 11:43:56 PM |\t  \n",
      "\n",
      "  ----------------epoch:79,\t\tlr_w:0.00020589113209464906,\t\tlr_v:0.00020589113209464906,\t\tlr_A:0.01----------------\n",
      "06/13 11:43:56 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:43:56 PM |\t   18.2%:\t  W_train_loss:0.0101202\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:56 PM |\t   45.5%:\t  W_train_loss:0.0068825\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:57 PM |\t   72.7%:\t  W_train_loss:0.0088677\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:57 PM |\t  1e+02%:\t  W_train_loss:0.0072873\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:57 PM |\t  w_train_loss:0.09947325696703047,v_train_loss:0\n",
      "06/13 11:43:57 PM |\t  \n",
      "\n",
      "  ----------------epoch:80,\t\tlr_w:0.00016677181699666576,\t\tlr_v:0.00016677181699666576,\t\tlr_A:0.01----------------\n",
      "06/13 11:43:57 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:43:57 PM |\t   18.2%:\t  W_train_loss:0.0210295\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:58 PM |\t   45.5%:\t  W_train_loss:0.0094336\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:58 PM |\t   72.7%:\t  W_train_loss:0.0065947\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:59 PM |\t  1e+02%:\t  W_train_loss:0.0049275\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:59 PM |\t  w_train_loss:0.1259558571036905,v_train_loss:0\n",
      "06/13 11:43:59 PM |\t  \n",
      "\n",
      "  ----------------epoch:81,\t\tlr_w:0.00018530201888518417,\t\tlr_v:0.00018530201888518417,\t\tlr_A:0.01----------------\n",
      "06/13 11:43:59 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:43:59 PM |\t   18.2%:\t  W_train_loss:0.0047740\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:43:59 PM |\t   45.5%:\t  W_train_loss:0.0056078\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:00 PM |\t   72.7%:\t  W_train_loss:0.0036321\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:00 PM |\t  1e+02%:\t  W_train_loss:0.0044461\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:00 PM |\t  w_train_loss:0.05537989147705957,v_train_loss:0\n",
      "06/13 11:44:00 PM |\t  \n",
      "\n",
      "  ----------------epoch:82,\t\tlr_w:0.00018530201888518417,\t\tlr_v:0.00018530201888518417,\t\tlr_A:0.01----------------\n",
      "06/13 11:44:00 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:44:01 PM |\t   18.2%:\t  W_train_loss:0.0095659\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:01 PM |\t   45.5%:\t  W_train_loss:0.0089255\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:01 PM |\t   72.7%:\t  W_train_loss:0.0056192\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:02 PM |\t  1e+02%:\t  W_train_loss:0.0040682\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:02 PM |\t  w_train_loss:0.08453624788671732,v_train_loss:0\n",
      "06/13 11:44:02 PM |\t  \n",
      "\n",
      "  ----------------epoch:83,\t\tlr_w:0.00018530201888518417,\t\tlr_v:0.00018530201888518417,\t\tlr_A:0.01----------------\n",
      "06/13 11:44:02 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:44:02 PM |\t   18.2%:\t  W_train_loss:0.0064903\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:04 PM |\t  x_decoded[:2]:['translate English to German: A Republican strategy to counter the re-election of Obama', 'translate English to German: Republican leaders justified their policy by the need to combat electoral fraud.']\n",
      "06/13 11:44:04 PM |\t  pred_decoded[:2]:['Nach der Tagesordnung folgt die re-election von Herrn von der re-election der re-election der re-election von Herrn von der re-election der re-election der re-election der re-election', 'Das war der Beschluß.']\n",
      "06/13 11:44:04 PM |\t  label_decoded[:2]:['Eine republikanische Strategie, um der Wiederwahl von Obama entgegenzutreten', 'Die Führungskräfte der Republikaner rechtfertigen ihre Politik mit der Notwendigkeit, den Wahlbetrug zu bekämpfen.']\n",
      "06/13 11:44:09 PM |\t  computing score...\n",
      "06/13 11:44:09 PM |\t  model_w_in_main sacreBLEU : 0.417800\n",
      "06/13 11:44:09 PM |\t  model_w_in_main test loss : 10.433816\n",
      "06/13 11:44:10 PM |\t  x_decoded[:2]:['translate English to German: A Republican strategy to counter the re-election of Obama', 'translate English to German: Republican leaders justified their policy by the need to combat electoral fraud.']\n",
      "06/13 11:44:10 PM |\t  pred_decoded[:2]:['.', 'In a letter to the Associated Press, the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported']\n",
      "06/13 11:44:10 PM |\t  label_decoded[:2]:['Eine republikanische Strategie, um der Wiederwahl von Obama entgegenzutreten', 'Die Führungskräfte der Republikaner rechtfertigen ihre Politik mit der Notwendigkeit, den Wahlbetrug zu bekämpfen.']\n",
      "06/13 11:44:18 PM |\t  computing score...\n",
      "06/13 11:44:18 PM |\t  model_v_in_main sacreBLEU : 0.194037\n",
      "06/13 11:44:18 PM |\t  model_v_in_main test loss : 5.270808\n",
      "06/13 11:44:18 PM |\t  ('Attention Weights A : ', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>))\n",
      "06/13 11:44:19 PM |\t   45.5%:\t  W_train_loss:0.0084249\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:20 PM |\t   72.7%:\t  W_train_loss:0.0024454\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:20 PM |\t  1e+02%:\t  W_train_loss:0.0035188\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:20 PM |\t  w_train_loss:0.06263809627853334,v_train_loss:0\n",
      "06/13 11:44:20 PM |\t  \n",
      "\n",
      "  ----------------epoch:84,\t\tlr_w:0.00018530201888518417,\t\tlr_v:0.00018530201888518417,\t\tlr_A:0.01----------------\n",
      "06/13 11:44:20 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:44:21 PM |\t   18.2%:\t  W_train_loss:0.0190198\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:21 PM |\t   45.5%:\t  W_train_loss:0.0047578\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:21 PM |\t   72.7%:\t  W_train_loss:0.0028425\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:22 PM |\t  1e+02%:\t  W_train_loss:0.0038133\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:22 PM |\t  w_train_loss:0.09129997581476346,v_train_loss:0\n",
      "06/13 11:44:22 PM |\t  \n",
      "\n",
      "  ----------------epoch:85,\t\tlr_w:0.0001500946352969992,\t\tlr_v:0.0001500946352969992,\t\tlr_A:0.01----------------\n",
      "06/13 11:44:22 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:44:22 PM |\t   18.2%:\t  W_train_loss:0.0063439\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:23 PM |\t   45.5%:\t  W_train_loss:0.0089685\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:23 PM |\t   72.7%:\t  W_train_loss:0.0036137\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:23 PM |\t  1e+02%:\t  W_train_loss:0.0036677\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:23 PM |\t  w_train_loss:0.06778166315052658,v_train_loss:0\n",
      "06/13 11:44:23 PM |\t  \n",
      "\n",
      "  ----------------epoch:86,\t\tlr_w:0.00016677181699666576,\t\tlr_v:0.00016677181699666576,\t\tlr_A:0.01----------------\n",
      "06/13 11:44:23 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:44:24 PM |\t   18.2%:\t  W_train_loss:0.0123269\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:24 PM |\t   45.5%:\t  W_train_loss:0.0111500\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:24 PM |\t   72.7%:\t  W_train_loss:0.0031569\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:25 PM |\t  1e+02%:\t  W_train_loss:0.0017096\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:25 PM |\t  w_train_loss:0.08503030717838556,v_train_loss:0\n",
      "06/13 11:44:25 PM |\t  \n",
      "\n",
      "  ----------------epoch:87,\t\tlr_w:0.00016677181699666576,\t\tlr_v:0.00016677181699666576,\t\tlr_A:0.01----------------\n",
      "06/13 11:44:25 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:44:25 PM |\t   18.2%:\t  W_train_loss:0.0074550\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:26 PM |\t   45.5%:\t  W_train_loss:0.0113743\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:26 PM |\t   72.7%:\t  W_train_loss:0.0062566\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:26 PM |\t  1e+02%:\t  W_train_loss:0.0027783\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:26 PM |\t  w_train_loss:0.08359280286822468,v_train_loss:0\n",
      "06/13 11:44:26 PM |\t  \n",
      "\n",
      "  ----------------epoch:88,\t\tlr_w:0.00016677181699666576,\t\tlr_v:0.00016677181699666576,\t\tlr_A:0.01----------------\n",
      "06/13 11:44:26 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:44:27 PM |\t   18.2%:\t  W_train_loss:0.0032607\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:27 PM |\t   45.5%:\t  W_train_loss:0.0041664\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:27 PM |\t   72.7%:\t  W_train_loss:0.0045885\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:28 PM |\t  1e+02%:\t  W_train_loss:0.0080574\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:28 PM |\t  w_train_loss:0.06021886970847845,v_train_loss:0\n",
      "06/13 11:44:28 PM |\t  \n",
      "\n",
      "  ----------------epoch:89,\t\tlr_w:0.00016677181699666576,\t\tlr_v:0.00016677181699666576,\t\tlr_A:0.01----------------\n",
      "06/13 11:44:28 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:44:28 PM |\t   18.2%:\t  W_train_loss:0.0112947\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:29 PM |\t   45.5%:\t  W_train_loss:0.0039432\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:29 PM |\t   72.7%:\t  W_train_loss:0.0053367\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:29 PM |\t  1e+02%:\t  W_train_loss:0.0073353\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:29 PM |\t  w_train_loss:0.08372960105771199,v_train_loss:0\n",
      "06/13 11:44:29 PM |\t  \n",
      "\n",
      "  ----------------epoch:90,\t\tlr_w:0.0001350851717672993,\t\tlr_v:0.0001350851717672993,\t\tlr_A:0.01----------------\n",
      "06/13 11:44:29 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:44:30 PM |\t   18.2%:\t  W_train_loss:0.0100204\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:30 PM |\t   45.5%:\t  W_train_loss:0.0120612\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:30 PM |\t   72.7%:\t  W_train_loss:0.0101148\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:31 PM |\t  1e+02%:\t  W_train_loss:0.0051683\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:31 PM |\t  w_train_loss:0.11209393315948546,v_train_loss:0\n",
      "06/13 11:44:31 PM |\t  \n",
      "\n",
      "  ----------------epoch:91,\t\tlr_w:0.0001500946352969992,\t\tlr_v:0.0001500946352969992,\t\tlr_A:0.01----------------\n",
      "06/13 11:44:31 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:44:31 PM |\t   18.2%:\t  W_train_loss:0.0042069\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:32 PM |\t   45.5%:\t  W_train_loss:0.0124391\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:32 PM |\t   72.7%:\t  W_train_loss:0.0077703\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:32 PM |\t  1e+02%:\t  W_train_loss:0.0036601\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:32 PM |\t  w_train_loss:0.08422953344415873,v_train_loss:0\n",
      "06/13 11:44:32 PM |\t  \n",
      "\n",
      "  ----------------epoch:92,\t\tlr_w:0.0001500946352969992,\t\tlr_v:0.0001500946352969992,\t\tlr_A:0.01----------------\n",
      "06/13 11:44:32 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:44:33 PM |\t   18.2%:\t  W_train_loss:0.0127015\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:33 PM |\t   45.5%:\t  W_train_loss:0.0083633\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:34 PM |\t   72.7%:\t  W_train_loss:0.0207182\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:34 PM |\t  1e+02%:\t  W_train_loss:0.0077152\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:34 PM |\t  w_train_loss:0.14849458076059818,v_train_loss:0\n",
      "06/13 11:44:34 PM |\t  \n",
      "\n",
      "  ----------------epoch:93,\t\tlr_w:0.0001500946352969992,\t\tlr_v:0.0001500946352969992,\t\tlr_A:0.01----------------\n",
      "06/13 11:44:34 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:44:34 PM |\t   18.2%:\t  W_train_loss:0.0141431\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:35 PM |\t   45.5%:\t  W_train_loss:0.0028352\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:37 PM |\t  x_decoded[:2]:['translate English to German: A Republican strategy to counter the re-election of Obama', 'translate English to German: Republican leaders justified their policy by the need to combat electoral fraud.']\n",
      "06/13 11:44:37 PM |\t  pred_decoded[:2]:['Nach der Tagesordnung folgt die re-election von Herrn von der re-election der Präsidentin.', 'Das war der Beschluß.']\n",
      "06/13 11:44:37 PM |\t  label_decoded[:2]:['Eine republikanische Strategie, um der Wiederwahl von Obama entgegenzutreten', 'Die Führungskräfte der Republikaner rechtfertigen ihre Politik mit der Notwendigkeit, den Wahlbetrug zu bekämpfen.']\n",
      "06/13 11:44:42 PM |\t  computing score...\n",
      "06/13 11:44:42 PM |\t  model_w_in_main sacreBLEU : 0.289195\n",
      "06/13 11:44:42 PM |\t  model_w_in_main test loss : 10.491489\n",
      "06/13 11:44:44 PM |\t  x_decoded[:2]:['translate English to German: A Republican strategy to counter the re-election of Obama', 'translate English to German: Republican leaders justified their policy by the need to combat electoral fraud.']\n",
      "06/13 11:44:44 PM |\t  pred_decoded[:2]:['.', 'In a letter to the Associated Press, the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported']\n",
      "06/13 11:44:44 PM |\t  label_decoded[:2]:['Eine republikanische Strategie, um der Wiederwahl von Obama entgegenzutreten', 'Die Führungskräfte der Republikaner rechtfertigen ihre Politik mit der Notwendigkeit, den Wahlbetrug zu bekämpfen.']\n",
      "06/13 11:44:51 PM |\t  computing score...\n",
      "06/13 11:44:51 PM |\t  model_v_in_main sacreBLEU : 0.194037\n",
      "06/13 11:44:51 PM |\t  model_v_in_main test loss : 5.270808\n",
      "06/13 11:44:51 PM |\t  ('Attention Weights A : ', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>))\n",
      "06/13 11:44:53 PM |\t   72.7%:\t  W_train_loss:0.0102425\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:53 PM |\t  1e+02%:\t  W_train_loss:0.0035573\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:53 PM |\t  w_train_loss:0.0923342548776418,v_train_loss:0\n",
      "06/13 11:44:53 PM |\t  \n",
      "\n",
      "  ----------------epoch:94,\t\tlr_w:0.0001500946352969992,\t\tlr_v:0.0001500946352969992,\t\tlr_A:0.01----------------\n",
      "06/13 11:44:53 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:44:54 PM |\t   18.2%:\t  W_train_loss:0.0103234\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:54 PM |\t   45.5%:\t  W_train_loss:0.0148615\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:55 PM |\t   72.7%:\t  W_train_loss:0.0045470\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:55 PM |\t  1e+02%:\t  W_train_loss:0.0039276\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:55 PM |\t  w_train_loss:0.10097821350791492,v_train_loss:0\n",
      "06/13 11:44:55 PM |\t  \n",
      "\n",
      "  ----------------epoch:95,\t\tlr_w:0.00012157665459056936,\t\tlr_v:0.00012157665459056936,\t\tlr_A:0.01----------------\n",
      "06/13 11:44:55 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:44:55 PM |\t   18.2%:\t  W_train_loss:0.0068694\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:56 PM |\t   45.5%:\t  W_train_loss:0.0094401\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:56 PM |\t   72.7%:\t  W_train_loss:0.0079110\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:57 PM |\t  1e+02%:\t  W_train_loss:0.0057984\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:57 PM |\t  w_train_loss:0.09005677024833858,v_train_loss:0\n",
      "06/13 11:44:57 PM |\t  \n",
      "\n",
      "  ----------------epoch:96,\t\tlr_w:0.0001350851717672993,\t\tlr_v:0.0001350851717672993,\t\tlr_A:0.01----------------\n",
      "06/13 11:44:57 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:44:57 PM |\t   18.2%:\t  W_train_loss:0.0122084\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:57 PM |\t   45.5%:\t  W_train_loss:0.0041425\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:58 PM |\t   72.7%:\t  W_train_loss:0.0035665\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:58 PM |\t  1e+02%:\t  W_train_loss:0.0014061\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:58 PM |\t  w_train_loss:0.0639703109045513,v_train_loss:0\n",
      "06/13 11:44:58 PM |\t  \n",
      "\n",
      "  ----------------epoch:97,\t\tlr_w:0.0001350851717672993,\t\tlr_v:0.0001350851717672993,\t\tlr_A:0.01----------------\n",
      "06/13 11:44:58 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:44:59 PM |\t   18.2%:\t  W_train_loss:0.0145003\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:59 PM |\t   45.5%:\t  W_train_loss:0.0055946\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:44:59 PM |\t   72.7%:\t  W_train_loss:0.0017510\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:45:00 PM |\t  1e+02%:\t  W_train_loss:0.0033384\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:45:00 PM |\t  w_train_loss:0.07555270986631513,v_train_loss:0\n",
      "06/13 11:45:00 PM |\t  \n",
      "\n",
      "  ----------------epoch:98,\t\tlr_w:0.0001350851717672993,\t\tlr_v:0.0001350851717672993,\t\tlr_A:0.01----------------\n",
      "06/13 11:45:00 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:45:00 PM |\t   18.2%:\t  W_train_loss:0.0071150\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:45:00 PM |\t   45.5%:\t  W_train_loss:0.0057481\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:45:01 PM |\t   72.7%:\t  W_train_loss:0.0031282\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:45:01 PM |\t  1e+02%:\t  W_train_loss:0.0016853\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:45:01 PM |\t  w_train_loss:0.053029980044811964,v_train_loss:0\n",
      "06/13 11:45:01 PM |\t  \n",
      "\n",
      "  ----------------epoch:99,\t\tlr_w:0.0001350851717672993,\t\tlr_v:0.0001350851717672993,\t\tlr_A:0.01----------------\n",
      "06/13 11:45:01 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:45:02 PM |\t   18.2%:\t  W_train_loss:0.0087900\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:45:02 PM |\t   45.5%:\t  W_train_loss:0.0050727\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:45:02 PM |\t   72.7%:\t  W_train_loss:0.0040243\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:45:03 PM |\t  1e+02%:\t  W_train_loss:0.0056832\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:45:03 PM |\t  w_train_loss:0.07071068318327889,v_train_loss:0\n",
      "06/13 11:45:03 PM |\t  \n",
      "\n",
      "  ----------------epoch:100,\t\tlr_w:0.00010941898913151243,\t\tlr_v:0.00010941898913151243,\t\tlr_A:0.01----------------\n",
      "06/13 11:45:03 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:45:03 PM |\t   18.2%:\t  W_train_loss:0.0102309\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:45:04 PM |\t   45.5%:\t  W_train_loss:0.0054223\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:45:04 PM |\t   72.7%:\t  W_train_loss:0.0161710\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:45:04 PM |\t  1e+02%:\t  W_train_loss:0.0016361\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:45:04 PM |\t  w_train_loss:0.10038088558940217,v_train_loss:0\n",
      "06/13 11:45:04 PM |\t  \n",
      "\n",
      "  ----------------epoch:101,\t\tlr_w:0.00012157665459056936,\t\tlr_v:0.00012157665459056936,\t\tlr_A:0.01----------------\n",
      "06/13 11:45:04 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:45:05 PM |\t   18.2%:\t  W_train_loss:0.0049310\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:45:05 PM |\t   45.5%:\t  W_train_loss:0.0026442\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:45:05 PM |\t   72.7%:\t  W_train_loss:0.0019044\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:45:06 PM |\t  1e+02%:\t  W_train_loss:0.0019415\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:45:06 PM |\t  w_train_loss:0.03426321770530194,v_train_loss:0\n",
      "06/13 11:45:06 PM |\t  \n",
      "\n",
      "  ----------------epoch:102,\t\tlr_w:0.00012157665459056936,\t\tlr_v:0.00012157665459056936,\t\tlr_A:0.01----------------\n",
      "06/13 11:45:06 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:45:06 PM |\t   18.2%:\t  W_train_loss:0.0070713\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:45:07 PM |\t   45.5%:\t  W_train_loss:0.0079521\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:45:07 PM |\t   72.7%:\t  W_train_loss:0.0036576\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:45:07 PM |\t  1e+02%:\t  W_train_loss:0.0016544\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:45:07 PM |\t  w_train_loss:0.061006144038401544,v_train_loss:0\n",
      "06/13 11:45:07 PM |\t  \n",
      "\n",
      "  ----------------epoch:103,\t\tlr_w:0.00012157665459056936,\t\tlr_v:0.00012157665459056936,\t\tlr_A:0.01----------------\n",
      "06/13 11:45:07 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:45:08 PM |\t   18.2%:\t  W_train_loss:0.0092515\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:45:08 PM |\t   45.5%:\t  W_train_loss:0.0121809\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:45:09 PM |\t   72.7%:\t  W_train_loss:0.0032180\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:45:09 PM |\t  1e+02%:\t  W_train_loss:0.0031312\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:45:09 PM |\t  w_train_loss:0.08334476145682856,v_train_loss:0\n",
      "06/13 11:45:09 PM |\t  \n",
      "\n",
      "  ----------------epoch:104,\t\tlr_w:0.00012157665459056936,\t\tlr_v:0.00012157665459056936,\t\tlr_A:0.01----------------\n",
      "06/13 11:45:09 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:45:11 PM |\t  x_decoded[:2]:['translate English to German: A Republican strategy to counter the re-election of Obama', 'translate English to German: Republican leaders justified their policy by the need to combat electoral fraud.']\n",
      "06/13 11:45:11 PM |\t  pred_decoded[:2]:['Nach der Tagesordnung folgt die re-election von Herrn von der re-election der re-election der Obama re-election.', 'Das war der Beschluß.']\n",
      "06/13 11:45:11 PM |\t  label_decoded[:2]:['Eine republikanische Strategie, um der Wiederwahl von Obama entgegenzutreten', 'Die Führungskräfte der Republikaner rechtfertigen ihre Politik mit der Notwendigkeit, den Wahlbetrug zu bekämpfen.']\n",
      "06/13 11:45:16 PM |\t  computing score...\n",
      "06/13 11:45:16 PM |\t  model_w_in_main sacreBLEU : 0.314861\n",
      "06/13 11:45:16 PM |\t  model_w_in_main test loss : 10.448193\n",
      "06/13 11:45:18 PM |\t  x_decoded[:2]:['translate English to German: A Republican strategy to counter the re-election of Obama', 'translate English to German: Republican leaders justified their policy by the need to combat electoral fraud.']\n",
      "06/13 11:45:18 PM |\t  pred_decoded[:2]:['.', 'In a letter to the Associated Press, the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported that the Associated Press reported']\n",
      "06/13 11:45:18 PM |\t  label_decoded[:2]:['Eine republikanische Strategie, um der Wiederwahl von Obama entgegenzutreten', 'Die Führungskräfte der Republikaner rechtfertigen ihre Politik mit der Notwendigkeit, den Wahlbetrug zu bekämpfen.']\n",
      "06/13 11:45:26 PM |\t  computing score...\n",
      "06/13 11:45:26 PM |\t  model_v_in_main sacreBLEU : 0.194037\n",
      "06/13 11:45:26 PM |\t  model_v_in_main test loss : 5.270808\n",
      "06/13 11:45:26 PM |\t  ('Attention Weights A : ', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>))\n",
      "06/13 11:45:27 PM |\t   18.2%:\t  W_train_loss:0.0092863\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:45:28 PM |\t   45.5%:\t  W_train_loss:0.0039927\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:45:28 PM |\t   72.7%:\t  W_train_loss:0.0044355\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:45:29 PM |\t  1e+02%:\t  W_train_loss:0.0032380\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:45:29 PM |\t  w_train_loss:0.06285767850931734,v_train_loss:0\n",
      "06/13 11:45:29 PM |\t  \n",
      "\n",
      "  ----------------epoch:105,\t\tlr_w:9.847709021836118e-05,\t\tlr_v:9.847709021836118e-05,\t\tlr_A:0.01----------------\n",
      "06/13 11:45:29 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:45:29 PM |\t   18.2%:\t  W_train_loss:0.0037567\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:45:29 PM |\t   45.5%:\t  W_train_loss:0.0095098\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:45:30 PM |\t   72.7%:\t  W_train_loss:0.0026929\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:45:30 PM |\t  1e+02%:\t  W_train_loss:0.0133520\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:45:30 PM |\t  w_train_loss:0.08793415717082098,v_train_loss:0\n",
      "06/13 11:45:30 PM |\t  \n",
      "\n",
      "  ----------------epoch:106,\t\tlr_w:0.00010941898913151243,\t\tlr_v:0.00010941898913151243,\t\tlr_A:0.01----------------\n",
      "06/13 11:45:30 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:45:30 PM |\t   18.2%:\t  W_train_loss:0.0054607\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:45:31 PM |\t   45.5%:\t  W_train_loss:0.0065228\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:45:31 PM |\t   72.7%:\t  W_train_loss:0.0027176\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:45:32 PM |\t  1e+02%:\t  W_train_loss:0.0012882\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:45:32 PM |\t  w_train_loss:0.04796761478064582,v_train_loss:0\n",
      "06/13 11:45:32 PM |\t  \n",
      "\n",
      "  ----------------epoch:107,\t\tlr_w:0.00010941898913151243,\t\tlr_v:0.00010941898913151243,\t\tlr_A:0.01----------------\n",
      "06/13 11:45:32 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:45:32 PM |\t   18.2%:\t  W_train_loss:0.0046621\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:45:32 PM |\t   45.5%:\t  W_train_loss:0.0078464\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:45:33 PM |\t   72.7%:\t  W_train_loss:0.0067328\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:45:33 PM |\t  1e+02%:\t  W_train_loss:0.0018933\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:45:33 PM |\t  w_train_loss:0.06340378650929779,v_train_loss:0\n",
      "06/13 11:45:33 PM |\t  \n",
      "\n",
      "  ----------------epoch:108,\t\tlr_w:0.00010941898913151243,\t\tlr_v:0.00010941898913151243,\t\tlr_A:0.01----------------\n",
      "06/13 11:45:33 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:45:34 PM |\t   18.2%:\t  W_train_loss:0.0059996\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:45:34 PM |\t   45.5%:\t  W_train_loss:0.0017448\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:45:34 PM |\t   72.7%:\t  W_train_loss:0.0021274\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:45:35 PM |\t  1e+02%:\t  W_train_loss:0.0014449\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:45:35 PM |\t  w_train_loss:0.03395031136460602,v_train_loss:0\n",
      "06/13 11:45:35 PM |\t  \n",
      "\n",
      "  ----------------epoch:109,\t\tlr_w:0.00010941898913151243,\t\tlr_v:0.00010941898913151243,\t\tlr_A:0.01----------------\n",
      "06/13 11:45:35 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:45:35 PM |\t   18.2%:\t  W_train_loss:0.0034537\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:45:35 PM |\t   45.5%:\t  W_train_loss:0.0074059\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:45:36 PM |\t   72.7%:\t  W_train_loss:0.0058599\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:45:36 PM |\t  1e+02%:\t  W_train_loss:0.0025547\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:45:36 PM |\t  w_train_loss:0.0578225152567029,v_train_loss:0\n",
      "06/13 11:45:36 PM |\t  \n",
      "\n",
      "  ----------------epoch:110,\t\tlr_w:8.862938119652506e-05,\t\tlr_v:8.862938119652506e-05,\t\tlr_A:0.01----------------\n",
      "06/13 11:45:36 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:45:37 PM |\t   18.2%:\t  W_train_loss:0.0038185\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:45:37 PM |\t   45.5%:\t  W_train_loss:0.0056467\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:45:37 PM |\t   72.7%:\t  W_train_loss:0.0045886\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:45:38 PM |\t  1e+02%:\t  W_train_loss:0.0014255\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n",
      "06/13 11:45:38 PM |\t  w_train_loss:0.04643834161106497,v_train_loss:0\n",
      "06/13 11:45:38 PM |\t  \n",
      "\n",
      "  ----------------epoch:111,\t\tlr_w:9.847709021836118e-05,\t\tlr_v:9.847709021836118e-05,\t\tlr_A:0.01----------------\n",
      "06/13 11:45:38 PM |\t  split size:[4, 4, 4, 4]\n",
      "06/13 11:45:38 PM |\t   18.2%:\t  W_train_loss:0.0036005\tV_train_syn_loss:0.0000000\tV_train_loss:0.0000000\t  V_star_val_loss:0.0000000\t  V_val_loss:0.0000000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_115156/1114895497.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"\\n\\n  ----------------epoch:{epoch},\\t\\tlr_w:{lr_w},\\t\\tlr_v:{lr_v},\\t\\tlr_A:{args.A_lr}----------------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mw_train_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv_train_loss\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mmy_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_v\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0marchitect\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_optimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv_optimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr_w\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr_v\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtot_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mscheduler_w\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_115156/3616846423.py\u001b[0m in \u001b[0;36mmy_train\u001b[1;34m(epoch, _dataloader, validdataloader, w_model, v_model, architect, A, w_optimizer, v_optimizer, lr_w, lr_v, tot_iter)\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0mloss_w\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[0mobjs_w\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_w\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwsize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m         \u001b[0mw_optimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m         \u001b[1;31m# assert False\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\optim\\lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[1;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    131\u001b[0m                     \u001b[0mstate_steps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'step'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m             F.adam(params_with_grad,\n\u001b[0m\u001b[0;32m    134\u001b[0m                    \u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m                    \u001b[0mexp_avgs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\optim\\_functional.py\u001b[0m in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[1;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m         \u001b[0mexp_avg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m         \u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# if(args.valid_begin==1):\n",
    "#     my_test(valid_dataloader,model_w,-1) #before train\n",
    "#     my_test(valid_dataloader,model_v,-1)  \n",
    "\n",
    "tot_iter = [0]\n",
    "for epoch in range(args.epochs):\n",
    "    lr_w = scheduler_w.get_lr()[0]\n",
    "    lr_v = scheduler_v.get_lr()[0]\n",
    "    lr_A = scheduler_A.get_lr()[0]\n",
    "\n",
    "    logging.info(f\"\\n\\n  ----------------epoch:{epoch},\\t\\tlr_w:{lr_w},\\t\\tlr_v:{lr_v},\\t\\tlr_A:{args.A_lr}----------------\")\n",
    "\n",
    "    w_train_loss,v_train_loss =  my_train(epoch, train_dataloader, valid_dataloader, model_w, model_v,  architect, A, w_optimizer, v_optimizer, lr_w,lr_v,tot_iter)\n",
    "    \n",
    "    scheduler_w.step()\n",
    "    scheduler_v.step()\n",
    "    scheduler_A.step()\n",
    "\n",
    "\n",
    "    logging.info(f\"w_train_loss:{w_train_loss},v_train_loss:{v_train_loss}\")\n",
    "    # wandb.log({'w_train_loss': w_train_loss, 'v_train_loss':v_train_loss})\n",
    "\n",
    "\n",
    "\n",
    "torch.save(model_v,'./model/'+now+'model_w.pt')\n",
    "torch.save(model_v,'./model/'+now+'model_v.pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.6343e-03,  1.6985e-04,  4.6182e-05,  ..., -4.5622e-05,\n",
       "           4.9963e-05, -7.9150e-05],\n",
       "         [ 8.2149e-05, -4.7620e-05,  8.2381e-05,  ...,  8.6653e-05,\n",
       "           1.1960e-04,  3.4265e-06],\n",
       "         [ 5.5713e-06,  9.0648e-05, -3.2042e-05,  ..., -4.1399e-05,\n",
       "          -5.0304e-05, -9.8498e-05],\n",
       "         ...,\n",
       "         [ 1.6356e-03,  1.6731e-04,  4.5340e-05,  ..., -5.2783e-05,\n",
       "           4.2435e-05, -8.5164e-05],\n",
       "         [ 1.6356e-03,  1.6731e-04,  4.5343e-05,  ..., -5.2783e-05,\n",
       "           4.2434e-05, -8.5163e-05],\n",
       "         [ 1.6356e-03,  1.6731e-04,  4.5342e-05,  ..., -5.2784e-05,\n",
       "           4.2434e-05, -8.5163e-05]],\n",
       "\n",
       "        [[ 1.6345e-03,  1.6776e-04,  4.2936e-05,  ..., -4.4132e-05,\n",
       "           5.1346e-05, -7.9345e-05],\n",
       "         [-7.6601e-06, -3.0543e-05, -5.0514e-05,  ...,  1.1752e-05,\n",
       "          -1.2760e-04,  1.2106e-05],\n",
       "         [ 2.6243e-05, -3.8717e-05,  8.9031e-05,  ...,  4.1839e-05,\n",
       "          -1.4667e-05,  3.6620e-05],\n",
       "         ...,\n",
       "         [ 1.6364e-03,  1.7076e-04,  4.0118e-05,  ..., -4.6903e-05,\n",
       "           4.4114e-05, -8.4955e-05],\n",
       "         [ 1.6364e-03,  1.7077e-04,  4.0118e-05,  ..., -4.6904e-05,\n",
       "           4.4115e-05, -8.4954e-05],\n",
       "         [ 1.6364e-03,  1.7077e-04,  4.0116e-05,  ..., -4.6902e-05,\n",
       "           4.4116e-05, -8.4954e-05]],\n",
       "\n",
       "        [[ 1.6347e-03,  1.6664e-04,  4.3874e-05,  ..., -4.6535e-05,\n",
       "           5.1058e-05, -7.8006e-05],\n",
       "         [ 8.2920e-05, -5.1228e-05,  8.0187e-05,  ...,  8.5533e-05,\n",
       "           1.2085e-04,  4.4378e-06],\n",
       "         [-8.3324e-06, -6.6662e-05, -4.1717e-06,  ...,  8.9557e-05,\n",
       "           1.4526e-05,  7.6432e-05],\n",
       "         ...,\n",
       "         [ 1.6358e-03,  1.6664e-04,  4.4311e-05,  ..., -5.2517e-05,\n",
       "           4.4142e-05, -8.3808e-05],\n",
       "         [ 1.6358e-03,  1.6663e-04,  4.4312e-05,  ..., -5.2520e-05,\n",
       "           4.4142e-05, -8.3808e-05],\n",
       "         [ 1.6358e-03,  1.6663e-04,  4.4311e-05,  ..., -5.2518e-05,\n",
       "           4.4142e-05, -8.3806e-05]],\n",
       "\n",
       "        [[ 1.6357e-03,  1.6781e-04,  4.4269e-05,  ..., -4.4928e-05,\n",
       "           4.8897e-05, -7.9563e-05],\n",
       "         [ 1.3823e-04, -6.3264e-05,  6.3322e-05,  ..., -2.6144e-05,\n",
       "           5.9140e-05, -1.2902e-05],\n",
       "         [ 6.3026e-05,  5.7359e-05, -7.1889e-05,  ...,  9.2064e-06,\n",
       "          -2.3302e-06,  3.5582e-06],\n",
       "         ...,\n",
       "         [ 1.6376e-03,  1.6354e-04,  4.5136e-05,  ..., -5.1854e-05,\n",
       "           4.0205e-05, -8.6836e-05],\n",
       "         [ 1.6376e-03,  1.6354e-04,  4.5135e-05,  ..., -5.1851e-05,\n",
       "           4.0201e-05, -8.6841e-05],\n",
       "         [ 1.6376e-03,  1.6354e-04,  4.5136e-05,  ..., -5.1853e-05,\n",
       "           4.0202e-05, -8.6839e-05]]], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load('logits.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'main_v.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_175828/2885071301.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mm1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'main_v.pt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mm1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mm2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'unrolled_v.pt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mm2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'encoding'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 594\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    595\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m             \u001b[1;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'w'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'main_v.pt'"
     ]
    }
   ],
   "source": [
    "m1 = torch.load('main_v.pt')\n",
    "m1.eval()\n",
    "m2 = torch.load('unrolled_v.pt')\n",
    "m2.eval()\n",
    "''\n",
    "for k1, k2 in zip(m1.state_dict(), m2.state_dict()):\n",
    "    v1= m1.state_dict()[k1]\n",
    "    v2= m2.state_dict()[k2]\n",
    "    print(k1,k2)\n",
    "    # print(v1,v2)\n",
    "    print((abs(v1.data-v2.data)).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(1)\n",
    "a.add(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('python38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d33c3b0ef123e851f98887a8750ca7da758e4ff258891935cfe6ff9c0394387"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
