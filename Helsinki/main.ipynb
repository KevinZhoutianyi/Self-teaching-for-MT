{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd() \n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from Model import *\n",
    "from datasets import load_dataset\n",
    "from transformers import T5Tokenizer\n",
    "from MT_hyperparams import *\n",
    "import torch.backends.cudnn as cudnn\n",
    "from utils import *\n",
    "from attention_params import *\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, SubsetRandomSampler\n",
    "from torch.autograd import Variable\n",
    "from losses import *\n",
    "from architect import *\n",
    "import logging\n",
    "import sys\n",
    "import time\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, MBart50Tokenizer,MBartTokenizer\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoConfig\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/14 11:24:37 AM |\t  Reusing dataset opus_euconst (/home/li/.cache/huggingface/datasets/opus_euconst/en-fr/1.0.0/d1e611a011f28fdda67a97024820e0a3813b4e4decca194d9a20b3207a39b908)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f48202fd766b4aa092ad8e1ecba4949d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/14 11:24:37 AM |\t  DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 10104\n",
      "    })\n",
      "})\n",
      "01/14 11:24:37 AM |\t  {'translation': {'en': 'CONSIDERING that Article IV-437(2)(e) of the Constitution provides that the Treaty of 16 April 2003 concerning the accessions referred to above shall be repealed;  ', 'fr': \"CONSIDÉRANT que l'article\\xa0IV-437, paragraphe\\xa02, point\\xa0e), de la Constitution prévoit l'abrogation du traité du 16\\xa0avril 2003 relatif aux adhésions visées ci-dessus;  \"}}\n"
     ]
    }
   ],
   "source": [
    "now = time.strftime(\"%Y-%m-%d-%H_%M_%S\",time.localtime(time.time())) \n",
    "log_format = '%(asctime)s |\\t  %(message)s'\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO,\n",
    "    format=log_format, datefmt='%m/%d %I:%M:%S %p')\n",
    "fh = logging.FileHandler(os.path.join(\"./log/\", now+'.txt'))\n",
    "fh.setFormatter(logging.Formatter(log_format))\n",
    "logging.getLogger().addHandler(fh)\n",
    "dataset = load_dataset('opus_euconst','en-fr')\n",
    "logging.info(dataset)\n",
    "logging.info(dataset['train'][5])\n",
    "\n",
    "\n",
    "\n",
    "writer = SummaryWriter('tensorboard')\n",
    "\n",
    "# Setting the seeds\n",
    "np.random.seed(seed_)\n",
    "torch.cuda.set_device(1)\n",
    "cudnn.benchmark = True\n",
    "torch.manual_seed(seed_)\n",
    "cudnn.enabled=True\n",
    "torch.cuda.manual_seed(seed_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Helsinki-NLP/opus-mt-en-fr\"\n",
    "tokenizer_name = \"Helsinki-NLP/opus-mt-en-fr\"\n",
    "pretrained  =  AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "torch.save(pretrained,'HelsinkiBASE.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MarianMTModel(\n",
       "  (model): MarianModel(\n",
       "    (shared): Embedding(59514, 512, padding_idx=59513)\n",
       "    (encoder): MarianEncoder(\n",
       "      (embed_tokens): Embedding(59514, 512, padding_idx=59513)\n",
       "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
       "      (layers): ModuleList(\n",
       "        (0): MarianEncoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): MarianEncoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): MarianEncoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): MarianEncoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): MarianEncoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): MarianEncoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder): MarianDecoder(\n",
       "      (embed_tokens): Embedding(59514, 512, padding_idx=59513)\n",
       "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
       "      (layers): ModuleList(\n",
       "        (0): MarianDecoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): MarianDecoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): MarianDecoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): MarianDecoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): MarianDecoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): MarianDecoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=59514, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/14 11:24:48 AM |\t  Loading cached shuffled indices for dataset at /home/li/.cache/huggingface/datasets/opus_euconst/en-fr/1.0.0/d1e611a011f28fdda67a97024820e0a3813b4e4decca194d9a20b3207a39b908/cache-958ee3b3f04d6886.arrow\n",
      "01/14 11:24:49 AM |\t  train len: 1000\n",
      "01/14 11:24:49 AM |\t  valid len: 200\n",
      "01/14 11:24:49 AM |\t  test len: 500\n",
      "01/14 11:24:49 AM |\t  {'en': 'ASSOCIATION OF THE OVERSEAS COUNTRIES AND TERRITORIES  ', 'fr': \"L'ASSOCIATION DES PAYS ET TERRITOIRES D'OUTRE-MER  \"}\n"
     ]
    }
   ],
   "source": [
    "# Load the tokenizer.\n",
    "import random\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss( reduction='none')#ignore_index = tokenizer.pad_token_id,\n",
    "dataset = dataset.shuffle(seed=seed_)\n",
    "L = len(dataset['train'])\n",
    "L_t =train_num_points\n",
    "L_v =valid_num_points\n",
    "L_test = test_num_points\n",
    "\n",
    "\n",
    "train = dataset['train']['translation'][:L_t]\n",
    "valid = dataset['train']['translation'][L_t:L_t+L_v]\n",
    "test = dataset['train']['translation'][L_t+L_v:L_t+L_v+L_test]\n",
    "def preprocess(dat):\n",
    "    for t in dat:\n",
    "        t['en'] = '' + t['en']\n",
    "preprocess(train)\n",
    "preprocess(valid)\n",
    "preprocess(test)\n",
    "logging.info(\"train len: %d\",len(train))\n",
    "logging.info(\"valid len: %d\",len(valid))\n",
    "logging.info(\"test len: %d\" ,len(test))\n",
    "logging.info(train[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data = get_train_Dataset(train, tokenizer)# Create the DataLoader for our training set.\n",
    "train_dataloader = DataLoader(train_data, sampler=SequentialSampler(train_data), \n",
    "                        batch_size=batch_size, pin_memory=True, num_workers=0)\n",
    "valid_data = get_aux_dataset(valid, tokenizer)# Create the DataLoader for our training set.\n",
    "valid_dataloader = DataLoader(valid_data, sampler=SequentialSampler(valid_data), \n",
    "                        batch_size=batch_size, pin_memory=True, num_workers=0)\n",
    "test_data = get_aux_dataset(test, tokenizer)# Create the DataLoader for our training set.\n",
    "test_dataloader = DataLoader(test_data, sampler=SequentialSampler(test_data),\n",
    "                        batch_size=batch_size, pin_memory=True, num_workers=0)#, sampler=RandomSampler(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "A = attention_params(len(train)//2)#half of train regarded as u\n",
    "A = A.cuda()\n",
    "\n",
    "# TODO: model loaded from saved model\n",
    "model_w = Model(criterion=criterion, tokenizer= tokenizer, name = 'model_w_in_main')\n",
    "model_w = model_w.cuda()\n",
    "w_optimizer = torch.optim.SGD(model_w.parameters(),w_lr,momentum=momentum,weight_decay=decay)\n",
    "scheduler_w  = torch.optim.lr_scheduler.CosineAnnealingLR(w_optimizer, float(epochs), eta_min=learning_rate_min)\n",
    "\n",
    "\n",
    "\n",
    "model_v = Model(criterion=criterion, tokenizer= tokenizer, name = 'model_v_in_main')\n",
    "model_v = model_v.cuda()\n",
    "v_optimizer = torch.optim.SGD(model_v.parameters(),v_lr,momentum=momentum,weight_decay=decay)\n",
    "scheduler_v  = torch.optim.lr_scheduler.CosineAnnealingLR(v_optimizer, float(epochs), eta_min=learning_rate_min)\n",
    "\n",
    "\n",
    "\n",
    "architect = Architect(model_w, model_v,  A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad> Mon nom est Kevin<pad>', \"<pad> C'est mon nom.\"]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = ['my name is kevin','it is my nameit is']\n",
    "for index,i in enumerate(x) :\n",
    "    x[index] = '' + x[index]\n",
    "y= tokenize(x, tokenizer, max_length = summary_length)\n",
    "input = y[0].cuda()\n",
    "output  = model_v.generate(input,max_length=summary_length)\n",
    "tokenizer.batch_decode(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def my_test(test_dataloader,model,epoch):\n",
    "    acc = 0\n",
    "    counter = 0\n",
    "    model.eval()\n",
    "    for step, batch in enumerate(test_dataloader):\n",
    "        test_dataloaderx = Variable(batch[0], requires_grad=False).cuda()\n",
    "        n = test_dataloaderx.size(0)   \n",
    "        test_dataloaderx_attn = Variable(batch[1], requires_grad=False).cuda()\n",
    "        test_dataloadery = Variable(batch[2], requires_grad=False).cuda()\n",
    "        test_dataloadery_attn = Variable(batch[3], requires_grad=False).cuda()\n",
    "        # logging.info(f\"{model.name}\")\n",
    "        # logging.info(f\"test: x {test_dataloaderx}\")\n",
    "        # logging.info(f\"test: y {test_dataloadery}\")\n",
    "        # logging.info(f\"generate:{model.generate(test_dataloaderx)}\")\n",
    "        ls = my_loss(test_dataloaderx,test_dataloaderx_attn,test_dataloadery,test_dataloadery_attn,model)\n",
    "        \n",
    "        # logging.info(f\"loss:{ls}\")\n",
    "        acc+= ls\n",
    "        counter+= 1\n",
    "    \n",
    "    logging.info('%s test loss : %f',model.name,acc/(counter*n))\n",
    "    writer.add_scalar(\"MT/\"+model.name+\"test_loss\", acc/counter, global_step=epoch)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_train(epoch, train_dataloader, valid_dataloader, w_model, v_model, architect, A, w_optimizer, v_optimizer, lr_w, lr_v, ):\n",
    "    v_trainloss_acc = 0\n",
    "    w_trainloss_acc = 0\n",
    "    counter = 0\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        counter+=1\n",
    "        # logging.info(\" \\t\\t Step count: %d\",step)\n",
    "        \n",
    "        batch_loss_w, batch_loss_v,  batch_count = 0, 0, 0\n",
    "        input_w = Variable(batch[0], requires_grad=False).cuda()\n",
    "        input_w_attn = Variable(batch[1], requires_grad=False).cuda()\n",
    "        output_w = Variable(batch[2], requires_grad=False).cuda()\n",
    "        output_w_attn = Variable(batch[3], requires_grad=False).cuda()        \n",
    "        input_v = Variable(batch[4], requires_grad=False).cuda()\n",
    "        input_v_attn = Variable(batch[5], requires_grad=False).cuda()      \n",
    "        attn_idx = Variable(batch[6], requires_grad=False).cuda()\n",
    "        \n",
    "        \n",
    "        valid_batch = next(iter(valid_dataloader))\n",
    "        valid_input_v      = Variable(valid_batch[0], requires_grad=False).cuda()\n",
    "        valid_input_v_attn = Variable(valid_batch[1], requires_grad=False).cuda()\n",
    "        valid_out_v      = Variable(valid_batch[2], requires_grad=False).cuda()\n",
    "        valid_out_v_attn = Variable(valid_batch[3], requires_grad=False).cuda()\n",
    "        \n",
    "\n",
    "        if epoch <= epochs:\n",
    "            architect.step(input_w,  output_w,input_w_attn, output_w_attn, w_optimizer, input_v, input_v_attn,valid_input_v, valid_input_v_attn, valid_out_v, \n",
    "                valid_out_v_attn, v_optimizer, attn_idx, lr_w, lr_v)\n",
    "\n",
    "        if epoch <=epochs:\n",
    "            \n",
    "            w_optimizer.zero_grad()\n",
    "            loss_w = CTG_loss(input_w, input_w_attn, output_w, output_w_attn, attn_idx, A, w_model)\n",
    "            # logging.info(f\"loss_w (train):{loss_w}\")\n",
    "            batch_loss_w += loss_w.item()\n",
    "            loss_w.backward()\n",
    "            nn.utils.clip_grad_norm(w_model.parameters(), grad_clip)\n",
    "            w_optimizer.step()\n",
    "\n",
    "\n",
    "            v_optimizer.zero_grad()\n",
    "            loss_aug = calc_loss_aug(input_v, input_v_attn, w_model, v_model)\n",
    "            v_loss =  (loss_aug)\n",
    "            # logging.info(f\"v_loss (train):{v_loss}\")\n",
    "            batch_loss_v += v_loss.item()\n",
    "            v_loss.backward()\n",
    "            nn.utils.clip_grad_norm(v_model.parameters(), grad_clip)\n",
    "            v_optimizer.step()     \n",
    "                \n",
    "            v_trainloss_acc+=v_loss.item()\n",
    "            w_trainloss_acc+=loss_w.item()\n",
    "        if(step*batch_size%5==0):\n",
    "            logging.info(f\"{step*batch_size*100/(train_num_points//2)}%\")\n",
    "    \n",
    "    logging.info(str((\"Attention Weights A : \", A.alpha)))\n",
    "    return w_trainloss_acc,v_trainloss_acc/(counter*batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/14 12:31:07 PM |\t  model_w_in_main test loss : 6.314329\n",
      "01/14 12:31:10 PM |\t  model_v_in_main test loss : 6.314329\n",
      "01/14 12:31:10 PM |\t  \n",
      "\n",
      "  ----------------epoch:0,\t\tlr_w:0.001,\t\tlr_v:0.0001----------------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Only Tensors of floating point and complex dtype can require gradients",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8673/2545072791.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n\\n  ----------------epoch:{epoch},\\t\\tlr_w:{lr_w},\\t\\tlr_v:{lr_v}----------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mw_train_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv_train_loss\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mmy_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_v\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0marchitect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_w\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mscheduler_w\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_8673/3886736090.py\u001b[0m in \u001b[0;36mmy_train\u001b[0;34m(epoch, train_dataloader, valid_dataloader, w_model, v_model, architect, A, w_optimizer, v_optimizer, lr_w, lr_v)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mbatch_loss_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_loss_v\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mbatch_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0minput_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0minput_w_attn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moutput_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Only Tensors of floating point and complex dtype can require gradients"
     ]
    }
   ],
   "source": [
    "\n",
    "my_test(test_dataloader,model_w,-1) \n",
    "my_test(test_dataloader,model_v,-1)  \n",
    "for epoch in range(epochs):\n",
    "\n",
    "    lr_w = scheduler_w.get_lr()[0]\n",
    "    lr_v = scheduler_v.get_lr()[0]\n",
    "\n",
    "    logging.info(f\"\\n\\n  ----------------epoch:{epoch},\\t\\tlr_w:{lr_w},\\t\\tlr_v:{lr_v}----------------\")\n",
    "\n",
    "    w_train_loss,v_train_loss =  my_train(epoch, train_dataloader, valid_dataloader, model_w, model_v,  architect, A, w_optimizer, v_optimizer, lr_w,lr_v)\n",
    "    \n",
    "    scheduler_w.step()\n",
    "    scheduler_v.step()\n",
    "\n",
    "    writer.add_scalar(\"MT/w_trainloss\", w_train_loss, global_step=epoch)\n",
    "    writer.add_scalar(\"MT/v_trainloss\", v_train_loss, global_step=epoch)\n",
    "\n",
    "    logging.info(f\"w_train_loss:{w_train_loss},v_train_loss:{v_train_loss}\")\n",
    "\n",
    "    \n",
    "    my_test(test_dataloader,model_w,epoch) \n",
    "    my_test(test_dataloader,model_v,epoch)  \n",
    "\n",
    "    torch.save(model_v,'model_v.pt')\n",
    "     \n",
    "   \n",
    "   \n",
    "        \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decodizer(x,y,g,loss):\n",
    "    print(\"x\")\n",
    "    print(tokenizer.decode(x))\n",
    "    print(\"y\")\n",
    "    print(tokenizer.decode(y))\n",
    "    print(\"g\")\n",
    "    print(tokenizer.decode(g))\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decodizer([13959,  1566,    12,  2379,    10,  1570,     8,   262,   188,  3073,\n",
    "         16494,    63,     8,  1657,     3,   184,  4663,   226,  9457,   117,\n",
    "          2243,    13,  6923,     3,   184,  4663,   226,  8584,   117,  1522,\n",
    "            36,  5821,    57,     3,   184,  4663,   226,  9457,   117,  2243,\n",
    "            13,  6923,    13,     8,  1611,  3545,     3,   184,  4663,   226,\n",
    "          8584,   117,     3,     5,     1,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0],[ 3039,    90, 10152,   154,   205,  5080,   188,     6,   110,     3,\n",
    "         25814,     3,   184,  4663,   226,  1206,  5359,   117, 13579,    20,\n",
    "          4831,     3,   184,  4663,   226,  1206,  7640,   117,   527, 31522,\n",
    "             7,   260,   110,     3, 25814,     3,   184,  4663,   226,  1206,\n",
    "          5359,   117, 13579,    20,  4831,    20,     3,    40,    31, 19011,\n",
    "         15851,     3,   184,  4663,   226,  1206,  7640,   117,     3,     5,\n",
    "             1,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],[    0,     0, 32099,     8,     8,     3,     3,     6,     6,     3,\n",
    "            20,    20,   374,   374,    20,    93,    93,   146,   146,   970,\n",
    "           970,   146,    20,   247,   247,  3039,  3039,   247,  4692,  4692,\n",
    "         15648, 15648,  4679,  4679, 15648, 15591, 15591, 14976, 14976, 15591,\n",
    "          2435,  2435,   597,   597,  2435,   245,   245,    73,    73,   245,\n",
    "           444,   444,   202,   202,  7443,  7443,  4417,  4417,  7443, 13227,\n",
    "         13227, 11151, 11151,  3523,  3523, 10711, 10711, 12580, 12580, 16816,\n",
    "         16816,  5718,  5718,  3570,  3570,  3939,  3939, 14126, 14126,  3939,\n",
    "          3570,  9026,  9026, 20883, 20883,  6252,  6252, 10562, 10562,     5,\n",
    "             5,     1],16.631591796875)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode( [13959,  1566,    12,  2379,    10,  2962, 18901,     7,    13,     8,\n",
    "           423,  2243,  1522,    36,  3982,   163,     3,    99, 17310, 12330,\n",
    "             7,    33,  3823,     5,     1,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode([    0,   622, 15172,     7,    20,    50, 13579,  4752,   154, 19134,\n",
    "             3,    29,    15,   527,     3,  2165,   179,     7,   238,   108,\n",
    "           285,    29,   776, 21399,     7, 21442,    29,    17,     5,     1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode([    0,   622, 15172,     7,    20,    50, 13579,  4752,   154, 19134,\n",
    "             3,    29,    15,   527,     3,  2165,   179,     7,   238,   108,\n",
    "           285,    29,   776, 21399,     7, 21442,    29,    17,     5,     1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode([13959,  1566,    12,  2379,    10,  2266,     1,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode([ 4738,   288,  3908,    20,    50,  1419, 23650,    20,    50,  6919,\n",
    "            20,  2209,  9424,  5672,    20,    50,   377,   154,  3764,  2661,\n",
    "            20, 30342,   247,    90,  2625,    15,    20,     3,    40,    31,\n",
    "           154,    40,  8240,  9343,    20,     3,    40,    31, 19011,   117,\n",
    "             1,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode([    0,  7762,    23,  3764,  3569,    50,  1419, 23650,    20,    50,\n",
    "          6919,    20,  2209,  9424,  5672,   247,    50,   377,   154,  3764,\n",
    "          2661,    20, 30342,   247,    90,  2625,    15,    20,     3,    40,\n",
    "            31,   154,    40,  8240,  9343,    20,  7421,    18,    75,    23,\n",
    "           117,     1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode([0,  6206,  6667,    27,     1])\n",
    "tokenizer.decode([13959,  1566,    12,  2379,    10, 17608,   994,    27,     1,     0])\n",
    "logging.info(\"vocab size : %d\",model_v.vocab_size)\n",
    "logit = torch.load('logits.pt')\n",
    "target = torch.load('target_ids.pt')\n",
    "tokenizer.decode(target[0])\n",
    "logit.shape\n",
    "_,maxx = torch.max(logit,dim=-1,keepdim=True)\n",
    "maxx.shape\n",
    "tokenizer.decode(maxx[0].squeeze(-1))\n",
    "\n",
    "model_v.embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.alpha.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode([13959,  1566,    12,  2379,    10,   634,     3,  2685, 10140,    29,\n",
    "            30,  5178,    16,     8,  2509,    18,  2206,  8557,    13,     8,\n",
    "          1611,  1290,  1582,  1208,  2149,     3,  4822,    12,    16,  7491,\n",
    "          6289,    18, 24151, 14296,   599,    75,    61,    13,     8, 11378,\n",
    "          1522,  1243,    24,     8,  8541,  1015,  4376,    65, 13841,     8,\n",
    "          1389, 23460,   257,  6346,     7,   937,    21,    57,     8,  2509,\n",
    "            18,  2206,  8557,    13,     8,  1611,  1290,  1582,  1208,  2149,\n",
    "           406,  5274,  7012,     7,    21,    44,   709,     8,   336,   192,\n",
    "           203,   274,     8,  6498,     5,     1,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0])\n",
    "tokenizer.decode([    0,   312,     3, 12563,  2970,    20,  5178,   185,     3, 28874,\n",
    "            20,   483,   146,  4870,  1911,   154,  5785, 18779,  4642,   154,\n",
    "             3,    85,     3,    40,    31,  8372,  6289,    18, 24151,     6,\n",
    "          8986,    15,  1914,   500,     3,    75,   201,    20,    50, 11378,\n",
    "             6, 16558,   238,    90,  3277, 13924,  2410,   154,  1445,    15,\n",
    "           110,  3157,  2897,  1389,    15,     7,    20, 23460,   257,     3,\n",
    "         25796,     7,   260,    90, 17100,    20,  1112,   146,  5224,     7,\n",
    "            17,  5843,  2963,   154,  2046,  6274,  2430,  3890,    35,  1532,\n",
    "          7012,     7,     3,     7,   154,   208, 12449,  4530,   185,  3000,\n",
    "           110,  1763,  6062,     7,  5228,  2811,    75,   154,    26,   288,\n",
    "            90, 10418,     5,     1])\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "65768f95ed3f1ad80799466926a66640b39a99ef5d94bbece814e59aa067606e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('python38': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
